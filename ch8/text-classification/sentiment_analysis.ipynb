{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ”§ **Setup Required**: Before running this notebook, please follow the [setup instructions](../../README.md#setup-instructions) to configure your environment and API keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Sentiment Analysis Pipeline with Custom Components\n",
    "\n",
    "Welcome to this comprehensive tutorial on building a sentiment analysis pipeline using Haystack with custom components! This notebook demonstrates how to create a sophisticated system that fetches business reviews from the Yelp API and performs sentiment analysis using transformer models.\n",
    "\n",
    "## What you'll learn\n",
    "\n",
    "After completing this notebook, you will be able to:\n",
    "- Build custom Haystack components that integrate with external APIs\n",
    "- Implement sentiment analysis using transformer-based models\n",
    "- Create robust data processing pipelines for real-world applications\n",
    "- Handle API authentication and data extraction patterns\n",
    "- Combine multiple processing steps in a reusable component\n",
    "- Structure Haystack pipelines with custom business logic\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "Before we begin, let's understand some core concepts:\n",
    "- **Custom Components**: Extend Haystack functionality with domain-specific logic\n",
    "- **API Integration**: Fetch external data within pipeline workflows\n",
    "- **Sentiment Analysis**: Classify text as positive, negative, or neutral using ML models\n",
    "- **Component Composition**: Build complex pipelines from modular, reusable parts\n",
    "- **Document Metadata**: Enrich documents with additional context and analysis results\n",
    "\n",
    "\n",
    "Let's dive in and build our sentiment analysis pipeline step by step!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load environment variables\n",
    "\n",
    "We'll be working with the Yelp Reviews API https://rapidapi.com/beat-analytics-beat-analytics-default/api/yelp-business-reviews\n",
    "\n",
    "Ensure to obtain a key and store it in your `.venv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "# We begin by loading environment variables (such as API keys) from a `.env` file.\n",
    "# This keeps sensitive information secure and out of the codebase.\n",
    "\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "# Retrieve the RapidAPI key for Yelp Business Reviews API\n",
    "RAPID_API_KEY = os.getenv(\"RAPID_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sentiment Analysis Model Setup\n",
    "\n",
    "We'll use Haystack's `TransformersTextRouter` component with a pre-trained sentiment analysis model:\n",
    "\n",
    "- **Model**: `cardiffnlp/twitter-roberta-base-sentiment`\n",
    "- **Architecture**: RoBERTa (Robustly optimized BERT approach)\n",
    "- **Training Data**: Twitter posts (ideal for short-form social media text)\n",
    "- **Output Classes**: \n",
    "  - LABEL_0: Negative sentiment\n",
    "  - LABEL_1: Neutral sentiment  \n",
    "  - LABEL_2: Positive sentiment\n",
    "\n",
    "The `warm_up()` method loads the model into memory, ensuring fast inference when processing reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "## 2. Initialize Sentiment Analysis Model\n",
    "\n",
    "# We'll use a pre-trained sentiment analysis model from Hugging Face\n",
    "# This model is based on RoBERTa and trained on Twitter data\n",
    "# It classifies text into three categories: negative, neutral, and positive\n",
    "\n",
    "from haystack.components.routers import TransformersTextRouter\n",
    "\n",
    "# Initialize the sentiment analysis router with a pre-trained model\n",
    "text_router = TransformersTextRouter(model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "# Warm up the model to load it into memory for faster inference\n",
    "text_router.warm_up()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anatomy of Our Custom Components\n",
    "\n",
    "### Core Concepts\n",
    "\n",
    "Following Haystack best practices, we'll build **three separate components** instead of one monolithic component:\n",
    "\n",
    "1. **YelpReviewFetcher**: Fetches reviews from the API and creates Documents\n",
    "2. **TransformersTextRouter**: Routes each review text based on sentiment classification (built-in Haystack component)\n",
    "3. **SentimentDocumentEnricher**: Enriches documents with human-readable sentiment labels\n",
    "\n",
    "\n",
    "### Pipeline Architecture\n",
    "\n",
    "```\n",
    "Input (API credentials + params)\n",
    "    â†“\n",
    "YelpReviewFetcher\n",
    "    â†“\n",
    "Documents (with rating, url)\n",
    "    â†“\n",
    "[Loop through each document]\n",
    "    â†“\n",
    "TransformersTextRouter (sentiment classification)\n",
    "    â”œâ”€â†’ LABEL_0 (negative) â†’ SentimentDocumentEnricher\n",
    "    â”œâ”€â†’ LABEL_1 (neutral)  â†’ SentimentDocumentEnricher  \n",
    "    â””â”€â†’ LABEL_2 (positive) â†’ SentimentDocumentEnricher\n",
    "           â†“\n",
    "Output: Documents with {rating, url, sentiment}\n",
    "```\n",
    "\n",
    "### Component Details\n",
    "\n",
    "**1. YelpReviewFetcher**\n",
    "- **Input**: url, headers, querystring\n",
    "- **Processing**: Makes API call, extracts review data\n",
    "- **Output**: List[Document] with metadata (rating, url)\n",
    "\n",
    "**2. TransformersTextRouter** (Haystack built-in)\n",
    "- **Input**: text (string)\n",
    "- **Processing**: Classifies text into sentiment labels\n",
    "- **Output**: Routes to label-specific sockets (LABEL_0, LABEL_1, LABEL_2)\n",
    "\n",
    "**3. SentimentDocumentEnricher**\n",
    "- **Input**: text (from router), original document\n",
    "- **Processing**: Maps label to human-readable sentiment\n",
    "- **Output**: Document with added sentiment metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Implementing the Custom Components\n",
    "\n",
    "# Import necessary classes from Haystack\n",
    "from haystack import component, Document\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "# ============================================================================\n",
    "# Component 1: YelpReviewFetcher\n",
    "# ============================================================================\n",
    "\n",
    "@component\n",
    "class YelpReviewFetcher:\n",
    "    \"\"\"\n",
    "    Fetches business reviews from the Yelp API via RapidAPI and converts them\n",
    "    into Haystack Document objects with metadata.\n",
    "    \n",
    "    This component handles API integration and data extraction, creating Documents\n",
    "    that can be processed by downstream components.\n",
    "    \n",
    "    Input Sockets:\n",
    "        - url (str): The Yelp API endpoint URL\n",
    "        - headers (Dict): Request headers including API authentication\n",
    "        - querystring (Dict): Query parameters for filtering/sorting reviews\n",
    "    \n",
    "    Output Sockets:\n",
    "        - documents (List[Document]): Reviews as Document objects with rating and URL metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the YelpReviewFetcher component.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @component.output_types(documents=List[Document])\n",
    "    def run(self, url: str, headers: Dict, querystring: Dict) -> Dict[str, List[Document]]:\n",
    "        \"\"\"\n",
    "        Fetch reviews from the Yelp API and convert them to Documents.\n",
    "        \n",
    "        Args:\n",
    "            url (str): Yelp API URL endpoint for business reviews\n",
    "            headers (Dict): Request headers containing API authentication\n",
    "            querystring (Dict): Query parameters (e.g., sortBy, limit)\n",
    "        \n",
    "        Returns:\n",
    "            Dict[str, List[Document]]: Dictionary with 'documents' key containing\n",
    "                                       list of review Documents with metadata\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Make the API request\n",
    "            response = requests.get(url, headers=headers, params=querystring)\n",
    "            \n",
    "            # Parse JSON response\n",
    "            results = response.json()\n",
    "            \n",
    "            # Create Document objects for each review\n",
    "            documents = []\n",
    "            for i, review_data in enumerate(results['reviews']):\n",
    "                doc = Document(\n",
    "                    content=review_data['text'],\n",
    "                    meta={\n",
    "                        \"rating\": review_data['rating'],\n",
    "                        \"url\": review_data['url'],\n",
    "                        \"review_id\": i\n",
    "                    }\n",
    "                )\n",
    "                documents.append(doc)\n",
    "            \n",
    "            return {\"documents\": documents}\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Return empty list on error to prevent pipeline failure\n",
    "            print(f\"Error fetching reviews: {e}\")\n",
    "            return {\"documents\": []}\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Component 2: SentimentDocumentEnricher  \n",
    "# ============================================================================\n",
    "\n",
    "@component\n",
    "class SentimentDocumentEnricher:\n",
    "    \"\"\"\n",
    "    Enriches documents with sentiment labels based on TransformersTextRouter output.\n",
    "    \n",
    "    This component receives text that has been routed through a sentiment classifier\n",
    "    and adds a human-readable sentiment label to the document metadata.\n",
    "    \n",
    "    Input Sockets:\n",
    "        - text (str): The review text (routed from TransformersTextRouter)\n",
    "        - documents (List[Document]): Original documents to enrich\n",
    "        - label (str): The sentiment label from the router\n",
    "    \n",
    "    Output Sockets:\n",
    "        - documents (List[Document]): Documents enriched with sentiment metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the SentimentDocumentEnricher component.\"\"\"\n",
    "        # Mapping from model labels to human-readable sentiment\n",
    "        self.sentiment_mapping = {\n",
    "            \"LABEL_0\": \"negative\",\n",
    "            \"LABEL_1\": \"neutral\",\n",
    "            \"LABEL_2\": \"positive\"\n",
    "        }\n",
    "    \n",
    "    @component.output_types(documents=List[Document])\n",
    "    def run(self, text: str, documents: List[Document], label: str) -> Dict[str, List[Document]]:\n",
    "        \"\"\"\n",
    "        Enrich documents with sentiment labels.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The review text that was classified\n",
    "            documents (List[Document]): Original documents from YelpReviewFetcher\n",
    "            label (str): The classification label (LABEL_0, LABEL_1, or LABEL_2)\n",
    "        \n",
    "        Returns:\n",
    "            Dict[str, List[Document]]: Dictionary with 'documents' key containing\n",
    "                                       enriched documents with sentiment metadata\n",
    "        \"\"\"\n",
    "        enriched_documents = []\n",
    "        \n",
    "        # Find matching document by text content\n",
    "        for doc in documents:\n",
    "            if doc.content == text:\n",
    "                # Create new document with enriched metadata\n",
    "                enriched_doc = Document(\n",
    "                    content=doc.content,\n",
    "                    meta={\n",
    "                        **doc.meta,  # Keep existing metadata (rating, url)\n",
    "                        \"sentiment\": self.sentiment_mapping.get(label, \"unknown\")\n",
    "                    }\n",
    "                )\n",
    "                enriched_documents.append(enriched_doc)\n",
    "        \n",
    "        return {\"documents\": enriched_documents}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stand-alone usage\n",
    "\n",
    "\n",
    "We'll test the review fetcher with lowest-rated reviews to ensure it correctly extracts data from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- YelpReviewFetcher Results ---\n",
      "Fetched 10 reviews\n",
      "\n",
      "Sample Document:\n",
      "  Content: Went in on a Tuesday for lunch. Wasn't overly busy,  cheese curds were great however.... Server didn...\n",
      "  Metadata: {'rating': 1, 'url': 'https://www.yelp.com/biz/RJNAeNA-209sctUO0dmwuA?hrid=pkO8UmZLWRI5Qfx0lJVRaQ', 'review_id': 0}\n"
     ]
    }
   ],
   "source": [
    "# --- Test YelpReviewFetcher Component ---\n",
    "\n",
    "# Define the API endpoint for a specific business\n",
    "url = \"https://yelp-business-reviews.p.rapidapi.com/reviews/RJNAeNA-209sctUO0dmwuA\"\n",
    "\n",
    "# Query parameters to sort by lowest rated reviews\n",
    "querystring = {\"sortBy\": \"lowestRated\"}\n",
    "\n",
    "# Set up headers with API authentication\n",
    "headers = {\n",
    "    \"x-rapidapi-key\": RAPID_API_KEY,\n",
    "    \"x-rapidapi-host\": \"yelp-business-reviews.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "# Instantiate and test the YelpReviewFetcher component\n",
    "review_fetcher = YelpReviewFetcher()\n",
    "fetcher_result = review_fetcher.run(url=url, headers=headers, querystring=querystring)\n",
    "\n",
    "print(\"--- YelpReviewFetcher Results ---\")\n",
    "print(f\"Fetched {len(fetcher_result['documents'])} reviews\\n\")\n",
    "\n",
    "# Display first review\n",
    "if fetcher_result['documents']:\n",
    "    first_doc = fetcher_result['documents'][0]\n",
    "    print(f\"Sample Document:\")\n",
    "    print(f\"  Content: {first_doc.content[:100]}...\")\n",
    "    print(f\"  Metadata: {first_doc.meta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contains the rating and content. We will apply the `TransformersTextRouter` to the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TransformersTextRouter Test ---\n",
      "Testing with text: Went in on a Tuesday for lunch. Wasn't overly busy,  cheese curds were great however.... Server didn...\n",
      "\n",
      "Router output: {'LABEL_2': \"Went in on a Tuesday for lunch. Wasn't overly busy,  cheese curds were great however.... Server didn't really check in on us and although the kids got their food the adults didn't. The server never thought of checking to see where the food was.\"}\n",
      "Detected label: LABEL_2\n"
     ]
    }
   ],
   "source": [
    "### Test 2: TransformersTextRouter Component\n",
    "\n",
    "# Test the sentiment router on a sample review\n",
    "if fetcher_result['documents']:\n",
    "    sample_text = fetcher_result['documents'][0].content\n",
    "    \n",
    "    print(\"\\n--- TransformersTextRouter Test ---\")\n",
    "    print(f\"Testing with text: {sample_text[:100]}...\")\n",
    "    \n",
    "    # Run the router\n",
    "    router_result = text_router.run(text=sample_text)\n",
    "    \n",
    "    print(f\"\\nRouter output: {router_result}\")\n",
    "    print(f\"Detected label: {list(router_result.keys())[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Building the Sentiment Analysis Pipeline\n",
    "\n",
    "Now let's integrate our custom components with the built-in `TransformersTextRouter` into a proper Haystack pipeline.\n",
    "\n",
    "### Challenge: Routing Multiple Documents\n",
    "\n",
    "The `TransformersTextRouter` processes **one text string at a time**, but our `YelpReviewFetcher` returns **multiple documents**. To handle this, we'll use a custom component to batch process (for production)\n",
    "\n",
    "### Pipeline Architecture for Single Review\n",
    "\n",
    "```\n",
    "YelpReviewFetcher â†’ documents\n",
    "         â†“\n",
    "[Select one document]\n",
    "         â†“\n",
    "TransformersTextRouter (text from document)\n",
    "    â”œâ”€â†’ LABEL_0 â†’ SentimentDocumentEnricher(negative)\n",
    "    â”œâ”€â†’ LABEL_1 â†’ SentimentDocumentEnricher(neutral)\n",
    "    â””â”€â†’ LABEL_2 â†’ SentimentDocumentEnricher(positive)\n",
    "         â†“\n",
    "Output: Document with sentiment\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchSentimentProcessor initialized and ready\n"
     ]
    }
   ],
   "source": [
    "@component\n",
    "class BatchSentimentProcessor:\n",
    "    \"\"\"\n",
    "    Processes multiple documents through sentiment analysis in batch.\n",
    "    \n",
    "    This component demonstrates how to wrap TransformersTextRouter functionality\n",
    "    for batch processing within a pipeline.\n",
    "    \n",
    "    Input Sockets:\n",
    "        - documents (List[Document]): Documents to analyze\n",
    "    \n",
    "    Output Sockets:\n",
    "        - documents (List[Document]): Documents enriched with sentiment metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = \"cardiffnlp/twitter-roberta-base-sentiment\"):\n",
    "        \"\"\"\n",
    "        Initialize the batch sentiment processor.\n",
    "        \n",
    "        Args:\n",
    "            model: Hugging Face model for sentiment classification\n",
    "        \"\"\"\n",
    "        self.router = TransformersTextRouter(model=model)\n",
    "        self.sentiment_mapping = {\n",
    "            \"LABEL_0\": \"negative\",\n",
    "            \"LABEL_1\": \"neutral\",\n",
    "            \"LABEL_2\": \"positive\"\n",
    "        }\n",
    "    \n",
    "    def warm_up(self):\n",
    "        \"\"\"Warm up the underlying transformer model.\"\"\"\n",
    "        self.router.warm_up()\n",
    "    \n",
    "    @component.output_types(documents=List[Document])\n",
    "    def run(self, documents: List[Document]) -> Dict[str, List[Document]]:\n",
    "        \"\"\"\n",
    "        Process documents through sentiment analysis.\n",
    "        \n",
    "        Args:\n",
    "            documents: List of documents to analyze\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with 'documents' key containing enriched documents\n",
    "        \"\"\"\n",
    "        enriched_docs = []\n",
    "        \n",
    "        for doc in documents:\n",
    "            # Classify the document content\n",
    "            router_result = self.router.run(text=doc.content)\n",
    "            label = list(router_result.keys())[0]\n",
    "            sentiment = self.sentiment_mapping.get(label, \"unknown\")\n",
    "            \n",
    "            # Create enriched document\n",
    "            enriched_doc = Document(\n",
    "                content=doc.content,\n",
    "                meta={\n",
    "                    **doc.meta,\n",
    "                    \"sentiment\": sentiment\n",
    "                }\n",
    "            )\n",
    "            enriched_docs.append(enriched_doc)\n",
    "        \n",
    "        return {\"documents\": enriched_docs}\n",
    "\n",
    "\n",
    "# Initialize and warm up the batch processor\n",
    "batch_processor = BatchSentimentProcessor()\n",
    "batch_processor.warm_up()\n",
    "\n",
    "print(\"BatchSentimentProcessor initialized and ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Building a Batching Sentiment Analysis Pipeline (Production Pattern)\n",
    "\n",
    "For production use, we create a **batch processing component** that handles multiple documents efficiently. This demonstrates the recommended pattern for integrating `TransformersTextRouter` into larger workflows.\n",
    "\n",
    "### Why Batch Processing?\n",
    "\n",
    "The `TransformersTextRouter` is designed to classify **one text at a time** and route it to different pipeline branches based on the classification label. However, when processing multiple documents:\n",
    "  \n",
    "- **Pipeline Approach**: Wrap router in a batch component (shown below)\n",
    "  - âœ… Can be serialized and deployed\n",
    "  - âœ… Follows best practices\n",
    "  - âœ… Scalable and maintainable\n",
    "\n",
    "### BatchSentimentProcessor Component\n",
    "\n",
    "This component demonstrates how to integrate `TransformersTextRouter` into a pipeline-friendly component that processes multiple documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline structure:\n",
      "<haystack.core.pipeline.pipeline.Pipeline object at 0x13f544b00>\n",
      "ðŸš… Components\n",
      "  - review_fetcher: YelpReviewFetcher\n",
      "  - sentiment_processor: BatchSentimentProcessor\n",
      "ðŸ›¤ï¸ Connections\n",
      "  - review_fetcher.documents -> sentiment_processor.documents (List[Document])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_fetcher = YelpReviewFetcher()\n",
    "batch_processor = BatchSentimentProcessor()\n",
    "# Build the sentiment analysis pipeline\n",
    "sentiment_pipeline = Pipeline()\n",
    "\n",
    "# Add components\n",
    "sentiment_pipeline.add_component(\"review_fetcher\", review_fetcher)\n",
    "sentiment_pipeline.add_component(\"sentiment_processor\", batch_processor)\n",
    "\n",
    "# Connect components: review_fetcher outputs -> sentiment_processor inputs\n",
    "sentiment_pipeline.connect(\"review_fetcher.documents\", \"sentiment_processor.documents\")\n",
    "\n",
    "print(\"Pipeline structure:\")\n",
    "print(sentiment_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Component Connections\n",
    "\n",
    "The pipeline connects components through their input/output sockets:\n",
    "\n",
    "**Component 1: YelpReviewFetcher**\n",
    "- **Inputs**: url, headers, querystring (provided at pipeline run time)\n",
    "- **Outputs**: `documents` socket â†’ List[Document] with metadata {rating, url}\n",
    "\n",
    "**Component 2: BatchSentimentProcessor**  \n",
    "- **Inputs**: `documents` socket (connected to YelpReviewFetcher output)\n",
    "- **Processing**: Uses TransformersTextRouter internally for each document\n",
    "- **Outputs**: `documents` socket â†’ List[Document] with metadata {rating, url, sentiment}\n",
    "\n",
    "The connection is made with:\n",
    "```python\n",
    "pipeline.connect(\"review_fetcher.documents\", \"sentiment_processor.documents\")\n",
    "```\n",
    "\n",
    "This means: \"Take the `documents` output from `review_fetcher` and pass it as the `documents` input to `sentiment_processor`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pipeline.draw(path=\"./images/sentiment_pipeline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/sentiment_pipeline.png)\n",
    "\n",
    "The pipeline diagram shows the two-component architecture:\n",
    "1. **review_fetcher** (YelpReviewFetcher): Fetches reviews from API\n",
    "2. **sentiment_processor** (BatchSentimentProcessor): Analyzes sentiment using TransformersTextRouter\n",
    "\n",
    "Documents flow from left to right, getting enriched with sentiment metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Sentiment Analysis Pipeline ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n",
      "/Users/laurafunderburk/Documents/GitHub/Building-Natural-Language-Pipelines/ch8/.venv/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 reviews with sentiment analysis\n",
      "\n",
      "--- Sample Results ---\n",
      "\n",
      "--- Review 1 ---\n",
      "Rating: 5/5\n",
      "Sentiment: positive\n",
      "Review: Food 5/5\n",
      "Service 4.5/5\n",
      "Ambiance 4.5/5\n",
      "\n",
      "A Wisconsin staple at this point, The Old Fashioned does pub food (and even some brunch) well. The cheese curds...\n",
      "URL: https://www.yelp.com/biz/RJNAeNA-209sctUO0dmwuA?hrid=-AHOyDmPRahLrNXnXYS0PA\n",
      "\n",
      "--- Review 2 ---\n",
      "Rating: 5/5\n",
      "Sentiment: positive\n",
      "Review: Came to Old Fashion on a mission to finally try their famous cheese curds and a Spotted Cow on tap (because when in Wisconsin, right?). The cheese cur...\n",
      "URL: https://www.yelp.com/biz/RJNAeNA-209sctUO0dmwuA?hrid=wwE2C7-nNV8v7aGwTso4Ug\n",
      "\n",
      "--- Review 3 ---\n",
      "Rating: 5/5\n",
      "Sentiment: positive\n",
      "Review: Very good and recommend for people who are visiting. We come from south Texas and looked up the reviews here and they were spot on. We got the chicken...\n",
      "URL: https://www.yelp.com/biz/RJNAeNA-209sctUO0dmwuA?hrid=UXwgu5Ez3eAjQY10Hd10nw\n"
     ]
    }
   ],
   "source": [
    "# Prepare the input data for the pipeline\n",
    "# The key 'review_fetcher' matches the component name we used\n",
    "pipeline_input = {\n",
    "    \"review_fetcher\": {\n",
    "        \"url\": url,\n",
    "        \"headers\": headers,\n",
    "        \"querystring\": {\"sortBy\": \"highestRated\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Execute the pipeline\n",
    "print(\"--- Running Sentiment Analysis Pipeline ---\\n\")\n",
    "pipeline_result = sentiment_pipeline.run(pipeline_input)\n",
    "\n",
    "# Extract the enriched documents from the pipeline output\n",
    "enriched_reviews = pipeline_result['sentiment_processor']['documents']\n",
    "\n",
    "# Display results\n",
    "print(f\"Processed {len(enriched_reviews)} reviews with sentiment analysis\\n\")\n",
    "print(\"--- Sample Results ---\")\n",
    "\n",
    "for i, doc in enumerate(enriched_reviews[:3]):  # Show first 3\n",
    "    print(f\"\\n--- Review {i+1} ---\")\n",
    "    print(f\"Rating: {doc.meta['rating']}/5\")\n",
    "    print(f\"Sentiment: {doc.meta['sentiment']}\")\n",
    "    print(f\"Review: {doc.content[:150]}...\")\n",
    "    print(f\"URL: {doc.meta['url']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Next Steps\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "Congratulations! You've successfully built a modular sentiment analysis pipeline using Haystack's component architecture. You've learned:\n",
    "\n",
    "âœ… **Modular Component Design**: How to build focused, single-responsibility components  \n",
    "âœ… **Component Integration**: Connecting custom components with built-in Haystack components (TransformersTextRouter)  \n",
    "âœ… **API Integration**: Techniques for fetching external data within pipeline workflows  \n",
    "âœ… **Sentiment Analysis**: Applying transformer models for text classification  \n",
    "âœ… **Document Metadata**: Enriching documents with analysis results and contextual information  \n",
    "âœ… **Pipeline Construction**: Building, connecting, visualizing, and executing Haystack pipelines  \n",
    "âœ… **Batch Processing**: Handling multiple documents efficiently in production-ready patterns\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Separation of Concerns**: Breaking functionality into discrete components improves reusability and testability\n",
    "2. **Component Composition**: Haystack's power comes from connecting small, focused components\n",
    "3. **Built-in Components**: Leverage existing Haystack components (like TransformersTextRouter) rather than reimplementing\n",
    "4. **Type Annotations**: Explicit input/output types enable pipeline validation and clear contracts\n",
    "5. **Batch vs. Stream**: Consider whether to process items individually or in batches based on your use case\n",
    "6. **Metadata Enrichment**: Store analysis results in document metadata for downstream processing\n",
    "\n",
    "### Extension Ideas\n",
    "\n",
    "Want to take this further? Try these enhancements:\n",
    "\n",
    "1. **Multi-Component Pipeline Extensions**  \n",
    "   - Add a `DocumentWriter` to save enriched reviews to a document store\n",
    "   - Include a `PromptBuilder` and `OpenAIGenerator` to generate sentiment summaries\n",
    "   - Add a `ConditionalRouter` to route reviews by sentiment (positive/negative/neutral)\n",
    "   - Use `DocumentJoiner` to merge reviews from multiple businesses\n",
    "\n",
    "2. **Enhanced Analysis**  \n",
    "   - Extract keywords using NER (Named Entity Recognition)\n",
    "   - Compute aggregate sentiment scores per business\n",
    "   - Compare sentiment vs. numeric ratings to detect discrepancies\n",
    "   - Track sentiment trends over time\n",
    "   - Identify topics using topic modeling\n",
    "\n",
    "3. **Data Processing Improvements**  \n",
    "   - Add `DocumentCleaner` to normalize review text\n",
    "   - Implement `DocumentSplitter` for very long reviews\n",
    "   - Create embeddings with `SentenceTransformersDocumentEmbedder` for semantic search\n",
    "   - Filter spam or low-quality reviews\n",
    "\n",
    "4. **Production Readiness**  \n",
    "   - Add rate limiting for API calls (use `time.sleep()` or a rate limiter component)\n",
    "   - Implement caching to avoid redundant API requests\n",
    "   - Add comprehensive error handling and logging\n",
    "   - Create unit tests for each custom component\n",
    "   - Add retry logic for failed API calls\n",
    "   - Monitor component performance metrics\n",
    "\n",
    "5. **Different Data Sources**  \n",
    "   - Adapt YelpReviewFetcher for other review platforms (Amazon, Google Reviews, TripAdvisor)\n",
    "   - Process social media posts (Twitter/X, Reddit, Instagram)\n",
    "   - Analyze customer support tickets\n",
    "   - Monitor product feedback from multiple sources\n",
    "\n",
    "6. **Advanced Sentiment Analysis**\n",
    "   - Use more sophisticated models (BERT, RoBERTa-large, domain-specific models)\n",
    "   - Implement aspect-based sentiment analysis (sentiment per product feature)\n",
    "   - Add emotion detection (happy, sad, angry, etc.)\n",
    "   - Calculate sentiment intensity/confidence scores\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-with-haystack-ch8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
