{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "open_ai_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurafunderburk/Documents/GitHub/Building-Natural-Language-Pipelines/venvs/dev/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.components.generators.utils import print_streaming_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build indexing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline, Document\n",
    "from haystack_integrations.document_stores.elasticsearch import ElasticsearchDocumentStore\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "import pandas as pd\n",
    "from haystack.components.preprocessors import DocumentCleaner\n",
    "from haystack.document_stores.types import DuplicatePolicy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Budget to set scene for election\\n \\n Gordon B...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Army chiefs in regiments decision\\n \\n Militar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Howard denies split over ID cards\\n \\n Michael...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Observers to monitor UK election\\n \\n Minister...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kilroy names election seat target\\n \\n Ex-chat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  Budget to set scene for election\\n \\n Gordon B...      0\n",
       "1  Army chiefs in regiments decision\\n \\n Militar...      0\n",
       "2  Howard denies split over ID cards\\n \\n Michael...      0\n",
       "3  Observers to monitor UK election\\n \\n Minister...      0\n",
       "4  Kilroy names election seat target\\n \\n Ex-chat...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"df_file.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_news = df['Text'].to_list()\n",
    "\n",
    "documents = [Document(id=str(i), content=list_of_news[i]) for i in range(len(list_of_news))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x1530973b0>\n",
       "🚅 Components\n",
       "  - doc_embedder: SentenceTransformersDocumentEmbedder\n",
       "  - doc_cleaner: DocumentCleaner\n",
       "  - doc_writer: DocumentWriter\n",
       "🛤️ Connections\n",
       "  - doc_embedder.documents -> doc_writer.documents (List[Document])\n",
       "  - doc_cleaner.documents -> doc_embedder.documents (List[Document])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "document_store = ElasticsearchDocumentStore(hosts = \"http://localhost:9200\",\n",
    "                                            embedding_similarity_function='cosine')\n",
    "\n",
    "embedder = SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "document_cleaner = DocumentCleaner(\n",
    "                                remove_empty_lines=True,\n",
    "                                remove_extra_whitespaces=True,\n",
    "                                remove_repeated_substrings=True,\n",
    "                                remove_substrings=['\\n']\n",
    "                            )\n",
    "document_writer = DocumentWriter(document_store=document_store,\n",
    "                                 policy=DuplicatePolicy.OVERWRITE )\n",
    "\n",
    "indexing_pipeline = Pipeline()\n",
    "indexing_pipeline.add_component(instance=embedder, name=\"doc_embedder\")\n",
    "indexing_pipeline.add_component(instance=document_cleaner, name='doc_cleaner')\n",
    "indexing_pipeline.add_component(instance=document_writer, name=\"doc_writer\")\n",
    "\n",
    "indexing_pipeline.connect(\"doc_cleaner.documents\", \"doc_embedder.documents\")\n",
    "indexing_pipeline.connect(\"doc_embedder.documents\", \"doc_writer.documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 70/70 [01:08<00:00,  1.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'doc_writer': {'documents_written': 2225}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run pipeline\n",
    "indexing_pipeline.run({\"doc_cleaner\": {\"documents\": documents}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack_integrations.components.retrievers.elasticsearch import ElasticsearchEmbeddingRetriever\n",
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x1532b3050>\n",
       "🚅 Components\n",
       "  - embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: ElasticsearchEmbeddingRetriever\n",
       "  - prompt_builder: ChatPromptBuilder\n",
       "  - llm: OpenAIChatGenerator\n",
       "🛤️ Connections\n",
       "  - embedder.embedding -> retriever.query_embedding (List[float])\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.messages (List[ChatMessage])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = [ChatMessage.from_system(\"\"\"\n",
    "Answer the questions based on the given context.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "Question: {{ question }}\n",
    "Answer:\n",
    "\"\"\")]\n",
    "query_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "query_retriever = ElasticsearchEmbeddingRetriever(document_store=document_store)\n",
    "prompt_builder = ChatPromptBuilder(template=template)\n",
    "llm = OpenAIChatGenerator(model=\"gpt-4o-mini\")\n",
    "rag_pipe = Pipeline()\n",
    "rag_pipe.add_component(instance= query_embedder, name = \"embedder\" )\n",
    "rag_pipe.add_component(instance=query_retriever, name=\"retriever\")\n",
    "rag_pipe.add_component(instance=prompt_builder, name=\"prompt_builder\")\n",
    "rag_pipe.add_component(instance=llm, name=\"llm\" )\n",
    "\n",
    "rag_pipe.connect(\"embedder.embedding\", \"retriever.query_embedding\")\n",
    "rag_pipe.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "rag_pipe.connect(\"prompt_builder.prompt\", \"llm.messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline_func(query: str):\n",
    "    result = rag_pipe.run({\"embedder\": {\"text\": query}, \"prompt_builder\": {\"question\": query}})\n",
    "\n",
    "    return {\"reply\": result[\"llm\"][\"replies\"][0].content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"rag_pipeline_func\",\n",
    "            \"description\": \"Get information about where people live\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The query to use in the search. Infer this from the user's message. It should be a question or a statement\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.components.generators.utils import print_streaming_chunk\n",
    "\n",
    "messages = [\n",
    "    ChatMessage.from_system(\n",
    "        \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"\n",
    "    ),\n",
    "    ChatMessage.from_user(\"Summarize news about Scottland\"),\n",
    "]\n",
    "\n",
    "chat_generator = OpenAIChatGenerator(model=\"gpt-4o-mini\", streaming_callback=print_streaming_chunk)\n",
    "response = chat_generator.run(messages=messages, generation_kwargs={\"tools\": tools})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Name: rag_pipeline_func\n",
      "Function Arguments: {'query': 'latest news about Scotland'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 34.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Response: {'reply': \"The latest news about Scotland includes the introduction of a comprehensive smoking ban in public places, which will be enforced by Spring 2006. This ban aims to improve Scotland's health rates and reduce preventable deaths caused by smoking. Additionally, the Scottish Environment Protection Agency has warned that climate change could be uncontrollable within decades, leading to discussions about nuclear energy and wind farms as potential solutions. The Scottish Parliament is also considering options regarding super-casinos, with a decision expected soon on whether to allow Westminster to legislate on the matter. Furthermore, there is an ongoing campaign against plans to merge the Scottish regiments, with a group targeting several key marginal Labour seats in the upcoming general election. Lastly, Euan Murray has returned to the Scotland training squad for the Six Nations after completing an eight-week ban.\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "## Parse function calling information\n",
    "function_call = json.loads(response[\"replies\"][0].text)[0]\n",
    "function_name = function_call[\"function\"][\"name\"]\n",
    "function_args = json.loads(function_call[\"function\"][\"arguments\"])\n",
    "print(\"Function Name:\", function_name)\n",
    "print(\"Function Arguments:\", function_args)\n",
    "\n",
    "## Find the correspoding function and call it with the given arguments\n",
    "available_functions = {\"rag_pipeline_func\": rag_pipeline_func}\n",
    "function_to_call = available_functions[function_name]\n",
    "function_response = function_to_call(**function_args)\n",
    "print(\"Function Response:\", function_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP pipelines",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
