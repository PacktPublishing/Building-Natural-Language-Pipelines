{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ad8fc67",
   "metadata": {},
   "source": [
    "# Pipeline 5: Interactive User Clarification\n",
    "\n",
    "## Overview\n",
    "This notebook implements an interactive Haystack pipeline that asks clarifying questions to help identify a user's LOCATION and KEY WORDS for business searches. It uses conversational AI to extract precise search parameters through natural dialogue.\n",
    "\n",
    "## What This Pipeline Does\n",
    "1. Engages in conversation with the user\n",
    "2. Asks targeted clarifying questions about location and preferences\n",
    "3. Extracts location and keywords from user responses\n",
    "4. Validates and confirms extracted information\n",
    "5. Returns structured search parameters ready for Pipeline 1\n",
    "\n",
    "## Use Cases\n",
    "- Interactive business search refinement\n",
    "- Ambiguous query clarification\n",
    "- User preference extraction\n",
    "- Conversational search interface\n",
    "\n",
    "## Pipeline Architecture\n",
    "```\n",
    "Initial Query ‚Üí Question Generator ‚Üí User Response ‚Üí Information Extractor ‚Üí Validation ‚Üí Final Parameters\n",
    "```\n",
    "\n",
    "## Integration Points\n",
    "- **Input**: Vague or incomplete user queries\n",
    "- **Output**: Location and keywords for Pipeline 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587da26",
   "metadata": {},
   "source": [
    "## Setup and Environment Variables\n",
    "\n",
    "Ensure your `.env` file contains:\n",
    "```\n",
    "OPENAI_API_KEY=your_openai_key_here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b319800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from haystack import Pipeline, component, Document\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from typing import List, Dict, Any, Optional\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(\".env\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"‚úì Environment variables loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3183d1f",
   "metadata": {},
   "source": [
    "## Prompt Templates for Interactive Dialogue\n",
    "\n",
    "Define prompt templates for asking clarifying questions and extracting information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb680355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template for generating clarifying questions\n",
    "CLARIFICATION_QUESTIONS_TEMPLATE = \"\"\"\n",
    "You are a helpful assistant helping users find businesses on Yelp.\n",
    "\n",
    "User's Initial Query: {{ user_query }}\n",
    "\n",
    "Current Information Extracted:\n",
    "- Location: {{ location if location else \"NOT SPECIFIED\" }}\n",
    "- Keywords: {{ keywords if keywords else \"NOT SPECIFIED\" }}\n",
    "\n",
    "Your task: Generate 1-2 specific, friendly clarifying questions to help identify:\n",
    "1. A specific LOCATION (city, neighborhood, or area) if not already clear\n",
    "2. KEY WORDS describing what type of business or specific preferences if vague\n",
    "\n",
    "Rules:\n",
    "- If location is missing or vague, prioritize asking for location first\n",
    "- If keywords are vague (e.g., \"food\", \"restaurant\"), ask for more specifics (cuisine type, atmosphere, etc.)\n",
    "- Keep questions natural and conversational\n",
    "- Don't ask questions if information is already clear\n",
    "- If both location and keywords are clear, respond with \"READY\" and summarize what you understand\n",
    "\n",
    "Format: Just provide the questions naturally, one per line. Or respond with \"READY: [summary]\" if no more questions needed.\n",
    "\"\"\"\n",
    "\n",
    "# Prompt template for extracting information from user responses\n",
    "INFORMATION_EXTRACTION_TEMPLATE = \"\"\"\n",
    "You are an information extraction assistant.\n",
    "\n",
    "Conversation History:\n",
    "{{ conversation_history }}\n",
    "\n",
    "Latest User Response: {{ user_response }}\n",
    "\n",
    "Task: Extract structured information from the user's response:\n",
    "1. LOCATION: Any city, neighborhood, or geographic area mentioned\n",
    "2. KEYWORDS: Business types, cuisine, features, or preferences mentioned\n",
    "\n",
    "Previous Extracted Info:\n",
    "- Location: {{ current_location if current_location else \"None\" }}\n",
    "- Keywords: {{ current_keywords if current_keywords else \"None\" }}\n",
    "\n",
    "Rules:\n",
    "- Update location ONLY if user mentions a new or more specific location\n",
    "- Add new keywords without removing previous ones unless contradicted\n",
    "- Return empty if nothing new is mentioned\n",
    "- Be conservative - only extract clear, explicit mentions\n",
    "\n",
    "Return a JSON object with this exact format:\n",
    "{\n",
    "  \"location\": \"extracted location or empty string\",\n",
    "  \"keywords\": [\"keyword1\", \"keyword2\"],\n",
    "  \"confidence\": \"high/medium/low\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚úì Prompt templates defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ab06a8",
   "metadata": {},
   "source": [
    "## Custom Component 1: Clarifying Question Generator\n",
    "\n",
    "This component generates targeted questions to extract missing information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "class ClarifyingQuestionGenerator:\n",
    "    \"\"\"\n",
    "    Generates clarifying questions based on current information state.\n",
    "    \n",
    "    This component:\n",
    "    1. Analyzes what information is missing (location, keywords)\n",
    "    2. Generates natural, targeted questions\n",
    "    3. Determines if enough information has been collected\n",
    "    \n",
    "    Input:\n",
    "        - user_query (str): Initial or current user query\n",
    "        - location (Optional[str]): Currently extracted location\n",
    "        - keywords (Optional[List[str]]): Currently extracted keywords\n",
    "    \n",
    "    Output:\n",
    "        - questions (str): Clarifying questions or READY signal\n",
    "        - is_ready (bool): Whether we have enough information\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"\n",
    "        Initialize the question generator.\n",
    "        \n",
    "        Args:\n",
    "            api_key: OpenAI API key\n",
    "        \"\"\"\n",
    "        self.prompt_builder = PromptBuilder(template=CLARIFICATION_QUESTIONS_TEMPLATE)\n",
    "        self.generator = OpenAIGenerator(\n",
    "            api_key=api_key,\n",
    "            model=\"gpt-4o-mini\",\n",
    "            generation_kwargs={\"temperature\": 0.7}\n",
    "        )\n",
    "    \n",
    "    @component.output_types(questions=str, is_ready=bool)\n",
    "    def run(\n",
    "        self,\n",
    "        user_query: str,\n",
    "        location: Optional[str] = \"\",\n",
    "        keywords: Optional[List[str]] = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate clarifying questions.\n",
    "        \n",
    "        Args:\n",
    "            user_query: User's query or latest response\n",
    "            location: Currently extracted location\n",
    "            keywords: Currently extracted keywords\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with questions and ready status\n",
    "        \"\"\"\n",
    "        keywords = keywords or []\n",
    "        \n",
    "        # Build prompt\n",
    "        prompt_result = self.prompt_builder.run(\n",
    "            user_query=user_query,\n",
    "            location=location,\n",
    "            keywords=\", \".join(keywords) if keywords else \"\"\n",
    "        )\n",
    "        \n",
    "        # Generate questions\n",
    "        llm_result = self.generator.run(prompt=prompt_result['prompt'])\n",
    "        response = llm_result['replies'][0] if llm_result['replies'] else \"\"\n",
    "        \n",
    "        # Check if ready\n",
    "        is_ready = response.startswith(\"READY\")\n",
    "        \n",
    "        return {\n",
    "            \"questions\": response,\n",
    "            \"is_ready\": is_ready\n",
    "        }\n",
    "\n",
    "print(\"‚úì ClarifyingQuestionGenerator component defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5920a1c",
   "metadata": {},
   "source": [
    "## Custom Component 2: Information Extractor\n",
    "\n",
    "This component extracts location and keywords from user responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f7dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "class InformationExtractor:\n",
    "    \"\"\"\n",
    "    Extracts location and keywords from user responses.\n",
    "    \n",
    "    This component:\n",
    "    1. Analyzes user responses for location mentions\n",
    "    2. Identifies business-related keywords and preferences\n",
    "    3. Updates extracted information incrementally\n",
    "    4. Returns structured data with confidence scores\n",
    "    \n",
    "    Input:\n",
    "        - user_response (str): User's response to questions\n",
    "        - conversation_history (str): Previous conversation context\n",
    "        - current_location (Optional[str]): Previously extracted location\n",
    "        - current_keywords (Optional[List[str]]): Previously extracted keywords\n",
    "    \n",
    "    Output:\n",
    "        - location (str): Updated location\n",
    "        - keywords (List[str]): Updated keywords\n",
    "        - confidence (str): Confidence level (high/medium/low)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"\n",
    "        Initialize the information extractor.\n",
    "        \n",
    "        Args:\n",
    "            api_key: OpenAI API key\n",
    "        \"\"\"\n",
    "        self.prompt_builder = PromptBuilder(template=INFORMATION_EXTRACTION_TEMPLATE)\n",
    "        self.generator = OpenAIGenerator(\n",
    "            api_key=api_key,\n",
    "            model=\"gpt-4o-mini\",\n",
    "            generation_kwargs={\"temperature\": 0.3}  # Lower temp for more consistent extraction\n",
    "        )\n",
    "    \n",
    "    @component.output_types(location=str, keywords=List[str], confidence=str)\n",
    "    def run(\n",
    "        self,\n",
    "        user_response: str,\n",
    "        conversation_history: str = \"\",\n",
    "        current_location: str = \"\",\n",
    "        current_keywords: Optional[List[str]] = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Extract information from user response.\n",
    "        \n",
    "        Args:\n",
    "            user_response: User's latest response\n",
    "            conversation_history: Previous conversation\n",
    "            current_location: Previously extracted location\n",
    "            current_keywords: Previously extracted keywords\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with updated location, keywords, and confidence\n",
    "        \"\"\"\n",
    "        current_keywords = current_keywords or []\n",
    "        \n",
    "        # Build prompt\n",
    "        prompt_result = self.prompt_builder.run(\n",
    "            user_response=user_response,\n",
    "            conversation_history=conversation_history,\n",
    "            current_location=current_location,\n",
    "            current_keywords=\", \".join(current_keywords) if current_keywords else \"\"\n",
    "        )\n",
    "        \n",
    "        # Extract information\n",
    "        llm_result = self.generator.run(prompt=prompt_result['prompt'])\n",
    "        response_text = llm_result['replies'][0] if llm_result['replies'] else \"{}\"\n",
    "        \n",
    "        # Parse JSON response\n",
    "        try:\n",
    "            # Extract JSON from response (handle markdown code blocks)\n",
    "            if \"```json\" in response_text:\n",
    "                json_start = response_text.find(\"```json\") + 7\n",
    "                json_end = response_text.find(\"```\", json_start)\n",
    "                json_text = response_text[json_start:json_end].strip()\n",
    "            elif \"```\" in response_text:\n",
    "                json_start = response_text.find(\"```\") + 3\n",
    "                json_end = response_text.find(\"```\", json_start)\n",
    "                json_text = response_text[json_start:json_end].strip()\n",
    "            else:\n",
    "                json_text = response_text\n",
    "            \n",
    "            extracted = json.loads(json_text)\n",
    "            \n",
    "            # Update location if new one provided\n",
    "            new_location = extracted.get(\"location\", \"\")\n",
    "            final_location = new_location if new_location else current_location\n",
    "            \n",
    "            # Merge keywords\n",
    "            new_keywords = extracted.get(\"keywords\", [])\n",
    "            final_keywords = list(set(current_keywords + new_keywords))\n",
    "            \n",
    "            confidence = extracted.get(\"confidence\", \"low\")\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            # If parsing fails, keep current values\n",
    "            final_location = current_location\n",
    "            final_keywords = current_keywords\n",
    "            confidence = \"low\"\n",
    "        \n",
    "        return {\n",
    "            \"location\": final_location,\n",
    "            \"keywords\": final_keywords,\n",
    "            \"confidence\": confidence\n",
    "        }\n",
    "\n",
    "print(\"‚úì InformationExtractor component defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175d1a8c",
   "metadata": {},
   "source": [
    "## Interactive Conversation Manager\n",
    "\n",
    "This class manages the conversation flow and coordinates the pipeline components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d88ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractiveConversationManager:\n",
    "    \"\"\"\n",
    "    Manages the interactive conversation flow for extracting search parameters.\n",
    "    \n",
    "    This class orchestrates the conversation, tracks state, and determines\n",
    "    when enough information has been collected.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"\n",
    "        Initialize the conversation manager.\n",
    "        \n",
    "        Args:\n",
    "            api_key: OpenAI API key\n",
    "        \"\"\"\n",
    "        self.question_generator = ClarifyingQuestionGenerator(api_key=api_key)\n",
    "        self.info_extractor = InformationExtractor(api_key=api_key)\n",
    "        \n",
    "        self.location = \"\"\n",
    "        self.keywords = []\n",
    "        self.conversation_history = []\n",
    "        self.is_ready = False\n",
    "    \n",
    "    def start_conversation(self, initial_query: str) -> str:\n",
    "        \"\"\"\n",
    "        Start the conversation with an initial query.\n",
    "        \n",
    "        Args:\n",
    "            initial_query: User's initial search query\n",
    "            \n",
    "        Returns:\n",
    "            First clarifying question or confirmation\n",
    "        \"\"\"\n",
    "        self.conversation_history.append(f\"User: {initial_query}\")\n",
    "        \n",
    "        # Generate initial questions\n",
    "        result = self.question_generator.run(\n",
    "            user_query=initial_query,\n",
    "            location=self.location,\n",
    "            keywords=self.keywords\n",
    "        )\n",
    "        \n",
    "        self.is_ready = result['is_ready']\n",
    "        response = result['questions']\n",
    "        \n",
    "        self.conversation_history.append(f\"Assistant: {response}\")\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def process_response(self, user_response: str) -> str:\n",
    "        \"\"\"\n",
    "        Process user's response and continue conversation.\n",
    "        \n",
    "        Args:\n",
    "            user_response: User's response to the question\n",
    "            \n",
    "        Returns:\n",
    "            Next question or confirmation message\n",
    "        \"\"\"\n",
    "        self.conversation_history.append(f\"User: {user_response}\")\n",
    "        \n",
    "        # Extract information from response\n",
    "        extraction_result = self.info_extractor.run(\n",
    "            user_response=user_response,\n",
    "            conversation_history=\"\\n\".join(self.conversation_history[-4:]),  # Last 4 messages\n",
    "            current_location=self.location,\n",
    "            current_keywords=self.keywords\n",
    "        )\n",
    "        \n",
    "        # Update state\n",
    "        self.location = extraction_result['location']\n",
    "        self.keywords = extraction_result['keywords']\n",
    "        \n",
    "        # Generate next question\n",
    "        question_result = self.question_generator.run(\n",
    "            user_query=user_response,\n",
    "            location=self.location,\n",
    "            keywords=self.keywords\n",
    "        )\n",
    "        \n",
    "        self.is_ready = question_result['is_ready']\n",
    "        response = question_result['questions']\n",
    "        \n",
    "        self.conversation_history.append(f\"Assistant: {response}\")\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def get_search_parameters(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get the final search parameters.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with location and keywords\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"location\": self.location,\n",
    "            \"keywords\": self.keywords,\n",
    "            \"is_ready\": self.is_ready\n",
    "        }\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the conversation state.\"\"\"\n",
    "        self.location = \"\"\n",
    "        self.keywords = []\n",
    "        self.conversation_history = []\n",
    "        self.is_ready = False\n",
    "\n",
    "print(\"‚úì InteractiveConversationManager class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f394097",
   "metadata": {},
   "source": [
    "## Test the Interactive System\n",
    "\n",
    "Let's simulate a conversation where the user provides a vague query and we clarify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902138b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the conversation manager\n",
    "manager = InteractiveConversationManager(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Scenario 1: Vague query - user wants food but no location or specifics\n",
    "print(\"=\"*60)\n",
    "print(\"SCENARIO 1: Vague Query\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "initial_query = \"I'm looking for a good place to eat\"\n",
    "print(f\"\\nUser: {initial_query}\")\n",
    "\n",
    "response = manager.start_conversation(initial_query)\n",
    "print(f\"\\nAssistant: {response}\")\n",
    "print(f\"\\nExtracted so far - Location: '{manager.location}', Keywords: {manager.keywords}\")\n",
    "print(f\"Ready: {manager.is_ready}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c513cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate user response with location but still vague on type\n",
    "user_response = \"I'm in Madison, Wisconsin\"\n",
    "print(f\"\\nUser: {user_response}\")\n",
    "\n",
    "response = manager.process_response(user_response)\n",
    "print(f\"\\nAssistant: {response}\")\n",
    "print(f\"\\nExtracted so far - Location: '{manager.location}', Keywords: {manager.keywords}\")\n",
    "print(f\"Ready: {manager.is_ready}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45955119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate user providing more specific preferences\n",
    "user_response = \"I want Mexican food, preferably something casual with good margaritas\"\n",
    "print(f\"\\nUser: {user_response}\")\n",
    "\n",
    "response = manager.process_response(user_response)\n",
    "print(f\"\\nAssistant: {response}\")\n",
    "print(f\"\\nExtracted - Location: '{manager.location}', Keywords: {manager.keywords}\")\n",
    "print(f\"Ready: {manager.is_ready}\")\n",
    "\n",
    "# Get final search parameters\n",
    "if manager.is_ready:\n",
    "    params = manager.get_search_parameters()\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL SEARCH PARAMETERS:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Location: {params['location']}\")\n",
    "    print(f\"Keywords: {', '.join(params['keywords'])}\")\n",
    "    print(f\"\\nThese parameters are ready for Pipeline 1!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2b217",
   "metadata": {},
   "source": [
    "## Test Scenario 2: Specific Query That Needs No Clarification\n",
    "\n",
    "Test with a query that already has clear location and keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f14c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset for new scenario\n",
    "manager.reset()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCENARIO 2: Specific Query\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "initial_query = \"Best Italian pizza restaurants in San Francisco with outdoor seating\"\n",
    "print(f\"\\nUser: {initial_query}\")\n",
    "\n",
    "response = manager.start_conversation(initial_query)\n",
    "print(f\"\\nAssistant: {response}\")\n",
    "print(f\"\\nExtracted - Location: '{manager.location}', Keywords: {manager.keywords}\")\n",
    "print(f\"Ready: {manager.is_ready}\")\n",
    "\n",
    "if manager.is_ready:\n",
    "    params = manager.get_search_parameters()\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL SEARCH PARAMETERS:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Location: {params['location']}\")\n",
    "    print(f\"Keywords: {', '.join(params['keywords'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bec204d",
   "metadata": {},
   "source": [
    "## Test Scenario 3: Query with Location but Vague Preferences\n",
    "\n",
    "Test with a query that has location but needs keyword clarification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bc1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset for new scenario\n",
    "manager.reset()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCENARIO 3: Has Location, Needs Keywords\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "initial_query = \"Looking for something good in downtown Seattle\"\n",
    "print(f\"\\nUser: {initial_query}\")\n",
    "\n",
    "response = manager.start_conversation(initial_query)\n",
    "print(f\"\\nAssistant: {response}\")\n",
    "print(f\"\\nExtracted - Location: '{manager.location}', Keywords: {manager.keywords}\")\n",
    "print(f\"Ready: {manager.is_ready}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacf5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User clarifies preferences\n",
    "user_response = \"I want a coffee shop with good WiFi, somewhere I can work for a few hours\"\n",
    "print(f\"\\nUser: {user_response}\")\n",
    "\n",
    "response = manager.process_response(user_response)\n",
    "print(f\"\\nAssistant: {response}\")\n",
    "print(f\"\\nExtracted - Location: '{manager.location}', Keywords: {manager.keywords}\")\n",
    "print(f\"Ready: {manager.is_ready}\")\n",
    "\n",
    "if manager.is_ready:\n",
    "    params = manager.get_search_parameters()\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL SEARCH PARAMETERS:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Location: {params['location']}\")\n",
    "    print(f\"Keywords: {', '.join(params['keywords'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf38bda",
   "metadata": {},
   "source": [
    "## Integration with Pipeline 1\n",
    "\n",
    "Demonstrate how to use the extracted parameters with Pipeline 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4e9e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_pipeline1_query(location: str, keywords: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Convert extracted parameters into a query for Pipeline 1.\n",
    "    \n",
    "    Args:\n",
    "        location: Extracted location\n",
    "        keywords: Extracted keywords\n",
    "        \n",
    "    Returns:\n",
    "        Formatted query string for Pipeline 1\n",
    "    \"\"\"\n",
    "    keyword_string = \" \".join(keywords)\n",
    "    query = f\"{keyword_string} in {location}\"\n",
    "    return query\n",
    "\n",
    "# Example usage\n",
    "manager.reset()\n",
    "\n",
    "# Simulate a complete conversation\n",
    "print(\"=\"*60)\n",
    "print(\"COMPLETE WORKFLOW: Pipeline 5 ‚Üí Pipeline 1\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "initial_query = \"I need somewhere to eat\"\n",
    "print(f\"\\nUser: {initial_query}\")\n",
    "response = manager.start_conversation(initial_query)\n",
    "print(f\"Assistant: {response}\")\n",
    "\n",
    "user_response = \"I'm in Chicago\"\n",
    "print(f\"\\nUser: {user_response}\")\n",
    "response = manager.process_response(user_response)\n",
    "print(f\"Assistant: {response}\")\n",
    "\n",
    "user_response = \"Thai food, something upscale for a date night\"\n",
    "print(f\"\\nUser: {user_response}\")\n",
    "response = manager.process_response(user_response)\n",
    "print(f\"Assistant: {response}\")\n",
    "\n",
    "# Get final parameters\n",
    "params = manager.get_search_parameters()\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"EXTRACTED PARAMETERS:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Location: {params['location']}\")\n",
    "print(f\"Keywords: {', '.join(params['keywords'])}\")\n",
    "\n",
    "# Prepare for Pipeline 1\n",
    "pipeline1_query = prepare_pipeline1_query(params['location'], params['keywords'])\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PIPELINE 1 INPUT:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Query: {pipeline1_query}\")\n",
    "print(f\"\\nThis query can now be sent to Pipeline 1 for business search!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0565919",
   "metadata": {},
   "source": [
    "## Complete Integration Example\n",
    "\n",
    "Here's how all pipelines work together in the full workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b771e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_workflow_example():\n",
    "    \"\"\"\n",
    "    Demonstrates the complete workflow from interactive clarification to recommendations.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"COMPLETE YELP NAVIGATOR WORKFLOW\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nüìç STEP 1: Interactive Clarification (Pipeline 5)\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Purpose: Extract clear location and keywords from user conversation\")\n",
    "    print(\"\\nExample conversation:\")\n",
    "    print(\"  User: 'I want food'\")\n",
    "    print(\"  Assistant: 'Where are you located?'\")\n",
    "    print(\"  User: 'Madison, WI'\")\n",
    "    print(\"  Assistant: 'What type of food are you looking for?'\")\n",
    "    print(\"  User: 'Mexican, casual'\")\n",
    "    print(\"\\n  Extracted: location='Madison, WI', keywords=['Mexican', 'casual']\")\n",
    "    \n",
    "    print(\"\\n\\nüîç STEP 2: Business Search with NER (Pipeline 1)\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Purpose: Search Yelp for businesses matching criteria\")\n",
    "    print(\"\\nInput: 'Mexican casual in Madison, WI'\")\n",
    "    print(\"Output: List of businesses with IDs and aliases\")\n",
    "    print(\"  - The Old Fashioned (ID: RJNAeNA-209sctUO0dmwuA)\")\n",
    "    print(\"  - Taqueria Guadalajara (ID: xyz123...)\")\n",
    "    print(\"  - etc.\")\n",
    "    \n",
    "    print(\"\\n\\nüìã STEP 3: Business Details (Pipeline 2)\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Purpose: Get detailed information and website content\")\n",
    "    print(\"\\nInput: Business IDs and aliases from Pipeline 1\")\n",
    "    print(\"Output: Documents with:\")\n",
    "    print(\"  - Price range, rating, location coordinates\")\n",
    "    print(\"  - Website content\")\n",
    "    print(\"  - Contact information\")\n",
    "    \n",
    "    print(\"\\n\\n‚≠ê STEP 4: Reviews & Sentiment Analysis (Pipeline 3)\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Purpose: Analyze customer reviews and sentiment\")\n",
    "    print(\"\\nInput: Business IDs from Pipeline 1\")\n",
    "    print(\"Output: Aggregated documents with:\")\n",
    "    print(\"  - Highest-rated reviews (positive sentiment)\")\n",
    "    print(\"  - Lowest-rated reviews (negative sentiment)\")\n",
    "    print(\"  - Sentiment distribution\")\n",
    "    \n",
    "    print(\"\\n\\nüí° STEP 5: Recommendations (Pipeline 4)\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Purpose: Generate personalized recommendations\")\n",
    "    print(\"\\nInput: Review documents + user preferences\")\n",
    "    print(\"Output: Personalized recommendations with:\")\n",
    "    print(\"  - Theme analysis\")\n",
    "    print(\"  - Pros and cons\")\n",
    "    print(\"  - Best suited for...\")\n",
    "    print(\"  - Final recommendation (Yes/No)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"END-TO-END RESULT: Intelligent business recommendations based on\")\n",
    "    print(\"user conversation, business data, and sentiment-analyzed reviews\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "complete_workflow_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b848293",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Built\n",
    "- **Pipeline 5** provides an interactive conversational interface for clarifying user intent\n",
    "- Extracts location and keywords through natural dialogue\n",
    "- Integrates seamlessly with Pipeline 1 to start the complete workflow\n",
    "\n",
    "### Key Features\n",
    "- **Adaptive Questions**: Asks only what's needed based on current information\n",
    "- **Incremental Extraction**: Builds understanding across multiple conversation turns\n",
    "- **Confidence Tracking**: Monitors extraction quality\n",
    "- **Ready Detection**: Knows when enough information has been collected\n",
    "\n",
    "### Integration with Complete System\n",
    "\n",
    "```\n",
    "User Query (vague)\n",
    "    ‚Üì\n",
    "Pipeline 5: Interactive Clarification\n",
    "    ‚îú‚îÄ‚Üí Extract Location\n",
    "    ‚îî‚îÄ‚Üí Extract Keywords\n",
    "    ‚Üì\n",
    "Pipeline 1: Business Search with NER\n",
    "    ‚îî‚îÄ‚Üí Returns business IDs and aliases\n",
    "    ‚Üì\n",
    "Pipeline 2: Business Details (optional)\n",
    "    ‚îî‚îÄ‚Üí Returns detailed business info\n",
    "    ‚Üì\n",
    "Pipeline 3: Reviews & Sentiment\n",
    "    ‚îî‚îÄ‚Üí Returns analyzed reviews\n",
    "    ‚Üì\n",
    "Pipeline 4: Recommendations\n",
    "    ‚îî‚îÄ‚Üí Returns personalized recommendations\n",
    "```\n",
    "\n",
    "### Usage Example\n",
    "```python\n",
    "# Initialize conversation manager\n",
    "manager = InteractiveConversationManager(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Start conversation\n",
    "response = manager.start_conversation(\"I want food\")\n",
    "print(response)  # Asks clarifying questions\n",
    "\n",
    "# Continue until ready\n",
    "while not manager.is_ready:\n",
    "    user_input = input(\"You: \")\n",
    "    response = manager.process_response(user_input)\n",
    "    print(f\"Assistant: {response}\")\n",
    "\n",
    "# Get parameters for Pipeline 1\n",
    "params = manager.get_search_parameters()\n",
    "query = f\"{' '.join(params['keywords'])} in {params['location']}\"\n",
    "\n",
    "# Now run Pipeline 1-4 with the extracted parameters...\n",
    "```\n",
    "\n",
    "### Benefits\n",
    "- Handles ambiguous user queries gracefully\n",
    "- Reduces failed searches due to missing information\n",
    "- Improves user experience with natural conversation\n",
    "- Ensures downstream pipelines have quality input data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
