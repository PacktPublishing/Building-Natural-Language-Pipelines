{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1bbb399",
   "metadata": {},
   "source": [
    "# Building a Tool-Calling AI Agent with Haystack\n",
    "\n",
    "Welcome to this tutorial on creating a **tool-calling AI agent** using Haystack! This notebook demonstrates how to build an AI agent that can autonomously decide when it needs external tools (like web search) to answer questions.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "By the end of this notebook, you'll understand:\n",
    "- What tool-calling agents are and why they're powerful\n",
    "- How to wrap Haystack components as tools that LLMs can use\n",
    "- How to build a decision loop that allows the agent to choose and use tools\n",
    "- The flow of information in a tool-calling pipeline\n",
    "- Best practices for implementing agentic workflows\n",
    "\n",
    "## What is a Tool-Calling Agent?\n",
    "\n",
    "A **tool-calling agent** is an AI system that can:\n",
    "1. **Recognize** when it needs external information or capabilities\n",
    "2. **Request** specific tools to gather that information\n",
    "3. **Process** the tool's output\n",
    "4. **Generate** a final answer using both its knowledge and the tool results\n",
    "\n",
    "Think of it like a human researcher who knows when to consult a book, search the web, or use a calculator.\n",
    "\n",
    "## The Pipeline Flow\n",
    "\n",
    "This implementation creates a manual tool-calling loop with these steps:\n",
    "\n",
    "```\n",
    "User Question\n",
    "    ‚Üì\n",
    "LLM (Generator)\n",
    "    ‚Üì\n",
    "Decision Point (Router)\n",
    "    ‚îú‚îÄ‚Üí Tool Call Needed? ‚Üí Invoke Tool ‚Üí Collect Results ‚Üí Back to LLM\n",
    "    ‚îî‚îÄ‚Üí No Tool Needed? ‚Üí Return Final Answer\n",
    "```\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **Tool Definition**: Wrap external functionality (web search) as a tool\n",
    "2. **Generator (LLM)**: The \"brain\" that decides when to use tools\n",
    "3. **Router**: Routes messages based on whether tool calls are present\n",
    "4. **Tool Invoker**: Executes the requested tool\n",
    "5. **Message Collector**: Maintains conversation history and tool results\n",
    "\n",
    "Let's dive into the implementation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfe868d",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Components\n",
    "\n",
    "We'll need several Haystack components to build our tool-calling agent:\n",
    "\n",
    "- **Pipeline**: Container for connecting components\n",
    "- **ToolInvoker**: Executes tools requested by the LLM\n",
    "- **OpenAIChatGenerator**: The LLM that will decide when to use tools\n",
    "- **ConditionalRouter**: Routes messages based on conditions (tool call present or not)\n",
    "- **SearchApiWebSearch**: Web search component we'll expose as a tool\n",
    "- **ComponentTool**: Wrapper that converts components into LLM-callable tools\n",
    "- **ChatMessage**: Structure for conversation messages\n",
    "\n",
    "We'll also create a custom **MessageCollector** component to manage conversation history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a2a40e",
   "metadata": {},
   "source": [
    "## Step 2: Understanding the MessageCollector Component\n",
    "\n",
    "The **MessageCollector** is a helper component that maintains the conversation history. Here's why we need it:\n",
    "\n",
    "**The Problem**: When the LLM requests a tool, we need to:\n",
    "1. Remember the original user question\n",
    "2. Collect the tool's response\n",
    "3. Send both back to the LLM so it can generate the final answer\n",
    "\n",
    "**The Solution**: MessageCollector acts as a memory buffer that:\n",
    "- Stores all messages (user queries, tool calls, tool results)\n",
    "- Extends its internal list with new messages using `Variadic[List[ChatMessage]]`\n",
    "- Returns the complete conversation history to feed back to the LLM\n",
    "\n",
    "**Key Features**:\n",
    "- `_messages`: Internal storage for conversation history\n",
    "- `run()`: Accepts multiple message lists and combines them\n",
    "- `clear()`: Resets the conversation history when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b1f7a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-11-17T04:40:10.978128Z\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mUnsafe mode is enabled. This allows execution of arbitrary code in the Jinja template. Use this only if you trust the source of the template.\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m199\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhaystack.components.routers.conditional_router\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x117aa5040>\n",
       "üöÖ Components\n",
       "  - message_collector: MessageCollector\n",
       "  - generator: OpenAIChatGenerator\n",
       "  - router: ConditionalRouter\n",
       "  - tool_invoker: ToolInvoker\n",
       "üõ§Ô∏è Connections\n",
       "  - message_collector.messages -> generator.messages (List[ChatMessage])\n",
       "  - generator.replies -> router.replies (list[ChatMessage])\n",
       "  - router.there_are_tool_calls -> tool_invoker.messages (List[ChatMessage])\n",
       "  - router.there_are_tool_calls -> message_collector.messages (List[ChatMessage])\n",
       "  - tool_invoker.tool_messages -> message_collector.messages (list[ChatMessage])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import component, Pipeline\n",
    "from haystack.components.tools import ToolInvoker\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.components.routers import ConditionalRouter\n",
    "from haystack.components.websearch import SearchApiWebSearch\n",
    "from haystack.core.component.types import Variadic\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.tools import ComponentTool\n",
    "from dotenv import load_dotenv\n",
    "from haystack.utils import Secret\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Load .env from the root of ch8 directory\n",
    "root_dir = Path(__file__).parent.parent if \"__file__\" in globals() else Path.cwd().parent\n",
    "load_dotenv(root_dir / \".env\")\n",
    "\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "# helper component to temporarily store last user query before the tool call \n",
    "@component()\n",
    "class MessageCollector:\n",
    "    def __init__(self):\n",
    "        self._messages = []\n",
    "\n",
    "    @component.output_types(messages=List[ChatMessage])\n",
    "    def run(self, messages: Variadic[List[ChatMessage]]) -> Dict[str, Any]:\n",
    "\n",
    "        self._messages.extend([msg for inner in messages for msg in inner])\n",
    "        return {\"messages\": self._messages}\n",
    "\n",
    "    def clear(self):\n",
    "        self._messages = []\n",
    "\n",
    "# Create a tool from a component\n",
    "web_tool = ComponentTool(\n",
    "    component=SearchApiWebSearch(top_k=5,\n",
    "                                api_key=Secret.from_env_var(\"SEARCH_API_KEY\"),\n",
    "                                allowed_domains=[\"https://www.britannica.com/\"])\n",
    ")\n",
    "\n",
    "# Define routing conditions\n",
    "routes = [\n",
    "    {\n",
    "        \"condition\": \"{{replies[0].tool_calls | length > 0}}\",\n",
    "        \"output\": \"{{replies}}\",\n",
    "        \"output_name\": \"there_are_tool_calls\",\n",
    "        \"output_type\": List[ChatMessage],\n",
    "    },\n",
    "    {\n",
    "        \"condition\": \"{{replies[0].tool_calls | length == 0}}\",\n",
    "        \"output\": \"{{replies}}\",\n",
    "        \"output_name\": \"final_replies\",\n",
    "        \"output_type\": List[ChatMessage], \n",
    "    },\n",
    "]\n",
    "\n",
    "# Create the pipeline\n",
    "tool_agent = Pipeline()\n",
    "tool_agent.add_component(\"message_collector\", MessageCollector())\n",
    "tool_agent.add_component(\"generator\", OpenAIChatGenerator(model=\"gpt-4o-mini\", tools=[web_tool]))\n",
    "tool_agent.add_component(\"router\", ConditionalRouter(routes, unsafe=True))\n",
    "tool_agent.add_component(\"tool_invoker\", ToolInvoker(tools=[web_tool]))\n",
    "\n",
    "tool_agent.connect(\"generator.replies\", \"router\")\n",
    "tool_agent.connect(\"router.there_are_tool_calls\", \"tool_invoker\")\n",
    "tool_agent.connect(\"router.there_are_tool_calls\", \"message_collector\")\n",
    "tool_agent.connect(\"tool_invoker.tool_messages\", \"message_collector\")\n",
    "tool_agent.connect(\"message_collector\", \"generator.messages\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b5e3cd",
   "metadata": {},
   "source": [
    "## Step 3: Create a Web Search Tool\n",
    "\n",
    "Now we'll wrap a web search component into a tool that the LLM can request:\n",
    "\n",
    "**ComponentTool**: This wrapper converts any Haystack component into a tool that:\n",
    "- The LLM can \"see\" and understand what it does\n",
    "- The LLM can request by name when it needs that capability\n",
    "- The ToolInvoker can execute automatically\n",
    "\n",
    "**SearchApiWebSearch Configuration**:\n",
    "- `top_k=5`: Returns the top 5 search results\n",
    "- `api_key`: Authenticates with the SearchAPI service\n",
    "- `allowed_domains`: Restricts searches to specific domains (optional, for focused results)\n",
    "\n",
    "The LLM will receive a description of this tool and can decide to call it when it needs current information from the web."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3370ee53",
   "metadata": {},
   "source": [
    "## Step 4: Define Routing Logic\n",
    "\n",
    "The **ConditionalRouter** is the decision point in our pipeline. It checks whether the LLM's response contains tool calls:\n",
    "\n",
    "### Route 1: Tool Call Detected\n",
    "```python\n",
    "\"condition\": \"{{replies[0].tool_calls | length > 0}}\"\n",
    "```\n",
    "- **When**: The LLM's reply contains tool call requests\n",
    "- **Action**: Routes to `ToolInvoker` to execute the requested tool\n",
    "- **Output Name**: `there_are_tool_calls`\n",
    "\n",
    "### Route 2: No Tool Call (Final Answer)\n",
    "```python\n",
    "\"condition\": \"{{replies[0].tool_calls | length == 0}}\"\n",
    "```\n",
    "- **When**: The LLM provides a direct answer (no tool needed)\n",
    "- **Action**: Routes to the final output\n",
    "- **Output Name**: `final_replies`\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. LLM generates a response with or without tool calls\n",
    "2. Router checks the `tool_calls` attribute\n",
    "3. If tool calls exist ‚Üí execute tool and loop back to LLM with results\n",
    "4. If no tool calls ‚Üí return the final answer to the user\n",
    "\n",
    "**Note**: `unsafe=True` allows the router to execute Jinja2 templates dynamically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7098f1e",
   "metadata": {},
   "source": [
    "## Step 5: Build and Connect the Pipeline\n",
    "\n",
    "Now we assemble all components into a working pipeline with these connections:\n",
    "\n",
    "### Component Setup\n",
    "1. **message_collector**: Stores conversation history\n",
    "2. **generator**: OpenAI LLM with access to the web search tool\n",
    "3. **router**: Decides whether to invoke tools or return final answer\n",
    "4. **tool_invoker**: Executes tool calls\n",
    "\n",
    "### Connection Flow\n",
    "\n",
    "```\n",
    "generator.replies ‚Üí router\n",
    "    ‚Üì\n",
    "router.there_are_tool_calls ‚Üí tool_invoker (execute tool)\n",
    "router.there_are_tool_calls ‚Üí message_collector (store tool call)\n",
    "    ‚Üì\n",
    "tool_invoker.tool_messages ‚Üí message_collector (store results)\n",
    "    ‚Üì\n",
    "message_collector ‚Üí generator.messages (feedback loop)\n",
    "```\n",
    "\n",
    "### The Feedback Loop\n",
    "\n",
    "When a tool is needed:\n",
    "1. Generator creates tool call ‚Üí Router detects it\n",
    "2. Tool call goes to both Invoker (to execute) and Collector (to remember)\n",
    "3. Tool results go to Collector\n",
    "4. Collector sends complete history back to Generator\n",
    "5. Generator uses tool results to create final answer\n",
    "\n",
    "This creates a cycle that allows the agent to iteratively use tools until it has enough information to answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ddc4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_agent.draw(path=\"./images/tool_agent_pipeline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539c4e66",
   "metadata": {},
   "source": [
    "## Step 6: Visualize the Pipeline\n",
    "\n",
    "Let's draw the pipeline to see how all components are connected. This visualization helps understand the data flow and decision points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff69bdd",
   "metadata": {},
   "source": [
    "## Pipeline Diagram Explained\n",
    "\n",
    "![](./images/tool_agent_pipeline.png)\n",
    "\n",
    "### What the Diagram Shows\n",
    "\n",
    "The diagram illustrates the complete tool-calling loop:\n",
    "\n",
    "1. **Entry Point**: Messages enter through `generator` (the LLM)\n",
    "2. **Decision Node**: `router` examines the LLM's response\n",
    "3. **Tool Path**: If tool call detected ‚Üí `tool_invoker` executes ‚Üí results to `message_collector`\n",
    "4. **Feedback Loop**: `message_collector` sends updated history back to `generator`\n",
    "5. **Exit Point**: When no tool call ‚Üí final answer exits through `router.final_replies`\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "- The **circular connection** from message_collector back to generator enables iterative tool use\n",
    "- The **router splits** the flow into two paths (tool call vs. final answer)\n",
    "- The **message_collector** receives inputs from both the router and tool_invoker, accumulating the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae688f7e",
   "metadata": {},
   "source": [
    "## Step 7: Running the Agent\n",
    "\n",
    "Now let's test our tool-calling agent with a question that requires current information (weather in Berlin).\n",
    "\n",
    "### Message Setup\n",
    "\n",
    "We create two messages:\n",
    "1. **System message**: Instructs the agent's behavior (\"choose the right tool when necessary\")\n",
    "2. **User message**: The actual question (\"How is the weather in Berlin?\")\n",
    "\n",
    "### Expected Flow\n",
    "\n",
    "When we run this:\n",
    "\n",
    "1. **LLM Analysis**: Generator receives the question and recognizes it needs current weather data\n",
    "2. **Tool Request**: LLM generates a tool call for web search with appropriate parameters\n",
    "3. **Router Decision**: Router detects the tool call and routes to tool_invoker\n",
    "4. **Tool Execution**: Web search runs and returns results about Berlin weather\n",
    "5. **Context Update**: MessageCollector combines the original question + tool call + search results\n",
    "6. **Final Generation**: Generator receives the search results and creates a natural language answer\n",
    "7. **Output**: Router detects no more tool calls and returns the final answer\n",
    "\n",
    "Let's see it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b818d429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The search did not provide specific current weather information for Berlin. However, you can check reliable weather websites or apps for the most accurate and updated weather conditions. Would you like me to search again or provide guidance on where to look?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    ChatMessage.from_system(\"You're a helpful agent choosing the right tool when necessary\"), \n",
    "    ChatMessage.from_user(\"How is the weather in Berlin?\")]\n",
    "result = tool_agent.run({\"messages\": messages})\n",
    "\n",
    "print(result[\"router\"][\"final_replies\"][0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149aa7e4",
   "metadata": {},
   "source": [
    "## Understanding the Output\n",
    "\n",
    "The agent successfully:\n",
    "1. ‚úÖ Recognized it needed external information (current weather)\n",
    "2. ‚úÖ Called the web search tool automatically\n",
    "3. ‚úÖ Retrieved relevant search results\n",
    "4. ‚úÖ Synthesized the information into a natural language answer\n",
    "\n",
    "### What Happened Behind the Scenes\n",
    "\n",
    "```\n",
    "User: \"How is the weather in Berlin?\"\n",
    "    ‚Üì\n",
    "LLM: \"I need current data, let me search the web\"\n",
    "    [generates tool_call: search_web(\"Berlin weather\")]\n",
    "    ‚Üì\n",
    "Router: \"Tool call detected, routing to tool_invoker\"\n",
    "    ‚Üì\n",
    "Tool Invoker: [executes web search]\n",
    "    ‚Üí Returns: [search results about Berlin weather]\n",
    "    ‚Üì\n",
    "Message Collector: [combines question + tool call + results]\n",
    "    ‚Üì\n",
    "LLM: \"Based on the search results, here's the weather...\"\n",
    "    [generates final answer with no tool calls]\n",
    "    ‚Üì\n",
    "Router: \"No tool call, returning final answer\"\n",
    "    ‚Üì\n",
    "Output: Natural language response about Berlin weather\n",
    "```\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- **Autonomy**: The agent decided *on its own* to use the web search tool\n",
    "- **Iteration**: The pipeline looped through generator ‚Üí router ‚Üí tool ‚Üí collector ‚Üí generator\n",
    "- **Context Awareness**: The final answer incorporated both the search results and natural language understanding\n",
    "- **Tool Transparency**: From the user's perspective, they just got an answer‚Äîthe tool usage was hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcba248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Additional Examples and Experiments\n",
    "# ============================================================================\n",
    "\n",
    "# Example 1: Question that doesn't need a tool\n",
    "print(\"=\"*80)\n",
    "print(\"Example 1: Simple factual question\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "messages_simple = [\n",
    "    ChatMessage.from_system(\"You're a helpful agent choosing the right tool when necessary\"),\n",
    "    ChatMessage.from_user(\"What is 25 + 37?\")\n",
    "]\n",
    "result_simple = tool_agent.run({\"messages\": messages_simple})\n",
    "print(f\"Question: What is 25 + 37?\")\n",
    "print(f\"Answer: {result_simple['router']['final_replies'][0].text}\")\n",
    "print()\n",
    "\n",
    "# Example 2: Question that needs current information\n",
    "print(\"=\"*80)\n",
    "print(\"Example 2: Current events question\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "messages_current = [\n",
    "    ChatMessage.from_system(\"You're a helpful agent choosing the right tool when necessary\"),\n",
    "    ChatMessage.from_user(\"What are the latest developments in AI technology?\")\n",
    "]\n",
    "result_current = tool_agent.run({\"messages\": messages_current})\n",
    "print(f\"Question: What are the latest developments in AI technology?\")\n",
    "print(f\"Answer: {result_current['router']['final_replies'][0].text}\")\n",
    "print()\n",
    "\n",
    "# Note: Clear message collector between runs if needed for fresh context\n",
    "# tool_agent.get_component(\"message_collector\").clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0c5419",
   "metadata": {},
   "source": [
    "## Key Takeaways and Best Practices\n",
    "\n",
    "### What We've Built\n",
    "\n",
    "You've created a **tool-calling agent** that demonstrates:\n",
    "\n",
    "1. **Autonomous Decision Making**: The LLM decides when to use tools\n",
    "2. **Tool Integration**: External capabilities (web search) are seamlessly available\n",
    "3. **Iterative Processing**: The feedback loop allows multiple tool calls if needed\n",
    "4. **Conversation Memory**: MessageCollector maintains context throughout the interaction\n",
    "\n",
    "### Architecture Patterns\n",
    "\n",
    "This manual implementation shows the core concepts, but Haystack also provides:\n",
    "- **Agent Component**: Higher-level abstraction for tool-calling (see other examples)\n",
    "- **Multiple Tools**: You can add more tools (calculators, databases, APIs)\n",
    "- **Tool Chains**: Agents can use multiple tools in sequence\n",
    "- **Error Handling**: Add try-catch logic around tool invocations\n",
    "\n",
    "### When to Use Tool-Calling Agents\n",
    "\n",
    "**Best for**:\n",
    "- Questions requiring current/external information\n",
    "- Tasks needing calculations or specialized processing\n",
    "- Multi-step reasoning with data retrieval\n",
    "- Situations where the LLM needs to \"decide\" what to do\n",
    "\n",
    "**Not ideal for**:\n",
    "- Simple Q&A where the LLM already knows the answer\n",
    "- High-speed/low-latency requirements (tool calls add overhead)\n",
    "- Fully deterministic workflows (use regular pipelines instead)\n",
    "\n",
    "### Extending This Example\n",
    "\n",
    "Try these enhancements:\n",
    "1. **Add more tools**: Calculator, database lookup, code execution\n",
    "2. **Multi-turn conversations**: Keep message history across multiple questions\n",
    "3. **Tool selection logic**: Add conditions for which tools are available\n",
    "4. **Fallback handling**: What if a tool fails or returns no results?\n",
    "5. **Cost optimization**: Track and limit the number of LLM calls\n",
    "\n",
    "### Comparison: Manual vs Agent Component\n",
    "\n",
    "**Manual Implementation (this notebook)**:\n",
    "- ‚úÖ Full control over routing logic\n",
    "- ‚úÖ Understand every step of the process\n",
    "- ‚úÖ Custom error handling and logging\n",
    "- ‚ùå More code to maintain\n",
    "- ‚ùå Need to handle edge cases\n",
    "\n",
    "**Agent Component** (simplified API):\n",
    "- ‚úÖ Less boilerplate code\n",
    "- ‚úÖ Built-in error handling\n",
    "- ‚úÖ Easier to add multiple tools\n",
    "- ‚ùå Less control over routing\n",
    "- ‚ùå Harder to debug internal behavior\n",
    "\n",
    "Both approaches are valid‚Äîchoose based on your needs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-with-haystack-ch8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
