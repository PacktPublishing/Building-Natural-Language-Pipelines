{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing content into a Document Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### `DocumentWriter`\n",
    "\n",
    "#### Writing regular documents\n",
    "\n",
    "We can write `Document` objects into a Document Store using the `DocumentWriter` class. In this example, we create a `DocumentStore` and write a `Document` object into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents written: 2\n"
     ]
    }
   ],
   "source": [
    "from haystack.preview.components.writers import DocumentWriter\n",
    "from haystack.preview.document_stores import InMemoryDocumentStore\n",
    "from haystack.preview.dataclasses import Document\n",
    "\n",
    "# Initialize an in-memory document store\n",
    "doc_store = InMemoryDocumentStore()\n",
    "\n",
    "# Create the DocumentWriter component with the document store\n",
    "document_writer = DocumentWriter(document_store=doc_store)\n",
    "\n",
    "# Define a list of documents to write\n",
    "documents_to_write = [\n",
    "    Document(content=\"Document 1 content\"),\n",
    "    Document(content=\"Document 2 content\"),\n",
    "]\n",
    "\n",
    "# Use the DocumentWriter component to write documents to the store\n",
    "result = document_writer.run(documents=documents_to_write)\n",
    "\n",
    "# Print the number of documents written\n",
    "print(f\"Documents written: {result['documents_written']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_store.count_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id=8bd659ba0ddd6820199db5c60404564834d86ad5d6492bffeba36dbff256a16d, content: 'Document 1 content'),\n",
       " Document(id=e9ddb15c1c34d025bad485665cb56e4a4e18450fe13afec1e749f85ab0dcc19c, content: 'Document 2 content')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_store.filter_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing embedded documents\n",
    "\n",
    "There may be times in which, either due to the size of the data, or to preserve semantic meaning while leveraging embedding models, that we may want to work with embeddings instead. \n",
    "\n",
    "We can follow the next key steps.\n",
    "\n",
    "* Compute Embeddings: Use either the `OpenAIDocumentEmbedder` or `SentenceTransformersDocumentEmbedder`, or other Haystack embedding model integration, to compute the embeddings for your documents.\n",
    "\n",
    "* Store Embeddings: The computed embeddings are stored in the embedding field of the Document objects.\n",
    "\n",
    "* Write to DocumentStore: Use the DocumentWriter component to write these Document objects, now with embeddings, into a DocumentStore.\n",
    "\n",
    "Here's an example code snippet that demonstrates how to use the SentenceTransformersDocumentEmbedder to write embeddings into a document store:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410de4f10a0144dcbd0e7a537f46cce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'documents_written': 2}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack.preview.document_stores import InMemoryDocumentStore\n",
    "from haystack.preview.components.writers import DocumentWriter\n",
    "from haystack.preview.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.preview.dataclasses import Document\n",
    "\n",
    "# Initialize document store and components\n",
    "doc_store = InMemoryDocumentStore()\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(model_name_or_path=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "document_writer = DocumentWriter(document_store=doc_store)\n",
    "\n",
    "# Example document\n",
    "documents = [\n",
    "    Document(content=\"The quick brown fox jumps over the lazy dog.\"),\n",
    "    Document(content=\"When it comes to natural language processing, context is key.\")\n",
    "]\n",
    "\n",
    "# Warm up the embedder and compute embeddings\n",
    "doc_embedder.warm_up()\n",
    "embedded_docs = doc_embedder.run(documents)['documents']\n",
    "\n",
    "# Write documents with embeddings to the document store\n",
    "document_writer.run(documents=embedded_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the document content and their embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: 2e3218009b01cfc57f865bbf81fa70de81b5ebae02c4cc7092e46ffde03f3c49\n",
      "Content: The quick brown fox jumps over the lazy dog.\n",
      "Embedding: [-0.03429264575242996, -0.0013394346460700035, 0.004336129408329725, -0.0018683503149077296, 0.025440821424126625]...\n",
      "\n",
      "\n",
      "Document ID: 8baba41960a8807c42da6783a39dbbf50873f9700ff861844ec8ccce65d4f50e\n",
      "Content: When it comes to natural language processing, context is key.\n",
      "Embedding: [0.049897201359272, -0.023004200309515, -0.03653186932206154, 0.05246769264340401, -0.01983010210096836]...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve all documents\n",
    "all_documents = doc_store.filter_documents()\n",
    "\n",
    "# Print details of each document, including the embedding if it exists\n",
    "for doc in all_documents:\n",
    "    print(f\"Document ID: {doc.id}\")\n",
    "    print(f\"Content: {doc.content}\")\n",
    "    if doc.embedding:\n",
    "        print(f\"Embedding: {doc.embedding[:5]}...\")  # Displaying first 5 values of the embedding for brevity\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-pipelines",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
