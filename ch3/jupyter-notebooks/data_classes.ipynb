{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building blocks in Haystack: Data classes \n",
    "\n",
    "When building data pipelines, a core component involved is the use of data structures. With data structures, we can store, manipulate and manage data through code. Having a solid foundation for data structures is key to ease NLP pipeline development, particularly when an LLM is involved.  With Haystack, we can leverage the following built-in data classes: \n",
    "\n",
    "* Haystack Documents data class \n",
    "\n",
    "* Haystack ByteStream data class \n",
    "\n",
    "* Haystack ChatMessage data class \n",
    "\n",
    "* Haystack StreaminhChunk data class \n",
    "\n",
    "![](./images/data-structures.png)\n",
    "\n",
    "Each of these classes act as data structures that can be used to store and process data. We can use these classes to store data in a standardized format, and then use the Haystack API to process the data through data pipelines.\n",
    "\n",
    "In the next section, we will provide examples of each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haystack Documents data class \n",
    "\n",
    "The Document is a foundational data class in Haystack that encapsulates a variety of data types that can be queried, such as text snippets, tables, and binary data.\n",
    "\n",
    "Let's import it and take a look at its functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.preview.dataclasses import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `help` function lets us see what parameters it accepts. \n",
    "\n",
    "### Let's create a simple Document object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id='ca53157e450d009adb4c2217111faadc9e7c02aefb22717c4901e1c1c1ba314a', content='This is a simple document', dataframe=None, blob=None, meta={'name': 'test_doc'}, score=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_document = Document(content=\"This is a simple document\", meta={\"name\": \"test_doc\"})\n",
    "sample_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ca53157e450d009adb4c2217111faadc9e7c02aefb22717c4901e1c1c1ba314a'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_document.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that an id was automatically generated for the document. Let's create a dataframe-based document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a simple document'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_document.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'test_doc'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_document.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a dataframe-based Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups, load_iris\n",
    "\n",
    "# Load some example data\n",
    "iris_df = load_iris(as_frame=True)[\"frame\"]\n",
    "news_df = pd.DataFrame(fetch_20newsgroups(subset=\"train\").data, columns=[\"text\"])\n",
    "\n",
    "# Save each row as a Document Object\n",
    "iris_docs = [Document(dataframe=row.to_frame().T) for _, row in iris_df.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that each row was converted into a Document object, each with its own id. Let's access the first Document  and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id='22cf9396b67c1929c273ed65a6fcea5b8ba8b384ae45d5164be9ca7b6827c66c', content=None, dataframe=   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  , blob=None, meta={}, score=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22cf9396b67c1929c273ed65a6fcea5b8ba8b384ae45d5164be9ca7b6827c66c'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_docs[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_docs[0].dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a ByteStream-based data structure\n",
    "\n",
    "The ByteStream class in Haystack represents a binary object that can be used within the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.preview.dataclasses import  ByteStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'binary_data' is your binary data, for example, read from a file:\n",
    "binary_data = b'Your binary data here'  # This could be the actual binary content, such as PDF or image data\n",
    "\n",
    "# Convert binary data to ByteStream object\n",
    "binary_blob = ByteStream(data=binary_data, mime_type='application/pdf')  # MIME type should match your data\n",
    "binary_document = Document(blob=binary_blob, meta={\"file_name\": \"example.pdf\", \"file_type\": \"PDF\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ByteStream(data=b'Your binary data here', metadata={}, mime_type='application/pdf')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_document.blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'93c323201fc3b8509e51056dff8baee6ca9dec1c22cf2ce2f6cfc0bb04397c14'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_document.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a ChatMessage Document\n",
    "\n",
    "ChatMessage comes built in with the following roles\n",
    "\n",
    "```python\n",
    "class ChatRole(str, Enum):\n",
    "    \"\"\"Enumeration representing the roles within a chat.\"\"\"\n",
    "\n",
    "    ASSISTANT = \"assistant\"\n",
    "    USER = \"user\"\n",
    "    SYSTEM = \"system\"\n",
    "    FUNCTION = \"function\"\n",
    "```\n",
    "\n",
    "These can be mapped to the roles present in OpenAI's GPT models. \n",
    "\n",
    "Read more https://help.openai.com/en/articles/7042661-chatgpt-api-transition-guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.preview.dataclasses import ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatMessage(content='Hello, how can I assist you today?', role=<ChatRole.ASSISTANT: 'assistant'>, name=None, metadata={})\n"
     ]
    }
   ],
   "source": [
    "# Create a message from the assistant\n",
    "assistant_msg = ChatMessage.from_assistant(content=\"Hello, how can I assist you today?\")\n",
    "\n",
    "print(assistant_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatMessage(content='Can you show me the weather forecast?', role=<ChatRole.USER: 'user'>, name=None, metadata={})\n"
     ]
    }
   ],
   "source": [
    "# Create a message from the user\n",
    "user_msg = ChatMessage.from_user(content=\"Can you show me the weather forecast?\")\n",
    "\n",
    "print(user_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatMessage(content='A new user has joined the chat.', role=<ChatRole.SYSTEM: 'system'>, name=None, metadata={})\n"
     ]
    }
   ],
   "source": [
    "# Create a system message, for instance, to indicate that a user has joined the chat\n",
    "system_msg = ChatMessage.from_system(content=\"A new user has joined the chat.\")\n",
    "\n",
    "print(system_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatMessage(content='Retrieving weather data...', role=<ChatRole.FUNCTION: 'function'>, name='fetch_weather', metadata={})\n"
     ]
    }
   ],
   "source": [
    "# Create a function message, for example, to execute a command to retrieve weather data\n",
    "function_msg = ChatMessage.from_function(content=\"Retrieving weather data...\", name=\"fetch_weather\")\n",
    "\n",
    "print(function_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's populate a Document object with a ChatMessage object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'740dcdab24b6c171e89af1f1158056d6f09c6cd238a39866dfe7160a47eeba9a'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_message_doct = Document(content = user_msg)\n",
    "\n",
    "user_message_doct.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessage(content='Can you show me the weather forecast?', role=<ChatRole.USER: 'user'>, name=None, metadata={})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_message_doct.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StreamingChunk  data class\n",
    "\n",
    "The StreamingChunk class is designed to manage segments of streamed content, which could be part of a larger message or data transfer in a streaming context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.preview.dataclasses import StreamingChunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of how to create an instance of the StreamingChunk data class, which might represent a segment of a live video stream or an ongoing audio broadcast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamingChunk(content='This is the first segment of the live stream.', metadata={'timestamp': '2023-11-08T12:00:00Z', 'stream_id': 'stream123', 'segment_number': 1})\n"
     ]
    }
   ],
   "source": [
    "# Metadata for the streaming chunk\n",
    "stream_metadata = {\n",
    "    \"timestamp\": \"2023-11-08T12:00:00Z\",\n",
    "    \"stream_id\": \"stream123\",\n",
    "    \"segment_number\": 1\n",
    "}\n",
    "\n",
    "# Content of the streaming chunk\n",
    "stream_content = \"This is the first segment of the live stream.\"\n",
    "\n",
    "# Create the StreamingChunk instance\n",
    "streaming_chunk = StreamingChunk(content=stream_content, metadata=stream_metadata)\n",
    "\n",
    "print(streaming_chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate metadata for the StreamingChunk object and capture changes in the stream. We can also store streaming content into Documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'55b3a7072cc30c752c726922b929f073bf377fb72dbe89431c323031cf5360cd'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_document = Document(content = stream_content, meta = stream_metadata)\n",
    "\n",
    "streaming_document.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is the first segment of the live stream.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_document.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `DocumentStore` class \n",
    "\n",
    "The `DocumentStore` class is an internal component of the Haystack library that serves as a registry for classes that are marked as document stores. A document store in Haystack is a place where documents are stored and retrieved, typically used as part of a pipeline to handle data for search and retrieval tasks. \n",
    "\n",
    "Let's begin saving our documents into a DocumentStore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.preview.document_stores.in_memory.document_store import InMemoryDocumentStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our iris dataframe collection of Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='22cf9396b67c1929c273ed65a6fcea5b8ba8b384ae45d5164be9ca7b6827c66c', content=None, dataframe=   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       " 0                5.1               3.5                1.4               0.2   \n",
       " \n",
       "    target  \n",
       " 0     0.0  , blob=None, meta={}, score=None),\n",
       " Document(id='c4852f58c6c65daaa7b11d7c009d8cbf7198c52c55f63fe27bf888beec64b673', content=None, dataframe=   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       " 1                4.9               3.0                1.4               0.2   \n",
       " \n",
       "    target  \n",
       " 1     0.0  , blob=None, meta={}, score=None),\n",
       " Document(id='109c0409cdbcf2343ee97efd3ec334e74e73b5eeed3ecc362cbcff8adda10603', content=None, dataframe=   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       " 2                4.7               3.2                1.3               0.2   \n",
       " \n",
       "    target  \n",
       " 2     0.0  , blob=None, meta={}, score=None),\n",
       " Document(id='3eef63e56ef7174a490478bd4147b70c113521fee93a13f430e14641a330fff3', content=None, dataframe=   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       " 3                4.6               3.1                1.5               0.2   \n",
       " \n",
       "    target  \n",
       " 3     0.0  , blob=None, meta={}, score=None),\n",
       " Document(id='eb5cd52bfc94cfc8fc3f750558e8f13cd9f0f69058994416850cba7c3ed8c895', content=None, dataframe=   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       " 4                5.0               3.6                1.4               0.2   \n",
       " \n",
       "    target  \n",
       " 4     0.0  , blob=None, meta={}, score=None)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_docs[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will initialize an InMemoryDocumentStore and save our documents into it. From its documentation:\n",
    "\n",
    "* Stores data in-memory. It's ephemeral and cannot be saved to disk.\n",
    "* Uses the BM25 algorithm for document search by default.\n",
    "* Useful for testing and quick prototyping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write documents to document store\n",
    "iris_docstore = InMemoryDocumentStore()\n",
    "iris_docstore.write_documents(documents=iris_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting total number of documents in the DocumentStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_docstore.count_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform DocumentStore into dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'InMemoryDocumentStore',\n",
       " 'init_parameters': {'bm25_tokenization_regex': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "  'bm25_algorithm': 'BM25Okapi',\n",
       "  'bm25_parameters': {},\n",
       "  'embedding_similarity_function': 'dot_product'}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_docstore.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we will begin to get familiar with components and pipelines. This will enable us to process the data further, and connect the document store to a retriever and an LLM for data extraction using Natural Language.\n",
    "\n",
    "[Follow next notebook](component.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-pipelines",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
