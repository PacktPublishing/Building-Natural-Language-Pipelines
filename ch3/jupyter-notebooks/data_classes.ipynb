{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building blocks in Haystack: Data classes \n",
    "\n",
    "With Haystack, we can leverage the following built-in data classes: \n",
    "\n",
    "* Haystack Documents data class \n",
    "\n",
    "* Haystack ByteStream data class \n",
    "\n",
    "* Haystack ChatMessage data class \n",
    "\n",
    "* Haystack StreaminhChunk data class \n",
    "\n",
    "Each of these classes act as data structures that can be used to store and process data. We can use these classes to store data in a standardized format, and then use the Haystack API to process the data through data pipelines.\n",
    "\n",
    "In the next section, we will provide examples of each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haystack Documents data class \n",
    "\n",
    "The Document is a foundational data class in Haystack that encapsulates a variety of data types that can be queried, such as text snippets, tables, and binary data.\n",
    "\n",
    "Let's import it and take a look at its functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Document in module haystack.preview.dataclasses.document:\n",
      "\n",
      "class Document(builtins.object)\n",
      " |  Document(*args, **kwargs)\n",
      " |  \n",
      " |  Base data class containing some data to be queried.\n",
      " |  Can contain text snippets, tables, and file paths to images or audios.\n",
      " |  Documents can be sorted by score and saved to/from dictionary and JSON.\n",
      " |  \n",
      " |  :param id: Unique identifier for the document. When not set, it's generated based on the Document fields' values.\n",
      " |  :param content: Text of the document, if the document contains text.\n",
      " |  :param dataframe: Pandas dataframe with the document's content, if the document contains tabular data.\n",
      " |  :param blob: Binary data associated with the document, if the document has any binary data associated with it.\n",
      " |  :param meta: Additional custom metadata for the document. Must be JSON-serializable.\n",
      " |  :param score: Score of the document. Used for ranking, usually assigned by retrievers.\n",
      " |  :param embedding: Vector representation of the document.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Compares Documents for equality.\n",
      " |      Two Documents are considered equals if their dictionary representation is identical.\n",
      " |  \n",
      " |  __init__(self, id: str = '', content: Optional[str] = None, dataframe: Optional[pandas.core.frame.DataFrame] = None, blob: Optional[haystack.preview.dataclasses.byte_stream.ByteStream] = None, meta: Dict[str, Any] = <factory>, score: Optional[float] = None, embedding: Optional[List[float]] = None) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __post_init__(self)\n",
      " |      Generate the ID based on the init parameters.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  to_dict(self, flatten=True) -> Dict[str, Any]\n",
      " |      Converts Document into a dictionary.\n",
      " |      `dataframe` and `blob` fields are converted to JSON-serializable types.\n",
      " |      \n",
      " |      :param flatten: Whether to flatten `meta` field or not. Defaults to `True` to be backward-compatible with Haystack 1.x.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_dict(data: Dict[str, Any]) -> 'Document' from haystack.preview.dataclasses.document._BackwardCompatible\n",
      " |      Creates a new Document object from a dictionary.\n",
      " |      `dataframe` and `blob` fields are converted to their original types.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  content_type\n",
      " |      Returns the type of the content for the document.\n",
      " |      This is necessary to keep backward compatibility with 1.x.\n",
      " |      A ValueError will be raised if both `text` and `dataframe` fields are set\n",
      " |      or both are missing.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'blob': typing.Optional[haystack.preview.dataclasse...\n",
      " |  \n",
      " |  __dataclass_fields__ = {'blob': Field(name='blob',type=typing.Optional...\n",
      " |  \n",
      " |  __dataclass_params__ = _DataclassParams(init=True,repr=True,eq=True,or...\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __match_args__ = ('id', 'content', 'dataframe', 'blob', 'meta', 'score...\n",
      " |  \n",
      " |  blob = None\n",
      " |  \n",
      " |  content = None\n",
      " |  \n",
      " |  dataframe = None\n",
      " |  \n",
      " |  embedding = None\n",
      " |  \n",
      " |  id = ''\n",
      " |  \n",
      " |  score = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from haystack.preview.dataclasses import Document\n",
    "\n",
    "help(Document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `help` function lets us see what parameters it accepts. \n",
    "\n",
    "### Let's create a simple Document object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id='ca53157e450d009adb4c2217111faadc9e7c02aefb22717c4901e1c1c1ba314a', content='This is a simple document', dataframe=None, blob=None, meta={'name': 'test_doc'}, score=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_document = Document(content=\"This is a simple document\", meta={\"name\": \"test_doc\"})\n",
    "sample_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ca53157e450d009adb4c2217111faadc9e7c02aefb22717c4901e1c1c1ba314a'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_document.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that an id was automatically generated for the document. Let's create a dataframe-based document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a simple document'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_document.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'test_doc'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_document.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a dataframe-based Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups, load_iris\n",
    "\n",
    "# Load some example data\n",
    "iris_df = load_iris(as_frame=True)[\"frame\"]\n",
    "news_df = pd.DataFrame(fetch_20newsgroups(subset=\"train\").data, columns=[\"text\"])\n",
    "\n",
    "# Save each row as a Document Object\n",
    "iris_docs = [Document(dataframe=row.to_frame().T) for _, row in iris_df.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that each row was converted into a Document object, each with its own id. Let's access the first Document  and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id='22cf9396b67c1929c273ed65a6fcea5b8ba8b384ae45d5164be9ca7b6827c66c', content=None, dataframe=   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  , blob=None, meta={}, score=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22cf9396b67c1929c273ed65a6fcea5b8ba8b384ae45d5164be9ca7b6827c66c'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_docs[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_docs[0].dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a ByteStream-based data structure\n",
    "\n",
    "The ByteStream class in Haystack represents a binary object that can be used within the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.preview.dataclasses import  ByteStream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'binary_data' is your binary data, for example, read from a file:\n",
    "binary_data = b'Your binary data here'  # This could be the actual binary content, such as PDF or image data\n",
    "\n",
    "# Convert binary data to ByteStream object\n",
    "binary_blob = ByteStream(data=binary_data, mime_type='application/pdf')  # MIME type should match your data\n",
    "binary_document = Document(blob=binary_blob, meta={\"file_name\": \"example.pdf\", \"file_type\": \"PDF\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ByteStream(data=b'Your binary data here', metadata={}, mime_type='application/pdf')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_document.blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'93c323201fc3b8509e51056dff8baee6ca9dec1c22cf2ce2f6cfc0bb04397c14'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_document.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a ChatMessage Document\n",
    "\n",
    "ChatMessage comes built in with the following roles\n",
    "\n",
    "```python\n",
    "class ChatRole(str, Enum):\n",
    "    \"\"\"Enumeration representing the roles within a chat.\"\"\"\n",
    "\n",
    "    ASSISTANT = \"assistant\"\n",
    "    USER = \"user\"\n",
    "    SYSTEM = \"system\"\n",
    "    FUNCTION = \"function\"\n",
    "```\n",
    "\n",
    "These can be mapped to the roles present in OpenAI's GPT models. \n",
    "\n",
    "Read more https://help.openai.com/en/articles/7042661-chatgpt-api-transition-guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ChatMessage in module haystack.preview.dataclasses.chat_message:\n",
      "\n",
      "class ChatMessage(builtins.object)\n",
      " |  ChatMessage(content: str, role: haystack.preview.dataclasses.chat_message.ChatRole, name: Optional[str], metadata: Dict[str, Any] = <factory>) -> None\n",
      " |  \n",
      " |  Represents a message in a LLM chat conversation.\n",
      " |  \n",
      " |  :param content: The text content of the message.\n",
      " |  :param role: The role of the entity sending the message.\n",
      " |  :param name: The name of the function being called (only applicable for role FUNCTION).\n",
      " |  :param metadata: Additional metadata associated with the message.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __init__(self, content: str, role: haystack.preview.dataclasses.chat_message.ChatRole, name: Optional[str], metadata: Dict[str, Any] = <factory>) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  is_from(self, role: haystack.preview.dataclasses.chat_message.ChatRole) -> bool\n",
      " |      Check if the message is from a specific role.\n",
      " |      \n",
      " |      :param role: The role to check against.\n",
      " |      :return: True if the message is from the specified role, False otherwise.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_assistant(content: str, metadata: Optional[Dict[str, Any]] = None) -> 'ChatMessage' from builtins.type\n",
      " |      Create a message from the assistant.\n",
      " |      \n",
      " |      :param content: The text content of the message.\n",
      " |      :param metadata: Additional metadata associated with the message.\n",
      " |      :return: A new ChatMessage instance.\n",
      " |  \n",
      " |  from_function(content: str, name: str) -> 'ChatMessage' from builtins.type\n",
      " |      Create a message from a function call.\n",
      " |      \n",
      " |      :param content: The text content of the message.\n",
      " |      :param name: The name of the function being called.\n",
      " |      :return: A new ChatMessage instance.\n",
      " |  \n",
      " |  from_system(content: str) -> 'ChatMessage' from builtins.type\n",
      " |      Create a message from the system.\n",
      " |      \n",
      " |      :param content: The text content of the message.\n",
      " |      :return: A new ChatMessage instance.\n",
      " |  \n",
      " |  from_user(content: str) -> 'ChatMessage' from builtins.type\n",
      " |      Create a message from the user.\n",
      " |      \n",
      " |      :param content: The text content of the message.\n",
      " |      :return: A new ChatMessage instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'content': <class 'str'>, 'metadata': typing.Dict[s...\n",
      " |  \n",
      " |  __dataclass_fields__ = {'content': Field(name='content',type=<class 's...\n",
      " |  \n",
      " |  __dataclass_params__ = _DataclassParams(init=True,repr=True,eq=True,or...\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __match_args__ = ('content', 'role', 'name', 'metadata')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from haystack.preview.dataclasses import ChatMessage\n",
    "\n",
    "help(ChatMessage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatMessage(content='Hello, how can I assist you today?', role=<ChatRole.ASSISTANT: 'assistant'>, name=None, metadata={})\n",
      "ChatMessage(content='Can you show me the weather forecast?', role=<ChatRole.USER: 'user'>, name=None, metadata={})\n",
      "ChatMessage(content='A new user has joined the chat.', role=<ChatRole.SYSTEM: 'system'>, name=None, metadata={})\n",
      "ChatMessage(content='Retrieving weather data...', role=<ChatRole.FUNCTION: 'function'>, name='fetch_weather', metadata={})\n"
     ]
    }
   ],
   "source": [
    "# Create a message from the assistant\n",
    "assistant_msg = ChatMessage.from_assistant(content=\"Hello, how can I assist you today?\")\n",
    "\n",
    "# Create a message from the user\n",
    "user_msg = ChatMessage.from_user(content=\"Can you show me the weather forecast?\")\n",
    "\n",
    "# Create a system message, for instance, to indicate that a user has joined the chat\n",
    "system_msg = ChatMessage.from_system(content=\"A new user has joined the chat.\")\n",
    "\n",
    "# Create a function message, for example, to execute a command to retrieve weather data\n",
    "function_msg = ChatMessage.from_function(content=\"Retrieving weather data...\", name=\"fetch_weather\")\n",
    "\n",
    "print(assistant_msg)\n",
    "print(user_msg)\n",
    "print(system_msg)\n",
    "print(function_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'740dcdab24b6c171e89af1f1158056d6f09c6cd238a39866dfe7160a47eeba9a'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_message_doct = Document(content = user_msg)\n",
    "\n",
    "user_message_doct.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessage(content='Can you show me the weather forecast?', role=<ChatRole.USER: 'user'>, name=None, metadata={})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_message_doct.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StreamingChunk  data class\n",
    "\n",
    "The StreamingChunk class is designed to manage segments of streamed content, which could be part of a larger message or data transfer in a streaming context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.preview.dataclasses import StreamingChunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class StreamingChunk in module haystack.preview.dataclasses.streaming_chunk:\n",
      "\n",
      "class StreamingChunk(builtins.object)\n",
      " |  StreamingChunk(content: str, metadata: Dict[str, Any] = <factory>) -> None\n",
      " |  \n",
      " |  The StreamingChunk class encapsulates a segment of streamed content along with\n",
      " |  associated metadata. This structure facilitates the handling and processing of\n",
      " |  streamed data in a systematic manner.\n",
      " |  \n",
      " |  :param content: The content of the message chunk as a string.\n",
      " |  :param metadata: A dictionary containing metadata related to the message chunk.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __init__(self, content: str, metadata: Dict[str, Any] = <factory>) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'content': <class 'str'>, 'metadata': typing.Dict[s...\n",
      " |  \n",
      " |  __dataclass_fields__ = {'content': Field(name='content',type=<class 's...\n",
      " |  \n",
      " |  __dataclass_params__ = _DataclassParams(init=True,repr=True,eq=True,or...\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __match_args__ = ('content', 'metadata')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(StreamingChunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of how to create an instance of the StreamingChunk data class, which might represent a segment of a live video stream or an ongoing audio broadcast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamingChunk(content='This is the first segment of the live stream.', metadata={'timestamp': '2023-11-08T12:00:00Z', 'stream_id': 'stream123', 'segment_number': 1})\n"
     ]
    }
   ],
   "source": [
    "# Metadata for the streaming chunk\n",
    "stream_metadata = {\n",
    "    \"timestamp\": \"2023-11-08T12:00:00Z\",\n",
    "    \"stream_id\": \"stream123\",\n",
    "    \"segment_number\": 1\n",
    "}\n",
    "\n",
    "# Content of the streaming chunk\n",
    "stream_content = \"This is the first segment of the live stream.\"\n",
    "\n",
    "# Create the StreamingChunk instance\n",
    "streaming_chunk = StreamingChunk(content=stream_content, metadata=stream_metadata)\n",
    "\n",
    "print(streaming_chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate metadata for the StreamingChunk object and capture changes in the stream. We can also store streaming content into Documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'55b3a7072cc30c752c726922b929f073bf377fb72dbe89431c323031cf5360cd'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_document = Document(content = stream_content, meta = stream_metadata)\n",
    "\n",
    "streaming_document.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is the first segment of the live stream.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_document.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `DocumentStore` class \n",
    "\n",
    "The `DocumentStore` class is an internal component of the Haystack library that serves as a registry for classes that are marked as document stores. A document store in Haystack is a place where documents are stored and retrieved, typically used as part of a pipeline to handle data for search and retrieval tasks. \n",
    "\n",
    "Let's begin saving our documents into a DocumentStore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.preview.document_stores.in_memory.document_store import InMemoryDocumentStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our iris dataframe collection of Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='22cf9396b67c1929c273ed65a6fcea5b8ba8b384ae45d5164be9ca7b6827c66c', content=None, dataframe=   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       " 0                5.1               3.5                1.4               0.2   \n",
       " \n",
       "    target  \n",
       " 0     0.0  , blob=None, meta={}, score=None),\n",
       " Document(id='c4852f58c6c65daaa7b11d7c009d8cbf7198c52c55f63fe27bf888beec64b673', content=None, dataframe=   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       " 1                4.9               3.0                1.4               0.2   \n",
       " \n",
       "    target  \n",
       " 1     0.0  , blob=None, meta={}, score=None),\n",
       " Document(id='109c0409cdbcf2343ee97efd3ec334e74e73b5eeed3ecc362cbcff8adda10603', content=None, dataframe=   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       " 2                4.7               3.2                1.3               0.2   \n",
       " \n",
       "    target  \n",
       " 2     0.0  , blob=None, meta={}, score=None),\n",
       " Document(id='3eef63e56ef7174a490478bd4147b70c113521fee93a13f430e14641a330fff3', content=None, dataframe=   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       " 3                4.6               3.1                1.5               0.2   \n",
       " \n",
       "    target  \n",
       " 3     0.0  , blob=None, meta={}, score=None),\n",
       " Document(id='eb5cd52bfc94cfc8fc3f750558e8f13cd9f0f69058994416850cba7c3ed8c895', content=None, dataframe=   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       " 4                5.0               3.6                1.4               0.2   \n",
       " \n",
       "    target  \n",
       " 4     0.0  , blob=None, meta={}, score=None)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_docs[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will initialize an InMemoryDocumentStore and save our documents into it. From its documentation:\n",
    "\n",
    "* Stores data in-memory. It's ephemeral and cannot be saved to disk.\n",
    "* Uses the BM25 algorithm for document search by default.\n",
    "* Useful for testing and quick prototyping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class InMemoryDocumentStore in module haystack.preview.document_stores.in_memory.document_store:\n",
      "\n",
      "class InMemoryDocumentStore(builtins.object)\n",
      " |  InMemoryDocumentStore(bm25_tokenization_regex: str = '(?u)\\\\b\\\\w\\\\w+\\\\b', bm25_algorithm: Literal['BM25Okapi', 'BM25L', 'BM25Plus'] = 'BM25Okapi', bm25_parameters: Optional[Dict] = None, embedding_similarity_function: Literal['dot_product', 'cosine'] = 'dot_product')\n",
      " |  \n",
      " |  Stores data in-memory. It's ephemeral and cannot be saved to disk.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, bm25_tokenization_regex: str = '(?u)\\\\b\\\\w\\\\w+\\\\b', bm25_algorithm: Literal['BM25Okapi', 'BM25L', 'BM25Plus'] = 'BM25Okapi', bm25_parameters: Optional[Dict] = None, embedding_similarity_function: Literal['dot_product', 'cosine'] = 'dot_product')\n",
      " |      Initializes the DocumentStore.\n",
      " |      \n",
      " |      :param bm25_tokenization_regex: The regular expression used to tokenize the text for BM25 retrieval.\n",
      " |      :param bm25_algorithm: The BM25 algorithm to use. One of \"BM25Okapi\", \"BM25L\", or \"BM25Plus\".\n",
      " |      :param bm25_parameters: Parameters for BM25 implementation in a dictionary format.\n",
      " |                              For example: {'k1':1.5, 'b':0.75, 'epsilon':0.25}\n",
      " |                              You can learn more about these parameters by visiting https://github.com/dorianbrown/rank_bm25.\n",
      " |                              By default, no parameters are set.\n",
      " |      :param embedding_similarity_function: The similarity function used to compare Documents embeddings.\n",
      " |                                            One of \"dot_product\" (default) or \"cosine\".\n",
      " |                                            To choose the most appropriate function, look for information about your embedding model.\n",
      " |  \n",
      " |  bm25_retrieval(self, query: str, filters: Optional[Dict[str, Any]] = None, top_k: int = 10, scale_score: bool = False) -> List[haystack.preview.dataclasses.document.Document]\n",
      " |      Retrieves documents that are most relevant to the query using BM25 algorithm.\n",
      " |      \n",
      " |      :param query: The query string.\n",
      " |      :param filters: A dictionary with filters to narrow down the search space.\n",
      " |      :param top_k: The number of top documents to retrieve. Default is 10.\n",
      " |      :param scale_score: Whether to scale the scores of the retrieved documents. Default is False.\n",
      " |      :return: A list of the top_k documents most relevant to the query.\n",
      " |  \n",
      " |  count_documents(self) -> int\n",
      " |      Returns the number of how many documents are present in the DocumentStore.\n",
      " |  \n",
      " |  delete_documents(self, document_ids: List[str]) -> None\n",
      " |      Deletes all documents with matching document_ids from the DocumentStore.\n",
      " |      Fails with `MissingDocumentError` if no document with this id is present in the DocumentStore.\n",
      " |      \n",
      " |      :param object_ids: The object_ids to delete.\n",
      " |  \n",
      " |  embedding_retrieval(self, query_embedding: List[float], filters: Optional[Dict[str, Any]] = None, top_k: int = 10, scale_score: bool = False, return_embedding: bool = False) -> List[haystack.preview.dataclasses.document.Document]\n",
      " |      Retrieves documents that are most similar to the query embedding using a vector similarity metric.\n",
      " |      \n",
      " |      :param query_embedding: Embedding of the query.\n",
      " |      :param filters: A dictionary with filters to narrow down the search space.\n",
      " |      :param top_k: The number of top documents to retrieve. Default is 10.\n",
      " |      :param scale_score: Whether to scale the scores of the retrieved Documents. Default is False.\n",
      " |      :param return_embedding: Whether to return the embedding of the retrieved Documents. Default is False.\n",
      " |      :return: A list of the top_k documents most relevant to the query.\n",
      " |  \n",
      " |  filter_documents(self, filters: Optional[Dict[str, Any]] = None) -> List[haystack.preview.dataclasses.document.Document]\n",
      " |      Returns the documents that match the filters provided.\n",
      " |      \n",
      " |      Filters are defined as nested dictionaries. The keys of the dictionaries can be a logical operator (`\"$and\"`,\n",
      " |      `\"$or\"`, `\"$not\"`), a comparison operator (`\"$eq\"`, `$ne`, `\"$in\"`, `$nin`, `\"$gt\"`, `\"$gte\"`, `\"$lt\"`,\n",
      " |      `\"$lte\"`) or a metadata field name.\n",
      " |      \n",
      " |      Logical operator keys take a dictionary of metadata field names and/or logical operators as value. Metadata\n",
      " |      field names take a dictionary of comparison operators as value. Comparison operator keys take a single value or\n",
      " |      (in case of `\"$in\"`) a list of values as value. If no logical operator is provided, `\"$and\"` is used as default\n",
      " |      operation. If no comparison operator is provided, `\"$eq\"` (or `\"$in\"` if the comparison value is a list) is used\n",
      " |      as default operation.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      filters = {\n",
      " |          \"$and\": {\n",
      " |              \"type\": {\"$eq\": \"article\"},\n",
      " |              \"date\": {\"$gte\": \"2015-01-01\", \"$lt\": \"2021-01-01\"},\n",
      " |              \"rating\": {\"$gte\": 3},\n",
      " |              \"$or\": {\n",
      " |                  \"genre\": {\"$in\": [\"economy\", \"politics\"]},\n",
      " |                  \"publisher\": {\"$eq\": \"nytimes\"}\n",
      " |              }\n",
      " |          }\n",
      " |      }\n",
      " |      # or simpler using default operators\n",
      " |      filters = {\n",
      " |          \"type\": \"article\",\n",
      " |          \"date\": {\"$gte\": \"2015-01-01\", \"$lt\": \"2021-01-01\"},\n",
      " |          \"rating\": {\"$gte\": 3},\n",
      " |          \"$or\": {\n",
      " |              \"genre\": [\"economy\", \"politics\"],\n",
      " |              \"publisher\": \"nytimes\"\n",
      " |          }\n",
      " |      }\n",
      " |      ```\n",
      " |      \n",
      " |      To use the same logical operator multiple times on the same level, logical operators can take a list of\n",
      " |      dictionaries as value.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      filters = {\n",
      " |          \"$or\": [\n",
      " |              {\n",
      " |                  \"$and\": {\n",
      " |                      \"Type\": \"News Paper\",\n",
      " |                      \"Date\": {\n",
      " |                          \"$lt\": \"2019-01-01\"\n",
      " |                      }\n",
      " |                  }\n",
      " |              },\n",
      " |              {\n",
      " |                  \"$and\": {\n",
      " |                      \"Type\": \"Blog Post\",\n",
      " |                      \"Date\": {\n",
      " |                          \"$gte\": \"2019-01-01\"\n",
      " |                      }\n",
      " |                  }\n",
      " |              }\n",
      " |          ]\n",
      " |      }\n",
      " |      ```\n",
      " |      \n",
      " |      :param filters: The filters to apply to the document list.\n",
      " |      :return: A list of Documents that match the given filters.\n",
      " |  \n",
      " |  to_dict(self) -> Dict[str, Any]\n",
      " |      Serializes this store to a dictionary.\n",
      " |  \n",
      " |  write_documents(self, documents: List[haystack.preview.dataclasses.document.Document], policy: haystack.preview.document_stores.protocols.DuplicatePolicy = <DuplicatePolicy.FAIL: 'fail'>) -> None\n",
      " |      Writes (or overwrites) documents into the DocumentStore.\n",
      " |      \n",
      " |      :param documents: A list of documents.\n",
      " |      :param policy: Documents with the same ID count as duplicates. When duplicates are met,\n",
      " |          the DocumentStore can:\n",
      " |           - skip: keep the existing document and ignore the new one.\n",
      " |           - overwrite: remove the old document and write the new one.\n",
      " |           - fail: an error is raised.\n",
      " |      :raises DuplicateError: Exception trigger on duplicate document if `policy=DuplicatePolicy.FAIL`\n",
      " |      :return: None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_dict(data: Dict[str, Any]) -> 'InMemoryDocumentStore' from builtins.type\n",
      " |      Deserializes the store from a dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __haystack_document_store__ = True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(InMemoryDocumentStore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write documents to document store\n",
    "iris_docstore = InMemoryDocumentStore()\n",
    "iris_docstore.write_documents(documents=iris_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting total number of documents in the DocumentStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_docstore.count_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform DocumentStore into dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'InMemoryDocumentStore',\n",
       " 'init_parameters': {'bm25_tokenization_regex': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "  'bm25_algorithm': 'BM25Okapi',\n",
       "  'bm25_parameters': {},\n",
       "  'embedding_similarity_function': 'dot_product'}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_docstore.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we will begin to get familiar with components and pipelines. This will enable us to process the data further, and connect the document store to a retriever and an LLM for data extraction using Natural Language.\n",
    "\n",
    "[Follow next notebook](component.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-pipelines",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
