{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building blocks in Haystack: Data classes \n",
    "\n",
    "When building data pipelines, a core component involved is the use of data structures. With data structures, we can store, manipulate and manage data through code. Having a solid foundation for data structures is key to ease NLP pipeline development, particularly when an LLM is involved.  With Haystack, we can leverage the following built-in data classes: \n",
    "\n",
    "* Data classes to represent Documents\n",
    "\n",
    "* Data classes to represent Byte stream data\n",
    "\n",
    "* Data classes to represent StreamingChunk data\n",
    "\n",
    "* Data classes to represent chat messages \n",
    "\n",
    "* Data classes to represent question and answer data \n",
    "\n",
    "We can store text, dataframe objects and byte stream objects into Documents. \n",
    "\n",
    "![](./images/data-structures.png)\n",
    "\n",
    "Each of these classes act as data structures that can be used to store and process data. We can use these classes to store data in a standardized format, and then use the Haystack API to process the data through data pipelines.\n",
    "\n",
    "In the next section, we will provide examples of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade haystack-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haystack `Document` data class \n",
    "\n",
    "The Document is a foundational data class in Haystack that encapsulates a variety of data types that can be queried, such as text snippets, tables, and binary data.\n",
    "\n",
    "Let's import it and take a look at its functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.dataclasses import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's create a simple Document object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id=ca53157e450d009adb4c2217111faadc9e7c02aefb22717c4901e1c1c1ba314a, content: 'This is a simple document', meta: {'name': 'test_doc'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_document = Document(content=\"This is a simple document\", meta={\"name\": \"test_doc\"})\n",
    "sample_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ca53157e450d009adb4c2217111faadc9e7c02aefb22717c4901e1c1c1ba314a'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_document.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that an id was automatically generated for the document. Let's access the content and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a simple document'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_document.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'test_doc'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_document.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we prefer to  ID, we control the ID by passing it in as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custom_doc_id'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a simple text-based Document with a custom ID\n",
    "sample_document = Document(\n",
    "    content=\"This is a simple document\",\n",
    "    meta={\"name\": \"test_doc\"},\n",
    "    id=\"custom_doc_id\"  \n",
    ")\n",
    "\n",
    "sample_document.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's create a dataframe-based Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load some example data\n",
    "iris_df = load_iris(as_frame=True)[\"frame\"]\n",
    "\n",
    "# Save each row as a Document Object\n",
    "iris_docs = [Document(dataframe=row.to_frame().T) for _, row in iris_df.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that each row was converted into a Document object, each with its own id. Let's access the first Document  and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id=22cf9396b67c1929c273ed65a6fcea5b8ba8b384ae45d5164be9ca7b6827c66c, dataframe: (1, 5))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22cf9396b67c1929c273ed65a6fcea5b8ba8b384ae45d5164be9ca7b6827c66c'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_docs[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_docs[0].dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's create a ByteStream-based data structure\n",
    "\n",
    "The ByteStream class in Haystack represents a binary object that can be used within the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.dataclasses import  ByteStream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read an image file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./images/data-struct2.png\" ,\"rb\") as image:\n",
    "    image_data=image.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we read the image to memory, we can create a `ByteStream` object, a `Document` object and access its attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert binary data to ByteStream object\n",
    "binary_image = ByteStream(data=image_data, mime_type='application/image')  # MIME type should match your data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods we can use\n",
    "\n",
    "* `data` - returns the binary data as a byte string\n",
    "* `from_file_path` - creates a ByteStream object from a file path\n",
    "* `from_string` - creates a ByteStream object from a string\n",
    "* `metadata` - returns the metadata associated with the ByteStream object\n",
    "* `mime_type` - returns the mime type of the ByteStream object\n",
    "* `to_file` - writes the ByteStream object to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the binary data to a `Document` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_document_im = Document(blob=binary_image, meta={\"file_name\": \"data-strcut2.png\", \"file_type\": \"image\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the content of the blob through the data structure properties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02\\xa9\\x00\\x00\\x00'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_document_im.blob.data[0:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'data-strcut2.png', 'file_type': 'image'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_document_im.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d59124d4c7495fdd763dc35e434cd4ae69cb198fed6b75270e388467e1c1688d'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_document_im.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read a PDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./images/Sample PDF.pdf\" ,\"rb\") as pdf:\n",
    "    pdf_data=pdf.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert binary data to ByteStream object\n",
    "binary_pdf = ByteStream(data=pdf_data, mime_type='application/pdf')  # MIME type should match your data\n",
    "binary_document_pdf = Document(blob=binary_pdf, meta={\"file_name\": \"Sample PDF.pdf\", \"file_type\": \"PDF\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'%PDF-1.4\\n%\\xd3\\xeb\\xe9\\xe1\\n1 0 obj\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_document_pdf.blob.data[0:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'Sample PDF.pdf', 'file_type': 'PDF'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_document_pdf.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3165cf5c70a2d635022a6aa264b9fea45a05675d3d632263a7603627b46316c9'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_document_pdf.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking the Document objects\n",
    "\n",
    "The next exercise demonstrates how to rank `Document` objects using the iris dataset as an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recalling the iris_df dataframe\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort the rows by sepal length (cm) in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "131                7.9               3.8                6.4               2.0   \n",
       "135                7.7               3.0                6.1               2.3   \n",
       "122                7.7               2.8                6.7               2.0   \n",
       "117                7.7               3.8                6.7               2.2   \n",
       "118                7.7               2.6                6.9               2.3   \n",
       "\n",
       "     target  \n",
       "131       2  \n",
       "135       2  \n",
       "122       2  \n",
       "117       2  \n",
       "118       2  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df = iris_df.sort_values(by=[\"sepal length (cm)\"], ascending=False)\n",
    "sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id=fefcdfd715c4f2fc66bdab55a84db31b23f30726b6f593acbf432f312f76a832, dataframe: (1, 5), score: 7.7)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's assume we want to use 'sepal length (cm)' as the score for ranking\n",
    "sorted_docs = []\n",
    "for  _, row in sorted_df.iterrows():\n",
    "    doc = Document(\n",
    "        dataframe=row.to_frame().T,\n",
    "        score=row[\"sepal length (cm)\"]  \n",
    "    )\n",
    "    sorted_docs.append(doc)\n",
    "\n",
    "# Let's check the first document\n",
    "sorted_docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id=5063934be73ae00dbddcc65b093948dd6af9bbfd13947c1906509898c0295460, dataframe: (1, 5), score: 4.3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the last document\n",
    "sorted_docs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we learn about components, we'll see how to use the ranker components to rank documents based on a specific metadata field using the score field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the `Documents`: introducing the `DocumentStore` class \n",
    "\n",
    "The `DocumentStore` class is an internal component of the Haystack library that serves as a registry for classes that are marked as document stores. A document store in Haystack is a place where documents are stored and retrieved, typically used as part of a pipeline to handle data for search and retrieval tasks. \n",
    "\n",
    "Let's begin saving our documents into a DocumentStore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores.in_memory.document_store import InMemoryDocumentStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will initialize an InMemoryDocumentStore and save our documents into it. From its documentation:\n",
    "\n",
    "* Stores data in-memory. It's ephemeral and cannot be saved to disk.\n",
    "* Uses the BM25 algorithm for document search by default.\n",
    "* Useful for testing and quick prototyping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write documents to document store\n",
    "sample_docstore = InMemoryDocumentStore()\n",
    "sample_docstore.write_documents(documents=sorted_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting total number of documents in the DocumentStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_docstore.count_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform DocumentStore into dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'haystack.document_stores.in_memory.document_store.InMemoryDocumentStore',\n",
       " 'init_parameters': {'bm25_tokenization_regex': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "  'bm25_algorithm': 'BM25L',\n",
       "  'bm25_parameters': {},\n",
       "  'embedding_similarity_function': 'dot_product'}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_docstore.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the `Document` associated to the blobs with binary data  to the same `DocumentStore`. Let's add the sample `Document` objects to the `DocumentStore`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_docstore.write_documents(documents=[binary_document_im, binary_document_pdf, sample_document])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the new record was added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_docstore.count_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the IDs are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = [item.id for item in sample_docstore.filter_documents()]\n",
    "\n",
    "len(set(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if the data changes over time, like in a chatbot or in an audio or video file?\n",
    "\n",
    "Haystack provides a `ChatMessage` class that can be to represent a chat message. This is useful for chatbots, where the data is constantly changing. It also provides a `StreamingChunk` class that can be used to represent a chunk of data that is streamed in real-time.\n",
    "\n",
    "![](./images/data-struct2.png)\n",
    "\n",
    "Both data structures can be used to enhance the functionality of our LLM based pipelines. Let's take a look at each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's create a `ChatMessage` data structure\n",
    "\n",
    "`ChatMessage` comes built in with the following roles\n",
    "\n",
    "```python\n",
    "class ChatRole(str, Enum):\n",
    "    \"\"\"Enumeration representing the roles within a chat.\"\"\"\n",
    "\n",
    "    ASSISTANT = \"assistant\"\n",
    "    USER = \"user\"\n",
    "    SYSTEM = \"system\"\n",
    "    FUNCTION = \"function\"\n",
    "```\n",
    "\n",
    "These can be mapped to the roles present in OpenAI's GPT models. \n",
    "\n",
    "Read more https://help.openai.com/en/articles/7042661-chatgpt-api-transition-guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.dataclasses import ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatMessage(content='Hello, how can I assist you today?', role=<ChatRole.ASSISTANT: 'assistant'>, name=None, meta={})\n"
     ]
    }
   ],
   "source": [
    "# Create a message from the assistant\n",
    "assistant_msg = ChatMessage.from_assistant(content=\"Hello, how can I assist you today?\")\n",
    "\n",
    "print(assistant_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatMessage(content='Can you show me the weather forecast?', role=<ChatRole.USER: 'user'>, name=None, meta={})\n"
     ]
    }
   ],
   "source": [
    "# Create a message from the user\n",
    "user_msg = ChatMessage.from_user(content=\"Can you show me the weather forecast?\")\n",
    "\n",
    "print(user_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatMessage(content='A new user has joined the chat.', role=<ChatRole.SYSTEM: 'system'>, name=None, meta={})\n"
     ]
    }
   ],
   "source": [
    "# Create a system message, for instance, to indicate that a user has joined the chat\n",
    "system_msg = ChatMessage.from_system(content=\"A new user has joined the chat.\")\n",
    "\n",
    "print(system_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatMessage(content='Retrieving weather data...', role=<ChatRole.FUNCTION: 'function'>, name='fetch_weather', meta={})\n"
     ]
    }
   ],
   "source": [
    "# Create a function message, for example, to execute a command to retrieve weather data\n",
    "function_msg = ChatMessage.from_function(content=\"Retrieving weather data...\", name=\"fetch_weather\")\n",
    "\n",
    "print(function_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `StreamingChunk`  data class\n",
    "\n",
    "Additionally, Haystack provides a `StreamingChunk` class that can be used to represent a segment of streamed content. This is useful for streaming data, such as audio or video, where the data is constantly changing.\n",
    "\n",
    "The `StreamingChunk` class is designed to manage segments of streamed content, which could be part of a larger message or data transfer in a streaming context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.dataclasses import StreamingChunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of how to create an instance of the StreamingChunk data class, which might represent a segment of a live video stream or an ongoing audio broadcast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "StreamingChunk.__init__() got an unexpected keyword argument 'metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m stream_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the first segment of the live stream.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Create the StreamingChunk instance\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m streaming_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mStreamingChunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(streaming_chunk)\n",
      "\u001b[0;31mTypeError\u001b[0m: StreamingChunk.__init__() got an unexpected keyword argument 'metadata'"
     ]
    }
   ],
   "source": [
    "# Metadata for the streaming chunk\n",
    "stream_metadata = {\n",
    "    \"timestamp\": \"2023-11-08T12:00:00Z\",\n",
    "    \"stream_id\": \"stream123\",\n",
    "    \"segment_number\": 1\n",
    "}\n",
    "\n",
    "# Content of the streaming chunk\n",
    "stream_content = \"This is the first segment of the live stream.\"\n",
    "\n",
    "# Create the StreamingChunk instance\n",
    "streaming_chunk = StreamingChunk(content=stream_content, metadata=stream_metadata)\n",
    "\n",
    "print(streaming_chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about data structures to validate responses in a Q&A system?\n",
    "\n",
    "We will now turn our attention to a data structure focused on question and answer systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Answer`, `ExtractedAnswer` and `GeneratedAnswer` data classes\n",
    "\n",
    "These classes can be used as additional tooling when building in natural language processing (NLP) pipelines, particularly in the context of question answering systems.\n",
    "\n",
    "The `Answer`, `ExtractedAnswer`, and `GeneratedAnswer` are data classes in Haystack that represent the structure of answers obtained from different components in a search or question-answering pipeline.\n",
    "\n",
    "![](./images/qa-data-structures.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.dataclasses import Answer, GeneratedAnswer, ExtractedAnswer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Answer` \n",
    "\n",
    "This is a base data class used to encapsulate the answer data along with its associated query and metadata. It's a generic class that can be used in different contexts where an answer object is required.\n",
    "\n",
    "* data: The content of the answer. \n",
    "\n",
    "* query: The original question or query that prompted the answer. \n",
    "\n",
    "* metadata: A dictionary containing any additional information about the answer. \n",
    "\n",
    "Use Cases for `Answer`\n",
    "\n",
    "* As a return type for components that generate answers to a query, ensuring a consistent interface.\n",
    "* To encapsulate answers for further processing in a pipeline, such as ranking or formatting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Protocols cannot be instantiated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assume we have a document that contains the answer to a question\u001b[39;00m\n\u001b[1;32m      2\u001b[0m doc \u001b[38;5;241m=\u001b[39m Document(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBerlin is the capital of Germany.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m123\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mAnswer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBerlin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWhat is the capital of Germany?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m answer\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-pipelines/lib/python3.10/typing.py:1405\u001b[0m, in \u001b[0;36m_no_init_or_replace_init\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_is_protocol:\n\u001b[0;32m-> 1405\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProtocols cannot be instantiated\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1407\u001b[0m \u001b[38;5;66;03m# Already using a custom `__init__`. No need to calculate correct\u001b[39;00m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;66;03m# `__init__` to call. This can lead to RecursionError. See bpo-45121.\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _no_init_or_replace_init:\n",
      "\u001b[0;31mTypeError\u001b[0m: Protocols cannot be instantiated"
     ]
    }
   ],
   "source": [
    "# Assume we have a document that contains the answer to a question\n",
    "doc = Document(content=\"Berlin is the capital of Germany.\", id=\"123\")\n",
    "\n",
    "answer = Answer(data='Berlin',\n",
    "                 query='What is the capital of Germany?',\n",
    "                 meta={})\n",
    "\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ExtractedAnswer` \n",
    "\n",
    "This is a specialized version of the Answer class for scenarios where an answer is extracted from a document. It's typically used in extractive question-answering systems.\n",
    "\n",
    "* data: The text of the answer extracted from a document. \n",
    "\n",
    "* document: The Document object from which the answer was extracted. \n",
    "\n",
    "* probability: A float representing the confidence score of the extracted answer being correct. \n",
    "\n",
    "* start: The start index of the answer in the content of the Document. \n",
    "\n",
    "* end: The end index of the answer in the content of the Document. \n",
    "\n",
    "Use Cases for `ExtractedAnswer`\n",
    "\n",
    "* In extractive QA systems where answers are directly pulled from the content of documents.\n",
    "* When there is a need to trace back the answer to its source for validation or display purposes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ExtractedAnswer.__init__() got an unexpected keyword argument 'start'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# After processing a query, we find the answer and create an ExtractedAnswer object\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m extracted_answer \u001b[38;5;241m=\u001b[39m \u001b[43mExtractedAnswer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBerlin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is the capital of Germany?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocument\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# These objects can then be used to present answers, log results, or further processing\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted Answer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextracted_answer\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with probability \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextracted_answer\u001b[38;5;241m.\u001b[39mprobability\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: ExtractedAnswer.__init__() got an unexpected keyword argument 'start'"
     ]
    }
   ],
   "source": [
    "# After processing a query, we find the answer and create an ExtractedAnswer object\n",
    "extracted_answer = ExtractedAnswer(\n",
    "    data=\"Berlin\",\n",
    "    query=\"What is the capital of Germany?\",\n",
    "    meta={},\n",
    "    document=doc,\n",
    "    score=0.95,\n",
    "    start=0,\n",
    "    end=6\n",
    ")\n",
    "\n",
    "\n",
    "# These objects can then be used to present answers, log results, or further processing\n",
    "print(f\"Extracted Answer: {extracted_answer.data} with probability {extracted_answer.probability}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `GeneratedAnswer` \n",
    "\n",
    "This class is used when an answer is generated by a model, as in generative question-answering systems, and is not a direct excerpt from any document.\n",
    "\n",
    "* data: The generated text of the answer. \n",
    "\n",
    "* documents: A list of Document objects that were used as context or reference to generate the answer. \n",
    "\n",
    "Use Cases for `GeneratedAnswer`\n",
    "\n",
    "* In generative QA systems where answers are composed by the model based on information from multiple documents.\n",
    "* In dialogue systems where the response is generated based on the context provided by previous conversation turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GeneratedAnswer.__init__() got an unexpected keyword argument 'metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# In another scenario, we might have a generated answer, not directly extracted from a specific location in a document\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m generated_answer \u001b[38;5;241m=\u001b[39m \u001b[43mGeneratedAnswer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBerlin is the capital of Germany.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is the capital of Germany?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Answer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerated_answer\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: GeneratedAnswer.__init__() got an unexpected keyword argument 'metadata'"
     ]
    }
   ],
   "source": [
    "# In another scenario, we might have a generated answer, not directly extracted from a specific location in a document\n",
    "generated_answer = GeneratedAnswer(\n",
    "    data=\"Berlin is the capital of Germany.\",\n",
    "    documents=[doc],\n",
    "    query=\"What is the capital of Germany?\",\n",
    "    metadata={},\n",
    ")\n",
    "\n",
    "print(f\"Generated Answer: {generated_answer.data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we will begin to get familiar with components and pipelines. This will enable us to process the data further, and connect the document store to a retriever and an LLM for data extraction using Natural Language.\n",
    "\n",
    "[Follow next notebook](components.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-pipelines",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
