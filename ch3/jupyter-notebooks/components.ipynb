{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building blocks in Haystack: components and pipelines\n",
    "\n",
    "In the [previous notebook](data_classes.ipynb), we learned how we can store structured and unstructured data through Documents objects, as well as dataframe, ByteStream, ChatMessage and StreamingChunk objects. We also learned how to store these objects into a Document Store. In this notebook, we will explore how to store and retrieve data from a Haystack Document store. Let's take a look at its architecture.\n",
    "\n",
    "Haystack's architecture leverages components as its core elements, each performing specific functions like text processing or summarization. These components are designed to be connected into pipelines, which orchestrate the flow of data and manage task execution in a structured manner. The Pipeline class facilitates this by allowing the addition and connection of components, which must have unique input and output points for data transfer.\n",
    "\n",
    "Pipelines are the backbone of NLP applications in Haystack, functioning as directed graphs where nodes are components and edges dictate data flow. They ensure smooth data processing, handle errors, and support debugging through visualization tools that help developers trace and optimize the data journey.\n",
    "\n",
    "Haystack emphasizes modularity and flexibility, providing a range of pre-built components while also supporting custom ones for specific needs. The framework's pipelines enable the assembly of sophisticated NLP applications, integrating various functionalities into a cohesive system. In this notebook we will explore key components. In  the pipelines.ipynb notebook we will see how to connect them into pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to components\n",
    "\n",
    "Within Haystack, we can find the following key ready-made components. There are more, but for now we will focus on these as we get started with Haystack's functionality.\n",
    "\n",
    "![](./images/haystack-components.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding components\n",
    "\n",
    "In this example, `docs` is a list of `Document` objects with text content to be embedded. The `OpenAIDocumentEmbedder` is initialized with an OpenAI API key and is used to generate embeddings for each document. The embeddings are then printed out for each document in the `docs` list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAIDocumentEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001609589671716094, 0.005959704983979464]\n",
      "[0.017629027366638184, -0.022774461656808853]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from haystack.preview import Document\n",
    "from haystack.preview.components.embedders import OpenAIDocumentEmbedder\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv(\"./../../.env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# List of documents to embed\n",
    "docs = [Document(content=\"The quick brown fox jumps over the lazy dog.\"), \n",
    "        Document(content=\"To be or not to be, that is the question.\")]\n",
    "\n",
    "# Initialize the embedder with your OpenAI API key\n",
    "document_embedder = OpenAIDocumentEmbedder(api_key=api_key)\n",
    "\"\"\n",
    "# Run the embedder to get embeddings\n",
    "result = document_embedder.run(docs)\n",
    "\n",
    "# Access the embeddings stored in the documents\n",
    "for doc in result['documents']:\n",
    "    print(doc.embedding[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the result data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'documents': [Document(id='2e3218009b01cfc57f865bbf81fa70de81b5ebae02c4cc7092e46ffde03f3c49', content='The quick brown fox jumps over the lazy dog.', dataframe=None, blob=None, meta={}, score=None),\n",
       "  Document(id='63a06e3e867cb70e52a99c00b2de17fe531431c98e7d851268be01d341ea9f20', content='To be or not to be, that is the question.', dataframe=None, blob=None, meta={}, score=None)],\n",
       " 'metadata': {'model': 'text-embedding-ada-002-v2',\n",
       "  'usage': {'prompt_tokens': 22, 'total_tokens': 22}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata shows the model and usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'text-embedding-ada-002-v2',\n",
       " 'usage': {'prompt_tokens': 22, 'total_tokens': 22}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['metadata']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAITextEmbedder\n",
    "\n",
    "In this snippet, `text_embedder` is created with an OpenAI API key and used to generate an embedding for the string \"I love pizza!\". The resulting embedding and associated metadata are then printed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.preview.components.embedders import OpenAITextEmbedder\n",
    "\n",
    "# Initialize the text embedder with your OpenAI API key\n",
    "text_embedder = OpenAITextEmbedder(api_key=api_key)\n",
    "\n",
    "# Text you want to embed\n",
    "text_to_embed = \"I love pizza!\"\n",
    "\n",
    "# Embed the text and print the result\n",
    "result_text= text_embedder.run(text_to_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['embedding', 'metadata'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_text.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can access the embeddings through the embedding key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.017020374536514282, -0.023255806416273117]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_text['embedding'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'text-embedding-ada-002-v2',\n",
       " 'usage': {'prompt_tokens': 4, 'total_tokens': 4}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_text['metadata']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SentenceTransformersDocumentEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695d690b186d49d78023f05d8d6178e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07804739475250244, 0.14989925920963287]\n"
     ]
    }
   ],
   "source": [
    "from haystack.preview.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "\n",
    "# Initialize the document embedder with a model from the Sentence Transformers library\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(model_name_or_path=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "doc_embedder.warm_up()\n",
    "\n",
    "# Create a document to embed\n",
    "doc = Document(content=\"I love pizza!\")\n",
    "\n",
    "# Embed the document and print the embedding\n",
    "result = doc_embedder.run([doc])\n",
    "print(result['documents'][0].embedding[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id='ac2bc369f8115bb5bdee26d31f642520041e731da70d578ef116d3f67ad50c69', content='I love pizza!', dataframe=None, blob=None, meta={}, score=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['documents'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SentenceTransformersTextEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b7466f1f2f4b75b120bb2880ef81e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07804739475250244, 0.14989925920963287]\n"
     ]
    }
   ],
   "source": [
    "from haystack.preview.components.embedders import SentenceTransformersTextEmbedder\n",
    "\n",
    "# Initialize the text embedder with a specific model from Sentence Transformers\n",
    "text_embedder = SentenceTransformersTextEmbedder(model_name_or_path=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# Warm up the model before use\n",
    "text_embedder.warm_up()\n",
    "\n",
    "# Define the text you want to embed\n",
    "text_to_embed = \"I love pizza!\"\n",
    "\n",
    "# Embed the text and retrieve the embedding\n",
    "result = text_embedder.run(text_to_embed)\n",
    "\n",
    "# Print the embedding vector\n",
    "print(result['embedding'][0:2])\n",
    "# Output: List of floats representing the embedded vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['embedding'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing content into a Document Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DocumentWriter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing regular documents\n",
    "\n",
    "We can write `Document` objects into a Document Store using the `DocumentWriter` class. In this example, we create a `DocumentStore` and write a `Document` object into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents written: 2\n"
     ]
    }
   ],
   "source": [
    "from haystack.preview.components.writers import DocumentWriter\n",
    "from haystack.preview.document_stores import InMemoryDocumentStore\n",
    "from haystack.preview.dataclasses import Document\n",
    "\n",
    "# Initialize an in-memory document store\n",
    "doc_store = InMemoryDocumentStore()\n",
    "\n",
    "# Create the DocumentWriter component with the document store\n",
    "document_writer = DocumentWriter(document_store=doc_store)\n",
    "\n",
    "# Define a list of documents to write\n",
    "documents_to_write = [\n",
    "    Document(content=\"Document 1 content\"),\n",
    "    Document(content=\"Document 2 content\"),\n",
    "]\n",
    "\n",
    "# Use the DocumentWriter component to write documents to the store\n",
    "result = document_writer.run(documents=documents_to_write)\n",
    "\n",
    "# Print the number of documents written\n",
    "print(f\"Documents written: {result['documents_written']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_store.count_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='10b329f15a2de8355bd9d538c759c45eb6193f51c7576f310400d14a9475deb8', content='Document 1 content', dataframe=None, blob=None, meta={}, score=None),\n",
       " Document(id='8d5435d9fd98ef235133c6c0bf4977595b69f10683fcc27a31e56fb15a024ff7', content='Document 2 content', dataframe=None, blob=None, meta={}, score=None)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_store.filter_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing embedded documents\n",
    "\n",
    "There may be times in which, either due to the size of the data, or to preserve semantic meaning while leveraging embedding models, that we may want to work with embeddings instead. \n",
    "\n",
    "We can follow the next key steps.\n",
    "\n",
    "* Compute Embeddings: Use either the `OpenAIDocumentEmbedder` or `SentenceTransformersDocumentEmbedder`, or other Haystack embedding model integration, to compute the embeddings for your documents.\n",
    "\n",
    "* Store Embeddings: The computed embeddings are stored in the embedding field of the Document objects.\n",
    "\n",
    "* Write to DocumentStore: Use the DocumentWriter component to write these Document objects, now with embeddings, into a DocumentStore.\n",
    "\n",
    "Here's an example code snippet that demonstrates how to use the SentenceTransformersDocumentEmbedder to write embeddings into a document store:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4306d3edbac04c60b39d2481bd71fc45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'documents_written': 2}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack.preview.document_stores import InMemoryDocumentStore\n",
    "from haystack.preview.components.writers import DocumentWriter\n",
    "from haystack.preview.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.preview.dataclasses import Document\n",
    "\n",
    "# Initialize document store and components\n",
    "doc_store = InMemoryDocumentStore()\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(model_name_or_path=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "document_writer = DocumentWriter(document_store=doc_store)\n",
    "\n",
    "# Example document\n",
    "documents = [\n",
    "    Document(content=\"The quick brown fox jumps over the lazy dog.\"),\n",
    "    Document(content=\"When it comes to natural language processing, context is key.\")\n",
    "]\n",
    "\n",
    "# Warm up the embedder and compute embeddings\n",
    "doc_embedder.warm_up()\n",
    "embedded_docs = doc_embedder.run(documents)['documents']\n",
    "\n",
    "# Write documents with embeddings to the document store\n",
    "document_writer.run(documents=embedded_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the document content and their embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: 2e3218009b01cfc57f865bbf81fa70de81b5ebae02c4cc7092e46ffde03f3c49\n",
      "Content: The quick brown fox jumps over the lazy dog.\n",
      "Embedding: [-0.03429264575242996, -0.0013394346460700035, 0.004336129408329725, -0.0018683503149077296, 0.025440821424126625]...\n",
      "\n",
      "\n",
      "Document ID: 8baba41960a8807c42da6783a39dbbf50873f9700ff861844ec8ccce65d4f50e\n",
      "Content: When it comes to natural language processing, context is key.\n",
      "Embedding: [0.049897201359272, -0.023004200309515, -0.03653186932206154, 0.05246769264340401, -0.01983010210096836]...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve all documents\n",
    "all_documents = doc_store.filter_documents()\n",
    "\n",
    "# Print details of each document, including the embedding if it exists\n",
    "for doc in all_documents:\n",
    "    print(f\"Document ID: {doc.id}\")\n",
    "    print(f\"Content: {doc.content}\")\n",
    "    if doc.embedding:\n",
    "        print(f\"Embedding: {doc.embedding[:5]}...\")  # Displaying first 5 values of the embedding for brevity\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-pipelines",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
