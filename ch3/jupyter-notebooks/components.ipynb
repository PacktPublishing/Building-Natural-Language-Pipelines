{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2789ce48",
   "metadata": {},
   "source": [
    "# Exploring Haystack Components: A Pedagogical Walkthrough\n",
    "This notebook demonstrates how to use Haystack's core components for document cleaning, splitting, prompt building, and LLM generation. Each step is explained with code and commentary to help you understand the pipeline construction process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a181b4a5",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "We start by loading environment variables (such as API keys) from a `.env` file. This is a best practice for keeping sensitive information out of your codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b083fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from.env file\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "# You can now access the API key using os.getenv\n",
    "# openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a7659",
   "metadata": {},
   "source": [
    "## 2. Creating Documents\n",
    "We use Haystack's `Document` class to represent pieces of text along with optional metadata. This is the basic unit that flows through Haystack pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b6978c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document(id=5dd82d78fe24f63940aee355fb069d6d2fc21c48b9a8ac14bc6ee12611c68f45, content: 'Haystack   is an open-source framework for building     search systems.', meta: {'source': 'haystack_docs', 'author': 'deepset'})\n"
     ]
    }
   ],
   "source": [
    "# Import the Document class from Haystack's data structures\n",
    "from haystack.dataclasses import Document\n",
    "\n",
    "# Create a list of Document objects\n",
    "# Each Document has 'content' (the text) and optional 'meta' (a dictionary for metadata)\n",
    "documents =[\n",
    "    Document(\n",
    "        content=\"Haystack   is an open-source framework for building     search systems.\",\n",
    "        meta={\"source\": \"haystack_docs\", \"author\": \"deepset\"},\n",
    "    ),\n",
    "    Document(\n",
    "        content=\"Transformers     provide state-of-the-art natural     language processing capabilities.\",\n",
    "        meta={\"source\": \"transformers_docs\", \"author\": \"huggingface\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Print the content of the first document to verify\n",
    "print(documents[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722ecb40",
   "metadata": {},
   "source": [
    "## 3. Cleaning Documents\n",
    "Text data is often messy. The `DocumentCleaner` component helps by removing empty lines and extra whitespace, making the text easier to process in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7212bb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original unclean document content:\n",
      "'Transformers     provide state-of-the-art natural     language processing capabilities.'\n",
      "\n",
      "Cleaned document content:\n",
      "'Transformers provide state-of-the-art natural language processing capabilities.'\n"
     ]
    }
   ],
   "source": [
    "# Import the DocumentCleaner component\n",
    "from haystack.components.preprocessors import DocumentCleaner\n",
    "\n",
    "# 1. Initialize the DocumentCleaner\n",
    "# We can configure its behavior with parameters. Here, we're telling it to:\n",
    "# - remove_empty_lines: Delete lines that contain only whitespace.\n",
    "# - remove_extra_whitespaces: Collapse multiple whitespace characters into a single space.\n",
    "cleaner = DocumentCleaner(remove_empty_lines=True, remove_extra_whitespaces=True)\n",
    "\n",
    "# 2. Run the component\n",
    "# The.run() method takes a list of documents as input under the 'documents' key.\n",
    "# It returns a dictionary where the cleaned documents are under the 'documents' key.\n",
    "result = cleaner.run(documents=documents)\n",
    "cleaned_documents = result[\"documents\"]\n",
    "\n",
    "# Let's inspect the content of the third document, which was messy before.\n",
    "print(\"Original unclean document content:\")\n",
    "print(f\"'{documents[1].content}'\")\n",
    "\n",
    "print(\"\\nCleaned document content:\")\n",
    "print(f\"'{cleaned_documents[1].content}'\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453a700c",
   "metadata": {},
   "source": [
    "## 4. Splitting Documents into Chunks\n",
    "Long documents are often split into smaller chunks for processing by language models. The `DocumentSplitter` component allows you to break up text by word count, character count, or other strategies, with optional overlap for context retention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a95173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original document had 2 document(s).\n",
      "After splitting, we have 5 documents (chunks).\n",
      "\n",
      "Chunks from the first document:\n",
      "- 'Transformers provide state-of-the-art natural language '\n",
      "- 'natural language processing capabilities.'\n"
     ]
    }
   ],
   "source": [
    "# Import the DocumentSplitter component\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "\n",
    "# 1. Initialize the DocumentSplitter\n",
    "# - split_by=\"word\": We want to split the text based on word count.\n",
    "# - split_length=5: Each chunk should have a maximum of 5 words.\n",
    "# - split_overlap=2: Each chunk will share the last 2 words of the previous chunk.\n",
    "splitter = DocumentSplitter(split_by=\"word\", split_length=5, split_overlap=2)\n",
    "\n",
    "\n",
    "# 2. Run the component on our cleaned documents\n",
    "result = splitter.run(documents=cleaned_documents)\n",
    "split_documents = result[\"documents\"]\n",
    "\n",
    "# Let's see how the first document was split\n",
    "print(f\"Original document had {len(cleaned_documents)} document(s).\")\n",
    "print(f\"After splitting, we have {len(split_documents)} documents (chunks).\")\n",
    "\n",
    "print(\"\\nChunks from the first document:\")\n",
    "for doc in split_documents:\n",
    "    # We can check the metadata to see which original document a chunk came from\n",
    "    if doc.meta['source'] == \"transformers_docs\":\n",
    "        print(f\"- '{doc.content}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9927966b",
   "metadata": {},
   "source": [
    "## 5. Building Prompts for LLMs\n",
    "Prompt engineering is crucial for getting good results from language models. The `PromptBuilder` component uses Jinja2 templates to dynamically construct prompts from your data and questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07595253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PromptBuilder has 2 prompt variables, but `required_variables` is not set. By default, all prompt variables are treated as optional, which may lead to unintended behavior in multi-branch pipelines. To avoid unexpected execution, ensure that variables intended to be required are explicitly set in `required_variables`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the following question based on the provided context.\n",
      "\n",
      "Context:\n",
      "\n",
      "- Haystack is an open-source framework \n",
      "\n",
      "- open-source framework for building search \n",
      "\n",
      "- building search systems.\n",
      "\n",
      "- Transformers provide state-of-the-art natural language \n",
      "\n",
      "- natural language processing capabilities.\n",
      "\n",
      "\n",
      "Question: What is the climate like in Islamabad?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "# Import the PromptBuilder component\n",
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "# 1. Define a Jinja2 template string\n",
    "# Placeholders are enclosed in double curly braces, like {{ query }} and {{ documents }}.\n",
    "# Jinja2 also supports control structures like for-loops.\n",
    "prompt_template = \"\"\"\n",
    "Answer the following question based on the provided context.\n",
    "\n",
    "Context:\n",
    "{% for doc in documents %}\n",
    "- {{ doc.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{ query }}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# 2. Initialize the PromptBuilder with the template\n",
    "prompt_builder = PromptBuilder(template=prompt_template)\n",
    "\n",
    "# 3. Run the component\n",
    "# We provide the values for the placeholders ('documents' and 'query') as keyword arguments.\n",
    "# The component will render the template into a single string.\n",
    "result = prompt_builder.run(\n",
    "    query=\"What is the climate like in Islamabad?\",\n",
    "    documents=split_documents  # Using the chunks from the previous step\n",
    ")\n",
    "\n",
    "# The final, rendered prompt is in the 'prompt' key of the output dictionary\n",
    "final_prompt = result[\"prompt\"]\n",
    "\n",
    "print(final_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029cbefd",
   "metadata": {},
   "source": [
    "## 6. Generating Answers with an LLM\n",
    "Finally, we use the `OpenAIGenerator` component to send our prompt to a language model (like GPT-4) and receive a generated answer. This step requires an API key and internet access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60146a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Reply:\n",
      "['The provided context does not contain any information regarding the climate in Islamabad. Therefore, I cannot answer that question based on the given context.']\n",
      "\n",
      "LLM Meta:\n",
      "[{'model': 'gpt-4o-mini-2024-07-18', 'index': 0, 'finish_reason': 'stop', 'usage': {'completion_tokens': 27, 'prompt_tokens': 70, 'total_tokens': 97, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}]\n"
     ]
    }
   ],
   "source": [
    "from haystack.utils import Secret\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "\n",
    "\n",
    "# Check if the API key is available\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "# 1. Initialize the OpenAIGenerator\n",
    "# We provide the API key securely using the Secret class.\n",
    "# We also specify the model we want to use.\n",
    "generator = OpenAIGenerator(\n",
    "    api_key=Secret.from_env_var(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "# 2. Run the component with the prompt from the PromptBuilder\n",
    "# The input key is 'prompt'.\n",
    "result = generator.run(prompt=final_prompt)\n",
    "\n",
    "# The generated text is in a list under the 'replies' key.\n",
    "# The 'meta' key contains additional information like token usage.\n",
    "llm_reply = result[\"replies\"]\n",
    "llm_meta = result[\"meta\"]\n",
    "\n",
    "print(\"LLM Reply:\")\n",
    "print(llm_reply)\n",
    "\n",
    "print(\"\\nLLM Meta:\")\n",
    "print(llm_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536fdccd",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary and Next Steps\n",
    "In this notebook, you learned how to use Haystack components to clean, split, and process documents, build prompts, and generate answers with an LLM. You can now experiment with your own data and templates, or extend the pipeline with more advanced components!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-with-haystack-ch3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
