{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07377961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue from the previous script, assuming 'document_store' is populated.\n",
    "from scripts.indexing import document_store #this runs our indexing pipeline\n",
    "# Import additional components for hybrid retrieval\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack.components.joiners import DocumentJoiner\n",
    "from haystack.components.rankers import TransformersSimilarityRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c3723ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary components for the query pipeline\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.utils import Secret\n",
    "from haystack import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cc72ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TransformersSimilarityRanker is considered legacy and will no longer receive updates. It may be deprecated in a future release, with removal following after a deprecation period. Consider using SentenceTransformersSimilarityRanker instead, which provides the same functionality along with additional features.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Initialize Query Pipeline Components ---\n",
    "\n",
    "# Text Embedder: To embed the user's query. Must be compatible with the document embedder.\n",
    "text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Retriever: Fetches documents from the DocumentStore based on vector similarity.\n",
    "retriever = InMemoryEmbeddingRetriever(document_store=document_store, top_k=3)\n",
    "\n",
    "# PromptBuilder: Creates a prompt using the retrieved documents and the query.\n",
    "# The Jinja2 template iterates through the documents and adds their content to the prompt.\n",
    "prompt_template_for_pipeline = \"\"\"\n",
    "Given the following information, answer the user's question.\n",
    "If the information is not available in the provided documents, say that you don't have enough information to answer.\n",
    "\n",
    "Context:\n",
    "{% for doc in documents %}\n",
    "    {{ doc.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt_builder_inst = PromptBuilder(template=prompt_template_for_pipeline,\n",
    "                                    required_variables=\"*\")\n",
    "llm_generator_inst = OpenAIGenerator(api_key=Secret.from_env_var(\"OPENAI_API_KEY\"), model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "\n",
    "# Sparse Retriever (BM25): For keyword-based search.\n",
    "# This retriever needs to be \"warmed up\" by calculating statistics on the documents in the store.\n",
    "bm25_retriever = InMemoryBM25Retriever(document_store=document_store, top_k=3)\n",
    "\n",
    "# DocumentJoiner: To merge the results from the two retrievers.\n",
    "# The default 'concatenate' mode works well here as the ranker will handle final ordering.\n",
    "document_joiner = DocumentJoiner()\n",
    "\n",
    "# Ranker: A cross-encoder model to re-rank the combined results for higher precision.\n",
    "# This model is highly effective at identifying the most relevant documents from a candidate set.\n",
    "ranker = TransformersSimilarityRanker(model=\"BAAI/bge-reranker-base\", top_k=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db01788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Build the Hybrid RAG Pipeline ---\n",
    "\n",
    "hybrid_rag_pipeline = Pipeline()\n",
    "\n",
    "# Add all necessary components\n",
    "hybrid_rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "hybrid_rag_pipeline.add_component(\"embedding_retriever\", retriever) # Dense retriever\n",
    "hybrid_rag_pipeline.add_component(\"bm25_retriever\", bm25_retriever) # Sparse retriever\n",
    "hybrid_rag_pipeline.add_component(\"document_joiner\", document_joiner)\n",
    "hybrid_rag_pipeline.add_component(\"ranker\", ranker)\n",
    "hybrid_rag_pipeline.add_component(\"prompt_builder\", prompt_builder_inst)\n",
    "hybrid_rag_pipeline.add_component(\"llm\", llm_generator_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e556bc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x330ebb9b0>\n",
       "🚅 Components\n",
       "  - text_embedder: SentenceTransformersTextEmbedder\n",
       "  - embedding_retriever: InMemoryEmbeddingRetriever\n",
       "  - bm25_retriever: InMemoryBM25Retriever\n",
       "  - document_joiner: DocumentJoiner\n",
       "  - ranker: TransformersSimilarityRanker\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "🛤️ Connections\n",
       "  - text_embedder.embedding -> embedding_retriever.query_embedding (list[float])\n",
       "  - embedding_retriever.documents -> document_joiner.documents (list[Document])\n",
       "  - bm25_retriever.documents -> document_joiner.documents (list[Document])\n",
       "  - document_joiner.documents -> ranker.documents (list[Document])\n",
       "  - ranker.documents -> prompt_builder.documents (list[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 3. Connect the Components in a Graph ---\n",
    "\n",
    "# The query is embedded for the dense retriever\n",
    "hybrid_rag_pipeline.connect(\"text_embedder.embedding\", \"embedding_retriever.query_embedding\")\n",
    "\n",
    "# The raw query text is sent to the BM25 retriever and the ranker\n",
    "# Note: The query input for these components is the raw text string.\n",
    "\n",
    "# The outputs of both retrievers are fed into the document joiner\n",
    "hybrid_rag_pipeline.connect(\"embedding_retriever.documents\", \"document_joiner.documents\")\n",
    "hybrid_rag_pipeline.connect(\"bm25_retriever.documents\", \"document_joiner.documents\")\n",
    "\n",
    "# The joined documents are sent to the ranker\n",
    "hybrid_rag_pipeline.connect(\"document_joiner.documents\", \"ranker.documents\")\n",
    "\n",
    "# The ranked documents are sent to the prompt builder\n",
    "hybrid_rag_pipeline.connect(\"ranker.documents\", \"prompt_builder.documents\")\n",
    "\n",
    "# The final prompt is sent to the LLM\n",
    "hybrid_rag_pipeline.connect(\"prompt_builder.prompt\", \"llm.prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24e1e4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid pipeline visualization saved to 'hybrid_rag_pipeline.png'\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Visualize the Pipeline (Optional) ---\n",
    "try:\n",
    "    hybrid_rag_pipeline.draw(path=\"./images/hybrid_rag_pipeline.png\")\n",
    "    print(\"Hybrid pipeline visualization saved to 'hybrid_rag_pipeline.png'\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not draw hybrid pipeline: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da4975a",
   "metadata": {},
   "source": [
    "![](./images/hybrid_rag_pipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4b9b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.69s/it]\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Run the Pipeline ---\n",
    "\n",
    "# A query that benefits from both semantic and keyword matching\n",
    "hybrid_question = \"What is the Haystack 2.0 framework?\"\n",
    "\n",
    "# The run dictionary must now provide inputs for all components at the start of the graph.\n",
    "# The query text needs to be passed to the text_embedder, bm25_retriever, ranker, and prompt_builder.\n",
    "hybrid_result = hybrid_rag_pipeline.run({\n",
    "    \"text_embedder\": {\"text\": hybrid_question},\n",
    "    \"bm25_retriever\": {\"query\": hybrid_question},\n",
    "    \"ranker\": {\"query\": hybrid_question},\n",
    "    \"prompt_builder\": {\"question\": hybrid_question}\n",
    "})\n",
    "\n",
    "print(f\"\\nQuestion: {hybrid_question}\")\n",
    "print(f\"Answer: {hybrid_result['llm']['replies'].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9963e80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-with-haystack-ch4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
