{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building pipelines that perform routing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional routing\n",
    "\n",
    "This example will route the query to different processing paths, such as checking the query length and checking if the query contains specific keywords.\n",
    "\n",
    "Scenario: Keyword Detection Routing:\n",
    "\n",
    "* If the query contains the keyword \"capital\", it routes to a query generation component that fetches city names.\n",
    "* If the query doesn't contain \"capital\", it goes to a general information retrieval system that can provide a broader response.\n",
    "\n",
    "We'll build this example using a conditional router that handles both conditions based on query length and keyword detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x14fbb7f50>\n",
       "ðŸš… Components\n",
       "  - router: ConditionalRouter\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - generator: OpenAIGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - router.capital_related_query -> prompt_builder.query (str)\n",
       "  - prompt_builder.prompt -> generator.prompt (str)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.routers import ConditionalRouter\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from haystack.utils import Secret\n",
    "\n",
    "load_dotenv('.env')\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Example of a pipeline with a ConditionalRouter that routes \n",
    "# queries based on their keyword presence\n",
    "\n",
    "# Define the routes based on query length and keyword check\n",
    "routes = [\n",
    "\n",
    "    {\n",
    "        \"condition\": \"{{'capital' in query}}\",  # Check if the query contains the keyword \"capital\"\n",
    "        \"output\": \"{{query}}\",  # Proceed with the query if \"capital\" is in the query\n",
    "        \"output_name\": \"capital_related_query\",\n",
    "        \"output_type\": str,\n",
    "    },\n",
    "    {\n",
    "        \"condition\": \"{{'capital' not in query}}\",  # Otherwise, handle general queries\n",
    "        \"output\": \"This is a general query: {{query}}\",\n",
    "        \"output_name\": \"general_query\",\n",
    "        \"output_type\": str,\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create the router\n",
    "router = ConditionalRouter(routes=routes)\n",
    "\n",
    "# Create the pipeline with components\n",
    "pipe = Pipeline()\n",
    "\n",
    "# Add the router, prompt builder, document retriever, and generator\n",
    "pipe.add_component(\"router\", router)\n",
    "pipe.add_component(\"prompt_builder\", PromptBuilder(\"Answer the following query: {{query}}\"))\n",
    "pipe.add_component(\"generator\", OpenAIGenerator( api_key= Secret.from_env_var(\"OPENAI_API_KEY\"),\n",
    "))\n",
    "\n",
    "# Connect the components\n",
    "pipe.connect(\"router.capital_related_query\", \"prompt_builder.query\")\n",
    "pipe.connect(\"prompt_builder\", \"generator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'router': {'general_query': 'This is a general query: Berlin'}}\n"
     ]
    }
   ],
   "source": [
    "# Example 1: A short query that triggers a warning\n",
    "result_short = pipe.run(data={\"router\": {\"query\": \"Berlin\"}})\n",
    "print(result_short)\n",
    "# Expected output: {'router': {'short_query_warning': 'Query is too short: Berlin'}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generator': {'replies': ['The capital of France is Paris.'], 'meta': [{'model': 'gpt-4o-mini-2024-07-18', 'index': 0, 'finish_reason': 'stop', 'usage': {'completion_tokens': 7, 'prompt_tokens': 19, 'total_tokens': 26, 'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), 'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0)}}]}}\n"
     ]
    }
   ],
   "source": [
    "# Example 2: A longer query containing the keyword \"capital\"\n",
    "result_long_capital = pipe.run(data={\"router\": {\"query\": \"What is the capital of France?\"}})\n",
    "print(result_long_capital)\n",
    "# Expected output: {'generator': {'replies': ['The capital of France is Paris.']}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'router': {'general_query': 'This is a general query: Tell me about the Eiffel Tower.'}}\n"
     ]
    }
   ],
   "source": [
    "# Example 3: A longer query without the keyword \"capital\"\n",
    "result_long_general = pipe.run(data={\"router\": {\"query\": \"Tell me about the Eiffel Tower.\"}})\n",
    "print(result_long_general)\n",
    "# Expected output: {'generator': {'replies': ['The Eiffel Tower is a famous landmark in Paris.']}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routing based on file type\n",
    "\n",
    "This router is useful for routing different file types (e.g., plain text, PDF, images, audio) to different components based on their MIME types. In this example, we will:\n",
    "\n",
    "Route file paths:\n",
    "Plain text files will be processed using a converter and splitter, while PDF files will be routed separately and converted into documents using a PDF converter.\n",
    "Unclassified files (files that don't match any MIME types provided) will be handled as an \"unclassified\" category.\n",
    "\n",
    "Scenario:\n",
    "We have the following files:\n",
    "\n",
    "* A plain text file: example.txt\n",
    "* An image file: image.jpg\n",
    "\n",
    "\n",
    "The objective is to:\n",
    "\n",
    "* Convert the plain text file into a document.\n",
    "* Skip the image file as it is unclassified and doesn't match any of the specified MIME types.\n",
    "\n",
    "We will use the `FileTypeRouter` to route these files to their respective processing paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x14fc01910>\n",
       "ðŸš… Components\n",
       "  - file_type_router: FileTypeRouter\n",
       "  - text_file_converter: TextFileToDocument\n",
       "  - splitter: DocumentSplitter\n",
       "  - writer: DocumentWriter\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - file_type_router.text/plain -> text_file_converter.sources (List[Union[str, Path, ByteStream]])\n",
       "  - text_file_converter.documents -> splitter.documents (List[Document])\n",
       "  - splitter.documents -> writer.documents (List[Document])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.routers import FileTypeRouter\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.converters import TextFileToDocument\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.components.writers import DocumentWriter\n",
    "\n",
    "# Create an in-memory document store to hold the processed documents\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "# Initialize the pipeline\n",
    "pipeline = Pipeline()\n",
    "\n",
    "# Add the FileTypeRouter that routes only 'text/plain' and 'application/pdf'\n",
    "pipeline.add_component(instance=FileTypeRouter(mime_types=[\"text/plain\", \"application/pdf\"]), name=\"file_type_router\")\n",
    "\n",
    "# Add components for text file conversion and PDF conversion\n",
    "pipeline.add_component(instance=TextFileToDocument(), name=\"text_file_converter\")\n",
    "\n",
    "# Add components for splitting and writing documents\n",
    "pipeline.add_component(instance=DocumentSplitter(), name=\"splitter\")\n",
    "pipeline.add_component(instance=DocumentWriter(document_store=document_store), name=\"writer\")\n",
    "\n",
    "# Connect components in the pipeline\n",
    "pipeline.connect(\"file_type_router.text/plain\", \"text_file_converter.sources\")\n",
    "pipeline.connect(\"text_file_converter.documents\", \"splitter.documents\")\n",
    "pipeline.connect(\"splitter.documents\", \"writer.documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_type_router': {'unclassified': [PosixPath('image.jpeg')]}, 'writer': {'documents_written': 1}}\n"
     ]
    }
   ],
   "source": [
    "# Run the pipeline with a list of file paths\n",
    "result = pipeline.run({\"file_type_router\": {\"sources\": [\"example.txt\", \"image.jpeg\"]}})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routers for text classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.routers import TransformersTextRouter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use case 1: classifying whether a query is a statement or question\n",
    "\n",
    "Using the `shahrukhx01/question-vs-statement-classifier` model from Hugging Face we can classify whether a question is in statement form or query form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurafunderburk/Documents/GitHub/Building-Natural-Language-Pipelines/venvs/dev/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Output Branch</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who was the father of Arya Stark</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lord Eddard was the father of Arya Stark</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>Statement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Query Output Branch      Class\n",
       "0          Who was the father of Arya Stark       LABEL_1   Question\n",
       "1  Lord Eddard was the father of Arya Stark       LABEL_0  Statement"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_router = TransformersTextRouter(model=\"shahrukhx01/question-vs-statement-classifier\")\n",
    "text_router.warm_up()\n",
    "\n",
    "queries = [\n",
    "    \"Who was the father of Arya Stark\",  # Interrogative Query\n",
    "    \"Lord Eddard was the father of Arya Stark\",  # Statement Query\n",
    "]\n",
    "\n",
    "results = {\"Query\": [], \"Output Branch\": [], \"Class\": []}\n",
    "\n",
    "for query in queries:\n",
    "    result = text_router.run(text=query)\n",
    "    results[\"Query\"].append(query)\n",
    "    results[\"Output Branch\"].append(next(iter(result)))\n",
    "    results[\"Class\"].append(\"Question\" if next(iter(result)) == \"LABEL_1\" else \"Statement\")\n",
    "\n",
    "pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment classification\n",
    "\n",
    "Using the `cardiffnlp/twitter-roberta-base-sentiment` model from  HF we will classify sentiments in statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_router = TransformersTextRouter(model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "text_router.warm_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurafunderburk/Documents/GitHub/Building-Natural-Language-Pipelines/venvs/dev/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Output Branch</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What's the answer?</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Would you be so lovely to tell me the answer?</td>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you give me the damn right answer for once??</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Query Output Branch     Class\n",
       "0                                What's the answer?       LABEL_1   neutral\n",
       "1     Would you be so lovely to tell me the answer?       LABEL_2  positive\n",
       "2  Can you give me the damn right answer for once??       LABEL_0  negative"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "queries = [\n",
    "    \"What's the answer?\",  # neutral query\n",
    "    \"Would you be so lovely to tell me the answer?\",  # positive query\n",
    "    \"Can you give me the damn right answer for once??\",  # negative query\n",
    "]\n",
    "\n",
    "sent_results = {\"Query\": [], \"Output Branch\": [], \"Class\": []}\n",
    "\n",
    "for query in queries:\n",
    "    result = text_router.run(text=query)\n",
    "    sent_results[\"Query\"].append(query)\n",
    "    sent_results[\"Output Branch\"].append(next(iter(result)))\n",
    "    sent_results[\"Class\"].append({\"LABEL_0\": \"negative\", \"LABEL_1\": \"neutral\", \"LABEL_2\":\"positive\"}.get(next(iter(result)), \"Unknown\"))\n",
    "\n",
    "pd.DataFrame.from_dict(sent_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Shot Classification with `TransformersZeroShotTextRouter`\n",
    "\n",
    "TransformersZeroShotTextRouter let's you perform zero-shot classification by providing a suitable base transformer model and defining the classes the model should predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.routers import TransformersZeroShotTextRouter\n",
    "\n",
    "text_router = TransformersZeroShotTextRouter(\n",
    "    model=\"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\",\n",
    "    labels=[\"spam\", \"not spam\"])\n",
    "text_router.warm_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Output Branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is an urgent request to transfer funds as...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an urgent request to resolve the a pow...</td>\n",
       "      <td>not spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Query Output Branch\n",
       "0  This is an urgent request to transfer funds as...          spam\n",
       "1  This is an urgent request to resolve the a pow...      not spam"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [\n",
    "    \"This is an urgent request to transfer funds as the CEO is facing an emergency, click on this link to proceed\",  # spam\n",
    "    \"This is an urgent request to resolve the a power outage at the building, please respond as soon as possible\",  # not spam\n",
    "]\n",
    "\n",
    "results = {\"Query\": [], \"Output Branch\": []}\n",
    "\n",
    "for query in queries:\n",
    "    result = text_router.run(text=query)\n",
    "    results[\"Query\"].append(query)\n",
    "    results[\"Output Branch\"].append(next(iter(result)))\n",
    "\n",
    "pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More on routers\n",
    "\n",
    "https://docs.haystack.deepset.ai/docs/routers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP pipelines",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
