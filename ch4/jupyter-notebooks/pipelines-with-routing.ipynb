{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building pipelines that perform routing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional routing\n",
    "\n",
    "This example will route the query to different processing paths, such as checking the query length and checking if the query contains specific keywords.\n",
    "\n",
    "Scenario: Keyword Detection Routing:\n",
    "\n",
    "* If the query contains the keyword \"capital\", it routes to a query generation component that fetches city names.\n",
    "* If the query doesn't contain \"capital\", it goes to a general information retrieval system that can provide a broader response.\n",
    "\n",
    "We'll build this example using a conditional router that handles both conditions based on query length and keyword detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'router': {'general_query': 'This is a general query: Berlin'}}\n",
      "{'generator': {'replies': ['The capital of France is Paris.'], 'meta': [{'model': 'gpt-4o-mini-2024-07-18', 'index': 0, 'finish_reason': 'stop', 'usage': {'completion_tokens': 7, 'prompt_tokens': 19, 'total_tokens': 26, 'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), 'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0)}}]}}\n",
      "{'router': {'general_query': 'This is a general query: Tell me about the Eiffel Tower.'}}\n"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.routers import ConditionalRouter\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from haystack.utils import Secret\n",
    "\n",
    "load_dotenv('.env')\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Example of a pipeline with a ConditionalRouter that routes \n",
    "# queries based on their keyword presence\n",
    "\n",
    "# Define the routes based on query length and keyword check\n",
    "routes = [\n",
    "\n",
    "    {\n",
    "        \"condition\": \"{{'capital' in query}}\",  # Check if the query contains the keyword \"capital\"\n",
    "        \"output\": \"{{query}}\",  # Proceed with the query if \"capital\" is in the query\n",
    "        \"output_name\": \"capital_related_query\",\n",
    "        \"output_type\": str,\n",
    "    },\n",
    "    {\n",
    "        \"condition\": \"{{'capital' not in query}}\",  # Otherwise, handle general queries\n",
    "        \"output\": \"This is a general query: {{query}}\",\n",
    "        \"output_name\": \"general_query\",\n",
    "        \"output_type\": str,\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create the router\n",
    "router = ConditionalRouter(routes=routes)\n",
    "\n",
    "# Create the pipeline with components\n",
    "pipe = Pipeline()\n",
    "\n",
    "# Add the router, prompt builder, document retriever, and generator\n",
    "pipe.add_component(\"router\", router)\n",
    "pipe.add_component(\"prompt_builder\", PromptBuilder(\"Answer the following query: {{query}}\"))\n",
    "pipe.add_component(\"generator\", OpenAIGenerator( api_key= Secret.from_env_var(\"OPENAI_API_KEY\"),\n",
    "))\n",
    "\n",
    "# Connect the components\n",
    "pipe.connect(\"router.capital_related_query\", \"prompt_builder.query\")\n",
    "pipe.connect(\"prompt_builder\", \"generator\")\n",
    "\n",
    "# Example 1: A short query that triggers a warning\n",
    "result_short = pipe.run(data={\"router\": {\"query\": \"Berlin\"}})\n",
    "print(result_short)\n",
    "# Expected output: {'router': {'short_query_warning': 'Query is too short: Berlin'}}\n",
    "\n",
    "# Example 2: A longer query containing the keyword \"capital\"\n",
    "result_long_capital = pipe.run(data={\"router\": {\"query\": \"What is the capital of France?\"}})\n",
    "print(result_long_capital)\n",
    "# Expected output: {'generator': {'replies': ['The capital of France is Paris.']}}\n",
    "\n",
    "# Example 3: A longer query without the keyword \"capital\"\n",
    "result_long_general = pipe.run(data={\"router\": {\"query\": \"Tell me about the Eiffel Tower.\"}})\n",
    "print(result_long_general)\n",
    "# Expected output: {'generator': {'replies': ['The Eiffel Tower is a famous landmark in Paris.']}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routing based on file type\n",
    "\n",
    "This router is useful for routing different file types (e.g., plain text, PDF, images, audio) to different components based on their MIME types. In this example, we will:\n",
    "\n",
    "Route file paths:\n",
    "Plain text files will be processed using a converter and splitter, while PDF files will be routed separately and converted into documents using a PDF converter.\n",
    "Unclassified files (files that don't match any MIME types provided) will be handled as an \"unclassified\" category.\n",
    "\n",
    "Scenario:\n",
    "We have the following files:\n",
    "\n",
    "* A plain text file: example.txt\n",
    "* An image file: image.jpg\n",
    "\n",
    "\n",
    "The objective is to:\n",
    "\n",
    "* Convert the plain text file into a document.\n",
    "* Skip the image file as it is unclassified and doesn't match any of the specified MIME types.\n",
    "\n",
    "We will use the `FileTypeRouter` to route these files to their respective processing paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_type_router': {'unclassified': [PosixPath('image.jpeg')]}, 'writer': {'documents_written': 1}}\n"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.routers import FileTypeRouter\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.converters import TextFileToDocument\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.components.writers import DocumentWriter\n",
    "\n",
    "# Create an in-memory document store to hold the processed documents\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "# Initialize the pipeline\n",
    "pipeline = Pipeline()\n",
    "\n",
    "# Add the FileTypeRouter that routes only 'text/plain' and 'application/pdf'\n",
    "pipeline.add_component(instance=FileTypeRouter(mime_types=[\"text/plain\", \"application/pdf\"]), name=\"file_type_router\")\n",
    "\n",
    "# Add components for text file conversion and PDF conversion\n",
    "pipeline.add_component(instance=TextFileToDocument(), name=\"text_file_converter\")\n",
    "\n",
    "# Add components for splitting and writing documents\n",
    "pipeline.add_component(instance=DocumentSplitter(), name=\"splitter\")\n",
    "pipeline.add_component(instance=DocumentWriter(document_store=document_store), name=\"writer\")\n",
    "\n",
    "# Connect components in the pipeline\n",
    "pipeline.connect(\"file_type_router.text/plain\", \"text_file_converter.sources\")\n",
    "pipeline.connect(\"text_file_converter.documents\", \"splitter.documents\")\n",
    "pipeline.connect(\"splitter.documents\", \"writer.documents\")\n",
    "\n",
    "# Run the pipeline with a list of file paths\n",
    "result = pipeline.run({\"file_type_router\": {\"sources\": [\"example.txt\", \"image.jpeg\"]}})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More on routers\n",
    "\n",
    "https://docs.haystack.deepset.ai/docs/routers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP pipelines",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
