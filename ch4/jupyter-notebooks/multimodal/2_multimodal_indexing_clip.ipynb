{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943e5fa8",
   "metadata": {},
   "source": [
    "**ðŸ”§ Setup Required**: Before running this notebook, please follow the [setup instructions](../../README.md#setup-instructions) to configure your environment and API keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535279d0",
   "metadata": {},
   "source": [
    "# Multimodal Indexing Pipeline with CLIP (Approach 1)\n",
    "\n",
    "This notebook demonstrates how to build a multimodal indexing pipeline using direct image embeddings with CLIP.\n",
    "\n",
    "## Approach 1: Image and Text Embeddings (CLIP)\n",
    "\n",
    "In this approach, we:\n",
    "\n",
    "1. **Route Documents**: Separate PDFs and images\n",
    "2. **Process Text**: Extract and embed text from PDFs\n",
    "3. **Process Images**: Embed images directly using CLIP\n",
    "4. **Store Everything**: Combine and store all embeddings\n",
    "\n",
    "### Advantages:\n",
    "- Fast processing (no LLM calls for images)\n",
    "- Good for image-to-image similarity\n",
    "- Works well with visual queries\n",
    "\n",
    "### Use Cases:\n",
    "- Visual search\n",
    "- Image similarity\n",
    "- Multimodal retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aab21c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9530bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"2_multimodal_indexing_clip.ipynb\")) if os.path.exists(\"2_multimodal_indexing_clip.ipynb\") else os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca0dfa",
   "metadata": {},
   "source": [
    "## Download Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f284cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "\n",
    "# Create SSL context\n",
    "ssl_context = ssl.create_default_context()\n",
    "ssl_context.check_hostname = False\n",
    "ssl_context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "def download_file(url, filename):\n",
    "    \"\"\"Download file with SSL context\"\"\"\n",
    "    req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    with urllib.request.urlopen(req, context=ssl_context) as response:\n",
    "        with open(filename, 'wb') as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "os.makedirs(\"data_for_indexing\", exist_ok=True)\n",
    "\n",
    "# Download images\n",
    "download_file(\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/2/26/Pink_Lady_Apple_%284107712628%29.jpg\",\n",
    "    \"images/apple.jpg\"\n",
    ")\n",
    "\n",
    "# Download PDF\n",
    "download_file(\n",
    "    \"https://arxiv.org/pdf/1706.03762\",\n",
    "    \"data_for_indexing/attention_is_all_you_need.pdf\"\n",
    ")\n",
    "\n",
    "print(\"Data downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f32d63c",
   "metadata": {},
   "source": [
    "## Initialize Pipeline Components\n",
    "\n",
    "We'll create all the components needed for our multimodal pipeline:\n",
    "\n",
    "**Storage**:\n",
    "- `InMemoryDocumentStore`: Stores documents and embeddings with cosine similarity\n",
    "\n",
    "**Routing**:\n",
    "- `FileTypeRouter`: Routes files based on MIME types (PDF vs JPEG)\n",
    "\n",
    "**Conversion**:\n",
    "- `ImageFileToDocument`: Converts images to documents\n",
    "- `PyPDFToDocument`: Extracts text from PDFs\n",
    "\n",
    "**Processing**:\n",
    "- `DocumentSplitter`: Splits PDFs into page-sized chunks\n",
    "- `ImagePathFixer`: Custom component to fix image file paths\n",
    "\n",
    "**Embedding**:\n",
    "- Text embedder for PDF content\n",
    "- Image embedder for images\n",
    "\n",
    "**Storage**:\n",
    "- `DocumentWriter`: Writes processed documents to the store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbba892b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurafunderburk/Documents/GitHub/Building-Natural-Language-Pipelines/ch4/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components initialized!\n"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.converters import PyPDFToDocument\n",
    "from haystack.components.converters.image import ImageFileToDocument\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.components.embedders.image import SentenceTransformersDocumentImageEmbedder\n",
    "from haystack.components.joiners import DocumentJoiner\n",
    "from haystack.components.preprocessors.document_splitter import DocumentSplitter\n",
    "from haystack.components.routers.file_type_router import FileTypeRouter\n",
    "from haystack.components.writers.document_writer import DocumentWriter\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "# Create document store\n",
    "doc_store_clip = InMemoryDocumentStore(embedding_similarity_function=\"cosine\")\n",
    "\n",
    "# Define components\n",
    "file_type_router = FileTypeRouter(mime_types=[\"application/pdf\", \"image/jpeg\"])\n",
    "final_doc_joiner = DocumentJoiner(sort_by_score=False)\n",
    "image_converter = ImageFileToDocument()\n",
    "pdf_converter = PyPDFToDocument()\n",
    "pdf_splitter = DocumentSplitter(split_by=\"page\", split_length=1)\n",
    "text_doc_embedder = SentenceTransformersDocumentEmbedder(\n",
    "    model=\"sentence-transformers/clip-ViT-L-14\",\n",
    "    progress_bar=False\n",
    ")\n",
    "# Don't set root_path - we'll use absolute paths instead\n",
    "image_embedder_clip = SentenceTransformersDocumentImageEmbedder(\n",
    "    model=\"sentence-transformers/clip-ViT-L-14\",\n",
    "    progress_bar=False\n",
    ")\n",
    "document_writer = DocumentWriter(doc_store_clip)\n",
    "\n",
    "print(\"Components initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e1eea6",
   "metadata": {},
   "source": [
    "## Create Custom ImagePathFixer Component\n",
    "\n",
    "The `ImagePathFixer` is crucial because `ImageFileToDocument` only stores the filename, not the full path.\n",
    "This component restores the full absolute path needed for the image embedder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "334372fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom ImagePathFixer component defined!\n"
     ]
    }
   ],
   "source": [
    "from haystack import component\n",
    "from haystack.dataclasses import Document\n",
    "from typing import List\n",
    "import os\n",
    "\n",
    "@component\n",
    "class ImagePathFixer:\n",
    "    \"\"\"\n",
    "    Fixes the file paths in image documents to be absolute paths.\n",
    "    ImageFileToDocument only stores the basename, so we need to restore the full path.\n",
    "    \"\"\"\n",
    "    \n",
    "    @component.output_types(documents=List[Document])\n",
    "    def run(self, documents: List[Document]) -> dict:\n",
    "        \"\"\"Fix the file paths in documents to be absolute.\"\"\"\n",
    "        for doc in documents:\n",
    "            if \"file_path\" in doc.meta:\n",
    "                file_path = doc.meta[\"file_path\"]\n",
    "                # If it's just a filename without directory, assume it's in the images folder\n",
    "                if os.path.basename(file_path) == file_path:\n",
    "                    # Get the notebook directory\n",
    "                    notebook_dir = os.path.dirname(os.path.abspath(\"2_multimodal_indexing_clip.ipynb\")) if os.path.exists(\"2_multimodal_indexing_clip.ipynb\") else os.getcwd()\n",
    "                    doc.meta[\"file_path\"] = os.path.join(notebook_dir, \"images\", file_path)\n",
    "        \n",
    "        return {\"documents\": documents}\n",
    "\n",
    "print(\"Custom ImagePathFixer component defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f016b244",
   "metadata": {},
   "source": [
    "## Build the Indexing Pipeline\n",
    "\n",
    "Now we'll connect all components into a complete indexing pipeline. The flow is:\n",
    "\n",
    "**PDF Branch**:\n",
    "1. File Router â†’ PDF Converter\n",
    "2. PDF Converter â†’ PDF Splitter\n",
    "3. PDF Splitter â†’ Text Embedder\n",
    "\n",
    "**Image Branch**:\n",
    "1. File Router â†’ Image Converter\n",
    "2. Image Converter â†’ Path Fixer (fixes file paths)\n",
    "3. Path Fixer â†’ Image Embedder\n",
    "\n",
    "**Final Steps**:\n",
    "1. Both embedders â†’ Document Joiner\n",
    "2. Document Joiner â†’ Document Writer â†’ Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77bad5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x3131311f0>\n",
       "ðŸš… Components\n",
       "  - file_type_router: FileTypeRouter\n",
       "  - pdf_converter: PyPDFToDocument\n",
       "  - pdf_splitter: DocumentSplitter\n",
       "  - image_converter: ImageFileToDocument\n",
       "  - image_path_fixer: ImagePathFixer\n",
       "  - text_doc_embedder: SentenceTransformersDocumentEmbedder\n",
       "  - image_doc_embedder: SentenceTransformersDocumentImageEmbedder\n",
       "  - final_doc_joiner: DocumentJoiner\n",
       "  - document_writer: DocumentWriter\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - file_type_router.application/pdf -> pdf_converter.sources (list[Union[str, Path, ByteStream]])\n",
       "  - file_type_router.image/jpeg -> image_converter.sources (list[Union[str, Path, ByteStream]])\n",
       "  - pdf_converter.documents -> pdf_splitter.documents (list[Document])\n",
       "  - pdf_splitter.documents -> text_doc_embedder.documents (list[Document])\n",
       "  - image_converter.documents -> image_path_fixer.documents (list[Document])\n",
       "  - image_path_fixer.documents -> image_doc_embedder.documents (List[Document])\n",
       "  - text_doc_embedder.documents -> final_doc_joiner.documents (list[Document])\n",
       "  - image_doc_embedder.documents -> final_doc_joiner.documents (list[Document])\n",
       "  - final_doc_joiner.documents -> document_writer.documents (list[Document])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the indexing pipeline\n",
    "indexing_pipe_clip = Pipeline()\n",
    "indexing_pipe_clip.add_component(\"file_type_router\", file_type_router)\n",
    "indexing_pipe_clip.add_component(\"pdf_converter\", pdf_converter)\n",
    "indexing_pipe_clip.add_component(\"pdf_splitter\", pdf_splitter)\n",
    "indexing_pipe_clip.add_component(\"image_converter\", image_converter)\n",
    "indexing_pipe_clip.add_component(\"image_path_fixer\", ImagePathFixer())  \n",
    "indexing_pipe_clip.add_component(\"text_doc_embedder\", text_doc_embedder)\n",
    "indexing_pipe_clip.add_component(\"image_doc_embedder\", image_embedder_clip)\n",
    "indexing_pipe_clip.add_component(\"final_doc_joiner\", final_doc_joiner)\n",
    "indexing_pipe_clip.add_component(\"document_writer\", document_writer)\n",
    "\n",
    "# Connect components\n",
    "indexing_pipe_clip.connect(\"file_type_router.application/pdf\", \"pdf_converter.sources\")\n",
    "indexing_pipe_clip.connect(\"pdf_converter.documents\", \"pdf_splitter.documents\")\n",
    "indexing_pipe_clip.connect(\"pdf_splitter.documents\", \"text_doc_embedder.documents\")\n",
    "indexing_pipe_clip.connect(\"file_type_router.image/jpeg\", \"image_converter.sources\")\n",
    "indexing_pipe_clip.connect(\"image_converter.documents\", \"image_path_fixer.documents\")  \n",
    "indexing_pipe_clip.connect(\"image_path_fixer.documents\", \"image_doc_embedder.documents\")\n",
    "indexing_pipe_clip.connect(\"text_doc_embedder.documents\", \"final_doc_joiner.documents\")\n",
    "indexing_pipe_clip.connect(\"image_doc_embedder.documents\", \"final_doc_joiner.documents\")\n",
    "indexing_pipe_clip.connect(\"final_doc_joiner.documents\", \"document_writer.documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1655e33a",
   "metadata": {},
   "source": [
    "## Visualize the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42ca807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the pipeline\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "indexing_pipe_clip.draw(path=\"images/multimodal_indexing_clip.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3924752f",
   "metadata": {},
   "source": [
    "![](./images/multimodal_indexing_clip.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0866e475",
   "metadata": {},
   "source": [
    "![](./images/multimodal_indexing_clip.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d62664",
   "metadata": {},
   "source": [
    "## Run the Indexing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d13280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 16 documents\n"
     ]
    }
   ],
   "source": [
    "# Run the indexing pipeline\n",
    "# Use absolute paths to avoid path resolution issues\n",
    "\n",
    "indexing_result = indexing_pipe_clip.run(\n",
    "    data={\"file_type_router\": {\"sources\": [\n",
    "        os.path.join(notebook_dir, \"data_for_indexing/attention_is_all_you_need.pdf\"),\n",
    "        os.path.join(notebook_dir, \"images/apple.jpg\")\n",
    "    ]}}\n",
    ")\n",
    "indexed_documents = doc_store_clip.filter_documents()\n",
    "print(f\"Indexed {len(indexed_documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be59b923",
   "metadata": {},
   "source": [
    "## Inspect the Indexed Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b4187f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1:\n",
      "Type: /Users/laurafunderburk/Documents/GitHub/Building-Natural-Language-Pipelines/ch4/jupyter-notebooks/multimodal/images/apple.jpg\n",
      "Has embedding: True\n",
      "Embedding dimension: 768\n",
      "Content preview: None...\n",
      "\n",
      "Document 2:\n",
      "Type: attention_is_all_you_need.pdf\n",
      "Has embedding: True\n",
      "Embedding dimension: 768\n",
      "Content preview: Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and...\n",
      "\n",
      "Document 3:\n",
      "Type: attention_is_all_you_need.pdf\n",
      "Has embedding: True\n",
      "Embedding dimension: 768\n",
      "Content preview: 1 Introduction\n",
      "Recurrent neural networks, long short-term memory [13] and gated recurrent [7] neural...\n"
     ]
    }
   ],
   "source": [
    "# Check the first few documents\n",
    "for i, doc in enumerate(indexed_documents[:3]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"Type: {doc.meta.get('file_path', 'Unknown')}\")\n",
    "    print(f\"Has embedding: {doc.embedding is not None}\")\n",
    "    if doc.embedding:\n",
    "        print(f\"Embedding dimension: {len(doc.embedding)}\")\n",
    "    print(f\"Content preview: {str(doc.content)[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3bcf1a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. **Built a multimodal indexing pipeline** using CLIP embeddings\n",
    "2. **Processed both PDFs and images** in a single pipeline\n",
    "3. **Created embeddings** for both text and images in a shared space\n",
    "4. **Stored everything** in a document store for later retrieval\n",
    "\n",
    "### Key Advantages of this Approach:\n",
    "- **Fast**: No LLM calls needed for images\n",
    "- **Direct visual understanding**: Images are embedded as-is\n",
    "- **Good for visual queries**: Works well with image-to-image similarity\n",
    "\n",
    "### Limitations:\n",
    "- **Less semantic understanding**: May miss conceptual connections\n",
    "- **Text queries may be less accurate**: Works better with visual queries\n",
    "\n",
    "### Next Steps:\n",
    "- Continue to notebook 3 to see Approach 2 (LLM-based content extraction)\n",
    "- Compare the two approaches for your use case\n",
    "- Build a RAG pipeline using this indexed data (notebook 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-with-haystack-ch4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
