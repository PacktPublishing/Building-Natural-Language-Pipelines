{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a7bc245",
   "metadata": {},
   "source": [
    "ðŸ”§ **Setup Required**: Before running this notebook, please follow the [setup instructions](../README.md#setup-instructions) to configure your environment and API keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee060006",
   "metadata": {},
   "source": [
    "# Building Advanced RAG Systems with Haystack SuperComponents\n",
    "\n",
    "This notebook demonstrates how to build an advanced Retrieval-Augmented Generation (RAG) system using Haystack's SuperComponent feature. We'll cover:\n",
    "\n",
    "1. Setting up a hybrid RAG pipeline with both dense and sparse retrieval\n",
    "2. Creating a SuperComponent for simplified interface\n",
    "3. Building tools from components for agent-based systems\n",
    "4. Implementing a multi-tool agent for complex queries\n",
    "\n",
    "## Prerequisites\n",
    "- Basic understanding of RAG systems\n",
    "- Familiarity with Haystack components\n",
    "- OpenAI API key for LLM access\n",
    "- SerperDev API key for web search capabilities\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you will be able to:\n",
    "- Build a hybrid RAG pipeline combining multiple retrieval methods\n",
    "- Create a SuperComponent to simplify pipeline interfaces\n",
    "- Transform components into tools for agent-based systems\n",
    "- Implement an agent that can use multiple tools for complex queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac1266d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurafunderburk/Documents/GitHub/Building-Natural-Language-Pipelines/ch4/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running unified indexing pipeline for web, local files, and CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error processing document 1384ec36dd6d99f90ab589732d5219b7371dac846d0f0bd89c6385189c4079c0. Keeping it, but skipping cleaning. Error: Error tokenizing data. C error: Expected 5 fields in line 5, saw 7\n",
      "\n",
      "Error processing document 1384ec36dd6d99f90ab589732d5219b7371dac846d0f0bd89c6385189c4079c0. Keeping it, but skipping splitting. Error: Error tokenizing data. C error: Expected 5 fields in line 5, saw 7\n",
      "\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  6.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.indexing import document_store\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f22b0e",
   "metadata": {},
   "source": [
    "## 1. Setting Up Components\n",
    "\n",
    "In this section, we'll set up the core components needed for our hybrid RAG pipeline. We'll use both dense and sparse retrieval methods to achieve better search results:\n",
    "\n",
    "1. **Dense Retrieval**: Uses embeddings to find semantically similar documents\n",
    "   - SentenceTransformersTextEmbedder: Converts text into vector representations\n",
    "   - InMemoryEmbeddingRetriever: Searches for similar vectors in the document store\n",
    "\n",
    "2. **Sparse Retrieval**: Uses keyword matching (BM25 algorithm)\n",
    "   - InMemoryBM25Retriever: Performs traditional keyword-based search\n",
    "\n",
    "3. **Post-processing**:\n",
    "   - DocumentJoiner: Combines results from both retrievers\n",
    "   - SentenceTransformersSimilarityRanker: Re-ranks results for better precision\n",
    "\n",
    "4. **Generation**:\n",
    "   - PromptBuilder: Creates structured prompts with context\n",
    "   - OpenAIGenerator: Generates responses using GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7f43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.utils import Secret\n",
    "from haystack import Pipeline\n",
    "\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack.components.joiners import DocumentJoiner\n",
    "from haystack.components.rankers import SentenceTransformersSimilarityRanker\n",
    "\n",
    "# --- 1. Initialize Query Pipeline Components ---\n",
    "\n",
    "# Text Embedder: To embed the user's query. Must be compatible with the document embedder.\n",
    "text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Retriever: Fetches documents from the DocumentStore based on vector similarity.\n",
    "retriever = InMemoryEmbeddingRetriever(document_store=document_store, top_k=3)\n",
    "\n",
    "# PromptBuilder: Creates a prompt using the retrieved documents and the query.\n",
    "# The Jinja2 template iterates through the documents and adds their content to the prompt.\n",
    "prompt_template_for_pipeline = \"\"\"\n",
    "Given the following information, answer the user's question.\n",
    "If the information is not available in the provided documents, \n",
    "say that you don't have enough information to answer.\n",
    "\n",
    "Context:\n",
    "{% for doc in documents %}\n",
    "    {{ doc.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt_builder_inst = PromptBuilder(template=prompt_template_for_pipeline,\n",
    "                                    required_variables=\"*\")\n",
    "llm_generator_inst = OpenAIGenerator(api_key=Secret.from_env_var(\"OPENAI_API_KEY\"), model=\"gpt-4o-mini\")\n",
    "\n",
    "# optional - if you want to use open source model instead of OpenAI\n",
    "# from haystack.components.generators import HuggingFaceLocalGenerator\n",
    "# llm_generator_inst = HuggingFaceLocalGenerator(model=\"google/flan-t5-large\",\n",
    "#                                       task=\"text2text-generation\",\n",
    "#                                       generation_kwargs={\n",
    "#                                         \"max_new_tokens\": 100,\n",
    "#                                         \"temperature\": 0.9,\n",
    "#                                         })\n",
    "\n",
    "# llm_generator_inst.warm_up()\n",
    "\n",
    "# To use models from Ollama, check https://docs.haystack.deepset.ai/docs/ollamagenerator\n",
    "\n",
    "# Sparse Retriever (BM25): For keyword-based search.\n",
    "# This retriever needs to be \"warmed up\" by calculating statistics on the documents in the store.\n",
    "bm25_retriever = InMemoryBM25Retriever(document_store=document_store, top_k=3)\n",
    "\n",
    "# DocumentJoiner: To merge the results from the two retrievers.\n",
    "# The default 'concatenate' mode works well here as the ranker will handle final ordering.\n",
    "document_joiner = DocumentJoiner()\n",
    "\n",
    "# Ranker: A cross-encoder model to re-rank the combined results for higher precision.\n",
    "# This model is highly effective at identifying the most relevant documents from a candidate set.\n",
    "ranker = SentenceTransformersSimilarityRanker(model=\"BAAI/bge-reranker-base\", top_k=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a628b16",
   "metadata": {},
   "source": [
    "## 2. Building the Hybrid RAG Pipeline\n",
    "\n",
    "A hybrid RAG (Retrieval Augmented Generation) pipeline combines multiple retrieval methods to improve the quality of document search. Here's how we'll build it:\n",
    "\n",
    "1. **Component Creation**:\n",
    "   - Initialize both dense and sparse retrievers\n",
    "   - Set up the document joiner and ranker\n",
    "   - Configure the prompt builder and generator\n",
    "\n",
    "2. **Pipeline Assembly**:\n",
    "   - Chain components together in a logical sequence\n",
    "   - Define how documents flow through the pipeline\n",
    "   - Set parameters for each component\n",
    "\n",
    "3. **Benefits**:\n",
    "   - Better search accuracy by combining methods\n",
    "   - More robust to different types of queries\n",
    "   - Improved context selection for generation\n",
    "\n",
    "The resulting pipeline will provide both semantic understanding and keyword matching capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "942bd06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Build the Hybrid RAG Pipeline ---\n",
    "hybrid_rag_pipeline = Pipeline()\n",
    "\n",
    "# Add all necessary components\n",
    "hybrid_rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "hybrid_rag_pipeline.add_component(\"embedding_retriever\", retriever) # Dense retriever\n",
    "hybrid_rag_pipeline.add_component(\"bm25_retriever\", bm25_retriever) # Sparse retriever\n",
    "hybrid_rag_pipeline.add_component(\"document_joiner\", document_joiner)\n",
    "hybrid_rag_pipeline.add_component(\"ranker\", ranker)\n",
    "hybrid_rag_pipeline.add_component(\"prompt_builder\", prompt_builder_inst)\n",
    "hybrid_rag_pipeline.add_component(\"llm\", llm_generator_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c73c1dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x3c6d6e420>\n",
       "ðŸš… Components\n",
       "  - text_embedder: SentenceTransformersTextEmbedder\n",
       "  - embedding_retriever: InMemoryEmbeddingRetriever\n",
       "  - bm25_retriever: InMemoryBM25Retriever\n",
       "  - document_joiner: DocumentJoiner\n",
       "  - ranker: SentenceTransformersSimilarityRanker\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - text_embedder.embedding -> embedding_retriever.query_embedding (list[float])\n",
       "  - embedding_retriever.documents -> document_joiner.documents (list[Document])\n",
       "  - bm25_retriever.documents -> document_joiner.documents (list[Document])\n",
       "  - document_joiner.documents -> ranker.documents (list[Document])\n",
       "  - ranker.documents -> prompt_builder.documents (list[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 3. Connect the Components in a Graph ---\n",
    "\n",
    "# The query is embedded for the dense retriever\n",
    "hybrid_rag_pipeline.connect(\"text_embedder.embedding\", \"embedding_retriever.query_embedding\")\n",
    "\n",
    "# The raw query text is sent to the BM25 retriever and the ranker\n",
    "# Note: The query input for these components is the raw text string.\n",
    "\n",
    "# The outputs of both retrievers are fed into the document joiner\n",
    "hybrid_rag_pipeline.connect(\"embedding_retriever.documents\", \"document_joiner.documents\")\n",
    "hybrid_rag_pipeline.connect(\"bm25_retriever.documents\", \"document_joiner.documents\")\n",
    "\n",
    "# The joined documents are sent to the ranker\n",
    "hybrid_rag_pipeline.connect(\"document_joiner.documents\", \"ranker.documents\")\n",
    "\n",
    "# The ranked documents are sent to the prompt builder\n",
    "hybrid_rag_pipeline.connect(\"ranker.documents\", \"prompt_builder.documents\")\n",
    "\n",
    "# The final prompt is sent to the LLM\n",
    "hybrid_rag_pipeline.connect(\"prompt_builder.prompt\", \"llm.prompt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9ca6dd",
   "metadata": {},
   "source": [
    "## 3. Creating the SuperComponent\n",
    "\n",
    "A SuperComponent is a special type of pipeline component that can contain and coordinate multiple sub-pipelines. Here's what makes it powerful:\n",
    "\n",
    "1. **Encapsulation**:\n",
    "   - Groups related components into a single unit\n",
    "   - Manages internal data flow and state\n",
    "   - Provides a clean interface to the outside\n",
    "\n",
    "2. **Flexibility**:\n",
    "   - Can switch between different sub-pipelines\n",
    "   - Adapts behavior based on input or conditions\n",
    "   - Easy to modify internal logic\n",
    "\n",
    "3. **Reusability**:\n",
    "   - Package complex behavior into a single component\n",
    "   - Share across different pipelines\n",
    "   - Maintain consistency in processing\n",
    "\n",
    "The SuperComponent pattern helps manage complexity while keeping our pipeline modular and maintainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0242f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a super component with simplified input/output mapping\n",
    "from haystack import SuperComponent\n",
    "\n",
    "hybrid_rag_sc = SuperComponent(\n",
    "    pipeline=hybrid_rag_pipeline,\n",
    "    input_mapping={\n",
    "        \"query\": [\"text_embedder.text\", \n",
    "                  \"bm25_retriever.query\",\n",
    "                  \"ranker.query\",\n",
    "                  \"prompt_builder.question\"],\n",
    "    },\n",
    "    output_mapping={\n",
    "        \"llm.replies\": \"replies\",\n",
    "        \"ranker.documents\": \"documents\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ec3ab2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run the pipeline with simplified interface\n",
    "no_answer_question = hybrid_rag_sc.run(query=\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40e94195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def pretty_print_response(response):\n",
    "    # Display as Markdown for better formatting\n",
    "    display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a140bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I don't have enough information to answer."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretty_print_response(no_answer_question['replies'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2adb9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.51it/s]\n"
     ]
    }
   ],
   "source": [
    "pdf_ai_question = hybrid_rag_sc.run(query=\"Summarize how people use AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "980fb2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "People use AI in various ways, both at work and outside of work. Research indicates that generative AI, like ChatGPT, is often utilized as an advisor or research assistant rather than just a tool for completing job tasks. Users derive value from AI by seeking information or advice to make better decisions and improve their productivity, especially in knowledge-intensive jobs where quality decision-making enhances output. Additionally, there is a classification of user intents when interacting with AI, such as asking for information, doing tasks, or expressing thoughts."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretty_print_response(pdf_ai_question['replies'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e39d4",
   "metadata": {},
   "source": [
    "## 5. Creating Tools from Components\n",
    "\n",
    "Components can be transformed into tools that agents can use. Here's how:\n",
    "\n",
    "1. **Tool Creation**:\n",
    "   - Define tool interface and parameters\n",
    "   - Map component functionality to tool actions\n",
    "   - Add input validation and error handling\n",
    "\n",
    "2. **Tool Configuration**:\n",
    "   - Set default parameters\n",
    "   - Define input/output formats\n",
    "   - Add usage documentation\n",
    "\n",
    "3. **Integration with Agents**:\n",
    "   - Register tools with agent\n",
    "   - Define tool selection logic\n",
    "   - Handle tool responses\n",
    "\n",
    "This abstraction allows agents to use complex pipeline functionality through a simple interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84daec98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Supercomponent has been successfully wrapped into a Tool.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from haystack.tools.component_tool import ComponentTool\n",
    "\n",
    "# --- 1. Create a Tool from our Supercomponent ---\n",
    "\n",
    "# The name should be a simple, machine-readable identifier.\n",
    "tool_name = \"internal_document_search\"\n",
    "\n",
    "# The description is crucial. It tells the agent's LLM what the tool is for.\n",
    "# It should be clear, detailed, and specific.\n",
    "tool_description = (\n",
    "    \"Use this tool to search and answer questions about internal knowledge, \"\n",
    "    \"including information about Haystack, LLM models, and AI frameworks. \"\n",
    "    \"This is the primary source for any questions related to company-specific data.\"\n",
    ")\n",
    "\n",
    "# Wrap the supercomponent instance in a ComponentTool\n",
    "internal_search_tool = ComponentTool(\n",
    "    name=tool_name,\n",
    "    component=hybrid_rag_sc,\n",
    "    description=tool_description,\n",
    ")\n",
    "\n",
    "print(\"RAG Supercomponent has been successfully wrapped into a Tool.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abf3d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the SERPER_API_KEY environment variable.\n",
    "\n",
    "from haystack.components.agents import Agent\n",
    "from haystack.components.websearch import SerperDevWebSearch\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "\n",
    "\n",
    "# --- 1. Create a Web Search Tool ---\n",
    "\n",
    "# Instantiate the web search component\n",
    "web_search_component = SerperDevWebSearch(api_key=Secret.from_env_var(\"SERPERDEV_API_KEY\"))\n",
    "\n",
    "# Wrap it in a ComponentTool with a clear name and description\n",
    "web_search_tool = ComponentTool(\n",
    "    name=\"web_search\",\n",
    "    component=web_search_component,\n",
    "    description=\"Use this tool to search the public internet for current events, news, and general knowledge. \"\n",
    "                \"It is best for information that is not specific to our internal documents.\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b26074c",
   "metadata": {},
   "source": [
    "## 6. Building an Agent with Multiple Tools\n",
    "\n",
    "Agents become more powerful when equipped with multiple tools. Here's our approach:\n",
    "\n",
    "1. **Agent Architecture**:\n",
    "   - Define agent's capabilities and goals\n",
    "   - Create tool selection strategy\n",
    "   - Implement decision-making logic\n",
    "\n",
    "2. **Tool Management**:\n",
    "   - Register multiple tools\n",
    "   - Handle tool dependencies\n",
    "   - Manage tool state\n",
    "\n",
    "3. **Coordination**:\n",
    "   - Select appropriate tools for tasks\n",
    "   - Chain tool operations\n",
    "   - Handle tool failures\n",
    "\n",
    "4. **Benefits**:\n",
    "   - More flexible problem-solving\n",
    "   - Better task completion rates\n",
    "   - Adaptable to different scenarios\n",
    "\n",
    "The resulting agent can handle complex tasks by combining tool capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e169876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Initialize the Agent ---\n",
    "\n",
    "# The agent needs a list of all available tools\n",
    "tools = [internal_search_tool, web_search_tool]\n",
    "\n",
    "# The agent's reasoning is powered by an LLM. It must be a model that supports tool calling.\n",
    "agent_llm = OpenAIChatGenerator(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Define a system prompt to guide the agent's behavior\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful research assistant. Your goal is to answer the user's question accurately and comprehensively.\n",
    "You have access to two tools:\n",
    "1. internal_document_search: For questions about our internal knowledge base (Haystack, AI models, etc.).\n",
    "2. web_search: For questions about current events or general public information.\n",
    "\n",
    "First, think about which tool is most appropriate for the user's question.\n",
    "Then, call that tool with the necessary query.\n",
    "If the question requires information from both sources, you can call the tools sequentially.\n",
    "Finally, synthesize the information from the tools into a final answer for the user.\n",
    "\"\"\"\n",
    "\n",
    "# Instantiate the Agent\n",
    "agent = Agent(chat_generator=agent_llm, tools=tools, system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a618e6",
   "metadata": {},
   "source": [
    "## 7. Running Complex Queries\n",
    "\n",
    "Let's explore how our agent handles complex queries using multiple tools:\n",
    "\n",
    "1. **Query Processing**:\n",
    "   - Parse user input\n",
    "   - Identify required tools\n",
    "   - Plan execution strategy\n",
    "\n",
    "2. **Tool Orchestration**:\n",
    "   - Execute tools in sequence\n",
    "   - Handle intermediate results\n",
    "   - Combine tool outputs\n",
    "\n",
    "3. **Result Generation**:\n",
    "   - Synthesize final response\n",
    "   - Format output\n",
    "   - Provide explanations\n",
    "\n",
    "We'll demonstrate this with increasingly complex query examples to show the system's capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cf7d965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running agent with complex query: 'Using the internal documents, explain how people use AI, then investigate the latest trends in 2025 in AI from a web search.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.63it/s]\n",
      "Failed to invoke Tool `web_search` with parameters {'query': 'latest trends in AI 2025'}. Error: An error occurred while querying SerperDevWebSearch. Error: 400 Client Error: Bad Request for url: https://google.serper.dev/search\n",
      "Failed to invoke Tool `web_search` with parameters {'query': 'latest trends in AI 2025'}. Error: An error occurred while querying SerperDevWebSearch. Error: 400 Client Error: Bad Request for url: https://google.serper.dev/search\n",
      "Failed to invoke Tool `web_search` with parameters {'query': 'AI trends 2025'}. Error: An error occurred while querying SerperDevWebSearch. Error: 400 Client Error: Bad Request for url: https://google.serper.dev/search\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Run the Agent with a Complex Query ---\n",
    "\n",
    "# This query requires both internal knowledge (about Haystack) and external knowledge (current news).\n",
    "complex_query = (\n",
    "    \"Using the internal documents, explain how people use AI, then investigate the latest trends in 2025 in AI from a web search.\"\n",
    ")\n",
    "\n",
    "print(f\"\\nRunning agent with complex query: '{complex_query}'\")\n",
    "\n",
    "# The agent will now perform a multi-step reasoning process.\n",
    "# We can inspect the 'transcript' to see its thoughts and actions.\n",
    "agent_result = agent.run(messages=[ChatMessage.from_user(complex_query)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f22e7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## System Prompt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "\n",
       "You are a helpful research assistant. Your goal is to answer the user's question accurately and comprehensively.\n",
       "You have access to two tools:\n",
       "1. internal_document_search: For questions about our internal knowledge base (Haystack, AI models, etc.).\n",
       "2. web_search: For questions about current events or general public information.\n",
       "\n",
       "First, think about which tool is most appropriate for the user's question.\n",
       "Then, call that tool with the necessary query.\n",
       "If the question requires information from both sources, you can call the tools sequentially.\n",
       "Finally, synthesize the information from the tools into a final answer for the user.\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## User Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Using the internal documents, explain how people use AI, then investigate the latest trends in 2025 in AI from a web search.*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Agent Actions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Tool Used:** internal_document_search"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Query:** how people use AI"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Tool Used:** web_search"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Query:** latest trends in AI 2025"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Tool Used:** web_search"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Query:** latest trends in AI 2025"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Tool Used:** web_search"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Query:** AI trends 2025"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Final Response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "It appears that I'm having difficulties accessing the web search tool for the latest trends in AI for 2025. However, I can summarize the information found in the internal documents regarding how people use AI.\n",
       "\n",
       "### How People Use AI\n",
       "\n",
       "1. **Generative AI Applications**: Users employ generative AI for a variety of tasks including augmenting and automating workplace tasks. This can involve generating content, assisting with programming tasks, and providing creative suggestions.\n",
       "\n",
       "2. **Classification of User Intent**: A significant focus of recent studies categorizes user intent when interacting with AI. There are three primary intents identified:\n",
       "   - **Asking**: Seeking information or advice, aiming to make more informed decisions.\n",
       "   - **Doing**: Engaging in tasks that require action based on the AI's input.\n",
       "   - **Expressing**: Communicating feelings or thoughts, where AI can provide companionship or emotional support.\n",
       "\n",
       "3. **Demographic Trends**: There is evidence of a narrowing gender gap in AI usage, particularly in platforms like ChatGPT. The trends indicate that the user base is becoming more diverse over time.\n",
       "\n",
       "4. **Daily Usage Statistics**: It was noted that over 2.5 billion prompts are generated daily, highlighting the extensive engagement with AI technologies.\n",
       "\n",
       "5. **Popular Use Cases**: Some of the most significant uses of generative AI include:\n",
       "   - **Therapy and Companionship**: Many users are seeking AI for emotional support or companionship, reflecting a broader societal trend towards well-being and mental health resources.\n",
       "   - **Practical Guidance**: Users often ask for tailored advice, such as fitness plans or educational support.\n",
       "\n",
       "Unfortunately, I was unable to gather the latest trends for 2025 due to technical issues with the external search tool. If you have any specific areas of interest or another query, I can assist with that or try again later to get the external information."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pretty_print_agent_steps(agent_result):\n",
    "    \"\"\"\n",
    "    Pretty prints the steps taken by the agent and its final response.\n",
    "    \n",
    "    Args:\n",
    "        agent_result (dict): The result dictionary from the agent's run\n",
    "    \"\"\"\n",
    "    # Print system message\n",
    "    system_msg = agent_result['messages'][0]._content[0].text\n",
    "    display(Markdown(\"## System Prompt\"))\n",
    "    display(Markdown(f\"```\\n{system_msg}\\n```\"))\n",
    "    \n",
    "    # Print user query\n",
    "    user_query = agent_result['messages'][1]._content[0].text\n",
    "    display(Markdown(\"## User Query\"))\n",
    "    display(Markdown(f\"*{user_query}*\"))\n",
    "    \n",
    "    # Print tool calls and results\n",
    "    display(Markdown(\"## Agent Actions\"))\n",
    "    for msg in agent_result['messages']:\n",
    "        if msg._role.value == 'assistant' and hasattr(msg._content[0], 'tool_name'):\n",
    "            for tool_call in msg._content:\n",
    "                display(Markdown(f\"**Tool Used:** {tool_call.tool_name}\"))\n",
    "                display(Markdown(f\"**Query:** {tool_call.arguments['query']}\"))\n",
    "    \n",
    "    # Print final response\n",
    "    display(Markdown(\"## Final Response\"))\n",
    "    display(Markdown(agent_result['last_message']._content[0].text))\n",
    "\n",
    "# Use the function\n",
    "pretty_print_agent_steps(agent_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-with-haystack-ch4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
