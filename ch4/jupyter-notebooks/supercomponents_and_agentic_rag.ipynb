{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a7bc245",
   "metadata": {},
   "source": [
    "🔧 **Setup Required**: Before running this notebook, please follow the [setup instructions](../README.md#setup-instructions) to configure your environment and API keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee060006",
   "metadata": {},
   "source": [
    "# Building Advanced RAG Systems with Haystack SuperComponents\n",
    "\n",
    "This notebook demonstrates how to build an advanced Retrieval-Augmented Generation (RAG) system using Haystack's SuperComponent feature. We'll cover:\n",
    "\n",
    "1. Setting up a hybrid RAG pipeline with both dense and sparse retrieval\n",
    "2. Creating a SuperComponent for simplified interface\n",
    "3. Building tools from components for agent-based systems\n",
    "4. Implementing a multi-tool agent for complex queries\n",
    "\n",
    "## Prerequisites\n",
    "- Basic understanding of RAG systems\n",
    "- Familiarity with Haystack components\n",
    "- OpenAI API key for LLM access\n",
    "- SerperDev API key for web search capabilities\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you will be able to:\n",
    "- Build a hybrid RAG pipeline combining multiple retrieval methods\n",
    "- Create a SuperComponent to simplify pipeline interfaces\n",
    "- Transform components into tools for agent-based systems\n",
    "- Implement an agent that can use multiple tools for complex queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ac1266d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.indexing import document_store\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f22b0e",
   "metadata": {},
   "source": [
    "## 1. Setting Up Components\n",
    "\n",
    "In this section, we'll set up the core components needed for our hybrid RAG pipeline. We'll use both dense and sparse retrieval methods to achieve better search results:\n",
    "\n",
    "1. **Dense Retrieval**: Uses embeddings to find semantically similar documents\n",
    "   - SentenceTransformersTextEmbedder: Converts text into vector representations\n",
    "   - InMemoryEmbeddingRetriever: Searches for similar vectors in the document store\n",
    "\n",
    "2. **Sparse Retrieval**: Uses keyword matching (BM25 algorithm)\n",
    "   - InMemoryBM25Retriever: Performs traditional keyword-based search\n",
    "\n",
    "3. **Post-processing**:\n",
    "   - DocumentJoiner: Combines results from both retrievers\n",
    "   - SentenceTransformersSimilarityRanker: Re-ranks results for better precision\n",
    "\n",
    "4. **Generation**:\n",
    "   - PromptBuilder: Creates structured prompts with context\n",
    "   - OpenAIGenerator: Generates responses using GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d7f43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.utils import Secret\n",
    "from haystack import Pipeline\n",
    "\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack.components.joiners import DocumentJoiner\n",
    "from haystack.components.rankers import SentenceTransformersSimilarityRanker\n",
    "\n",
    "# --- 1. Initialize Query Pipeline Components ---\n",
    "\n",
    "# Text Embedder: To embed the user's query. Must be compatible with the document embedder.\n",
    "text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Retriever: Fetches documents from the DocumentStore based on vector similarity.\n",
    "retriever = InMemoryEmbeddingRetriever(document_store=document_store, top_k=3)\n",
    "\n",
    "# PromptBuilder: Creates a prompt using the retrieved documents and the query.\n",
    "# The Jinja2 template iterates through the documents and adds their content to the prompt.\n",
    "prompt_template_for_pipeline = \"\"\"\n",
    "Given the following information, answer the user's question.\n",
    "If the information is not available in the provided documents, \n",
    "say that you don't have enough information to answer.\n",
    "\n",
    "Context:\n",
    "{% for doc in documents %}\n",
    "    {{ doc.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt_builder_inst = PromptBuilder(template=prompt_template_for_pipeline,\n",
    "                                    required_variables=\"*\")\n",
    "llm_generator_inst = OpenAIGenerator(api_key=Secret.from_env_var(\"OPENAI_API_KEY\"), model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "\n",
    "# Sparse Retriever (BM25): For keyword-based search.\n",
    "# This retriever needs to be \"warmed up\" by calculating statistics on the documents in the store.\n",
    "bm25_retriever = InMemoryBM25Retriever(document_store=document_store, top_k=3)\n",
    "\n",
    "# DocumentJoiner: To merge the results from the two retrievers.\n",
    "# The default 'concatenate' mode works well here as the ranker will handle final ordering.\n",
    "document_joiner = DocumentJoiner()\n",
    "\n",
    "# Ranker: A cross-encoder model to re-rank the combined results for higher precision.\n",
    "# This model is highly effective at identifying the most relevant documents from a candidate set.\n",
    "ranker = SentenceTransformersSimilarityRanker(model=\"BAAI/bge-reranker-base\", top_k=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a628b16",
   "metadata": {},
   "source": [
    "## 2. Building the Hybrid RAG Pipeline\n",
    "\n",
    "A hybrid RAG (Retrieval Augmented Generation) pipeline combines multiple retrieval methods to improve the quality of document search. Here's how we'll build it:\n",
    "\n",
    "1. **Component Creation**:\n",
    "   - Initialize both dense and sparse retrievers\n",
    "   - Set up the document joiner and ranker\n",
    "   - Configure the prompt builder and generator\n",
    "\n",
    "2. **Pipeline Assembly**:\n",
    "   - Chain components together in a logical sequence\n",
    "   - Define how documents flow through the pipeline\n",
    "   - Set parameters for each component\n",
    "\n",
    "3. **Benefits**:\n",
    "   - Better search accuracy by combining methods\n",
    "   - More robust to different types of queries\n",
    "   - Improved context selection for generation\n",
    "\n",
    "The resulting pipeline will provide both semantic understanding and keyword matching capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "942bd06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Build the Hybrid RAG Pipeline ---\n",
    "hybrid_rag_pipeline = Pipeline()\n",
    "\n",
    "# Add all necessary components\n",
    "hybrid_rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "hybrid_rag_pipeline.add_component(\"embedding_retriever\", retriever) # Dense retriever\n",
    "hybrid_rag_pipeline.add_component(\"bm25_retriever\", bm25_retriever) # Sparse retriever\n",
    "hybrid_rag_pipeline.add_component(\"document_joiner\", document_joiner)\n",
    "hybrid_rag_pipeline.add_component(\"ranker\", ranker)\n",
    "hybrid_rag_pipeline.add_component(\"prompt_builder\", prompt_builder_inst)\n",
    "hybrid_rag_pipeline.add_component(\"llm\", llm_generator_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c73c1dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x31ef77d40>\n",
       "🚅 Components\n",
       "  - text_embedder: SentenceTransformersTextEmbedder\n",
       "  - embedding_retriever: InMemoryEmbeddingRetriever\n",
       "  - bm25_retriever: InMemoryBM25Retriever\n",
       "  - document_joiner: DocumentJoiner\n",
       "  - ranker: SentenceTransformersSimilarityRanker\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "🛤️ Connections\n",
       "  - text_embedder.embedding -> embedding_retriever.query_embedding (list[float])\n",
       "  - embedding_retriever.documents -> document_joiner.documents (list[Document])\n",
       "  - bm25_retriever.documents -> document_joiner.documents (list[Document])\n",
       "  - document_joiner.documents -> ranker.documents (list[Document])\n",
       "  - ranker.documents -> prompt_builder.documents (list[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 3. Connect the Components in a Graph ---\n",
    "\n",
    "# The query is embedded for the dense retriever\n",
    "hybrid_rag_pipeline.connect(\"text_embedder.embedding\", \"embedding_retriever.query_embedding\")\n",
    "\n",
    "# The raw query text is sent to the BM25 retriever and the ranker\n",
    "# Note: The query input for these components is the raw text string.\n",
    "\n",
    "# The outputs of both retrievers are fed into the document joiner\n",
    "hybrid_rag_pipeline.connect(\"embedding_retriever.documents\", \"document_joiner.documents\")\n",
    "hybrid_rag_pipeline.connect(\"bm25_retriever.documents\", \"document_joiner.documents\")\n",
    "\n",
    "# The joined documents are sent to the ranker\n",
    "hybrid_rag_pipeline.connect(\"document_joiner.documents\", \"ranker.documents\")\n",
    "\n",
    "# The ranked documents are sent to the prompt builder\n",
    "hybrid_rag_pipeline.connect(\"ranker.documents\", \"prompt_builder.documents\")\n",
    "\n",
    "# The final prompt is sent to the LLM\n",
    "hybrid_rag_pipeline.connect(\"prompt_builder.prompt\", \"llm.prompt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9ca6dd",
   "metadata": {},
   "source": [
    "## 3. Creating the SuperComponent\n",
    "\n",
    "A SuperComponent is a special type of pipeline component that can contain and coordinate multiple sub-pipelines. Here's what makes it powerful:\n",
    "\n",
    "1. **Encapsulation**:\n",
    "   - Groups related components into a single unit\n",
    "   - Manages internal data flow and state\n",
    "   - Provides a clean interface to the outside\n",
    "\n",
    "2. **Flexibility**:\n",
    "   - Can switch between different sub-pipelines\n",
    "   - Adapts behavior based on input or conditions\n",
    "   - Easy to modify internal logic\n",
    "\n",
    "3. **Reusability**:\n",
    "   - Package complex behavior into a single component\n",
    "   - Share across different pipelines\n",
    "   - Maintain consistency in processing\n",
    "\n",
    "The SuperComponent pattern helps manage complexity while keeping our pipeline modular and maintainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0242f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a super component with simplified input/output mapping\n",
    "from haystack import SuperComponent\n",
    "\n",
    "hybrid_rag_sc = SuperComponent(\n",
    "    pipeline=hybrid_rag_pipeline,\n",
    "    input_mapping={\n",
    "        \"query\": [\"text_embedder.text\", \n",
    "                  \"bm25_retriever.query\",\n",
    "                  \"ranker.query\",\n",
    "                  \"prompt_builder.question\"],\n",
    "    },\n",
    "    output_mapping={\n",
    "        \"llm.replies\": \"replies\",\n",
    "        \"ranker.documents\": \"documents\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ec3ab2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 30.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run the pipeline with simplified interface\n",
    "no_answer_question = hybrid_rag_sc.run(query=\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "40e94195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def pretty_print_response(response):\n",
    "    # Display as Markdown for better formatting\n",
    "    display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5a140bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I don't have enough information to answer."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretty_print_response(no_answer_question['replies'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2adb9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.84it/s]\n"
     ]
    }
   ],
   "source": [
    "pdf_ai_question = hybrid_rag_sc.run(query=\"Summarize how people use AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "980fb2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "People use generative AI in various ways, both at work and outside of work. The primary uses include seeking information or advice to make informed decisions (asking), performing specific tasks (doing), and expressing thoughts or feelings (expressing). Users derive significant value from applications like ChatGPT, where it serves as an advisor or research assistant rather than just a tool for task completion. This decision support is particularly beneficial in knowledge-intensive jobs, where productivity can be enhanced through improved decision-making. Overall, the flexibility of generative AI allows for a wide range of applications tailored to users' intents and needs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretty_print_response(pdf_ai_question['replies'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e39d4",
   "metadata": {},
   "source": [
    "## 5. Creating Tools from Components\n",
    "\n",
    "Components can be transformed into tools that agents can use. Here's how:\n",
    "\n",
    "1. **Tool Creation**:\n",
    "   - Define tool interface and parameters\n",
    "   - Map component functionality to tool actions\n",
    "   - Add input validation and error handling\n",
    "\n",
    "2. **Tool Configuration**:\n",
    "   - Set default parameters\n",
    "   - Define input/output formats\n",
    "   - Add usage documentation\n",
    "\n",
    "3. **Integration with Agents**:\n",
    "   - Register tools with agent\n",
    "   - Define tool selection logic\n",
    "   - Handle tool responses\n",
    "\n",
    "This abstraction allows agents to use complex pipeline functionality through a simple interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84daec98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Supercomponent has been successfully wrapped into a Tool.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from haystack.tools.component_tool import ComponentTool\n",
    "\n",
    "# --- 1. Create a Tool from our Supercomponent ---\n",
    "\n",
    "# The name should be a simple, machine-readable identifier.\n",
    "tool_name = \"internal_document_search\"\n",
    "\n",
    "# The description is crucial. It tells the agent's LLM what the tool is for.\n",
    "# It should be clear, detailed, and specific.\n",
    "tool_description = (\n",
    "    \"Use this tool to search and answer questions about internal knowledge, \"\n",
    "    \"including information about Haystack, LLM models, and AI frameworks. \"\n",
    "    \"This is the primary source for any questions related to company-specific data.\"\n",
    ")\n",
    "\n",
    "# Wrap the supercomponent instance in a ComponentTool\n",
    "internal_search_tool = ComponentTool(\n",
    "    name=tool_name,\n",
    "    component=hybrid_rag_sc,\n",
    "    description=tool_description,\n",
    ")\n",
    "\n",
    "print(\"RAG Supercomponent has been successfully wrapped into a Tool.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "abf3d661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running agent with complex query: 'Using the internal documents, explain how people use AI, then investigate the latest trends in 2025 in AI from a web search.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set the SERPER_API_KEY environment variable.\n",
    "\n",
    "from haystack.components.agents import Agent\n",
    "from haystack.components.websearch import SerperDevWebSearch\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "\n",
    "\n",
    "# --- 1. Create a Web Search Tool ---\n",
    "\n",
    "# Instantiate the web search component\n",
    "web_search_component = SerperDevWebSearch(api_key=Secret.from_env_var(\"SERPERDEV_API_KEY\"))\n",
    "\n",
    "# Wrap it in a ComponentTool with a clear name and description\n",
    "web_search_tool = ComponentTool(\n",
    "    name=\"web_search\",\n",
    "    component=web_search_component,\n",
    "    description=\"Use this tool to search the public internet for current events, news, and general knowledge. \"\n",
    "                \"It is best for information that is not specific to our internal documents.\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b26074c",
   "metadata": {},
   "source": [
    "## 6. Building an Agent with Multiple Tools\n",
    "\n",
    "Agents become more powerful when equipped with multiple tools. Here's our approach:\n",
    "\n",
    "1. **Agent Architecture**:\n",
    "   - Define agent's capabilities and goals\n",
    "   - Create tool selection strategy\n",
    "   - Implement decision-making logic\n",
    "\n",
    "2. **Tool Management**:\n",
    "   - Register multiple tools\n",
    "   - Handle tool dependencies\n",
    "   - Manage tool state\n",
    "\n",
    "3. **Coordination**:\n",
    "   - Select appropriate tools for tasks\n",
    "   - Chain tool operations\n",
    "   - Handle tool failures\n",
    "\n",
    "4. **Benefits**:\n",
    "   - More flexible problem-solving\n",
    "   - Better task completion rates\n",
    "   - Adaptable to different scenarios\n",
    "\n",
    "The resulting agent can handle complex tasks by combining tool capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e169876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Initialize the Agent ---\n",
    "\n",
    "# The agent needs a list of all available tools\n",
    "tools = [internal_search_tool, web_search_tool]\n",
    "\n",
    "# The agent's reasoning is powered by an LLM. It must be a model that supports tool calling.\n",
    "agent_llm = OpenAIChatGenerator(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Define a system prompt to guide the agent's behavior\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful research assistant. Your goal is to answer the user's question accurately and comprehensively.\n",
    "You have access to two tools:\n",
    "1. internal_document_search: For questions about our internal knowledge base (Haystack, AI models, etc.).\n",
    "2. web_search: For questions about current events or general public information.\n",
    "\n",
    "First, think about which tool is most appropriate for the user's question.\n",
    "Then, call that tool with the necessary query.\n",
    "If the question requires information from both sources, you can call the tools sequentially.\n",
    "Finally, synthesize the information from the tools into a final answer for the user.\n",
    "\"\"\"\n",
    "\n",
    "# Instantiate the Agent\n",
    "agent = Agent(chat_generator=agent_llm, tools=tools, system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a618e6",
   "metadata": {},
   "source": [
    "## 7. Running Complex Queries\n",
    "\n",
    "Let's explore how our agent handles complex queries using multiple tools:\n",
    "\n",
    "1. **Query Processing**:\n",
    "   - Parse user input\n",
    "   - Identify required tools\n",
    "   - Plan execution strategy\n",
    "\n",
    "2. **Tool Orchestration**:\n",
    "   - Execute tools in sequence\n",
    "   - Handle intermediate results\n",
    "   - Combine tool outputs\n",
    "\n",
    "3. **Result Generation**:\n",
    "   - Synthesize final response\n",
    "   - Format output\n",
    "   - Provide explanations\n",
    "\n",
    "We'll demonstrate this with increasingly complex query examples to show the system's capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8cf7d965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running agent with complex query: 'Using the internal documents, explain how people use AI, then investigate the latest trends in 2025 in AI from a web search.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Run the Agent with a Complex Query ---\n",
    "\n",
    "# This query requires both internal knowledge (about Haystack) and external knowledge (current news).\n",
    "complex_query = (\n",
    "    \"Using the internal documents, explain how people use AI, then investigate the latest trends in 2025 in AI from a web search.\"\n",
    ")\n",
    "\n",
    "print(f\"\\nRunning agent with complex query: '{complex_query}'\")\n",
    "\n",
    "# The agent will now perform a multi-step reasoning process.\n",
    "# We can inspect the 'transcript' to see its thoughts and actions.\n",
    "agent_result = agent.run(messages=[ChatMessage.from_user(complex_query)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1f22e7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## System Prompt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "\n",
       "You are a helpful research assistant. Your goal is to answer the user's question accurately and comprehensively.\n",
       "You have access to two tools:\n",
       "1. internal_document_search: For questions about our internal knowledge base (Haystack, AI models, etc.).\n",
       "2. web_search: For questions about current events or general public information.\n",
       "\n",
       "First, think about which tool is most appropriate for the user's question.\n",
       "Then, call that tool with the necessary query.\n",
       "If the question requires information from both sources, you can call the tools sequentially.\n",
       "Finally, synthesize the information from the tools into a final answer for the user.\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## User Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Using the internal documents, explain how people use AI, then investigate the latest trends in 2025 in AI from a web search.*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Agent Actions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Tool Used:** internal_document_search"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Query:** how people use AI"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Tool Used:** web_search"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Query:** latest trends in AI 2025"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Final Response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### How People Use AI\n",
       "\n",
       "People utilize AI in diverse ways, both in professional and personal contexts. Some significant applications include:\n",
       "\n",
       "1. **Seeking Information or Advice**: Many users interact with AI systems to get information that can aid them in making informed decisions, whether at work, school, or in personal matters. This category of use is described as \"asking\".\n",
       "\n",
       "2. **Receiving Practical Guidance**: Users might request specific guidance tailored to their needs, such as customized workout plans or troubleshooting help in technical tasks. This is often referred to as \"doing\".\n",
       "\n",
       "3. **Engaging in Therapy or Companionship**: A notable trend is the use of AI for emotional support and companionship. This use case has grown significantly, with some reports indicating it to be a primary application of generative AI, especially as public comfort with AI usage has increased over time.\n",
       "\n",
       "4. **Programming and IT Tasks**: Statistics suggest that a substantial portion of AI interactions are related to programming or IT tasks, indicating a strong interest in these areas among users.\n",
       "\n",
       "Additionally, demographic studies reveal that the previously observed gender gap in AI usage has narrowed, suggesting that AI has become more universally adopted across different user groups.\n",
       "\n",
       "### Latest Trends in AI (2025)\n",
       "\n",
       "From recent web searches, several trends in AI for 2025 have emerged:\n",
       "\n",
       "1. **Increased Efficiency and Accessibility**: AI technologies are becoming more efficient and affordable, with open-weight models closing the performance gap relative to closed models.\n",
       "\n",
       "2. **The Rise of Generative AI**: Generative AI continues to expand, expected to be a significant driver of productivity across various sectors. Many businesses report impressive financial outcomes, with users experiencing notable revenue growth and cost savings.\n",
       "\n",
       "3. **Evolution of AI Agents**: AI is moving beyond simple tools and chatbots to more advanced multi-agent systems that can autonomously perform tasks and interact in more complex scenarios.\n",
       "\n",
       "4. **Multimodal AI**: These systems integrate various data types (text, image, sound) to provide richer, context-aware interactions. This trend signifies a shift in how AI is trained and utilized.\n",
       "\n",
       "5. **Human-Machine Collaboration**: There is a growing focus on enhancing the collaboration between humans and machines, with models designed to interoperate smoothly and increase overall productivity.\n",
       "\n",
       "6. **Two-Tier Ecosystem**: While AI adoption is proliferating, there is a concern regarding a \"two-tier\" ecosystem, which could create disparities in access and benefits from AI technologies.\n",
       "\n",
       "7. **Regulatory Complexity**: As AI technologies become more powerful, regulatory frameworks are evolving to ensure safe and ethical use, posing new challenges for developers and organizations.\n",
       "\n",
       "For more in-depth reading, various detailed reports and resources are available, including a comprehensive AI Index Report by Stanford HAI and industry insights from organizations like McKinsey and IBM. \n",
       "\n",
       "### References for Further Reading\n",
       "- [Stanford AI Index Report 2025](https://hai.stanford.edu/ai-index/2025-ai-index-report)\n",
       "- [McKinsey Insights on Technology Trends](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech)\n",
       "- [IBM's Insights on AI Trends](https://www.ibm.com/think/insights/artificial-intelligence-trends)\n",
       "- [AI News and Updates](https://www.crescendo.ai/news/latest-ai-news-and-updates)\n",
       "- [Microsoft AI Trends for 2025](https://news.microsoft.com/source/features/ai/6-ai-trends-youll-see-more-of-in-2025/)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pretty_print_agent_steps(agent_result):\n",
    "    \"\"\"\n",
    "    Pretty prints the steps taken by the agent and its final response.\n",
    "    \n",
    "    Args:\n",
    "        agent_result (dict): The result dictionary from the agent's run\n",
    "    \"\"\"\n",
    "    # Print system message\n",
    "    system_msg = agent_result['messages'][0]._content[0].text\n",
    "    display(Markdown(\"## System Prompt\"))\n",
    "    display(Markdown(f\"```\\n{system_msg}\\n```\"))\n",
    "    \n",
    "    # Print user query\n",
    "    user_query = agent_result['messages'][1]._content[0].text\n",
    "    display(Markdown(\"## User Query\"))\n",
    "    display(Markdown(f\"*{user_query}*\"))\n",
    "    \n",
    "    # Print tool calls and results\n",
    "    display(Markdown(\"## Agent Actions\"))\n",
    "    for msg in agent_result['messages']:\n",
    "        if msg._role.value == 'assistant' and hasattr(msg._content[0], 'tool_name'):\n",
    "            for tool_call in msg._content:\n",
    "                display(Markdown(f\"**Tool Used:** {tool_call.tool_name}\"))\n",
    "                display(Markdown(f\"**Query:** {tool_call.arguments['query']}\"))\n",
    "    \n",
    "    # Print final response\n",
    "    display(Markdown(\"## Final Response\"))\n",
    "    display(Markdown(agent_result['last_message']._content[0].text))\n",
    "\n",
    "# Use the function\n",
    "pretty_print_agent_steps(agent_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af04800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-with-haystack-ch4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
