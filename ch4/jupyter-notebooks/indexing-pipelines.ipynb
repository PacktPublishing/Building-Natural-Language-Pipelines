{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building LLM-powered pipelines perform indexing Haystack\n",
    "\n",
    "In [the previous notebook](./extraction-and-processing-pipelines.ipynb), we learned how to initialize components that convert files of different formats (PDF, Word, HTML, etc.) into a format that can be cleaned by Haystack components. \n",
    "\n",
    "In this notebook, we will integrate components to convert the text into vectors using embedding model provider integrations through Haystack. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Document, Pipeline\n",
    "from haystack.utils import Secret\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.converters import MarkdownToDocument\n",
    "from haystack.components.embedders import OpenAIDocumentEmbedder\n",
    "from haystack.components.preprocessors import DocumentCleaner\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from pathlib import Path\n",
    "from haystack.document_stores.types import DuplicatePolicy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with embedding models from OpenAI\n",
    "\n",
    "In this section, we will build an indexing pipeline that uses an embedding model from OpenAI to convert the text into vectors. We will transform Markdown files into vectors using the embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"./../../.env\")\n",
    "\n",
    "open_ai_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting markdown files to Documents: 100%|██████████| 3/3 [00:00<00:00, 15.19it/s]\n",
      "Calculating embeddings: 100%|██████████| 4/4 [00:02<00:00,  1.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'embedder': {'meta': {'model': 'text-embedding-ada-002',\n",
       "   'usage': {'prompt_tokens': 825, 'total_tokens': 825}}},\n",
       " 'writer': {'documents_written': 93}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store = InMemoryDocumentStore(embedding_similarity_function=\"cosine\")\n",
    "\n",
    "# Initialize components\n",
    "markdown_converter = MarkdownToDocument(table_to_single_line=True)\n",
    "document_cleaner = DocumentCleaner(\n",
    "                    remove_empty_lines=True,\n",
    "                    remove_extra_whitespaces=True,\n",
    "                    remove_repeated_substrings=False\n",
    "                )\n",
    "document_splitter = DocumentSplitter(split_by=\"word\", split_length=5)\n",
    "document_writer = DocumentWriter(document_store=document_store,\n",
    "                                 policy = DuplicatePolicy.OVERWRITE)\n",
    "embedding = OpenAIDocumentEmbedder(model=\"text-embedding-ada-002\", \n",
    "                                    batch_size=24,\n",
    "                                    )\n",
    "\n",
    "# Initialize pipeline\n",
    "indexing_pipeline = Pipeline()\n",
    "\n",
    "# Add components\n",
    "indexing_pipeline.add_component(\"converter\", markdown_converter)\n",
    "indexing_pipeline.add_component(\"cleaner\", document_cleaner)\n",
    "indexing_pipeline.add_component(\"splitter\", document_splitter)\n",
    "indexing_pipeline.add_component(\"embedder\", embedding)\n",
    "indexing_pipeline.add_component(\"writer\", document_writer)\n",
    "\n",
    "# Connect components to one another\n",
    "indexing_pipeline.connect(\"converter\", \"cleaner\")\n",
    "indexing_pipeline.connect(\"cleaner.documents\", \"splitter.documents\")\n",
    "indexing_pipeline.connect(\"splitter.documents\", \"embedder.documents\")\n",
    "indexing_pipeline.connect(\"embedder.documents\", \"writer.documents\")\n",
    "\n",
    "# Execute pipeline\n",
    "file_names = [str(f) for f in Path(\"./markdown_pages\").rglob(\"*.md\")]\n",
    "indexing_pipeline.run({\"converter\": {\"sources\": file_names}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing_pipeline.draw(\"./images/indexing_pipeline.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id=ec917c19b99ca38d0bef64aa62d389315af136b55470a40a88d6d9812589201d, content: 'templates. Handlebars is the default.extextension ', meta: {'file_path': 'markdown_pages/page3.md', 'source_id': '09730ab93795029b54abdb66b59d722d53971f4de54e66eebf0e0b1385a439ea'}, embedding: vector of size 1536)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store.filter_documents()[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the embedding values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.01753813587129116,\n",
       " 0.015475629828870296,\n",
       " -0.010899869725108147,\n",
       " -0.007409999147057533,\n",
       " 0.010271556675434113,\n",
       " 0.023493453860282898,\n",
       " -0.005897266790270805,\n",
       " -0.002530326833948493,\n",
       " 0.012142837978899479,\n",
       " -0.014847316779196262]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store.filter_documents()[10].embedding[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-pipelines",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
