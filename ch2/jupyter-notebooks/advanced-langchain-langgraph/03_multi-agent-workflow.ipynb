{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a017a721",
   "metadata": {},
   "source": [
    "üîß **Setup Required**: Before running this notebook, please follow the [setup instructions](../../README.md#setup-instructions) to configure your environment and API keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a3dc3e",
   "metadata": {},
   "source": [
    "# Multi-Agent Workflow Using LangChain \n",
    "\n",
    "This notebook demonstrates how to build a **simple multi-agent system** using **LangChain** without LangGraph or middleware. We'll create a supervisor agent that coordinates with subordinate agents using basic tool calling.\n",
    "\n",
    "## Key Features:\n",
    "- **Simple tool-based architecture** - no complex middleware\n",
    "- **Dynamic agent invocation** - subordinate agents are created as tools\n",
    "- **Direct LLM-to-tool communication**\n",
    "- **Lightweight coordination** between supervisor and specialized agents\n",
    "\n",
    "## Based on:\n",
    "Reference article: [LangChain 1.0 ‚Äî A second look](https://medium.com/mitb-for-all/langchain-a-second-look-6ed720e27fec)\n",
    "Simplified version focusing on core multi-agent patterns without advanced features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ddb17d",
   "metadata": {},
   "source": [
    "## 1. Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f383f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurafunderburk/Documents/GitHub/Building-Natural-Language-Pipelines/ch2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474e73c7",
   "metadata": {},
   "source": [
    "## 2. Initialize the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "001c4e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm doing well, thank you for asking. (I don't have feelings like humans do, but I'm here and ready to assist you.) How about you? How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# Initialize the language model\n",
    "llm = ChatOllama(\n",
    "    model=\"mistral-nemo:12b\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "\n",
    "# Test the LLM\n",
    "response = llm.invoke(\"Hello! How are you?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6efd8f",
   "metadata": {},
   "source": [
    "## 3. Create Subordinate Agent Tools\n",
    "\n",
    "The key pattern from the article: **subordinate agents are created as tools**. Each tool dynamically spawns an agent, executes its task, and returns results.\n",
    "\n",
    "This approach provides:\n",
    "- **Agent isolation** - each subordinate agent has its own scope\n",
    "- **Stateless execution** - agents don't retain history between calls\n",
    "- **Clean separation of concerns** - each agent focuses on one domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "674a5323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Specialized tools created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define specialized tools for subordinate agents\n",
    "\n",
    "@tool\n",
    "def calculate_math(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs mathematical calculations. \n",
    "    Use this for any math-related queries.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression to evaluate (e.g., \"2 + 2\", \"sqrt(16)\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Safe evaluation of math expressions\n",
    "        import math\n",
    "        # Create a safe namespace with math functions\n",
    "        safe_dict = {\n",
    "            'sqrt': math.sqrt,\n",
    "            'pow': math.pow,\n",
    "            'sin': math.sin,\n",
    "            'cos': math.cos,\n",
    "            'tan': math.tan,\n",
    "            'log': math.log,\n",
    "            'pi': math.pi,\n",
    "            'e': math.e\n",
    "        }\n",
    "        result = eval(expression, {\"__builtins__\": {}}, safe_dict)\n",
    "        return f\"The result of {expression} is: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating {expression}: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def get_weather_info(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Gets weather information for a location.\n",
    "    Use this for weather-related queries.\n",
    "    \n",
    "    Args:\n",
    "        location: The city or location to get weather for\n",
    "    \"\"\"\n",
    "    # Simulated weather data (in real scenario, would call weather API)\n",
    "    weather_data = {\n",
    "        \"New York\": \"Sunny, 72¬∞F (22¬∞C)\",\n",
    "        \"London\": \"Cloudy, 61¬∞F (16¬∞C)\",\n",
    "        \"Tokyo\": \"Rainy, 68¬∞F (20¬∞C)\",\n",
    "        \"Paris\": \"Partly cloudy, 65¬∞F (18¬∞C)\"\n",
    "    }\n",
    "    \n",
    "    weather = weather_data.get(location, f\"Weather data not available for {location}. Please try a major city.\")\n",
    "    return f\"Weather in {location}: {weather}\"\n",
    "\n",
    "@tool \n",
    "def translate_text(text: str, target_language: str) -> str:\n",
    "    \"\"\"\n",
    "    Translates text to a target language.\n",
    "    Use this for translation requests.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to translate\n",
    "        target_language: The target language (e.g., 'Spanish', 'French', 'German')\n",
    "    \"\"\"\n",
    "    # Simulated translation (in real scenario, would use translation API)\n",
    "    translations = {\n",
    "        \"Spanish\": f\"[Spanish translation of: {text}]\",\n",
    "        \"French\": f\"[French translation of: {text}]\", \n",
    "        \"German\": f\"[German translation of: {text}]\",\n",
    "        \"Japanese\": f\"[Japanese translation of: {text}]\"\n",
    "    }\n",
    "    \n",
    "    translation = translations.get(target_language, f\"Translation to {target_language} not available\")\n",
    "    return translation\n",
    "\n",
    "print(\"‚úÖ Specialized tools created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c214c01",
   "metadata": {},
   "source": [
    "## 4. Create Subordinate Agent Tools (Dynamic Agent Pattern)\n",
    "\n",
    "Following the article's pattern: **wrap agents as tools**. Each tool spawns a specialized agent on-demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eef0e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent tools created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create subordinate agents wrapped as tools\n",
    "# This follows the pattern from the article: agents as tools\n",
    "\n",
    "@tool\n",
    "def ask_math_agent(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Asks the math specialist agent to solve mathematical problems.\n",
    "    Use this for calculations, equations, or math-related questions.\n",
    "    \n",
    "    Args:\n",
    "        question: The math question to ask\n",
    "    \"\"\"\n",
    "    logger.info(f\"üßÆ Spawning math agent for: {question}\")\n",
    "    \n",
    "    # Dynamically create the math agent with its specialized tool\n",
    "    math_agent = create_agent(\n",
    "        model=llm,\n",
    "        tools=[calculate_math],\n",
    "        system_prompt=\"You are a mathematics expert. Use the calculate_math tool to solve problems accurately.\"\n",
    "    )\n",
    "    \n",
    "    # Invoke the agent\n",
    "    response = math_agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=question)]\n",
    "    })\n",
    "    \n",
    "    logger.info(\"‚úÖ Math agent completed task\")\n",
    "    return response['messages'][-1].content\n",
    "\n",
    "@tool\n",
    "def ask_weather_agent(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Asks the weather specialist agent about weather conditions.\n",
    "    Use this for weather-related queries.\n",
    "    \n",
    "    Args:\n",
    "        question: The weather question to ask\n",
    "    \"\"\"\n",
    "    logger.info(f\"üå§Ô∏è Spawning weather agent for: {question}\")\n",
    "    \n",
    "    # Dynamically create the weather agent with its specialized tool\n",
    "    weather_agent = create_agent(\n",
    "        model=llm,\n",
    "        tools=[get_weather_info],\n",
    "        system_prompt=\"You are a weather information specialist. Use the get_weather_info tool to provide weather data.\"\n",
    "    )\n",
    "    \n",
    "    # Invoke the agent\n",
    "    response = weather_agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=question)]\n",
    "    })\n",
    "    \n",
    "    logger.info(\"‚úÖ Weather agent completed task\")\n",
    "    return response['messages'][-1].content\n",
    "\n",
    "@tool\n",
    "def ask_translator_agent(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Asks the translation specialist agent to translate text.\n",
    "    Use this for translation requests.\n",
    "    \n",
    "    Args:\n",
    "        question: The translation request\n",
    "    \"\"\"\n",
    "    logger.info(f\"üåê Spawning translator agent for: {question}\")\n",
    "    \n",
    "    # Dynamically create the translator agent with its specialized tool\n",
    "    translator_agent = create_agent(\n",
    "        model=llm,\n",
    "        tools=[translate_text],\n",
    "        system_prompt=\"You are a translation specialist. Use the translate_text tool to translate content.\"\n",
    "    )\n",
    "    \n",
    "    # Invoke the agent\n",
    "    response = translator_agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=question)]\n",
    "    })\n",
    "    \n",
    "    logger.info(\"‚úÖ Translator agent completed task\")\n",
    "    return response['messages'][-1].content\n",
    "\n",
    "print(\"‚úÖ Agent tools created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb38e87",
   "metadata": {},
   "source": [
    "## 5. Create the Supervisor Agent\n",
    "\n",
    "The supervisor agent coordinates the entire workflow by:\n",
    "1. Understanding the user's request\n",
    "2. Deciding which subordinate agent(s) to invoke\n",
    "3. Collecting and synthesizing responses\n",
    "4. Providing a comprehensive answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d3d7549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Supervisor agent created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create the supervisor agent with access to all subordinate agent tools\n",
    "supervisor_agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[ask_math_agent, ask_weather_agent, ask_translator_agent],\n",
    "    system_prompt=\"\"\"You are a helpful supervisor agent that coordinates with specialized agents.\n",
    "\n",
    "When a user asks a question:\n",
    "1. Determine which specialist agent can best answer it\n",
    "2. Use the appropriate agent tool to get the answer\n",
    "3. Synthesize the response clearly for the user\n",
    "\n",
    "Available agents:\n",
    "- ask_math_agent: For mathematical calculations and problems\n",
    "- ask_weather_agent: For weather information\n",
    "- ask_translator_agent: For text translation\n",
    "\n",
    "You can use multiple agents if the query requires it.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Supervisor agent created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadc236a",
   "metadata": {},
   "source": [
    "## 6. Test the Multi-Agent System\n",
    "\n",
    "Let's test with different types of queries to see the agents in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc312436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 1: Math Query\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:üßÆ Spawning math agent for: (sqrt(144) + pow(2,3))\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:‚úÖ Math agent completed task\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Query: What is the square root of 144 plus 2 to the power of 3?\n",
      "\n",
      "ü§ñ Response: The square root of 144 plus 2 to the power of 3 equals 20.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Math query\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST 1: Math Query\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "query1 = \"What is the square root of 144 plus 2 to the power of 3?\"\n",
    "response1 = supervisor_agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=query1)]\n",
    "})\n",
    "\n",
    "print(f\"\\nüìù Query: {query1}\")\n",
    "print(f\"\\nü§ñ Response: {response1['messages'][-1].content}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a37a3a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 2: Weather Query\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:üå§Ô∏è Spawning weather agent for: What's the weather like in Tokyo?\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:‚úÖ Weather agent completed task\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Query: What's the weather like in Tokyo?\n",
      "\n",
      "ü§ñ Response: The current weather in Tokyo is rainy with a temperature of 68¬∞F (20¬∞C).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Weather query\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST 2: Weather Query\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "query2 = \"What's the weather like in Tokyo?\"\n",
    "response2 = supervisor_agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=query2)]\n",
    "})\n",
    "\n",
    "print(f\"\\nüìù Query: {query2}\")\n",
    "print(f\"\\nü§ñ Response: {response2['messages'][-1].content}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4410fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 3: Translation Query\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:üåê Spawning translator agent for: Translate 'Hello, how are you?' to Spanish\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:‚úÖ Translator agent completed task\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Query: Translate 'Hello, how are you?' to Spanish\n",
      "\n",
      "ü§ñ Response: The translation of 'Hello, how are you?' to Spanish is: Hola, ¬øc√≥mo est√°s?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Translation query\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST 3: Translation Query\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "query3 = \"Translate 'Hello, how are you?' to Spanish\"\n",
    "response3 = supervisor_agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=query3)]\n",
    "})\n",
    "\n",
    "print(f\"\\nüìù Query: {query3}\")\n",
    "print(f\"\\nü§ñ Response: {response3['messages'][-1].content}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cc4daa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 4: Multi-Agent Query\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:üßÆ Spawning math agent for: What's the weather like in Paris?\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:‚úÖ Math agent completed task\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Query: Calculate 15 * 8, and then tell me the weather in Paris\n",
      "\n",
      "ü§ñ Response: The current weather in Paris, France is:\n",
      "- Temperature: 15¬∞C (59¬∞F)\n",
      "- Conditions: Partly cloudy\n",
      "- Humidity: 60%\n",
      "- Wind: Light breeze from the north-east at 7 km/h\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 4: Multi-agent query (requires multiple agents)\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST 4: Multi-Agent Query\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "query4 = \"Calculate 15 * 8, and then tell me the weather in Paris\"\n",
    "response4 = supervisor_agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=query4)]\n",
    "})\n",
    "\n",
    "print(f\"\\nüìù Query: {query4}\")\n",
    "print(f\"\\nü§ñ Response: {response4['messages'][-1].content}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953141f8",
   "metadata": {},
   "source": [
    "## 7. Streaming Responses\n",
    "\n",
    "LangChain 1.0 supports streaming for real-time responses. Let's see the supervisor agent stream its response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0c2655b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 5: Streaming Response\n",
      "================================================================================\n",
      "\n",
      "üìù Query: What is the cosine of pi?\n",
      "\n",
      "ü§ñ Streaming Response:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:üßÆ Spawning math agent for: What is the cosine of pi?\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:‚úÖ Math agent completed task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine of œÄ (pi) is -1. This means that on the unit circle, which represents all possible points in a complex plane at a distance of 1 from the origin, the point corresponding to œÄ radians has an x-coordinate of -1 and a y-coordinate of 0."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a visual representation:\n",
      "\n",
      "```\n",
      "    ^\n",
      "    |\n",
      "    |   (0, 1)\n",
      "    |\n",
      "---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "    |   (1, 0)     œÄ/2      (0, -1)       -(œÄ/2)\n",
      "    |\n",
      "---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "    |   (1, 0)     œÄ      (-1, 0)       -(œÄ/2)\n",
      "    |\n",
      "---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "    |   (0, 1)     3œÄ/2  (-1, 0)       -(œÄ)\n",
      "    |\n",
      "    +---v---v---v---v---v---v---v---v---v---v---v---v---v---v---v---v---v---v---+\n",
      "      -2   -1     0      1       2\n",
      "```\n",
      "\n",
      "So, cos(œÄ) = -1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stream a response\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST 5: Streaming Response\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "query5 = \"What is the cosine of pi?\"\n",
    "print(f\"\\nüìù Query: {query5}\")\n",
    "print(f\"\\nü§ñ Streaming Response:\\n\")\n",
    "\n",
    "for chunk in supervisor_agent.stream(\n",
    "    {\"messages\": [HumanMessage(content=query5)]},\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    for key in chunk.keys():\n",
    "        if not chunk[key]:\n",
    "            continue\n",
    "        if 'messages' in chunk[key]:\n",
    "            for message in chunk[key]['messages']:\n",
    "                if hasattr(message, 'content') and message.content:\n",
    "                    print(message.content, end='', flush=True)\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f97b09",
   "metadata": {},
   "source": [
    "## 8. Understanding the Architecture\n",
    "\n",
    "### Key Patterns from the Article:\n",
    "\n",
    "1. **Agents as Tools**: Subordinate agents are wrapped as tools that the supervisor can call\n",
    "2. **Dynamic Spawning**: Agents are created on-demand when needed, not pre-initialized\n",
    "3. **Stateless Execution**: Each subordinate agent runs independently without shared state\n",
    "4. **Clean Separation**: Each agent has a focused responsibility\n",
    "\n",
    "### Advantages:\n",
    "\n",
    "- ‚úÖ **Simple to understand and maintain**\n",
    "- ‚úÖ **No complex orchestration needed**\n",
    "- ‚úÖ **Agents are isolated and focused**\n",
    "- ‚úÖ **Easy to add new specialized agents**\n",
    "- ‚úÖ **Supervisor handles coordination naturally**\n",
    "\n",
    "### When to Use This Pattern:\n",
    "\n",
    "- When you need **multiple specialized capabilities**\n",
    "- When agents don't need to **share context**\n",
    "- When you want **simple, clean code** without middleware complexity\n",
    "- When you're building a **proof of concept** or **MVP**\n",
    "\n",
    "### When to Use LangGraph Instead:\n",
    "\n",
    "- When you need **fine-grained control** over agent interactions\n",
    "- When agents need to **maintain state** across interactions\n",
    "- When you need **complex branching logic**\n",
    "- When you need **human-in-the-loop** approval workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe832e7",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "This notebook demonstrated a **simple multi-agent workflow** using LangChain without LangGraph or middleware, based on patterns from the article [LangChain 1.0 ‚Äî A second look](https://medium.com/mitb-for-all/langchain-a-second-look-6ed720e27fec).\n",
    "\n",
    "### What We Built:\n",
    "- ‚úÖ Multiple specialized agents (math, weather, translation)\n",
    "- ‚úÖ A supervisor agent that coordinates them\n",
    "- ‚úÖ Dynamic agent spawning using the \"agents as tools\" pattern\n",
    "- ‚úÖ Clean, maintainable code without complex middleware\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **LangChain 1.0** makes multi-agent systems much simpler than before\n",
    "2. **Agents as tools** is an elegant pattern for coordination\n",
    "3. **Dynamic spawning** keeps agents stateless and focused\n",
    "4. This pattern is **perfect for MVPs** and simpler use cases\n",
    "\n",
    "### Next Steps:\n",
    "- Add more specialized agents for your domain\n",
    "- Implement error handling and retries\n",
    "- Add logging and monitoring\n",
    "- Consider LangGraph for more complex orchestration needs\n",
    "\n",
    "### References:\n",
    "- [LangChain 1.0 Documentation](https://docs.langchain.com/)\n",
    "- [Original Article](https://medium.com/mitb-for-all/langchain-a-second-look-6ed720e27fec)\n",
    "- [Author's GitHub Repository](https://github.com/tituslhy/glowing-guide)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-with-haystack-ch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
