{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd78f6a",
   "metadata": {},
   "source": [
    "üîß **Setup Required**: Before running this notebook, please follow the [setup instructions](../../README.md#setup-instructions) to configure your environment and API keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aa961a",
   "metadata": {},
   "source": [
    "# Building a Graph-based Agent with Tools using LangGraph\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates how to create an **agent** that uses external tools to answer questions, running entirely locally with Ollama and Mistral-Nemo.\n",
    "\n",
    "## What You'll Learn\n",
    "1. How to set up a local LLM agent with Ollama\n",
    "2. How to integrate search tools (Tavily) with an agent\n",
    "3. How to build an agent loop that decides when to use tools\n",
    "4. How to manage state across multiple agent steps\n",
    "\n",
    "## Requirements\n",
    "- **Ollama** installed with Mistral-Nemo model: `ollama pull mistral-nemo:12b`\n",
    "- **Tavily API key** for search functionality (get free key at [tavily.com](https://tavily.com))\n",
    "\n",
    "## Benefits\n",
    "- üîí **Privacy**: LLM runs completely locally\n",
    "- üí∞ **Cost-effective**: No API costs for the language model\n",
    "- ‚ö° **Fast**: Mistral-Nemo is optimized for speed and quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a942c806",
   "metadata": {},
   "source": [
    "## Step 1: Verify Ollama Setup\n",
    "\n",
    "Let's check that Ollama is running and the Mistral-Nemo model is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79182f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Ollama is installed and running\n",
      "\n",
      "Available models:\n",
      "NAME                       ID              SIZE      MODIFIED     \n",
      "nomic-embed-text:latest    0a109f422b47    274 MB    3 days ago      \n",
      "mistral-nemo:12b           e7e06d107c6c    7.1 GB    3 days ago      \n",
      "qwen2:0.5b                 6f48b936a09f    352 MB    2 weeks ago     \n",
      "gpt-oss:20b                f2b8351c629c    13 GB     3 months ago    \n",
      "\n",
      "\n",
      "‚úì Mistral-Nemo model is ready!\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(['ollama', 'list'], capture_output=True, text=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úì Ollama is installed and running\\n\")\n",
    "        print(\"Available models:\")\n",
    "        print(result.stdout)\n",
    "        \n",
    "        if 'mistral-nemo' in result.stdout.lower():\n",
    "            print(\"\\n‚úì Mistral-Nemo model is ready!\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è  Run: ollama pull mistral-nemo:12b\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Ollama might not be running. Try: ollama serve\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Ollama not found. Install from: https://ollama.com\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3359671",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries\n",
    "\n",
    "We'll import:\n",
    "- **LangGraph**: For building the agent workflow\n",
    "- **ChatOllama**: For local LLM integration  \n",
    "- **TavilySearchResults**: For web search capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73faa6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurafunderburk/Documents/GitHub/Building-Natural-Language-Pipelines/ch2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Annotated, Literal\n",
    "from operator import add\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI  # Alternative for faster performance\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (for Tavily API key)\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b573b7c6",
   "metadata": {},
   "source": [
    "## Step 3: Define Agent State\n",
    "\n",
    "The state tracks:\n",
    "- **messages**: Conversation history (inherited from `MessagesState`)\n",
    "- **tool_calls_count**: Number of times tools have been used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7e75b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Agent state defined\n"
     ]
    }
   ],
   "source": [
    "class AgentState(MessagesState):\n",
    "    \"\"\"State for our agent that tracks conversation and tool usage.\"\"\"\n",
    "    tool_calls_count: Annotated[int, add]\n",
    "\n",
    "print(\"‚úì Agent state defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3660d7f1",
   "metadata": {},
   "source": [
    "## Step 4: Set Up Tools and Model\n",
    "\n",
    "We configure:\n",
    "- **Tavily search tool**: Returns top 3 search results\n",
    "- **Mistral-Nemo model**: A 12B parameter model optimized for tool use\n",
    "- **Tool binding**: Connects the tools to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c96043",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Performance Note\n",
    "\n",
    "**Running Time**: Using Ollama with local models will be **slower** than cloud-based APIs, especially on CPU. The Mistral-Nemo 12B model may take several seconds per response.\n",
    "\n",
    "**For Faster Performance**: If you need quicker responses and don't mind using a cloud API:\n",
    "- Use **ChatOpenAI** instead (requires OpenAI API key)\n",
    "- Responses will be significantly faster but will incur API costs\n",
    "- The code for ChatOpenAI alternative is included below as commented code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfd0d925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Mistral-Nemo model initialized with tools\n",
      "‚úì Available tools: ['tavily_search_results_json']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k7/8m84jpf52x7gvx628v82h2p80000gn/T/ipykernel_29858/4026440701.py:2: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
      "  tools = [TavilySearchResults(max_results=3)]\n"
     ]
    }
   ],
   "source": [
    "# Initialize search tool\n",
    "tools = [TavilySearchResults(max_results=3)]\n",
    "\n",
    "# Initialize local LLM with Ollama (slower but private and free)\n",
    "llm = ChatOllama(\n",
    "    model=\"mistral-nemo:12b\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# # Alternative: Use ChatOpenAI for faster performance (requires API key)\n",
    "# # Uncomment the lines below and comment out ChatOllama above to use OpenAI\n",
    "# llm = ChatOpenAI(\n",
    "#     model=\"gpt-4o-mini\",  # or \"gpt-4\" for better quality\n",
    "#     temperature=0,\n",
    "# )\n",
    "\n",
    "# Bind tools to the model\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"‚úì Mistral-Nemo model initialized with tools\")\n",
    "print(f\"‚úì Available tools: {[tool.name for tool in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fd4d6a",
   "metadata": {},
   "source": [
    "## Step 5: Define Agent Node\n",
    "\n",
    "The agent node is where the LLM:\n",
    "1. Receives the conversation history\n",
    "2. Decides whether to use a tool or respond directly\n",
    "3. Returns its decision (which may include tool calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "278f483b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Agent node defined\n"
     ]
    }
   ],
   "source": [
    "def agent_node(state: AgentState):\n",
    "    \"\"\"The agent decides whether to use tools or respond directly.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "print(\"‚úì Agent node defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5793297c",
   "metadata": {},
   "source": [
    "## Step 6: Define Routing Logic\n",
    "\n",
    "This function determines the next step:\n",
    "- If the agent wants to use tools ‚Üí route to \"tools\"\n",
    "- If the agent has finished ‚Üí route to END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58f34a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Routing logic defined\n"
     ]
    }
   ],
   "source": [
    "def should_continue(state: AgentState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"Determine if we should continue to tools or end.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # Check if the agent wants to use tools\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"__end__\"\n",
    "\n",
    "print(\"‚úì Routing logic defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b263c8e",
   "metadata": {},
   "source": [
    "## Step 7: Build the Agent Graph\n",
    "\n",
    "The graph structure:\n",
    "```\n",
    "START ‚Üí agent ‚Üí [decision]\n",
    "                ‚îú‚Üí tools ‚Üí agent (loop back)\n",
    "                ‚îî‚Üí END\n",
    "```\n",
    "\n",
    "This creates a loop where:\n",
    "1. Agent analyzes the question\n",
    "2. If needed, calls tools for information\n",
    "3. Processes tool results\n",
    "4. Repeats until ready to answer\n",
    "5. Returns final response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e2e2e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Agent graph compiled successfully!\n"
     ]
    }
   ],
   "source": [
    "# Build the workflow\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define the flow\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\"tools\": \"tools\", \"__end__\": END}\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"‚úì Agent graph compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0b6fed",
   "metadata": {},
   "source": [
    "## Step 8: Visualize the Graph\n",
    "\n",
    "Let's see the structure of our agent workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "457f0dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x14fa6c6b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the graph\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21045cd5",
   "metadata": {},
   "source": [
    "## Step 9: Test the Agent\n",
    "\n",
    "Let's test with a query that requires current information (will trigger tool use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25f94449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query: What are the latest developments in AI language models in 2025?\n",
      "================================================================================\n",
      "AGENT RESPONSE:\n",
      "================================================================================\n",
      "Here are some of the latest developments in AI language models as of November 2025:\n",
      "\n",
      "1. **Top Large Language Models:**\n",
      "   - Grok 4 and Grok 4 Heavy from xAI lead the pack, demonstrating enhanced reasoning capabilities refined through large-scale reinforcement learning. These models can handle complex tasks and make decisive plans due to their native tool use and real-time search features, making them \"agentic.\" (Source: [Top 9 Large Language Models as of November 2025 | Shakudo](https://www.shakudo.io/blog/top-9-large-language-models))\n",
      "\n",
      "2. **Global AI Model Development:**\n",
      "   - In 2024, U.S.-based institutions produced 40 notable AI models, while China produced 15 and Europe produced three. Although the U.S. maintains its lead in quantity, Chinese models have closed the quality gap significantly. (Source: [The 2025 AI Index Report | Stanford HAI](https://hai.stanford.edu/ai-index/2025-ai-index-report))\n",
      "\n",
      "3. **Rapid Growth and Competition:**\n",
      "   - Model scale continues to grow rapidly, with training compute doubling every five months, datasets every eight months, and power use annually. Performance gaps between models are shrinking, indicating increased competition at the frontier. (Source: [The 2025 AI Index Report | Stanford HAI](https://hai.stanford.edu/ai-index/2025-ai-index-report))\n",
      "\n",
      "4. **Key NLP Technologies in 2025:**\n",
      "   - Transformer and reasoning models, multimodal and multilingual models, and low-resource language optimization are some of the key NLP technologies prevalent in 2025. (Source: [Natural Language Processing in 2025: Trends & Use Cases - Aezion](https://www.aezion.com/blogs/natural-language-processing/))\n",
      "\n",
      "================================================================================\n",
      "üìä Total messages: 4\n",
      "üîß Tool used: True\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the latest developments in AI language models in 2025?\"\n",
    "\n",
    "print(f\"üîç Query: {query}\")\n",
    "\n",
    "\n",
    "# Run the agent\n",
    "result = app.invoke({\n",
    "    \"messages\": [(\"user\", query)],\n",
    "    \"tool_calls_count\": 0\n",
    "})\n",
    "\n",
    "# Display the response\n",
    "print(\"=\" * 80)\n",
    "print(\"AGENT RESPONSE:\")\n",
    "print(\"=\" * 80)\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"üìä Total messages: {len(result['messages'])}\")\n",
    "print(f\"üîß Tool used: {len(result['messages']) > 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527a65e0",
   "metadata": {},
   "source": [
    "## Step 10: View Conversation Trace\n",
    "\n",
    "Let's examine how the agent processed the request step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccea1bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FULL CONVERSATION TRACE:\n",
      "================================================================================\n",
      "\n",
      "Message 1 (HumanMessage):\n",
      "----------------------------------------\n",
      "Content: What are the latest developments in AI language models in 2025?\n",
      "\n",
      "Message 2 (AIMessage):\n",
      "----------------------------------------\n",
      "Tool Calls: 1 tool(s) requested\n",
      "\n",
      "Message 3 (ToolMessage):\n",
      "----------------------------------------\n",
      "Content: [{\"title\": \"Top 9 Large Language Models as of November 2025 | Shakudo\", \"url\": \"https://www.shakudo.io/blog/top-9-large-language-models\", \"content\": \"Alibaba has been actively advancing its language m...\n",
      "\n",
      "Message 4 (AIMessage):\n",
      "----------------------------------------\n",
      "Content: As of 2025, several significant developments in AI language models have emerged:\n",
      "\n",
      "1. **Hybrid Mixture-of-Experts Models**: Alibaba has introduced the Qwen3 series, which includes models like Qwen3-235...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFULL CONVERSATION TRACE:\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "for i, msg in enumerate(result[\"messages\"], 1):\n",
    "    msg_type = type(msg).__name__\n",
    "    print(f\"Message {i} ({msg_type}):\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if hasattr(msg, 'content') and msg.content:\n",
    "        content = str(msg.content)\n",
    "        print(f\"Content: {content[:200]}...\" if len(content) > 200 else f\"Content: {content}\")\n",
    "    \n",
    "    if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "        print(f\"Tool Calls: {len(msg.tool_calls)} tool(s) requested\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2913b9",
   "metadata": {},
   "source": [
    "## Step 11: Test Different Query Types\n",
    "\n",
    "Let's see how the agent handles different types of questions:\n",
    "- Questions requiring search (should use tools)\n",
    "- Simple questions (should answer directly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da84f90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AGENT RESPONSE:\n",
      "================================================================================\n",
      "2 + 2 equals 4.\n",
      "\n",
      "================================================================================\n",
      "üìä Total messages: 2\n",
      "üîß Tool used: False\n"
     ]
    }
   ],
   "source": [
    "result = app.invoke({\n",
    "        \"messages\": [(\"user\", \"What is 2 + 2?\")],\n",
    "        \"tool_calls_count\": 0\n",
    "    })\n",
    "\n",
    "# Display the response\n",
    "print(\"=\" * 80)\n",
    "print(\"AGENT RESPONSE:\")\n",
    "print(\"=\" * 80)\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"üìä Total messages: {len(result['messages'])}\")\n",
    "print(f\"üîß Tool used: {len(result['messages']) > 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16757e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AGENT RESPONSE:\n",
      "================================================================================\n",
      "The 2023 Nobel Prize in Physics was awarded to:\n",
      "\n",
      "- **Pierre Agostini** (The Ohio State University, USA)\n",
      "- **Ferenc Krausz** (Max Planck Institute of Quantum Optics, Germany)\n",
      "- **Anne L‚ÄôHuillier** (Lund University, Sweden)\n",
      "\n",
      "They were recognized for their experimental methods that generate attosecond pulses of light, which are used to study electron dynamics in matter. \n",
      "\n",
      "For more details, you can visit the official [Nobel Prize press release](https://www.nobelprize.org/prizes/physics/2023/press-release/).\n",
      "\n",
      "================================================================================\n",
      "üìä Total messages: 4\n",
      "üîß Tool used: True\n"
     ]
    }
   ],
   "source": [
    "result = app.invoke({\n",
    "        \"messages\": [(\"user\",\"Who won the latest Nobel Prize in Physics?\")],\n",
    "        \"tool_calls_count\": 0\n",
    "    })\n",
    "\n",
    "# Display the response\n",
    "print(\"=\" * 80)\n",
    "print(\"AGENT RESPONSE:\")\n",
    "print(\"=\" * 80)\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"üìä Total messages: {len(result['messages'])}\")\n",
    "print(f\"üîß Tool used: {len(result['messages']) > 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e704893d",
   "metadata": {},
   "source": [
    "## Step 12: Stream Agent Execution (Optional)\n",
    "\n",
    "For long-running queries, we can stream the agent's execution to see each step in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7719e1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query: What are the top 3 tech companies by market cap right now?\n",
      "\n",
      "Streaming execution...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[Step: agent]\n",
      "Type: AIMessage\n",
      "----------------------------------------\n",
      "\n",
      "[Step: agent]\n",
      "Type: AIMessage\n",
      "----------------------------------------\n",
      "\n",
      "[Step: tools]\n",
      "Type: ToolMessage\n",
      "Preview: [{\"title\": \"The Largest Technology Companies by Market Cap in November ...\", \"url\": \"https://www.fool.com/research/largest-tech-companies/\", \"content\"...\n",
      "----------------------------------------\n",
      "\n",
      "[Step: tools]\n",
      "Type: ToolMessage\n",
      "Preview: [{\"title\": \"The Largest Technology Companies by Market Cap in November ...\", \"url\": \"https://www.fool.com/research/largest-tech-companies/\", \"content\"...\n",
      "----------------------------------------\n",
      "\n",
      "[Step: agent]\n",
      "Type: AIMessage\n",
      "Preview: As of October 2023, the top three tech companies by market capitalization are:\n",
      "\n",
      "1. **Nvidia (NASDAQ: NVDA)** - Market Cap: $4.8 trillion\n",
      "2. **Apple (N...\n",
      "----------------------------------------\n",
      "\n",
      "[Step: agent]\n",
      "Type: AIMessage\n",
      "Preview: As of October 2023, the top three tech companies by market capitalization are:\n",
      "\n",
      "1. **Nvidia (NASDAQ: NVDA)** - Market Cap: $4.8 trillion\n",
      "2. **Apple (N...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the top 3 tech companies by market cap right now?\"\n",
    "\n",
    "print(f\"üîç Query: {query}\\n\")\n",
    "print(\"Streaming execution...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for event in app.stream({\n",
    "    \"messages\": [(\"user\", query)],\n",
    "    \"tool_calls_count\": 0\n",
    "}):\n",
    "    for node_name, value in event.items():\n",
    "        print(f\"\\n[Step: {node_name}]\")\n",
    "        if \"messages\" in value:\n",
    "            last_msg = value[\"messages\"][-1]\n",
    "            msg_type = type(last_msg).__name__\n",
    "            print(f\"Type: {msg_type}\")\n",
    "            \n",
    "            if hasattr(last_msg, 'content') and last_msg.content:\n",
    "                content = str(last_msg.content)\n",
    "                preview = content[:150] + \"...\" if len(content) > 150 else content\n",
    "                print(f\"Preview: {preview}\")\n",
    "        print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d43854f",
   "metadata": {},
   "source": [
    "## Understanding Agent Behavior\n",
    "\n",
    "### When Does the Agent Use Tools?\n",
    "- **Current information**: Weather, news, recent events\n",
    "- **Factual verification**: When uncertain about facts\n",
    "- **Real-time data**: Stock prices, sports scores\n",
    "\n",
    "### When Does the Agent Answer Directly?\n",
    "- **General knowledge**: Math, science, history\n",
    "- **Reasoning tasks**: Logic problems, explanations\n",
    "- **Creative tasks**: Writing, brainstorming\n",
    "\n",
    "### The Agent Loop\n",
    "```\n",
    "User Question ‚Üí Agent Analyzes ‚Üí Need Info?\n",
    "                                    ‚Üì Yes\n",
    "Final Answer ‚Üê Agent Synthesizes ‚Üê Tools Execute\n",
    "      ‚Üì No\n",
    "     END\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa70474",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### What We Built\n",
    "‚úÖ **Local agent**: Runs entirely on your machine with Ollama  \n",
    "‚úÖ **Tool integration**: Agent can search the web when needed  \n",
    "‚úÖ **Smart routing**: Decides when to use tools vs. answer directly  \n",
    "‚úÖ **State management**: Tracks conversation across multiple steps  \n",
    "\n",
    "### Benefits\n",
    "- üîí **Privacy**: No data sent to external LLM APIs\n",
    "- üí∞ **Cost-effective**: Free LLM inference\n",
    "- ‚ö° **Fast**: Mistral-Nemo is optimized for speed\n",
    "- üéØ **Capable**: Handles tool calling and multi-step reasoning\n",
    "\n",
    "### Next Steps\n",
    "1. **Try different models**: Test with larger models like `llama3.1:70b`\n",
    "2. **Add more tools**: Calculator, file operations, database queries\n",
    "3. **Implement memory**: Add persistent conversation history\n",
    "4. **Add human-in-the-loop**: Require approval for sensitive actions\n",
    "5. **Build multi-agent systems**: Coordinate multiple specialized agents\n",
    "\n",
    "### Best Practices\n",
    "- Start with 1-2 tools and expand gradually\n",
    "- Write clear tool descriptions to guide the agent\n",
    "- Monitor tool usage and costs (for paid APIs like Tavily)\n",
    "- Test with various query types to understand agent behavior\n",
    "- Use streaming for better user experience with long queries\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "**1. Ollama Not Found**\n",
    "```bash\n",
    "# Install Ollama from https://ollama.com\n",
    "# Then pull the model:\n",
    "ollama pull mistral-nemo:12b\n",
    "```\n",
    "\n",
    "**2. Tavily API Key Missing**\n",
    "```python\n",
    "# Set the API key:\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"your-key-here\"\n",
    "# Or add to .env file: TAVILY_API_KEY=your-key-here\n",
    "```\n",
    "\n",
    "**3. Agent Not Using Tools**\n",
    "- Make sure your query requires current information\n",
    "- Try rephrasing the question more explicitly\n",
    "- Check that tools are properly bound: `llm_with_tools`\n",
    "\n",
    "**4. Slow Performance**\n",
    "- Try a smaller model: `mistral:7b` or `qwen2:7b`\n",
    "- Ensure Ollama has sufficient RAM\n",
    "- Check CPU/GPU usage during inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-with-haystack-ch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
