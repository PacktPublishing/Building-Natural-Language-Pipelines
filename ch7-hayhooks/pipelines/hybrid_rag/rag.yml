components:
  bm25_retriever:
    init_parameters:
      document_store:
        init_parameters:
          api_key: null
          embedding_dim: 1536
          force_disable_check_same_thread: false
          grpc_port: 6334
          hnsw_config: null
          host: null
          https: null
          index: documents
          location: null
          metadata: &id001 {}
          on_disk: false
          on_disk_payload: null
          optimizers_config: null
          path: ./qdrant_storage
          payload_fields_to_index: null
          port: 6333
          prefer_grpc: false
          prefix: null
          progress_bar: true
          quantization_config: null
          recreate_index: false
          replication_factor: null
          return_embedding: false
          scroll_size: 10000
          shard_number: null
          similarity: cosine
          sparse_idf: false
          timeout: null
          url: null
          use_sparse_embeddings: true
          wait_result_from_api: true
          wal_config: null
          write_batch_size: 100
          write_consistency_factor: null
        type: haystack_integrations.document_stores.qdrant.document_store.QdrantDocumentStore
      filter_policy: replace
      filters: null
      group_by: null
      group_size: null
      return_embedding: false
      scale_score: false
      score_threshold: null
      top_k: 3
    type: haystack_integrations.components.retrievers.qdrant.retriever.QdrantSparseEmbeddingRetriever
  document_joiner:
    init_parameters:
      join_mode: concatenate
      sort_by_score: true
      top_k: null
      weights: null
    type: haystack.components.joiners.document_joiner.DocumentJoiner
  embedding_retriever:
    init_parameters:
      document_store:
        init_parameters:
          api_key: null
          embedding_dim: 1536
          force_disable_check_same_thread: false
          grpc_port: 6334
          hnsw_config: null
          host: null
          https: null
          index: documents
          location: null
          metadata: *id001
          on_disk: false
          on_disk_payload: null
          optimizers_config: null
          path: ./qdrant_storage
          payload_fields_to_index: null
          port: 6333
          prefer_grpc: false
          prefix: null
          progress_bar: true
          quantization_config: null
          recreate_index: false
          replication_factor: null
          return_embedding: false
          scroll_size: 10000
          shard_number: null
          similarity: cosine
          sparse_idf: false
          timeout: null
          url: null
          use_sparse_embeddings: true
          wait_result_from_api: true
          wal_config: null
          write_batch_size: 100
          write_consistency_factor: null
        type: haystack_integrations.document_stores.qdrant.document_store.QdrantDocumentStore
      filter_policy: replace
      filters: null
      group_by: null
      group_size: null
      return_embedding: false
      scale_score: false
      score_threshold: null
      top_k: 3
    type: haystack_integrations.components.retrievers.qdrant.retriever.QdrantEmbeddingRetriever
  llm:
    init_parameters:
      api_base_url: null
      api_key:
        env_vars:
        - OPENAI_API_KEY
        strict: true
        type: env_var
      generation_kwargs: {}
      http_client_kwargs: null
      model: gpt-4o-mini
      organization: null
      streaming_callback: null
      system_prompt: null
    type: haystack.components.generators.openai.OpenAIGenerator
  prompt_builder:
    init_parameters:
      required_variables:
      - documents
      - question
      template: "\nGiven the following information, answer the user's question.\n\
        If the information is not available in the provided documents, say that you\
        \ don't have enough information to answer.\n\nContext:\n{% for doc in documents\
        \ %}\n    {{ doc.content }}\n{% endfor %}\n\nQuestion: {{question}}\nAnswer:\n"
      variables: null
    type: haystack.components.builders.prompt_builder.PromptBuilder
  ranker:
    init_parameters:
      backend: torch
      batch_size: 16
      config_kwargs: null
      device:
        device: cpu
        type: single
      document_prefix: ''
      embedding_separator: '

        '
      meta_fields_to_embed: []
      model: BAAI/bge-reranker-base
      model_kwargs: null
      query_prefix: ''
      scale_score: true
      score_threshold: null
      token:
        env_vars:
        - HF_API_TOKEN
        - HF_TOKEN
        strict: false
        type: env_var
      tokenizer_kwargs: null
      top_k: 3
      trust_remote_code: false
    type: haystack.components.rankers.sentence_transformers_similarity.SentenceTransformersSimilarityRanker
  sparse_text_embedder:
    init_parameters:
      cache_dir: null
      local_files_only: false
      model: prithivida/Splade_PP_en_v1
      model_kwargs: null
      parallel: null
      progress_bar: true
      threads: null
    type: haystack_integrations.components.embedders.fastembed.fastembed_sparse_text_embedder.FastembedSparseTextEmbedder
  text_embedder:
    init_parameters:
      api_base_url: null
      api_key:
        env_vars:
        - OPENAI_API_KEY
        strict: true
        type: env_var
      dimensions: null
      http_client_kwargs: null
      max_retries: null
      model: text-embedding-3-small
      organization: null
      prefix: ''
      suffix: ''
      timeout: null
    type: haystack.components.embedders.openai_text_embedder.OpenAITextEmbedder
connection_type_validation: true
connections:
- receiver: embedding_retriever.query_embedding
  sender: text_embedder.embedding
- receiver: bm25_retriever.query_sparse_embedding
  sender: sparse_text_embedder.sparse_embedding
- receiver: document_joiner.documents
  sender: embedding_retriever.documents
- receiver: document_joiner.documents
  sender: bm25_retriever.documents
- receiver: ranker.documents
  sender: document_joiner.documents
- receiver: prompt_builder.documents
  sender: ranker.documents
- receiver: llm.prompt
  sender: prompt_builder.prompt
max_runs_per_component: 100
metadata: {}
