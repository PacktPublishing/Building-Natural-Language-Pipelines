{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### `spaCy` Use Case: Named Entity Recognition (NER)\n",
    "Extract named entities (e.g., person names, organizations, locations) from a text using spaCy's pre-trained models.\n",
    "\n",
    "Code Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities, Phrases, and Concepts:\n",
      "Apple (ORG)\n",
      "U.K. (GPE)\n",
      "$1 billion (MONEY)\n",
      "Tim Cook (PERSON)\n",
      "Apple (ORG)\n",
      "San Francisco (GPE)\n",
      "last week (DATE)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load a pre-trained spaCy model for English (en_core_web_sm)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Example text for Named Entity Recognition (NER)\n",
    "text = \"\"\"\n",
    "Apple is looking at buying U.K. startup for $1 billion. \n",
    "Tim Cook, the CEO of Apple, confirmed the deal in San Francisco last week.\n",
    "\"\"\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract and print named entities\n",
    "print(\"Named Entities, Phrases, and Concepts:\")\n",
    "for entity in doc.ents:\n",
    "    print(f\"{entity.text} ({entity.label_})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* We load a small pre-trained model (en_core_web_sm), which has been trained for tasks like part-of-speech tagging, named entity recognition (NER), etc.\n",
    "* The doc.ents gives us the named entities identified in the text, such as organizations, locations, dates, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `spaCy` Use Case: Dependency Parsing\n",
    "Use Case: Extract syntactic relationships between words in a sentence (e.g., subject, verb, object) using spaCyâ€™s dependency parsing.\n",
    "\n",
    "Code Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word         Dependency      Head Word\n",
      "The          det             cat\n",
      "cat          nsubj           sat\n",
      "sat          ROOT            sat\n",
      "on           prep            sat\n",
      "the          det             mat\n",
      "mat          pobj            on\n",
      ".            punct           sat\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English model for dependency parsing\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Example sentence\n",
    "sentence = \"The cat sat on the mat.\"\n",
    "\n",
    "# Process the sentence\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Display syntactic dependencies\n",
    "print(f\"{'Word':<12} {'Dependency':<15} {'Head Word'}\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<12} {token.dep_:<15} {token.head.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* In dependency parsing, each word in the sentence is linked to a \"head\" word and has a syntactic role (like subject, verb, object).\n",
    "* The above code prints the word, its syntactic dependency, and the word it depends on (head word)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `spaCy` Use Case: Part-of-Speech Tagging\n",
    "Use Case: Identify the part of speech (e.g., noun, verb, adjective) for each word in a sentence using spaCy.\n",
    "\n",
    "Code Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: PROPN\n",
      "is: AUX\n",
      "an: DET\n",
      "amazing: ADJ\n",
      "programming: NOUN\n",
      "language: NOUN\n",
      ".: PUNCT\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Example sentence for POS tagging\n",
    "sentence = \"Python is an amazing programming language.\"\n",
    "\n",
    "# Process the sentence\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Print each word with its part of speech\n",
    "for token in doc:\n",
    "    print(f\"{token.text}: {token.pos_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* The `pos_` attribute gives the part of speech for each token (e.g., `NOUN`, `VERB`, `ADJ`).\n",
    "* This is useful for tasks like syntactic analysis, text classification, or parsing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face Transformers Use Case: Sentiment Analysis\n",
    "Use Case: Perform sentiment analysis (e.g., determine whether a sentence is positive, negative, or neutral) using a pre-trained model from Hugging Face.\n",
    "\n",
    "Code Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurafunderburk/Documents/GitHub/Building-Natural-Language-Pipelines/venvs/dev/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9997923970222473}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained sentiment-analysis pipeline from Hugging Face\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Example text for sentiment analysis\n",
    "text = \"I love working with Python, it makes development fun and easy!\"\n",
    "\n",
    "# Analyze sentiment\n",
    "result = sentiment_analyzer(text)\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* We use the pipeline function to easily load a pre-trained sentiment analysis model from Hugging Face. The model returns whether the sentiment is POSITIVE or NEGATIVE along with a confidence score.\n",
    "* This pipeline makes it easy to perform sentiment analysis without manually handling the model and tokenization process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face Transformers Use Case: Text Summarization\n",
    "Use Case: Generate a summary for a long text using a pre-trained text summarization model from Hugging Face.\n",
    "\n",
    "Code Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Apollo 11 mission was the first manned mission to land on the Moon . American astronauts Neil Armstrong and Buzz Aldrin landed the lunar module on July 20, 1969 . The event was broadcast to an audience of millions, and it marked a significant milestone in space exploration .\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained summarization pipeline from Hugging Face\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "# Example long text\n",
    "text = \"\"\"\n",
    "The Apollo 11 mission was the first manned mission to land on the Moon. \n",
    "On July 20, 1969, American astronauts Neil Armstrong and Buzz Aldrin landed the lunar module, \n",
    "Eagle, on the surface of the Moon while Michael Collins remained in orbit around the Moon. \n",
    "Neil Armstrong became the first human to set foot on the Moon, followed shortly by Buzz Aldrin. \n",
    "The event was broadcast to an audience of millions, and it marked a significant milestone in the history of space exploration.\n",
    "\"\"\"\n",
    "\n",
    "# Summarize the text\n",
    "summary = summarizer(text, max_length=100, min_length=50, do_sample=False)\n",
    "\n",
    "# Print the summary\n",
    "print(summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* The `summarization` pipeline from Hugging Face is used here to reduce the length of a long text while retaining the main points.\n",
    "* The `max_length` and min_length parameters control the length of the summary. The do_sample=False ensures deterministic summarization (no randomness).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face Transformers Use Case: Named Entity Recognition (NER)\n",
    "Use Case: Extract named entities (like locations, organizations, people) from text using a Hugging Face model for NER.\n",
    "\n",
    "Code Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'I-PER', 'score': np.float32(0.9989973), 'index': 1, 'word': 'Barack', 'start': 0, 'end': 6}\n",
      "{'entity': 'I-PER', 'score': np.float32(0.99942195), 'index': 2, 'word': 'Obama', 'start': 7, 'end': 12}\n",
      "{'entity': 'I-LOC', 'score': np.float32(0.99836236), 'index': 6, 'word': 'Honolulu', 'start': 25, 'end': 33}\n",
      "{'entity': 'I-LOC', 'score': np.float32(0.9995079), 'index': 8, 'word': 'Hawaii', 'start': 35, 'end': 41}\n",
      "{'entity': 'I-LOC', 'score': np.float32(0.99870396), 'index': 19, 'word': 'United', 'start': 83, 'end': 89}\n",
      "{'entity': 'I-LOC', 'score': np.float32(0.9919043), 'index': 20, 'word': 'States', 'start': 90, 'end': 96}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained NER pipeline from Hugging Face\n",
    "ner_model = pipeline(\"ner\")\n",
    "\n",
    "# Example text for NER\n",
    "text = \"Barack Obama was born in Honolulu, Hawaii, and served as the 44th President of the United States.\"\n",
    "\n",
    "# Perform NER on the text\n",
    "entities = ner_model(text)\n",
    "\n",
    "# Print the named entities\n",
    "for entity in entities:\n",
    "    print(entity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP pipelines",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
