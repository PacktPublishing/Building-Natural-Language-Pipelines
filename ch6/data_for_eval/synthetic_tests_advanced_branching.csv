user_input,reference_contexts,reference,synthesizer_name
What significant updates were introduced in Haystack 2.0 that were first tested in December 2023?,"['Haystack 2.0: The Composable Open-Source LLM Framework\nMeet Haystack 2.0, a more flexible, customizable LLM framework\nMarch 11, 2024Today we are happy to announce the stable release of Haystack 2.0 - we‚Äôve been working on this for a while, and some of you have already been testing the beta since its first release in December 2023.\nHaystack is an open-source Python framework for building production-ready LLM applications, with integrations to almost all major model providers and databases.\nAt its core, Haystack 2.0 is a major rework of the previous version with a very clear goal in mind: making it possible to implement composable AI systems that are easy to use, customize, extend, optimise, evaluate and ultimately deploy to production.\nWe encourage you to start using Haystack 2.0 as of today, whether you‚Äôve been a Haystack user before or not. You can get started by installing haystack-ai\n, our new package for Haystack 2.0\n‚≠êÔ∏è To get started:\npip install haystack-ai\nand follow the get started instructions to build your first LLM app with just a few lines of code.\nIf you‚Äôre already using Haystack 1.0 in production, don‚Äôt worry! If your applications depend on farm-haystack\nand you‚Äôre not ready to migrate just yet, you don‚Äôt have to take any action: we will keep supporting Haystack 1.0, releasing security updates and critical bug fixes, giving everybody enough time to migrate. In the coming weeks, we will also start sharing some migration guides to help you along the way.\n Why Haystack 2.0?\nHaystack was first officially released in 2020, in the good old days when the forefront of NLP was semantic search, retrieval, and extractive question-answering. During this time, we established the core of what makes Haystack Haystack: Components and Pipelines. These allowed users to build end-to-end applications by combining their desired language models (embedding, extractive QA, ranking) with their database of choice.\nThe boom of LLMs in 2023 made two things clear:\n- üëç The pipeline-component structure is a great abstraction for building composable LLM applications with many moving parts.\n- üëé Haystack 1.0 often assumed that you would be doing retrieval and extractive QA over a set of documents, imposing limitations and providing a developer experience far from ideal when building LLM applications.\nSo, we decided that the best thing we could do for Haystack and our community was to rewrite the component and pipeline architecture to keep up with the fast-paced AI industry. While Haystack 2.0 is a complete rewrite, the underlying principle of composing components into flexible pipelines remains the same.\nWith that, let‚Äôs take a look at the pillars of Haystack 2.0:\n- Composable and customizable pipelines\n- A common interface for storing data\n- A clear path to production\n- Optimization and Evaluation for Retrieval Augmentation\n']","Haystack 2.0, which was first tested in December 2023, introduced a more flexible and customizable LLM framework. It is a major rework of the previous version, aimed at enabling the implementation of composable AI systems that are easy to use, customize, extend, optimize, evaluate, and deploy to production.",single_hop_specific_query_synthesizer
What is Haystack and how it help with making AI pipelines better and more flexible for users who want to customize their components?,"['Composable and customizable Pipelines\nModern LLM applications comprise many moving parts: retrievers, rankers, LLMs, and many more such as entity extractors, summarizers, format converters and data cleaners. Each one of these ‚Äòsubtasks‚Äô is a component in Haystack.\nWith the first version of Haystack we proved that pipelines are a good abstraction for connecting all those moving parts, but some of the assumptions we made in Haystack 1.0 dated back to a pre-LLM era and needed rethinking.\nOne important limitation in Haystack 1.0 is that loops are not allowed, and the pipeline graph has to be acyclic. This makes it difficult to implement, for example, agents, which are often designed with a reasoning flow that loops until a task is resolved.\nIn Haystack 2.0 the pipeline graph can have cycles. Combined with decision components (think about if-then-else clauses in the execution flow) and routers (components that direct the execution flow towards a specific subgraph depending on the input) this can be used to build sophisticated loops that model agentic behavior.\n Customizable Components\nWe believe that the design of an AI framework should meet the following requirements:\n- Be technology agnostic: Allow users the flexibility to decide what vendor or technology they want for each of these components and make it easy to switch out any component for another.\n- Be explicit: Make it transparent as to how these components can ‚Äútalk‚Äù to each other.\n- Be flexible: Make it possible to create custom components whenever custom behavior is desirable.\n- Be extensible: Provide a uniform and easy way for the community and third parties to build their own components and foster an open ecosystem around Haystack.\nAll components in Haystack 2.0 (including Haystack Integrations) are built with a common ‚Äúcomponent‚Äù interface. The principle is simple:\n- A component implements some logic in a method called\nrun\n- The\nrun\nmethod receives one or more input values - The\nrun\nmethod returns one or more output values\nTake embedders as an example: these components expect text as input and create vector representations (embeddings) that they return as output. On the other hand, retrievers may need embeddings as input and return documents as output. When creating a new component, to decide what inputs and outputs it should have is part of the ideation process.\nWhile there are many ready-made components built into Haystack, we want to highlight that building your own custom components is also a core functionality of Haystack 2.0.\nIn fact, we‚Äôve taken advantage of this ourselves. For example, you can read about how to use the latest optimization techniques (like HyDE) in Haystack pipelines with custom components.\n']","Haystack is an AI framework that allows for the creation of composable and customizable pipelines, which include various components like retrievers, rankers, and entity extractors. In Haystack 2.0, the pipeline graph can have cycles, enabling sophisticated loops that model agentic behavior. It is designed to be technology agnostic, explicit in component communication, flexible for custom components, and extensible for community contributions. Each component implements logic in a method called 'run', which processes input values and returns output values, allowing users to easily switch components and create custom behaviors.",single_hop_specific_query_synthesizer
What is Haystack and how does it help in AI applications?,"['A common interface for storing data - A clear path to production - Optimization and Evaluation for Retrieval Augmentation Composable and customizable Pipelines Modern LLM applications comprise many moving parts: retrievers, rankers, LLMs, and many more such as entity extractors, summarizers, format converters and data cleaners. Each one of these ‚Äòsubtasks‚Äô is a component in Haystack. With the first version of Haystack we proved that pipelines are a good abstraction for connecting all those moving parts, but some of the assumptions we made in Haystack 1.0 dated back to a pre-LLM era and needed rethinking. One important limitation in Haystack 1.0 is that loops are not allowed, and the pipeline graph has to be acyclic. This makes it difficult to implement, for example, agents, which are often designed with a reasoning flow that loops until a task is resolved. In Haystack 2.0 the pipeline graph can have cycles. Combined with decision components (think about if-then-else clauses in the execution flow) and routers (components that direct the execution flow towards a specific subgraph depending on the input) this can be used to build sophisticated loops that model agentic behavior. Customizable Components We believe that the design of an AI framework should meet the following requirements: - Be technology agnostic: Allow users the flexibility to decide what vendor or technology they want for each of these components and make it easy to switch out any component for another. - Be explicit: Make it transparent as to how these components can ‚Äútalk‚Äù to each other. - Be flexible: Make it possible to create custom components whenever custom behavior is desirable. - Be extensible: Provide a uniform and easy way for the community and third parties to build their own components and foster an open ecosystem around Haystack. All components in Haystack 2.0 (including Haystack Integrations) are built with a common ‚Äúcomponent‚Äù interface. The principle is simple: - A component implements some logic in a method called run - The run method receives one or more input values - The run method returns one or more output values Take embedders as an example: these components expect text as input and create vector representations (embeddings) that they return as output. On the other hand, retrievers may need embeddings as input and return documents as output. When creating a new component, to decide what inputs and outputs it should have is part of the ideation process. While there are many ready-made components built into Haystack, we want to highlight that building your own custom components is also a core functionality of Haystack 2.0. In fact, we‚Äôve taken advantage of this ourselves. For example, you can read about how to use the latest optimization techniques (like HyDE) in Haystack pipelines with custom components. Sharing Custom Components Since the release of Haystack 2.0-Beta, we‚Äôve seen the benefits of having a well-defined simple interface for components. We, our community, and third parties have already created many components, available as additional packages for you to install. We share these on the Haystack Integrations page, which has expanded to include all sorts of components over the last few months (with contributions from Assembly AI, Jina AI, mixedbread ai and more). We will continue to expand this page with new integrations and you can help us by creating a PR on haystack-integrations if you‚Äôd like to share a component with the community. To learn more about integrations and how to share them, you can check out our ‚ÄúIntroduction to Integrations‚Äù documentation. A common interface for storing data Most NLP applications work on large amounts of data. A common design pattern is to connect your internal knowledge base to a Large Language Model (LLM) so that it can answer questions, summarize or translate documents, and extract specific information. For example, in retrieval-augment generative pipelines (RAG), you often use an LLM to answer questions about some data that was previously retrieved. This data has to come from somewhere, and Haystack 2.0 provides a common interface to access it in a consistent way, independently from where data comes from. This interface is called ‚ÄúDocument Store‚Äù, and it‚Äôs implemented for many different storage services, to make data easily available from within Haystack pipelines. Today, we are releasing Haystack 2.0 with a large selection of database and vector store integrations. These include Chroma, Weaviate, Pinecone, Qdrant, Elasticsearch, Open Search, pgvector, MongoDB, AstraDB, Neo4j, Marqo DB, and the list will keep growing. And if your storage service is not supported yet, or should you need a high degree of customization on top of an existing one, by following our guide to creating custom document stores, you can connect your Haystack pipelines to your']","Haystack is an AI framework that provides a common interface for storing data and facilitates the creation of customizable and composable pipelines for modern LLM applications. It allows users to connect various components such as retrievers, rankers, and LLMs, enabling sophisticated loops and decision-making processes in AI applications.",single_hop_specific_query_synthesizer
What is Haystack and why is it important for AI applications?,"['data from pretty much any storage service. A clear path to production The experience we got over the last couple of years, working on Haystack 1.0 and interacting with its community, taught us two things: - It‚Äôs essential for any AI application framework to be feature-complete and developer-friendly. - It‚Äôs only after the deployment phase that AI-based applications can truly make an impact. While rewriting the framework from scratch, we took the opportunity to incorporate specific features that would simplify the deployment of Haystack-based AI applications in a production-grade environment: - A customizable logging system that supports structured logging and tracing correlation out of the box.']","Haystack is an AI application framework that is essential for being feature-complete and developer-friendly. It allows for the deployment of AI-based applications, which can truly make an impact only after the deployment phase.",single_hop_specific_query_synthesizer
What is Neo4j in the context of storage services?,"['These include Chroma, Weaviate, Pinecone, Qdrant, Elasticsearch, Open Search, pgvector, MongoDB, AstraDB, Neo4j, Marqo DB, and the list will keep growing. And if your storage service is not supported yet, or should you need a high degree of customization on top of an existing one, by following our guide to creating custom document stores, you can connect your Haystack pipelines to your data from pretty much any storage service.\n A clear path to production\nThe experience we got over the last couple of years, working on Haystack 1.0 and interacting with its community, taught us two things:\n- It‚Äôs essential for any AI application framework to be feature-complete and developer-friendly.\n- It‚Äôs only after the deployment phase that AI-based applications can truly make an impact.\nWhile rewriting the framework from scratch, we took the opportunity to incorporate specific features that would simplify the deployment of Haystack-based AI applications in a production-grade environment:\n- A customizable logging system that supports structured logging and tracing correlation out of the box.\n- Code instrumentation collecting spans and traces in strategic points of the execution path, with support for Open Telemetry and Datadog already in place.\nIn addition, we decided to start a dedicated project to simplify deploying Haystack pipelines behind a RESTful API: Hayhooks.\nHayhooks is a client-server application that allows you to deploy Haystack pipelines, serving them through HTTP endpoints dynamically spawned. Two foundational features of Haystack 2.0 made this possible:\n- The ability to introspect a pipeline, determining its inputs and outputs at runtime. This means that every REST endpoint has well-defined, dynamically generated schemas for the request and response body, all depending on the specific pipeline structure.\n- A robust serialization mechanism. This allows for the conversion of Haystack pipelines from Python to a preferred data serialization format, and vice versa. The default format is YAML but Haystack is designed to easily extend support for additional serialization formats.\n Optimization and Evaluation of Retrieval Augmentation\nWe‚Äôve already been seeing the benefits of the new Haystack design, with pipeline optimization and evaluation being good examples of how we‚Äôve been leveraging Haystack 2.0. How?:\n- It‚Äôs easier to extend the capabilities of Haystack\n- It‚Äôs easy to implement new integrations\n  Evaluation of Retrieval Augmentation\nWe‚Äôve already been seeing the benefits of the new Haystack design, with pipeline optimization and evaluation being good examples of how we‚Äôve been leveraging Haystack 2.0. How?:\n- It‚Äôs easier to extend the capabilities of Haystack\n- It‚Äôs easy to implement new integrations\nImplementing the latest retrieval optimizations\nRetrieval is a crucial step for successful RAG pipelines. And there‚Äôs been a lot of work to optimize this step. With Haystack 2.0, we‚Äôve been able to:\n- Implement Hypothetical Document Embeddings (HyDE) easily, and we‚Äôve already published a guide to HyDE along with an example walkthrough\n- Added an integration for Optimum embedders by Hugging Face\nAnd we will be able to add more optimization techniques along the way!\nEvaluation\nHaystack 2.0 is being released with a few evaluation framework integrations in place:\nAlong with a guide to model-based evaluation.\n']","Neo4j is mentioned as one of the storage services included in the list alongside others like Chroma, Weaviate, Pinecone, Qdrant, Elasticsearch, Open Search, pgvector, MongoDB, and AstraDB.",single_hop_specific_query_synthesizer
What are the implications of Collis and Brynjolfsson's findings on ChatGPT's usage for decision-making in various occupations?,"['<1-hop>\n\nOverall, our findings suggest that ChatGPT has a broad-based impact on the global economy.\nThe fact that non-work usage is increasing faster suggests that the welfare gains from generative AI\nusage could be substantial. Collis and Brynjolfsson (2025) estimate that US users would have to\nbe paid$98 to forgo using generative AI for a month, implying a surplus of at least$97 billion a\nyear. Within work usage, we find that users currently appear to derive value from using ChatGPT\nas an advisor or research assistant, not just a technology that performs job tasks directly. Still,\nChatGPT likely improves worker output by providingdecision support, which is especially important\nin knowledge-intensive jobs where productivity is increasing in the quality of decision-making.\n36\x0c T. Chan, Pat Pataranuta- porn, and Pattie Maes, ‚ÄúInvestigating Affective Use and Emotional Well-being on ChatGPT,‚Äù 2025. Reuters, ‚ÄúOpenAI hits$12 billion in annualized revenue, The Information reports,‚ÄùReuters, July 30 2025.', '<2-hop>\n\nCorporate\nusers may also use ChatGPT Business (formerly known as Teams) or ChatGPT Enterprise.\n28Very few work-related messages are classified asExpressing.\n29Appendix D contains a full report of GWA counts broken down by occupation, for both work-related ChatGPT\n31\x0cWe find remarkable similarity across occupations in how ChatGPT is used at work. For example,\nMaking Decisions and Solving Problemsis one of the two most common GWAs in every single oc-\ncupation group where at least two GWAs can be reported. 30 Similarly,Documenting and Recording\nInformationranks in the top four of all occupations.Thinking Creativelyis ranked as the third most\ncommon GWA in 10 of the 13 occupation groups where at least three GWAs can be reported. Even\nthough there are 41 GWAs, the seven most common overall are also the most common within each\noccupation group and are ranked similarly. Not surprisingly,Working with Computersis the most\ncommon GWA in computer-related occupations. In the appendix, we report the full distribution of\nGWA classifications intersected with two-digit SOC codes, as well as the most frequently requested\nGWAs out of the subset of queries which are work-related. Across all occupations, ChatGPT usage\nis broadly focused on seeking information and assistance with decision-making.\nusage and all ChatGPT usage.\n30For legal and food service occupations, we are only able to rank one of the GWAs because of user privacy protections\n- no other GWAs were requested by more than 100 users in that group.\n32\x0c Panel A.Work Related\n Panel B1.Asking.  Panel B2.Doing.\nFigure 23:(continued on next page)\n33\x0c Panel C1.Writing.  complete tasks that can be plugged into a process (Doing), and 1% are messages that have no clear intent (Expressing).Askingmessages have grown faster thanDoingmessages over the last year and are rated higher quality using both a classifier that measures user satisfaction and direct user feedback. Fifth, gender gaps in ChatGPT usage have likely closed substantially over time. As of July 2025, more than half of weekly active users had typically female first names. Sixth, nearly half of all messages sent by adults were from users under the age of 26. Seventh, ChatGPT usage has grown especially fast over the last year in low- and middle-income countries. Eighth, we find that users who are highly educated and working in professional occupations are more likely to use ChatGPT for work-related messages and forAskingrather thanDoingmessages at work. Overall, our findings suggest that ChatGPT has a broad-based impact on the global economy. The fact that non-work usage is increasing faster suggests that the welfare gains from generative AI usage could be substantial. Collis and Brynjolfsson (2025) estimate that US users would have to be paid$98 to forgo using generative AI for a month, implying a surplus of at least$97 billion a year. Within work usage, we find that users currently appear to derive value from using ChatGPT as an advisor or research assistant, not just a technology that performs job tasks directly. Still, ChatGPT likely improves worker output by providingdecision support, which is especially important in knowledge-intensive jobs where productivity is increasing in the quality of decision-making.']","Collis and Brynjolfsson's findings suggest that ChatGPT has a significant impact on decision-making across various occupations. They highlight that users derive value from ChatGPT not only as a tool for performing job tasks but also as an advisor or research assistant. This is particularly important in knowledge-intensive jobs, where the quality of decision-making enhances productivity. The research indicates that the most common generative work activities (GWAs) across occupations include Making Decisions and Solving Problems, which underscores the role of ChatGPT in providing decision support. Additionally, the findings reveal that ChatGPT usage is broadly focused on seeking information and assistance, further emphasizing its importance in enhancing worker output.",multi_hop_specific_query_synthesizer
"What demographic patterns in ChatGPT usage did Bick et al. (2024) identify, and how do these patterns relate to the classification of messages in a secure data clean room?","['<1-hop>\n\n6 Who Uses ChatGPT\nIn this section we report basic descriptive facts about who uses consumer ChatGPT. Existing work\ndocuments variation in generative AI use by demographic groups within representative samples in\nthe U.S. (Bick et al. (2024), Hartley et al. (2025)) and within a subset of occupations in Denmark\n(Humlum and Vestergaard, 2025a). All of these papers find that generative AI is used more frequently\nby men, young people, and those with tertiary and/or graduate education.\nWe make three contributions relative to this prior literature. First, we confirm these broad demo-\ngraphic patterns in a global sample rather than a single country. Second, we provide more detail for\nselected demographics such as age, gender, and country of origin and study how gaps in each have\nchanged over time. Third, we use a secure data clean room to analyze how ChatGPT usage varies by\neducation and occupation.\n 6.1 Name Analysis\nWe investigate potential variation by gender by classifying a global random sample of over 1.1 million\nChatGPT users‚Äô first names using public aggregated datasets of name-gender associations. We used\nthe World Gender Name Dictionary, and Social Security popular names, as well as datasets of popular\nBrazilian and Latin American names. This methodology is similar to that in (Hofstra et al., 2020)\nand (West et al., 2013). Names that were not in these datasets, or were flagged as ambiguous in the\ndatasets, or had significant disagreement amongst these datasets were classified asUnknown.\nExcludingUnknown, a significant share (around 80%) of the weekly active users (WAU) in the\nfirst few months after ChatGPT was released were by users with typically masculine first names.\nHowever, in the first half of 2025, we see the share of active users with typically feminine and typically\nmasculine names reach near-parity. By June 2025 we observe active users are more likely to have\ntypically feminine names. This suggests that gender gaps in ChatGPT usage have closed substantially\nover time.\nWe also study differences in usage topics. Users with typically female first names are relatively more\nlikely to send messages related toWritingandPractical Guidance. ', '<2-hop>\n\nLLM, allowing us to classify messages without any human seeing them. We give the text of most prompts in Appendix A along with details about how the prompts were validated in Appendix B.6 The classification pipeline is protected by a series of privacy measures, detailed below, to ensure no leakage of sensitive information during the automated analysis. In a secure data clean room, we relate taxonomies of messages to aggregated employment and education categories. Table 1 shows the growth in total message volume for work and non-work usage. Both types of 1Reuters (2025), Roth (2025) 2Bick et al. (2024) report that 28% of US adults used ChatGPT in late 2024, higher than any other chatbot. 3We use the term LLM loosely here and give more details in the following section. 4Wiggers (2025) reports estimates that in April 2025 ChatGPT was receiving more than 10 times as many visitors as either Claude or Copilot. 5Our sample includes the three consumer plans (Free, Plus, or Pro). OpenAI also offers a variety of other ChatGPT plans (Business fka. Teams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related.\nTotal daily counts are exact measurements of message volume from all consumer plans. Daily counts of work\nand non-work related messages are estimated by classifying a random sample of conversations from that day.\n']","Bick et al. (2024) identified that generative AI, including ChatGPT, is used more frequently by men, young people, and those with tertiary and/or graduate education. They confirmed these demographic patterns in a global sample and provided detailed insights into variations by age, gender, and country of origin. Additionally, in a secure data clean room, the study related taxonomies of messages to aggregated employment and education categories, showing a significant growth in total message volume for both work and non-work usage, with a notable increase in non-work messages over time.",multi_hop_specific_query_synthesizer
What share of ChatGPT queries are related to paid work and how does this relate to the information in Appendix B?,"['<1-hop>\n\nWhat share of ChatGPT queries are related to paid work?\nWe label each user message in our dataset based on whether it appears to be related to work, using\nan LLM classifier. The critical part of the prompt is as follows: 21\nDoes the last user message of this conversation transcript seem likely to be related to doing\nsome work/employment? Answer with one of the following:\n(1) likely part of work (e.g., ‚Äúrewrite this HR complaint‚Äù)\n(0) likely not part of work (e.g., ‚Äúdoes ice reduce pimples?‚Äù)\nTable 1 shows that both types of queries grew rapidly between June 2024 and June 2025, however\nnon-work-related messages grew faster: 53% of messages were not related to work in June 2024, which\nclimbed to 73% by June 2025.\nFigure 6 plots the share of non-work messages decomposed by cumulative sign-up cohorts. Succes-\nsive cohorts have had a higher share of non-work messages, but also within each cohort their non-work\nuse has increased. Comparing the share among all users (black line) to the share among the earliest\ncohort of users (yellow line), we can see that they track very closely.\n21See Appendix A for the full prompt, see Appendix B for validation.\n12\x0cFigure 6:The solid black line represents the probability that a messages on a given day is not related to\nwork, as determined by an automated classifier. Values are averaged over a 28-day lagging window. The\ndotted orange line shows the same calculation, but conditioned on messages being from users who first used\nChatGPT during or before Q2 of 2024. The remaining lines are defined similarly for successive quarters, with\ncoloring cooling for more recent cohorts. Counts are calculated from a sample of approximately 1.1 million\nsampled conversations from May 15, 2024 through June 26, 2025. Observations are reweighted to reflect total\nmessage volumes on a given day. Sampling details available in Section 3.\n5.2 ']","The share of ChatGPT queries related to paid work shows that non-work-related messages grew from 53% in June 2024 to 73% by June 2025. This trend is detailed in the context, where it mentions that both work-related and non-work-related queries grew rapidly, but non-work-related messages increased at a faster rate. Appendix B is referenced for validation of the data and methodology used in this analysis.",multi_hop_specific_query_synthesizer
What trends in user satisfaction and interaction quality were observed in late 2024 and how do they relate to the growth in message volume from ChatGPT users?,"['<1-hop>\n\nThe yellow line represents the first cohort of ChatGPT users: their usage declined somewhat over\n2023, but started growing again in late 2024 and is now higher than it has ever been. The pink line\nrepresents messages from users who signed up in Q3 of 2023 or earlier, and so thedifferencebetween\n20Note that we expect our counts of distinct accounts to somewhat exceed distinct people when one person has two\naccounts (or, for logged-out users, one person using two devices). For logged-in users, the count is based on distinct\nlogin credentials (email addresses), and one person may have multiple accounts. For logged-out users, the count is based\non distinct browser cookies; this would double-count people if someone returns to ChatGPT after clearing their cookies,\nor if they access ChatGPT with two different devices in the same week.\n10\x0cFigure 4:Daily message volumes from ChatGPT consumer plans (Free, Plus, Pro), split by sign-up date of\nthe requesting user. Reported values are moving averages of the past 90 days. Y-axis is an index normalized\nto the reported value for ‚ÄùAll Cohorts‚Äù at the end of Q1 2024 (April 1, 2024).\nthe yellow and pink lines represents the messages sent by users who signed up in Q2 and Q3 of 2023.\nThere has been dramatic growth in message volume both by new cohorts of users, and from growth\nin existing cohorts.\nFigure 5 normalizes each cohort, plotting daily messages per weekly active user. Each line rep-\nresents an individual cohort (instead of a cumulative cohort, as in Figure 4). The figure shows that\nearlier sign-ups have consistently had higher usage, but that usage has also consistently grown within\nevery cohort, which we interpret as due to both (1) improvements in the capabilities of the models,\nand (2) users slowly discovering new uses for existing capabilities.\n5  How ChatGPT is Used\nWe next report on thecontentof ChatGPT conversations using a variety of different taxonomies. For\neach taxonomy we describe a ‚Äúprompt‚Äù which defines a set of categories, and then apply an LLM\nto map each message to a category. Our categories often apply to the user‚Äôsintention, rather than\nthe text of the conversation, and as such we never directly observe the ground truth. Nevertheless\nthe classifier results can be interpreted as the best-guess inferences that a human would make: the\nguesses from the LLM correlate highly with human guesses from the same prompt, and we get similar\nqualitative results when the prompt includes a third category for ‚Äúuncertain.‚Äù\n11\x0cFigure 5:Daily messages sent per weekly active user, split by sign-up cohort. Sample only considers users of\nChatGPT consumer plans (Free, Plus, Pro). Reported values are moving averages of the past 90 days and are\nreported starting 90 days after the cohort is fully formed. Y-axis is an index normalized to the first reported\nvalue for the Q1 2023 cohort.\n5.1 ', '<2-hop>\n\n5.5 Quality of Interactions\nWe additionally used automated classifiers to study the user‚Äôs apparent satisfaction with the chatbot‚Äôs\nresponse to their request. OurInteraction Qualityclassifier looks for an expression of satisfaction or\ndissatisfaction in the user‚Äôs subsequent message in the same conversation (if one exists), with three\npossible categories:Good,Bad, andUnknown. 23\nFigure 16 plots the overall growth of messages in these three buckets. In late 2024Goodinteractions\nwere about three times as common asBadinteractions, butGoodinteractions grew much more rapidly\nover the next nine months, and by July 2025 they were more than four times more common.\nFigure 16:Interaction quality shares, based on automated sentiment analysis of thenext responseprovided\nby the user. See Appendix B to understand how this classifier was validated. Values are averaged over a 28\nday lagging window. Shares are calculated from a sample of approximately 1.1 million sampled conversations\nfrom May 15, 2024 through June 26, 2025. Observations are reweighted to reflect total message volumes on a\ngiven day. Sampling details available in Section 3.\nDetails on the validation of this classifier, along with measurements of how it correlates with\nexplicit thumbs up/thumbs down annotations from users, are included in Appendix B.\nFigure 17 shows the ratio of good-to-bad messages by conversation topic and interaction type, as\nrated by Interaction Quality. Panel A shows thatSelf-Expressionis the highest rated topic, with a\ngood-to-bad ratio of more than seven, consistent with the growth in this category.Multimediaand\nTechnical Helphave the lowest good-to-bad ratios (1.7 and 2.7 respectively). Panel B shows that\nAskingmessages are substantially more likely to receive a good rating thanDoingorExpressing\nmessages.\n23For this classifier we do not disclose the prompt.\n23\x0cFigure 17:AverageGoodtoBadratio for user interactions by Conversation Topic (Panel A) and Ask-\ning/Doing/Expressing classification (Panel B). The prompts for each of these automated classifiers (with the\nexception of interaction quality) are available in Appendix A. Values represent the average ratio from May 15,\n2024 through June 26, 2025, where observations are reweighted to reflect total message volumes on a given\nday. Sampling details available in Section 3.\n24\x0c']","In late 2024, user satisfaction with ChatGPT interactions showed a significant trend, with 'Good' interactions being about three times as common as 'Bad' interactions. This growth in 'Good' interactions was notably rapid, indicating an improvement in user experience. Concurrently, there was dramatic growth in message volume from both new cohorts of users and existing cohorts, suggesting that as users discovered new uses for the capabilities of ChatGPT, their satisfaction and engagement levels increased.",multi_hop_specific_query_synthesizer
How does the gpt-5-mini model classify messages in relation to user behavior and engagement trends?,"['<1-hop>\n\n‚Äù (truncated)\n[user]: ‚Äú10 more‚Äù\nTable 2:Illustration of Context-Augmented Message Classifications (Synthetic Example). The left column\nshows a standalone message to be classified, and the right column shows the prior context included in the\nclassification of the message on the left.\nWe truncate each message to a maximum of 5,000 characters, because long context windows could\ninduce variability in the quality of the classification (Liu et al., 2023). We classify each message\nwith the ‚Äúgpt-5-mini‚Äù model, with the exception ofInteraction Quality,which uses ‚Äúgpt-5,‚Äù using the\nprompts listed in Appendix A.\n17Internal analyses show that the tool,Privacy Filter, has substantial alignment with human judgment.\n18In the case ofInteraction Quality,we additionally include the next two messages in the conversation as context.\n7\x0cWe validated each of the classification prompts by comparing model classification decisions against\nhuman-judged classifications of a sample of conversations from the publicly available WildChat dataset\n(Zhao et al., 2024), a set of conversations with a third-party chatbot which users affirmatively gave\ntheir assent to share publicly for research purposes. 19 Appendix B provides detail on our validation\napproach and performance relative to human judgment. For additional transparency, we classify\na sample of 100,000 public WildChat messages and provide those data in this paper‚Äôs replication\npackage.\n 3.3 Employment Dataset\nWe conduct limited analyses of aggregated employment categories based on publicly available data\nfor a sample of consumer ChatGPT users. This sample included approximately 130,000 Free, Plus,\nand Pro users, and the employment categories were aggregated by a vendor working through a secure\nData Clean Room (DCR). For this analysis, we use the same exclusion criteria as for the message-level\ndatasets: we exclude deactivated users, banned users, users who have opted out of training, and users\nwhose self-reported age is under 18. Because the data was only available for a subset of users the\nresults may not be representative of the full pool of users.\nDescription.The employment data, which is aggregated from publicly available sources, includes\nindustry, occupations coarsened to O*NET categories, seniority level, company size, and education\ninformation that is limited to the degree attained. A vendor working within a DCR procured this\ndataset, restricted us to running only aggregated queries against it through the DCR, and deleted it\nupon the study‚Äôs completion.\n']","The gpt-5-mini model classifies messages by analyzing the context of prior messages, as illustrated in the classification process where each message is truncated to a maximum of 5,000 characters to maintain quality. This model is used for classifying messages, while the Interaction Quality classification utilizes the gpt-5 model, which includes additional context from the next two messages in the conversation. The classification prompts were validated against human-judged classifications from the WildChat dataset, ensuring alignment with user behavior and engagement trends.",multi_hop_specific_query_synthesizer
"What are the primary ways in which ChatGPT is utilized in business settings, and how does this compare to its overall usage trends among different occupations?","['<1-hop>\n\nPanel C2.Technical Help. Panel C3.Seeking Information. Panel C4.Practical Guidance. Figure 23:Variation in ChatGPT usage by occupation. Panel A shows the share of messages that are work-related across broad occupation categories. Panel B presents variation in the share of Asking and Doing messages within work-related usage. Panel C presents the distribution of work-related conversation topics by occupation, focusing on Writing and Practical Guidance. The regression for these figures is the same one as the one used in Figure 22. 34 Occupation Group Documenting/ Recording Information Making Decisions And Solving Problems Thinking Creatively Working With Computers Interpreting The Meaning Of Information For Others Getting Information Providing Consultation And Advice To Others Management 2 1 3 6 4 5 8 Business 2 1 3 6 4 5 7 Computer/Math 4 2 5 1 3 6 7 Engineering 3 1 5 2 4 6 7 Science 2 1 4 3 6 5 7 Social Service 2 1 3 X 5 4 X Legal 1 X X X X X X Education 1 2 3 4 6 5 7 Arts/Design/Media 2 1 3 5 4 6 7 Health Professionals 1 2 3 X 5 4 6 Food Service 1 X X X X X X Personal Service 1 2 3 X 4 5 X Sales 2 1 3 6 4 5 7 Administrative 2 1 3 7 4 5 8 Transportation 2 1 3 X X 4 X Military 2 1 X X X X X Figure 24:The seven most commonly requested GWAs for work-related queries. Table reports the frequency ranking of each of these GWAs for each broad occupation groups (two-digit SOC codes). 1 represents the most frequently requested GWA for that occupation. X‚Äôs indicate that the ranking is unavailable since fewer than 100 users from that occupation group requested that specific GWA within the sample. Seven occupation groups are omitted because no GWA was requested by more than 100 users from a single occupation group. These omitted occupation groups (with corresponding SOC2 codes) are ‚ÄùHealthcare Support‚Äù (31), ‚ÄùProtective Service‚Äù (33), ‚ÄùBuilding and Grounds Cleaning and Maintenance‚Äù (37), ‚ÄùFarming, Fishing, and Forestry‚Äù (45), ‚ÄùConstruction and Extraction‚Äù (47), ‚ÄùInstallation, Maintenance, and Repair‚Äù (49), and ‚ÄùProduction‚Äù (51). Not pictured are twelve other GWAs which are less frequently requested and are reported fully in Appendix D. See Appendix for full cross-tabulations between GWA and two-digit SOC2 codes. 35 7 Conclusion This paper studies the rapid growth of ChatGPT, which launched in November 2022. By July 2025, ChatGPT had been used weekly by more than 700 million users, who were collectively sending more than 2.5 billion messages per day, or about 29,000 messages per second. Yet despite the rapid adop- tion of ChatGPT and Generative AI more broadly, little previous evidence existed on how this new technology is used and who is using it. This is the first economics paper to use internal ChatGPT message data, and we do so while introducing a novel privacy-preserving methodology. No user messages were observed by humans during any part of the work on this paper. This paper documents eight important facts about ChatGPT. First, as of July 2025 about 70% of ChatGPT consumer queries were unrelated to work; while both work-related and non-work-related queries have been increasing, non-work queries have been increasing faster. Second, the three most common ChatGPT conversation topics arePractical Guidance,Writing, andSeeking Information, collectively accounting for nearly 78% of all messages.Computer Pro- grammingandRelationships and Personal Reflectionaccount for only 4.2% and 1.9% of messages respectively. Third,Writingis by far the most common work use, accounting for 42% of work-related messages overall and more than half of all messages for users in management and business occupations. About two-thirds ofWritingmessages are requests to modify user text rather than to produce novel text from scratch. Fourth, we classify messages according to the kind of output users are seeking with a rubric we callAsking, Doing,orExpressing.About 49% of messages are users asking ChatGPT for guidance, advice, or information (Asking), 40% are requests to', '<2-hop>\n\nCorporate\nusers may also use ChatGPT Business (formerly known as Teams) or ChatGPT Enterprise.\n28Very few work-related messages are classified asExpressing.\n29Appendix D contains a full report of GWA counts broken down by occupation, for both work-related ChatGPT\n31\x0cWe find remarkable similarity across occupations in how ChatGPT is used at work. For example,\nMaking Decisions and Solving Problemsis one of the two most common GWAs in every single oc-\ncupation group where at least two GWAs can be reported. 30 Similarly,Documenting and Recording\nInformationranks in the top four of all occupations.Thinking Creativelyis ranked as the third most\ncommon GWA in 10 of the 13 occupation groups where at least three GWAs can be reported. Even\nthough there are 41 GWAs, the seven most common overall are also the most common within each\noccupation group and are ranked similarly. Not surprisingly,Working with Computersis the most\ncommon GWA in computer-related occupations. In the appendix, we report the full distribution of\nGWA classifications intersected with two-digit SOC codes, as well as the most frequently requested\nGWAs out of the subset of queries which are work-related. Across all occupations, ChatGPT usage\nis broadly focused on seeking information and assistance with decision-making.\nusage and all ChatGPT usage.\n30For legal and food service occupations, we are only able to rank one of the GWAs because of user privacy protections\n- no other GWAs were requested by more than 100 users in that group.\n32\x0c Panel A.Work Related\n Panel B1.Asking.  Panel B2.Doing.\nFigure 23:(continued on next page)\n33\x0c Panel C1.Writing.  complete tasks that can be plugged into a process (Doing), and 1% are messages that have no clear intent (Expressing).Askingmessages have grown faster thanDoingmessages over the last year and are rated higher quality using both a classifier that measures user satisfaction and direct user feedback. Fifth, gender gaps in ChatGPT usage have likely closed substantially over time. As of July 2025, more than half of weekly active users had typically female first names. Sixth, nearly half of all messages sent by adults were from users under the age of 26. Seventh, ChatGPT usage has grown especially fast over the last year in low- and middle-income countries. Eighth, we find that users who are highly educated and working in professional occupations are more likely to use ChatGPT for work-related messages and forAskingrather thanDoingmessages at work. Overall, our findings suggest that ChatGPT has a broad-based impact on the global economy. The fact that non-work usage is increasing faster suggests that the welfare gains from generative AI usage could be substantial. Collis and Brynjolfsson (2025) estimate that US users would have to be paid$98 to forgo using generative AI for a month, implying a surplus of at least$97 billion a year. Within work usage, we find that users currently appear to derive value from using ChatGPT as an advisor or research assistant, not just a technology that performs job tasks directly. Still, ChatGPT likely improves worker output by providingdecision support, which is especially important in knowledge-intensive jobs where productivity is increasing in the quality of decision-making.']","In business settings, ChatGPT is primarily utilized for tasks such as Writing, Making Decisions and Solving Problems, and Seeking Information. Writing accounts for 42% of work-related messages, with a significant portion of these being requests to modify existing text rather than create new content. Additionally, the use of ChatGPT for Making Decisions and Solving Problems is consistently ranked among the top two most common goals across various occupations. Overall, while work-related queries are increasing, non-work-related queries are growing at a faster rate, indicating a broader trend in ChatGPT usage. The findings suggest that users derive value from ChatGPT not only as a tool for completing tasks but also as an advisor or research assistant, particularly in knowledge-intensive jobs where decision-making quality is crucial.",multi_hop_abstract_query_synthesizer
"What are the primary themes of ChatGPT usage in business contexts, and how do they compare to overall usage trends?","['<1-hop>\n\nPanel C2.Technical Help. Panel C3.Seeking Information. Panel C4.Practical Guidance. Figure 23:Variation in ChatGPT usage by occupation. Panel A shows the share of messages that are work-related across broad occupation categories. Panel B presents variation in the share of Asking and Doing messages within work-related usage. Panel C presents the distribution of work-related conversation topics by occupation, focusing on Writing and Practical Guidance. The regression for these figures is the same one as the one used in Figure 22. 34 Occupation Group Documenting/ Recording Information Making Decisions And Solving Problems Thinking Creatively Working With Computers Interpreting The Meaning Of Information For Others Getting Information Providing Consultation And Advice To Others Management 2 1 3 6 4 5 8 Business 2 1 3 6 4 5 7 Computer/Math 4 2 5 1 3 6 7 Engineering 3 1 5 2 4 6 7 Science 2 1 4 3 6 5 7 Social Service 2 1 3 X 5 4 X Legal 1 X X X X X X Education 1 2 3 4 6 5 7 Arts/Design/Media 2 1 3 5 4 6 7 Health Professionals 1 2 3 X 5 4 6 Food Service 1 X X X X X X Personal Service 1 2 3 X 4 5 X Sales 2 1 3 6 4 5 7 Administrative 2 1 3 7 4 5 8 Transportation 2 1 3 X X 4 X Military 2 1 X X X X X Figure 24:The seven most commonly requested GWAs for work-related queries. Table reports the frequency ranking of each of these GWAs for each broad occupation groups (two-digit SOC codes). 1 represents the most frequently requested GWA for that occupation. X‚Äôs indicate that the ranking is unavailable since fewer than 100 users from that occupation group requested that specific GWA within the sample. Seven occupation groups are omitted because no GWA was requested by more than 100 users from a single occupation group. These omitted occupation groups (with corresponding SOC2 codes) are ‚ÄùHealthcare Support‚Äù (31), ‚ÄùProtective Service‚Äù (33), ‚ÄùBuilding and Grounds Cleaning and Maintenance‚Äù (37), ‚ÄùFarming, Fishing, and Forestry‚Äù (45), ‚ÄùConstruction and Extraction‚Äù (47), ‚ÄùInstallation, Maintenance, and Repair‚Äù (49), and ‚ÄùProduction‚Äù (51). Not pictured are twelve other GWAs which are less frequently requested and are reported fully in Appendix D. See Appendix for full cross-tabulations between GWA and two-digit SOC2 codes. 35 7 Conclusion This paper studies the rapid growth of ChatGPT, which launched in November 2022. By July 2025, ChatGPT had been used weekly by more than 700 million users, who were collectively sending more than 2.5 billion messages per day, or about 29,000 messages per second. Yet despite the rapid adop- tion of ChatGPT and Generative AI more broadly, little previous evidence existed on how this new technology is used and who is using it. This is the first economics paper to use internal ChatGPT message data, and we do so while introducing a novel privacy-preserving methodology. No user messages were observed by humans during any part of the work on this paper. This paper documents eight important facts about ChatGPT. First, as of July 2025 about 70% of ChatGPT consumer queries were unrelated to work; while both work-related and non-work-related queries have been increasing, non-work queries have been increasing faster. Second, the three most common ChatGPT conversation topics arePractical Guidance,Writing, andSeeking Information, collectively accounting for nearly 78% of all messages.Computer Pro- grammingandRelationships and Personal Reflectionaccount for only 4.2% and 1.9% of messages respectively. Third,Writingis by far the most common work use, accounting for 42% of work-related messages overall and more than half of all messages for users in management and business occupations. About two-thirds ofWritingmessages are requests to modify user text rather than to produce novel text from scratch. Fourth, we classify messages according to the kind of output users are seeking with a rubric we callAsking, Doing,orExpressing.About 49% of messages are users asking ChatGPT for guidance, advice, or information (Asking), 40% are requests to', '<2-hop>\n\nCorporate\nusers may also use ChatGPT Business (formerly known as Teams) or ChatGPT Enterprise.\n28Very few work-related messages are classified asExpressing.\n29Appendix D contains a full report of GWA counts broken down by occupation, for both work-related ChatGPT\n31\x0cWe find remarkable similarity across occupations in how ChatGPT is used at work. For example,\nMaking Decisions and Solving Problemsis one of the two most common GWAs in every single oc-\ncupation group where at least two GWAs can be reported. 30 Similarly,Documenting and Recording\nInformationranks in the top four of all occupations.Thinking Creativelyis ranked as the third most\ncommon GWA in 10 of the 13 occupation groups where at least three GWAs can be reported. Even\nthough there are 41 GWAs, the seven most common overall are also the most common within each\noccupation group and are ranked similarly. Not surprisingly,Working with Computersis the most\ncommon GWA in computer-related occupations. In the appendix, we report the full distribution of\nGWA classifications intersected with two-digit SOC codes, as well as the most frequently requested\nGWAs out of the subset of queries which are work-related. Across all occupations, ChatGPT usage\nis broadly focused on seeking information and assistance with decision-making.\nusage and all ChatGPT usage.\n30For legal and food service occupations, we are only able to rank one of the GWAs because of user privacy protections\n- no other GWAs were requested by more than 100 users in that group.\n32\x0c Panel A.Work Related\n Panel B1.Asking.  Panel B2.Doing.\nFigure 23:(continued on next page)\n33\x0c Panel C1.Writing.  complete tasks that can be plugged into a process (Doing), and 1% are messages that have no clear intent (Expressing).Askingmessages have grown faster thanDoingmessages over the last year and are rated higher quality using both a classifier that measures user satisfaction and direct user feedback. Fifth, gender gaps in ChatGPT usage have likely closed substantially over time. As of July 2025, more than half of weekly active users had typically female first names. Sixth, nearly half of all messages sent by adults were from users under the age of 26. Seventh, ChatGPT usage has grown especially fast over the last year in low- and middle-income countries. Eighth, we find that users who are highly educated and working in professional occupations are more likely to use ChatGPT for work-related messages and forAskingrather thanDoingmessages at work. Overall, our findings suggest that ChatGPT has a broad-based impact on the global economy. The fact that non-work usage is increasing faster suggests that the welfare gains from generative AI usage could be substantial. Collis and Brynjolfsson (2025) estimate that US users would have to be paid$98 to forgo using generative AI for a month, implying a surplus of at least$97 billion a year. Within work usage, we find that users currently appear to derive value from using ChatGPT as an advisor or research assistant, not just a technology that performs job tasks directly. Still, ChatGPT likely improves worker output by providingdecision support, which is especially important in knowledge-intensive jobs where productivity is increasing in the quality of decision-making.', '<3-hop>\n\nNBER WORKING PAPER SERIES\nHOW PEOPLE USE CHATGPT\nAaron Chatterji\nThomas Cunningham\nDavid J. Deming\nZoe Hitzig\nChristopher Ong\nCarl Yan Shan\nKevin Wadman\nWorking Paper 34255\nhttp://www.nber.org/papers/w34255\nNATIONAL BUREAU OF ECONOMIC RESEARCH\n1050 Massachusetts Avenue\nCambridge, MA 02138\nSeptember 2025\nWe acknowledge help and comments from Joshua Achiam, Hemanth Asirvatham, Ryan Beiermeister, Rachel Brown, Cassandra Duchan Solis, Jason Kwon, Elliott Mokski, Kevin Rao, Harrison Satcher, Gawesha Weeratunga, Hannah Wong, and Analytics & Insights team. We especially thank Tyna Eloundou and Pamela Mishkin who in several ways laid the foundation for this work. This study was approved by Harvard IRB (IRB25-0983). A repository containing all code run to produce the analyses in this paper is available on request. The views expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.\nAt least one co-author has disclosed additional relationships of potential relevance for this research. Further information is available online at http://www.nber.org/papers/w34255\nNBER working papers are circulated for discussion and comment purposes. They have not been peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies official NBER publications.\n¬© 2025 by Aaron Chatterji, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl Yan Shan, and Kevin Wadman. All rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including ¬© notice, is given to the source.\x0cHow People Use ChatGPT\nAaron Chatterji, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl\nYan Shan, and Kevin Wadman\nNBER Working Paper No. 34255\nSeptember 2025\nJEL No. J01, O3, O4\nABSTRACT\nDespite the rapid adoption of LLM chatbots, little is known about how they are used. We document the growth of ChatGPT‚Äôs consumer product from its launch in November 2022 through July 2025, when it had been adopted by around 10% of the world‚Äôs adult population. Early adopters were disproportionately male but the gender gap has narrowed dramatically, and we find higher growth rates in lower-income countries. Using a privacy-preserving automated pipeline, we classify usage patterns within a representative sample of ChatGPT conversations. We find steady growth in work-related messages bu t even faster growth in non-work-related messages, which have grown from 53% to more than 70% of all usage. Work usage is more common for educated users in highly-paid professional occupations. We classify messages by conversation top\nic and find that ‚ÄúPractical Guidance,‚Äù ‚ÄúSeeking Information,‚Äù and ‚ÄúWriting‚Äù are the three most common topics and collectively account for nearly 80% of all conversations. Writing dominates work-related tasks, highlighting chatbots‚Äô unique ability to generate digital outputs compared to traditional sear ch engines. Computer programming and self-expression both represent relatively small shares of use. Overall, we find that ChatGPT provides economic value through decision support, which is especially important in knowledge-intensive jobs.\nAaron Chatterji\nDuke University\nFuqua School of Business and OpenAI\nronnie@duke.edu\nThomas Cunningham OpenAI\ntom.cunningham@gmail.com\nDavid J. Deming\nHarvard University\nHarvard Kennedy School and NBER\ndavid_deming@harvard.edu\nZoe Hitzig\nOpenAI\nand Harvard Society of Fellows\nzhitzig@g.harvard.edu\nChristopher Ong\nHarvard University\nand OpenAI\nchristopherong@hks.harvard.edu\nCarl Yan Shan\nOpenAI\ncshan@openai.com\nKevin Wadman\nOpenAI\nkevin.wadman@c-openai.com\x0c']","In business contexts, the primary themes of ChatGPT usage include 'Practical Guidance,' 'Seeking Information,' and 'Writing,' which collectively account for nearly 80% of all conversations. Writing is particularly dominant in work-related tasks, making up 42% of work-related messages overall. This contrasts with overall usage trends, where about 70% of ChatGPT consumer queries are unrelated to work, indicating that while work-related usage is significant, non-work-related queries are increasing at a faster rate.",multi_hop_abstract_query_synthesizer
"How does ChatGPT usage vary across different occupations, and what are the most common tasks users seek help with in ChatGPT Business?","['<1-hop>\n\nPanel C2.Technical Help. Panel C3.Seeking Information. Panel C4.Practical Guidance. Figure 23:Variation in ChatGPT usage by occupation. Panel A shows the share of messages that are work-related across broad occupation categories. Panel B presents variation in the share of Asking and Doing messages within work-related usage. Panel C presents the distribution of work-related conversation topics by occupation, focusing on Writing and Practical Guidance. The regression for these figures is the same one as the one used in Figure 22. 34 Occupation Group Documenting/ Recording Information Making Decisions And Solving Problems Thinking Creatively Working With Computers Interpreting The Meaning Of Information For Others Getting Information Providing Consultation And Advice To Others Management 2 1 3 6 4 5 8 Business 2 1 3 6 4 5 7 Computer/Math 4 2 5 1 3 6 7 Engineering 3 1 5 2 4 6 7 Science 2 1 4 3 6 5 7 Social Service 2 1 3 X 5 4 X Legal 1 X X X X X X Education 1 2 3 4 6 5 7 Arts/Design/Media 2 1 3 5 4 6 7 Health Professionals 1 2 3 X 5 4 6 Food Service 1 X X X X X X Personal Service 1 2 3 X 4 5 X Sales 2 1 3 6 4 5 7 Administrative 2 1 3 7 4 5 8 Transportation 2 1 3 X X 4 X Military 2 1 X X X X X Figure 24:The seven most commonly requested GWAs for work-related queries. Table reports the frequency ranking of each of these GWAs for each broad occupation groups (two-digit SOC codes). 1 represents the most frequently requested GWA for that occupation. X‚Äôs indicate that the ranking is unavailable since fewer than 100 users from that occupation group requested that specific GWA within the sample. Seven occupation groups are omitted because no GWA was requested by more than 100 users from a single occupation group. These omitted occupation groups (with corresponding SOC2 codes) are ‚ÄùHealthcare Support‚Äù (31), ‚ÄùProtective Service‚Äù (33), ‚ÄùBuilding and Grounds Cleaning and Maintenance‚Äù (37), ‚ÄùFarming, Fishing, and Forestry‚Äù (45), ‚ÄùConstruction and Extraction‚Äù (47), ‚ÄùInstallation, Maintenance, and Repair‚Äù (49), and ‚ÄùProduction‚Äù (51). Not pictured are twelve other GWAs which are less frequently requested and are reported fully in Appendix D. See Appendix for full cross-tabulations between GWA and two-digit SOC2 codes. 35 7 Conclusion This paper studies the rapid growth of ChatGPT, which launched in November 2022. By July 2025, ChatGPT had been used weekly by more than 700 million users, who were collectively sending more than 2.5 billion messages per day, or about 29,000 messages per second. Yet despite the rapid adop- tion of ChatGPT and Generative AI more broadly, little previous evidence existed on how this new technology is used and who is using it. This is the first economics paper to use internal ChatGPT message data, and we do so while introducing a novel privacy-preserving methodology. No user messages were observed by humans during any part of the work on this paper. This paper documents eight important facts about ChatGPT. First, as of July 2025 about 70% of ChatGPT consumer queries were unrelated to work; while both work-related and non-work-related queries have been increasing, non-work queries have been increasing faster. Second, the three most common ChatGPT conversation topics arePractical Guidance,Writing, andSeeking Information, collectively accounting for nearly 78% of all messages.Computer Pro- grammingandRelationships and Personal Reflectionaccount for only 4.2% and 1.9% of messages respectively. Third,Writingis by far the most common work use, accounting for 42% of work-related messages overall and more than half of all messages for users in management and business occupations. About two-thirds ofWritingmessages are requests to modify user text rather than to produce novel text from scratch. Fourth, we classify messages according to the kind of output users are seeking with a rubric we callAsking, Doing,orExpressing.About 49% of messages are users asking ChatGPT for guidance, advice, or information (Asking), 40% are requests to', '<2-hop>\n\nCorporate\nusers may also use ChatGPT Business (formerly known as Teams) or ChatGPT Enterprise.\n28Very few work-related messages are classified asExpressing.\n29Appendix D contains a full report of GWA counts broken down by occupation, for both work-related ChatGPT\n31\x0cWe find remarkable similarity across occupations in how ChatGPT is used at work. For example,\nMaking Decisions and Solving Problemsis one of the two most common GWAs in every single oc-\ncupation group where at least two GWAs can be reported. 30 Similarly,Documenting and Recording\nInformationranks in the top four of all occupations.Thinking Creativelyis ranked as the third most\ncommon GWA in 10 of the 13 occupation groups where at least three GWAs can be reported. Even\nthough there are 41 GWAs, the seven most common overall are also the most common within each\noccupation group and are ranked similarly. Not surprisingly,Working with Computersis the most\ncommon GWA in computer-related occupations. In the appendix, we report the full distribution of\nGWA classifications intersected with two-digit SOC codes, as well as the most frequently requested\nGWAs out of the subset of queries which are work-related. Across all occupations, ChatGPT usage\nis broadly focused on seeking information and assistance with decision-making.\nusage and all ChatGPT usage.\n30For legal and food service occupations, we are only able to rank one of the GWAs because of user privacy protections\n- no other GWAs were requested by more than 100 users in that group.\n32\x0c Panel A.Work Related\n Panel B1.Asking.  Panel B2.Doing.\nFigure 23:(continued on next page)\n33\x0c Panel C1.Writing.  complete tasks that can be plugged into a process (Doing), and 1% are messages that have no clear intent (Expressing).Askingmessages have grown faster thanDoingmessages over the last year and are rated higher quality using both a classifier that measures user satisfaction and direct user feedback. Fifth, gender gaps in ChatGPT usage have likely closed substantially over time. As of July 2025, more than half of weekly active users had typically female first names. Sixth, nearly half of all messages sent by adults were from users under the age of 26. Seventh, ChatGPT usage has grown especially fast over the last year in low- and middle-income countries. Eighth, we find that users who are highly educated and working in professional occupations are more likely to use ChatGPT for work-related messages and forAskingrather thanDoingmessages at work. Overall, our findings suggest that ChatGPT has a broad-based impact on the global economy. The fact that non-work usage is increasing faster suggests that the welfare gains from generative AI usage could be substantial. Collis and Brynjolfsson (2025) estimate that US users would have to be paid$98 to forgo using generative AI for a month, implying a surplus of at least$97 billion a year. Within work usage, we find that users currently appear to derive value from using ChatGPT as an advisor or research assistant, not just a technology that performs job tasks directly. Still, ChatGPT likely improves worker output by providingdecision support, which is especially important in knowledge-intensive jobs where productivity is increasing in the quality of decision-making.', '<3-hop>\n\nNBER WORKING PAPER SERIES\nHOW PEOPLE USE CHATGPT\nAaron Chatterji\nThomas Cunningham\nDavid J. Deming\nZoe Hitzig\nChristopher Ong\nCarl Yan Shan\nKevin Wadman\nWorking Paper 34255\nhttp://www.nber.org/papers/w34255\nNATIONAL BUREAU OF ECONOMIC RESEARCH\n1050 Massachusetts Avenue\nCambridge, MA 02138\nSeptember 2025\nWe acknowledge help and comments from Joshua Achiam, Hemanth Asirvatham, Ryan Beiermeister, Rachel Brown, Cassandra Duchan Solis, Jason Kwon, Elliott Mokski, Kevin Rao, Harrison Satcher, Gawesha Weeratunga, Hannah Wong, and Analytics & Insights team. We especially thank Tyna Eloundou and Pamela Mishkin who in several ways laid the foundation for this work. This study was approved by Harvard IRB (IRB25-0983). A repository containing all code run to produce the analyses in this paper is available on request. The views expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.\nAt least one co-author has disclosed additional relationships of potential relevance for this research. Further information is available online at http://www.nber.org/papers/w34255\nNBER working papers are circulated for discussion and comment purposes. They have not been peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies official NBER publications.\n¬© 2025 by Aaron Chatterji, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl Yan Shan, and Kevin Wadman. All rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including ¬© notice, is given to the source.\x0cHow People Use ChatGPT\nAaron Chatterji, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl\nYan Shan, and Kevin Wadman\nNBER Working Paper No. 34255\nSeptember 2025\nJEL No. J01, O3, O4\nABSTRACT\nDespite the rapid adoption of LLM chatbots, little is known about how they are used. We document the growth of ChatGPT‚Äôs consumer product from its launch in November 2022 through July 2025, when it had been adopted by around 10% of the world‚Äôs adult population. Early adopters were disproportionately male but the gender gap has narrowed dramatically, and we find higher growth rates in lower-income countries. Using a privacy-preserving automated pipeline, we classify usage patterns within a representative sample of ChatGPT conversations. We find steady growth in work-related messages bu t even faster growth in non-work-related messages, which have grown from 53% to more than 70% of all usage. Work usage is more common for educated users in highly-paid professional occupations. We classify messages by conversation top\nic and find that ‚ÄúPractical Guidance,‚Äù ‚ÄúSeeking Information,‚Äù and ‚ÄúWriting‚Äù are the three most common topics and collectively account for nearly 80% of all conversations. Writing dominates work-related tasks, highlighting chatbots‚Äô unique ability to generate digital outputs compared to traditional sear ch engines. Computer programming and self-expression both represent relatively small shares of use. Overall, we find that ChatGPT provides economic value through decision support, which is especially important in knowledge-intensive jobs.\nAaron Chatterji\nDuke University\nFuqua School of Business and OpenAI\nronnie@duke.edu\nThomas Cunningham OpenAI\ntom.cunningham@gmail.com\nDavid J. Deming\nHarvard University\nHarvard Kennedy School and NBER\ndavid_deming@harvard.edu\nZoe Hitzig\nOpenAI\nand Harvard Society of Fellows\nzhitzig@g.harvard.edu\nChristopher Ong\nHarvard University\nand OpenAI\nchristopherong@hks.harvard.edu\nCarl Yan Shan\nOpenAI\ncshan@openai.com\nKevin Wadman\nOpenAI\nkevin.wadman@c-openai.com\x0c']","ChatGPT usage varies across different occupations, with a notable focus on work-related tasks. The most common tasks users seek help with include Making Decisions and Solving Problems, which is one of the two most common goals across all occupation groups. Additionally, Documenting and Recording Information ranks in the top four for all occupations. Writing is particularly significant, accounting for 42% of work-related messages overall, especially among users in management and business occupations. In ChatGPT Business, users may also utilize features tailored for corporate environments, enhancing their ability to seek information and assistance with decision-making.",multi_hop_abstract_query_synthesizer
How does ChatGPT usage relate to decision making and problem solving across different occupations?,"['<1-hop>\n\nPanel C2.Technical Help. Panel C3.Seeking Information. Panel C4.Practical Guidance. Figure 23:Variation in ChatGPT usage by occupation. Panel A shows the share of messages that are work-related across broad occupation categories. Panel B presents variation in the share of Asking and Doing messages within work-related usage. Panel C presents the distribution of work-related conversation topics by occupation, focusing on Writing and Practical Guidance. The regression for these figures is the same one as the one used in Figure 22. 34 Occupation Group Documenting/ Recording Information Making Decisions And Solving Problems Thinking Creatively Working With Computers Interpreting The Meaning Of Information For Others Getting Information Providing Consultation And Advice To Others Management 2 1 3 6 4 5 8 Business 2 1 3 6 4 5 7 Computer/Math 4 2 5 1 3 6 7 Engineering 3 1 5 2 4 6 7 Science 2 1 4 3 6 5 7 Social Service 2 1 3 X 5 4 X Legal 1 X X X X X X Education 1 2 3 4 6 5 7 Arts/Design/Media 2 1 3 5 4 6 7 Health Professionals 1 2 3 X 5 4 6 Food Service 1 X X X X X X Personal Service 1 2 3 X 4 5 X Sales 2 1 3 6 4 5 7 Administrative 2 1 3 7 4 5 8 Transportation 2 1 3 X X 4 X Military 2 1 X X X X X Figure 24:The seven most commonly requested GWAs for work-related queries. Table reports the frequency ranking of each of these GWAs for each broad occupation groups (two-digit SOC codes). 1 represents the most frequently requested GWA for that occupation. X‚Äôs indicate that the ranking is unavailable since fewer than 100 users from that occupation group requested that specific GWA within the sample. Seven occupation groups are omitted because no GWA was requested by more than 100 users from a single occupation group. These omitted occupation groups (with corresponding SOC2 codes) are ‚ÄùHealthcare Support‚Äù (31), ‚ÄùProtective Service‚Äù (33), ‚ÄùBuilding and Grounds Cleaning and Maintenance‚Äù (37), ‚ÄùFarming, Fishing, and Forestry‚Äù (45), ‚ÄùConstruction and Extraction‚Äù (47), ‚ÄùInstallation, Maintenance, and Repair‚Äù (49), and ‚ÄùProduction‚Äù (51). Not pictured are twelve other GWAs which are less frequently requested and are reported fully in Appendix D. See Appendix for full cross-tabulations between GWA and two-digit SOC2 codes. 35 7 Conclusion This paper studies the rapid growth of ChatGPT, which launched in November 2022. By July 2025, ChatGPT had been used weekly by more than 700 million users, who were collectively sending more than 2.5 billion messages per day, or about 29,000 messages per second. Yet despite the rapid adop- tion of ChatGPT and Generative AI more broadly, little previous evidence existed on how this new technology is used and who is using it. This is the first economics paper to use internal ChatGPT message data, and we do so while introducing a novel privacy-preserving methodology. No user messages were observed by humans during any part of the work on this paper. This paper documents eight important facts about ChatGPT. First, as of July 2025 about 70% of ChatGPT consumer queries were unrelated to work; while both work-related and non-work-related queries have been increasing, non-work queries have been increasing faster. Second, the three most common ChatGPT conversation topics arePractical Guidance,Writing, andSeeking Information, collectively accounting for nearly 78% of all messages.Computer Pro- grammingandRelationships and Personal Reflectionaccount for only 4.2% and 1.9% of messages respectively. Third,Writingis by far the most common work use, accounting for 42% of work-related messages overall and more than half of all messages for users in management and business occupations. About two-thirds ofWritingmessages are requests to modify user text rather than to produce novel text from scratch. Fourth, we classify messages according to the kind of output users are seeking with a rubric we callAsking, Doing,orExpressing.About 49% of messages are users asking ChatGPT for guidance, advice, or information (Asking), 40% are requests to', '<2-hop>\n\n5.4 O*NET Work Activities\nWe map message content to work activities using the Occupational Information Network (O*NET)\nDatabase Version 29.0, similar to Tomlinson et al (2025). O*NET was developed in partnership with\nthe U.S. Department of Labor and systematically classifies jobs according to the skills, tasks, and\nwork activities required to perform them. O*NET associates each occupation with a set of tasks that\nare performed at different levels of intensity. Each task is then aggregated up to three levels of detail\n- 2,087 detailed work activities (DWAs), 332 intermediate work activities (IWAs), and 41 generalized\nwork activities (GWAs).\nTo understand the work activities associated with ChatGPT usage, we mapped messages to one\nof the 332 O*NET Intermediate Work Activities (IWA), with an additional option ofAmbiguousto\naccount for situations where the user message lacked sufficient context. 22 We then used the official\n22We drew a sample of approximately 1.1 million conversations from May 2024 to June 2025, selected a random\nmessage within each, and classified it according to the prompt in A.\n19\x0cFigure 13:Shares of Asking, Doing, and Expressing messages split by work vs. non-work. See A to review\nthe prompts used by the automated classifiers. The annotations on the right show the shares of work and\nnon-work for the full sample. Each bin reports a percentage of the total population. Shares are calculated\nfrom a sample of approximately 1.1 million sampled conversations from May 15, 2024 through June 26, 2025.\nObservations are reweighted to reflect total message volumes on a given day. Sampling details available in\nSection 3.\nO*NET taxonomy to map these classified IWAs to one of the Generalized Work Activities (GWA). We\ndo not show the shares for the following GWAs as there were fewer than 100 users sending messages\nfor each category and group them intoSuppressed.\n Figure 14 presents the share of messages that belong to each GWA, in descending order. Nearly\nhalf of all messages (45.2%) fall under just three GWAs related to information use and manipula-\ntion:Getting Information(19.3%),Interpreting the Meaning of Information for Others(13.1%), and\nDocumenting/Recording Information(12.8%). The next most common work activities areProviding\nConsultation and Advice(9.2%),Thinking Creatively(9.1%),Making Decisions and Solving Problems\n(8.5%), andWorking with Computers(4.9%). These seven GWAs collectively account for 76.9% of\nall messages.\nFigure 15 presents the distribution of GWAs for the subsample of messages we classify as work-\nrelated. Among work-related messages, the most common GWAs areDocumenting/Recording In-\nformation(18.4%),Making Decisions and Solving Problems(14.9%),Thinking Creatively(13.0%),\nWorking with Computers(10.8%),Interpreting the Meaning of Information for Others(10.1%),Get-\nting Information(9.3%), andProviding Consultation and Advice to Others(4.4%). These seven GWAs\ncollectively account for nearly 81% of work-related messages. Overall, the majority of ChatGPT usage\nat work appears to be focused on two broad functions: 1) obtaining, documenting, and interpreting\ninformation; and 2) making decisions, giving advice, solving problems, and thinking creatively.\n20\x0cFigure 14:GWA Shares of 1.1M ChatGPT Messages. Messages are classified as pertaining to one of 332\nO*NET IWAs, orAmbiguoususing the prompt provided in the Appendix. IWAs were then aggregated to\nGWAs using the O*NET Work Activities taxonomy. Message sample from May 15, 2024 through June 26,\n2025. ']","ChatGPT usage is significantly related to decision making and problem solving, as indicated by the data showing that 8.5% of work-related messages are classified under Making Decisions and Solving Problems. This is part of a broader trend where nearly 81% of work-related messages focus on obtaining, documenting, and interpreting information, as well as making decisions and providing advice. The analysis of ChatGPT usage by occupation reveals that various groups, including management and business, utilize ChatGPT for these purposes, highlighting its role in enhancing decision-making processes.",multi_hop_abstract_query_synthesizer
"What are the primary ways ChatGPT is utilized in business settings, and how does this compare to general usage trends?","['<1-hop>\n\nPanel C2.Technical Help. Panel C3.Seeking Information. Panel C4.Practical Guidance. Figure 23:Variation in ChatGPT usage by occupation. Panel A shows the share of messages that are work-related across broad occupation categories. Panel B presents variation in the share of Asking and Doing messages within work-related usage. Panel C presents the distribution of work-related conversation topics by occupation, focusing on Writing and Practical Guidance. The regression for these figures is the same one as the one used in Figure 22. 34 Occupation Group Documenting/ Recording Information Making Decisions And Solving Problems Thinking Creatively Working With Computers Interpreting The Meaning Of Information For Others Getting Information Providing Consultation And Advice To Others Management 2 1 3 6 4 5 8 Business 2 1 3 6 4 5 7 Computer/Math 4 2 5 1 3 6 7 Engineering 3 1 5 2 4 6 7 Science 2 1 4 3 6 5 7 Social Service 2 1 3 X 5 4 X Legal 1 X X X X X X Education 1 2 3 4 6 5 7 Arts/Design/Media 2 1 3 5 4 6 7 Health Professionals 1 2 3 X 5 4 6 Food Service 1 X X X X X X Personal Service 1 2 3 X 4 5 X Sales 2 1 3 6 4 5 7 Administrative 2 1 3 7 4 5 8 Transportation 2 1 3 X X 4 X Military 2 1 X X X X X Figure 24:The seven most commonly requested GWAs for work-related queries. Table reports the frequency ranking of each of these GWAs for each broad occupation groups (two-digit SOC codes). 1 represents the most frequently requested GWA for that occupation. X‚Äôs indicate that the ranking is unavailable since fewer than 100 users from that occupation group requested that specific GWA within the sample. Seven occupation groups are omitted because no GWA was requested by more than 100 users from a single occupation group. These omitted occupation groups (with corresponding SOC2 codes) are ‚ÄùHealthcare Support‚Äù (31), ‚ÄùProtective Service‚Äù (33), ‚ÄùBuilding and Grounds Cleaning and Maintenance‚Äù (37), ‚ÄùFarming, Fishing, and Forestry‚Äù (45), ‚ÄùConstruction and Extraction‚Äù (47), ‚ÄùInstallation, Maintenance, and Repair‚Äù (49), and ‚ÄùProduction‚Äù (51). Not pictured are twelve other GWAs which are less frequently requested and are reported fully in Appendix D. See Appendix for full cross-tabulations between GWA and two-digit SOC2 codes. 35 7 Conclusion This paper studies the rapid growth of ChatGPT, which launched in November 2022. By July 2025, ChatGPT had been used weekly by more than 700 million users, who were collectively sending more than 2.5 billion messages per day, or about 29,000 messages per second. Yet despite the rapid adop- tion of ChatGPT and Generative AI more broadly, little previous evidence existed on how this new technology is used and who is using it. This is the first economics paper to use internal ChatGPT message data, and we do so while introducing a novel privacy-preserving methodology. No user messages were observed by humans during any part of the work on this paper. This paper documents eight important facts about ChatGPT. First, as of July 2025 about 70% of ChatGPT consumer queries were unrelated to work; while both work-related and non-work-related queries have been increasing, non-work queries have been increasing faster. Second, the three most common ChatGPT conversation topics arePractical Guidance,Writing, andSeeking Information, collectively accounting for nearly 78% of all messages.Computer Pro- grammingandRelationships and Personal Reflectionaccount for only 4.2% and 1.9% of messages respectively. Third,Writingis by far the most common work use, accounting for 42% of work-related messages overall and more than half of all messages for users in management and business occupations. About two-thirds ofWritingmessages are requests to modify user text rather than to produce novel text from scratch. Fourth, we classify messages according to the kind of output users are seeking with a rubric we callAsking, Doing,orExpressing.About 49% of messages are users asking ChatGPT for guidance, advice, or information (Asking), 40% are requests to', '<2-hop>\n\nCorporate\nusers may also use ChatGPT Business (formerly known as Teams) or ChatGPT Enterprise.\n28Very few work-related messages are classified asExpressing.\n29Appendix D contains a full report of GWA counts broken down by occupation, for both work-related ChatGPT\n31\x0cWe find remarkable similarity across occupations in how ChatGPT is used at work. For example,\nMaking Decisions and Solving Problemsis one of the two most common GWAs in every single oc-\ncupation group where at least two GWAs can be reported. 30 Similarly,Documenting and Recording\nInformationranks in the top four of all occupations.Thinking Creativelyis ranked as the third most\ncommon GWA in 10 of the 13 occupation groups where at least three GWAs can be reported. Even\nthough there are 41 GWAs, the seven most common overall are also the most common within each\noccupation group and are ranked similarly. Not surprisingly,Working with Computersis the most\ncommon GWA in computer-related occupations. In the appendix, we report the full distribution of\nGWA classifications intersected with two-digit SOC codes, as well as the most frequently requested\nGWAs out of the subset of queries which are work-related. Across all occupations, ChatGPT usage\nis broadly focused on seeking information and assistance with decision-making.\nusage and all ChatGPT usage.\n30For legal and food service occupations, we are only able to rank one of the GWAs because of user privacy protections\n- no other GWAs were requested by more than 100 users in that group.\n32\x0c Panel A.Work Related\n Panel B1.Asking.  Panel B2.Doing.\nFigure 23:(continued on next page)\n33\x0c Panel C1.Writing.  complete tasks that can be plugged into a process (Doing), and 1% are messages that have no clear intent (Expressing).Askingmessages have grown faster thanDoingmessages over the last year and are rated higher quality using both a classifier that measures user satisfaction and direct user feedback. Fifth, gender gaps in ChatGPT usage have likely closed substantially over time. As of July 2025, more than half of weekly active users had typically female first names. Sixth, nearly half of all messages sent by adults were from users under the age of 26. Seventh, ChatGPT usage has grown especially fast over the last year in low- and middle-income countries. Eighth, we find that users who are highly educated and working in professional occupations are more likely to use ChatGPT for work-related messages and forAskingrather thanDoingmessages at work. Overall, our findings suggest that ChatGPT has a broad-based impact on the global economy. The fact that non-work usage is increasing faster suggests that the welfare gains from generative AI usage could be substantial. Collis and Brynjolfsson (2025) estimate that US users would have to be paid$98 to forgo using generative AI for a month, implying a surplus of at least$97 billion a year. Within work usage, we find that users currently appear to derive value from using ChatGPT as an advisor or research assistant, not just a technology that performs job tasks directly. Still, ChatGPT likely improves worker output by providingdecision support, which is especially important in knowledge-intensive jobs where productivity is increasing in the quality of decision-making.', '<3-hop>\n\nOuyang, Long, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela\nMishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schul-\nman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter\nWelinder, Paul Christiano, Jan Leike, and Ryan Lowe, ‚ÄúTraining Language Models to\nFollow Instructions with Human Feedback,‚Äù 2022.\nPew Research Center, ‚ÄúU.S. adults‚Äô use of ChatGPT (June 2025 report),‚Äù 2025.\nPhang, Jason, Michael Lampe, Lama Ahmad, Sandhini Agarwal, Cathy Mengying Fang,\nAuren R. Liu, Valdemar Danry, Eunhae Lee, Samantha W. T. Chan, Pat Pataranuta-\nporn, and Pattie Maes, ‚ÄúInvestigating Affective Use and Emotional Well-being on ChatGPT,‚Äù\n2025.\nReuters, ‚ÄúOpenAI hits$12 billion in annualized revenue, The Information reports,‚ÄùReuters, July\n30 2025. Accessed: 2025-09-11.\nRoth, Emma, ‚ÄúOpenAI says ChatGPT users send over 2.5 billion prompts every day,‚Äù July 21 2025.\nAccessed: 2025-09-11.\nTomlinson, Kiran, Sonia Jaffe, Will Wang, Scott Counts, and Siddharth Suri, ‚ÄúWorking\nwith AI: Measuring the Occupational Implications of Generative AI,‚Äù 2025.\n39\x0cVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N.\nGomez, Lukasz Kaiser, and Illia Polosukhin, ‚ÄúAttention Is All You Need,‚Äù in I. Guyon,\nU. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, eds.,Ad-\nvances in Neural Information Processing Systems, Vol. 30 of31st Conference on Neural Information\nProcessing Systems (NIPS)Curran Associates, Inc. Long Beach, CA, USA 2017.\nWest, Jevin D., Jennifer Jacquet, Molly M. King, Shelley J. Correll, and Carl T.\nBergstrom, ‚ÄúThe Role of Gender in Scholarly Authorship,‚ÄùPLoS ONE, 2013,8(7), e66212.\nWiggers, Kyle, ‚ÄúChatGPT Isn‚Äôt the Only Chatbot That‚Äôs Gaining Users,‚ÄùTechCrunch, 2025. Ac-\ncessed: 2025-09-10.\nZao-Sanders, Marc, ‚ÄúHow People Are Really Using Gen AI in 2025,‚Äù Harvard Business Review\nApril 2025. https://hbr.org/2025/04/how-people-are-really-using-gen-ai-in-2025.\nZhao, Wenting, Xiang Ren, Jack Hessel, Claire Cardie, Yejin Choi, and Yuntian Deng,\n‚ÄúWildChat: 1M ChatGPT Interaction Logs in the Wild,‚Äù 2024.\n40\x0c']","In business settings, ChatGPT is primarily used for tasks such as Writing, Documenting and Recording Information, and Making Decisions and Solving Problems. Writing accounts for 42% of work-related messages, particularly among users in management and business occupations. This contrasts with general usage trends, where about 70% of ChatGPT consumer queries are unrelated to work, with Practical Guidance, Writing, and Seeking Information being the three most common conversation topics, collectively making up nearly 78% of all messages.",multi_hop_abstract_query_synthesizer
What are the trends in ChatGPT usage among different occupations and how does this impact the global economy?,"['<1-hop>\n\nPanel C2.Technical Help. Panel C3.Seeking Information. Panel C4.Practical Guidance. Figure 23:Variation in ChatGPT usage by occupation. Panel A shows the share of messages that are work-related across broad occupation categories. Panel B presents variation in the share of Asking and Doing messages within work-related usage. Panel C presents the distribution of work-related conversation topics by occupation, focusing on Writing and Practical Guidance. The regression for these figures is the same one as the one used in Figure 22. 34 Occupation Group Documenting/ Recording Information Making Decisions And Solving Problems Thinking Creatively Working With Computers Interpreting The Meaning Of Information For Others Getting Information Providing Consultation And Advice To Others Management 2 1 3 6 4 5 8 Business 2 1 3 6 4 5 7 Computer/Math 4 2 5 1 3 6 7 Engineering 3 1 5 2 4 6 7 Science 2 1 4 3 6 5 7 Social Service 2 1 3 X 5 4 X Legal 1 X X X X X X Education 1 2 3 4 6 5 7 Arts/Design/Media 2 1 3 5 4 6 7 Health Professionals 1 2 3 X 5 4 6 Food Service 1 X X X X X X Personal Service 1 2 3 X 4 5 X Sales 2 1 3 6 4 5 7 Administrative 2 1 3 7 4 5 8 Transportation 2 1 3 X X 4 X Military 2 1 X X X X X Figure 24:The seven most commonly requested GWAs for work-related queries. Table reports the frequency ranking of each of these GWAs for each broad occupation groups (two-digit SOC codes). 1 represents the most frequently requested GWA for that occupation. X‚Äôs indicate that the ranking is unavailable since fewer than 100 users from that occupation group requested that specific GWA within the sample. Seven occupation groups are omitted because no GWA was requested by more than 100 users from a single occupation group. These omitted occupation groups (with corresponding SOC2 codes) are ‚ÄùHealthcare Support‚Äù (31), ‚ÄùProtective Service‚Äù (33), ‚ÄùBuilding and Grounds Cleaning and Maintenance‚Äù (37), ‚ÄùFarming, Fishing, and Forestry‚Äù (45), ‚ÄùConstruction and Extraction‚Äù (47), ‚ÄùInstallation, Maintenance, and Repair‚Äù (49), and ‚ÄùProduction‚Äù (51). Not pictured are twelve other GWAs which are less frequently requested and are reported fully in Appendix D. See Appendix for full cross-tabulations between GWA and two-digit SOC2 codes. 35 7 Conclusion This paper studies the rapid growth of ChatGPT, which launched in November 2022. By July 2025, ChatGPT had been used weekly by more than 700 million users, who were collectively sending more than 2.5 billion messages per day, or about 29,000 messages per second. Yet despite the rapid adop- tion of ChatGPT and Generative AI more broadly, little previous evidence existed on how this new technology is used and who is using it. This is the first economics paper to use internal ChatGPT message data, and we do so while introducing a novel privacy-preserving methodology. No user messages were observed by humans during any part of the work on this paper. This paper documents eight important facts about ChatGPT. First, as of July 2025 about 70% of ChatGPT consumer queries were unrelated to work; while both work-related and non-work-related queries have been increasing, non-work queries have been increasing faster. Second, the three most common ChatGPT conversation topics arePractical Guidance,Writing, andSeeking Information, collectively accounting for nearly 78% of all messages.Computer Pro- grammingandRelationships and Personal Reflectionaccount for only 4.2% and 1.9% of messages respectively. Third,Writingis by far the most common work use, accounting for 42% of work-related messages overall and more than half of all messages for users in management and business occupations. About two-thirds ofWritingmessages are requests to modify user text rather than to produce novel text from scratch. Fourth, we classify messages according to the kind of output users are seeking with a rubric we callAsking, Doing,orExpressing.About 49% of messages are users asking ChatGPT for guidance, advice, or information (Asking), 40% are requests to', '<2-hop>\n\nCorporate\nusers may also use ChatGPT Business (formerly known as Teams) or ChatGPT Enterprise.\n28Very few work-related messages are classified asExpressing.\n29Appendix D contains a full report of GWA counts broken down by occupation, for both work-related ChatGPT\n31\x0cWe find remarkable similarity across occupations in how ChatGPT is used at work. For example,\nMaking Decisions and Solving Problemsis one of the two most common GWAs in every single oc-\ncupation group where at least two GWAs can be reported. 30 Similarly,Documenting and Recording\nInformationranks in the top four of all occupations.Thinking Creativelyis ranked as the third most\ncommon GWA in 10 of the 13 occupation groups where at least three GWAs can be reported. Even\nthough there are 41 GWAs, the seven most common overall are also the most common within each\noccupation group and are ranked similarly. Not surprisingly,Working with Computersis the most\ncommon GWA in computer-related occupations. In the appendix, we report the full distribution of\nGWA classifications intersected with two-digit SOC codes, as well as the most frequently requested\nGWAs out of the subset of queries which are work-related. Across all occupations, ChatGPT usage\nis broadly focused on seeking information and assistance with decision-making.\nusage and all ChatGPT usage.\n30For legal and food service occupations, we are only able to rank one of the GWAs because of user privacy protections\n- no other GWAs were requested by more than 100 users in that group.\n32\x0c Panel A.Work Related\n Panel B1.Asking.  Panel B2.Doing.\nFigure 23:(continued on next page)\n33\x0c Panel C1.Writing.  complete tasks that can be plugged into a process (Doing), and 1% are messages that have no clear intent (Expressing).Askingmessages have grown faster thanDoingmessages over the last year and are rated higher quality using both a classifier that measures user satisfaction and direct user feedback. Fifth, gender gaps in ChatGPT usage have likely closed substantially over time. As of July 2025, more than half of weekly active users had typically female first names. Sixth, nearly half of all messages sent by adults were from users under the age of 26. Seventh, ChatGPT usage has grown especially fast over the last year in low- and middle-income countries. Eighth, we find that users who are highly educated and working in professional occupations are more likely to use ChatGPT for work-related messages and forAskingrather thanDoingmessages at work. Overall, our findings suggest that ChatGPT has a broad-based impact on the global economy. The fact that non-work usage is increasing faster suggests that the welfare gains from generative AI usage could be substantial. Collis and Brynjolfsson (2025) estimate that US users would have to be paid$98 to forgo using generative AI for a month, implying a surplus of at least$97 billion a year. Within work usage, we find that users currently appear to derive value from using ChatGPT as an advisor or research assistant, not just a technology that performs job tasks directly. Still, ChatGPT likely improves worker output by providingdecision support, which is especially important in knowledge-intensive jobs where productivity is increasing in the quality of decision-making.']","ChatGPT usage trends reveal that across various occupations, the most common work-related activities include Making Decisions and Solving Problems, as well as Documenting and Recording Information. These activities rank highly in nearly all occupation groups. The paper indicates that as of July 2025, about 70% of ChatGPT consumer queries were unrelated to work, with non-work-related queries increasing faster than work-related ones. This suggests a broad-based impact on the global economy, as the welfare gains from generative AI usage could be substantial. For instance, it is estimated that US users would require $98 to forgo using generative AI for a month, indicating a surplus of at least $97 billion annually. Additionally, users in professional occupations are more likely to utilize ChatGPT for work-related messages, primarily seeking guidance and information, which enhances decision-making and productivity in knowledge-intensive jobs.",multi_hop_abstract_query_synthesizer
