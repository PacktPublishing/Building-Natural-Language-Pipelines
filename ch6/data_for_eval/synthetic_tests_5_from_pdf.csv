user_input,reference_contexts,reference,synthesizer_name
What privacy measures were implemented in the analysis of user messages as referenced in Handa et al. (2025)?,"['<1-hop>\n\n3.4 Summarizing Our Approach to Privacy\nWe took measures to safeguard user privacy at every stage of analysis. To summarize, the key elements\nof our approach are:\nAutomated classification of messages.In the course of analysis, no one ever looked directly\nat the content of user messages: all of our analysis of the content of user messages is done\nthrough output of automated classifiers run on de-identified and PII-scrubbed usage data.\nAggregated employment data via a data clean room.We analyze and report aggregated\nemployment data through a secure data clean room environment: no one on the research\nteam had direct access to user-level demographic data and none of our analyses report\naggregates for groups with less than 100 users.\nIn following these measures, we aim to match or exceed the privacy protection precedents set by\nother social scientists studying chatbots and those linking digital platform data to external sources.\nWe follow the precedent established in recent analyses of chatbot conversations (Phang et al.\n(2025), Eloundou et al. (2025), Handa et al. (2025), Tomlinson et al. (2025)) that rely on automated\nclassification rather than human inspection of raw transcripts. In particular, Phang et al. (2025)’s\nstudy of affective use of ChatGPT and Eloundou et al. (2025) investigation of first-person fairness in\nchatbots both analyze ChatGPT message content via automated classifiers and emphasize classifier-\nbased labeling as a scalable, privacy-preserving approach. Anthropic’s Handa et al. (2025) used a\nsimilar approach: theirCliomethodology applies automated classifiers to large collections of conver-\nsations, classifying conversations into thousands of topics, and in their appendix they describe manual\nvalidation on sampled conversations (100 user conversations flagged for review and 100 randomly sam-\npled calibrations). Like Eloundou et al., we validate our classifiers using WildChat, a public dataset\nof user conversations.\n9\x0cOther papers have analyzed digital behavior and demographic data; we mention a few relevant\nprecedents here. Humlum and Vestergaard (2025b) and Humlum and Vestergaard (2025a), for exam-\nple, analyze large-scale surveys on chatbot use along with Danish administrative labor market data.\nChetty et al. (2022) analyze de-identified Facebook friendship graphs and anonymized IRS tax records,\naggregated at the zip code level.\n']","In the analysis of user messages, privacy measures included automated classification of messages without direct human inspection of content, ensuring that all analysis was conducted on de-identified and PII-scrubbed usage data. Additionally, aggregated employment data was analyzed through a secure data clean room environment, preventing direct access to user-level demographic data and ensuring that analyses did not report aggregates for groups with fewer than 100 users. These measures align with the privacy protection precedents set by other studies, including Handa et al. (2025), which utilized automated classifiers for analyzing large collections of conversations.",multi_hop_specific_query_synthesizer
What are the key features of ChatGPT that differentiate it from earlier models like GPT-3.5 and how does the privacy mechanism work in relation to the analysis of user messages?,"['<1-hop>\n\nWhat is ChatGPT?\nHere we give a simplified overview of LLMs and chatbots. For more precise details, refer to the papers\nand system cards that OpenAI has released with each model e.g., (OpenAI, 2023, 2024a, 2025b). A\nchatbot is a statistical model trained to generate a text response given some text input, so as to\nmaximize the “quality” of that response, where the quality is measured with a variety of metrics.\nIn a prototypical interaction, a user submits a plain-text message (“prompt”) and ChatGPT\nreturns the message (“response”) generated from an underlying LLM. A large set of additional features\nhave been added to ChatGPT—including the possibility for the LLM to search the web or external\ndatabases, and generate images based on text—but the exchange of text-based messages remains the\nmost typical interaction.\nSince its launch ChatGPT has used a variety of different underlying LLMs e.g., GPT-3.5, GPT-4,\nGPT-4o, o1, o3, and GPT-5. 12 In addition there are occasional updates to the model’s weights and\nto the model’s system prompt (text instructions sent to the model along with all the queries).\nAn LLM can be thought of as a function from a string of words to a probability distribution over\nthe set of all possible words (more precisely, “tokens,” which very roughly correspond to words13). The\nfunctions are implemented with deep neural nets, typically with a transformer architecture (Vaswani\net al., 2017), parameterized with billions of model “weights”. We will refer to all of ChatGPT’s models\nas language models, though most can additionally process tokens representing images, audio, or other\nmedia.\nThe weights in an LLM-based chatbot are often trained in two stages, commonly called “pre-\ntraining” and “post-training”. In the first stage (“pre-training”), the LLMs are trained to predict the\nnext word in a string, given the preceding words, over an enormous corpus of text. At that point the\nmodels are purely predictors of the likelihood of the next word given a prior context, and as such they\nhave a relatively narrow application. In the second stage (“post-training”), the models are trained to\nproduce words that comprise “good” responses to some prompt. This stage often consists of a variety\nof different strategies: fine-tuning on a dataset of queries and ideal responses, reinforcement learning\nagainst another model that is trained to grade the quality of a response (Ouyang et al., 2022), or\nreinforcement learning against a function that knows the true response to queries (OpenAI (2024b),\n12For a timeline of model launches, see Appendix C.\n13Tokenization is a way of cutting a string of text into discrete chunks, chosen to be statistically efficient. In many\ntokenization schemes, one token corresponds to roughly three-quarters of an English word.\n4\x0cLambert et al. (2024)). This second stage also typically includes a number of “safety” constraints to\navoid certain classes of response, especially those which are deemed harmful or dangerous (OpenAI,\n2025a).\nThis two-stage process has a common statistical interpretation: the first stage teaches the model a\nlatent representation of the world; the second stage fits a function using that representation (Bengio\net al., 2014). Pre-training the model to predict the next word effectively teaches the model a low-\ndimensional representation of text, representing only the key semantic features, and therefore rendering\nthe prompt-response problem tractable with a reasonable set of training examples.\nTwo common ways of evaluating chatbots are with benchmarks (batteries of questions with known\nanswers, e.g. Measuring Massive Multitask Language Understanding (Hendrycks et al., 2021)) and\ncomparisons of human preferences over two alternative responses to the same message (e.g. Chatbot\nArena (Chiang et al., 2024)).\n3 ', '<2-hop>\n\nPrivacy via Automated Classifiers.No one looked at the content of messages while conducting\nanalysis for this paper. All analysis of message content was performed via automated LLM-based\nclassifiers run on de-identified and PII-scrubbed message data (see Figure 1). The messages are first\nscrubbed of PII using an internal LLM-based tool,17 and then classified according to classifiers defined\nover a controlled label space—the most precise classifier we use on the message-level data set is the\nO*NET Intermediate Work Activities taxonomy, which we augment to end up with 333 categories.\nWe introduce technical and procedural frictions that prevent accidental access to the underlying text\n(for example, interfaces that do not render message text to researchers).\nOur classifications aim to discern the intent of a given message, and thus we include the prior 10\nmessages in a conversation as context. 18 For an example, see Table 2.\n Stand-Alone Message Message with Prior Context\n[user]: “10 more” [user]: “give me 3 cultural activities to do with teens”\n[assistant]: “1. Visit a museum . . . ” (truncated)\n[user]: “10 more”\nTable 2:Illustration of Context-Augmented Message Classifications (Synthetic Example). The left column\nshows a standalone message to be classified, and the right column shows the prior context included in the\nclassification of the message on the left.\nWe truncate each message to a maximum of 5,000 characters, because long context windows could\ninduce variability in the quality of the classification (Liu et al., 2023). We classify each message\nwith the “gpt-5-mini” model, with the exception ofInteraction Quality,which uses “gpt-5,” using the\nprompts listed in Appendix A.\n17Internal analyses show that the tool,Privacy Filter, has substantial alignment with human judgment.\n']","ChatGPT has introduced a variety of features that differentiate it from earlier models like GPT-3.5, including the ability to search the web or external databases and generate images based on text. The underlying architecture remains a large language model (LLM) that has undergone pre-training and post-training stages to enhance its response quality. Regarding privacy, the analysis of user messages is conducted using automated LLM-based classifiers on de-identified and PII-scrubbed message data. This process ensures that no one looks at the content of messages directly, and the classifiers discern the intent of messages by including prior context from conversations.",multi_hop_specific_query_synthesizer
"What is the impact of education level on the usage patterns of ChatGPT, and how does this relate to its broader impact on the global economy?","['<1-hop>\n\nOverall, our findings suggest that ChatGPT has a broad-based impact on the global economy.\nThe fact that non-work usage is increasing faster suggests that the welfare gains from generative AI\nusage could be substantial. Collis and Brynjolfsson (2025) estimate that US users would have to\nbe paid$98 to forgo using generative AI for a month, implying a surplus of at least$97 billion a\nyear. Within work usage, we find that users currently appear to derive value from using ChatGPT\nas an advisor or research assistant, not just a technology that performs job tasks directly. Still,\nChatGPT likely improves worker output by providingdecision support, which is especially important\nin knowledge-intensive jobs where productivity is increasing in the quality of decision-making.\n36\x0c T. Chan, Pat Pataranuta- porn, and Pattie Maes, “Investigating Affective Use and Emotional Well-being on ChatGPT,” 2025. Reuters, “OpenAI hits$12 billion in annualized revenue, The Information reports,”Reuters, July 30 2025.', '<2-hop>\n\n37% of messages are work-related for users with less than a bachelor’s degree, compared to 46% for users with exactly a bachelor’s degree and 48% for those with some graduate education. Those differences are cut roughly in half after adjusting for other characteristics, but they are still statistically significant at the less than 1 percent level. Educated users are more likely to send work-related messages. Panel B explores variation by education in user intent.Askingconstitutes about 49% of messages for users with less than a bachelor’s degree, with little variation for more educated users. After regression adjustment, we find that users with a graduate degree are about two percentage points more likely to use ChatGPT forAskingmessages, a difference that is statistically significant at the 5% level. Prior to regression adjustment, the frequency ofDoingmessages is increasing in education. However, this pattern reverses after adjusting for other characteristics such as occupation. Users with a graduate degree are about 1.6 percentage points less likely to sendDoingmessages than users with less than a bachelor’s degree, and the difference is statistically significant at the 10% level. Panel C studies variation by education in the frequency of four different conversation topics – Practical Guidance,Seeking Information,Technical Help, andWriting. We find only modest differ- ences by education across most of these categories. The one exception is that the share of messages related toWritingis increasing in relation to education. 28 Panel A.Work Related Panel B1.Asking. Panel B2.Doing. Panel B3.Expressing. Figure 22:(continued on next page) 29 Panel C1.Writing. Panel C2.Technical Help. Panel C3.Seeking Information. Panel C4.Practical Guidance. Figure 22:Variation in ChatGPT usage by education. Each plot shows unadjusted vs. regression-adjusted estimates, with 95% confidence intervals. We regress each message share on education and occupation, control- ling for the following covariates: age, whether the name was typically masculine or feminine, seniority within role, company size, and industry. (To guarantee user privacy, we coarsen all covariates to broad categories and programmatically enforce that each group has at least 100 members prior to running the regression) We add the coefficients on each education and occupation category to the unadjusted value for the reference category and compute 95% confidence intervals using the standard errors from the regression coefficients. The sample for this regression is the approximately 40,000 users of the original 130,000 sample whose publicly available occupation was not blank or consisted of strictly special characters (as determined by a classification script). Shares for each user are calculated by randomly sampling up to six conversations attributed to the user from May 2024 through July 2025. 30 6.5 Variation by Occupation Figure 23 presents variation in ChatGPT usage by user occupation. Due to privacy-preserving aggre- gation limits, we report results for the following broad occupation categories – (1) all nonprofessional occupations, including administrative, clerical, service, and blue-collar occupations; (2) computer- related occupations; (3) engineering and science occupations; (4) management and business occupa- tions; and (5) all other professional occupations, including law, education, and health care. 26 As above, the left-hand side of the figure shows unadjusted comparisons and the right-hand side presents the coefficients on each occupation category from a regression of message shares on age, whether the name was typically masculine or feminine, education, occupation categories, job seniority, firm size, and industry. Users in highly paid professional and technical occupations are more likely to use ChatGPT for work.27 Panel A shows that the unadjusted work shares are 57% for computer-related occupations; 50% for management and business; 48% for engineering and science; 44% for other professional oc- cupations; and only 40% for all non-professional occupations. Regression adjustment moves these figures around slightly, but the gaps by occupation remain highly statistically significant. Users in highly-paid professional occupations are more likely to send work-related messages. Because work usage is so different by occupation, we restrict the sample only to work-related messages in Panels B and C. Panel B presents the share of work-related messages that areAsking messages, by occupation. We find that users in highly paid professional occupations are more likely to use ChatGPT forAskingrather thanDoing. 28 This is especially true in scientific and technical occupations. 47% of the work-related messages sent by users employed in computer-related occupa-', '<3-hop>\n\n6 Who Uses ChatGPT\nIn this section we report basic descriptive facts about who uses consumer ChatGPT. Existing work\ndocuments variation in generative AI use by demographic groups within representative samples in\nthe U.S. (Bick et al. (2024), Hartley et al. (2025)) and within a subset of occupations in Denmark\n(Humlum and Vestergaard, 2025a). All of these papers find that generative AI is used more frequently\nby men, young people, and those with tertiary and/or graduate education.\nWe make three contributions relative to this prior literature. First, we confirm these broad demo-\ngraphic patterns in a global sample rather than a single country. Second, we provide more detail for\nselected demographics such as age, gender, and country of origin and study how gaps in each have\nchanged over time. Third, we use a secure data clean room to analyze how ChatGPT usage varies by\neducation and occupation.\n 6.1 Name Analysis\nWe investigate potential variation by gender by classifying a global random sample of over 1.1 million\nChatGPT users’ first names using public aggregated datasets of name-gender associations. We used\nthe World Gender Name Dictionary, and Social Security popular names, as well as datasets of popular\nBrazilian and Latin American names. This methodology is similar to that in (Hofstra et al., 2020)\nand (West et al., 2013). Names that were not in these datasets, or were flagged as ambiguous in the\ndatasets, or had significant disagreement amongst these datasets were classified asUnknown.\nExcludingUnknown, a significant share (around 80%) of the weekly active users (WAU) in the\nfirst few months after ChatGPT was released were by users with typically masculine first names.\nHowever, in the first half of 2025, we see the share of active users with typically feminine and typically\nmasculine names reach near-parity. By June 2025 we observe active users are more likely to have\ntypically feminine names. This suggests that gender gaps in ChatGPT usage have closed substantially\nover time.\nWe also study differences in usage topics. Users with typically female first names are relatively more\nlikely to send messages related toWritingandPractical Guidance. ']","The impact of education level on the usage patterns of ChatGPT is significant, as evidenced by the data showing that 37% of messages are work-related for users with less than a bachelor’s degree, compared to 46% for those with a bachelor’s degree and 48% for users with some graduate education. This indicates that educated users are more likely to engage in work-related messaging. Furthermore, the findings suggest that ChatGPT has a broad-based impact on the global economy, with estimates indicating that US users would require $98 to forgo using generative AI for a month, implying a surplus of at least $97 billion a year. The relationship between education and usage patterns highlights that as education levels increase, users derive more value from ChatGPT, particularly in knowledge-intensive jobs where decision-making quality is crucial for productivity.",multi_hop_abstract_query_synthesizer
