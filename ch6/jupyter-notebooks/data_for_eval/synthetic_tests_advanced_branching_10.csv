user_input,reference_contexts,reference,synthesizer_name
What Alexa do in AI?,"[""What is AI, how does it work and why are some people concerned about it?\nArtificial intelligence (AI) has increasingly become part of everyday life over the past decade.\nIt is being used to personalise social media feeds, spot friends and family in smartphone photos and pave the way for medical breakthroughs.\nBut the rise of chatbots like OpenAI's ChatGPT and Meta AI has been accompanied by concern about the technology's environmental impact, ethical implications and data use.\n What is AI and what is it used for?\nAI allows computers to process large amounts of data, identify patterns and follow detailed instructions about what to do with that information.\nComputers cannot think, empathise or reason.\nHowever, scientists have developed systems that can perform tasks which usually require human intelligence, trying to replicate how people acquire and use knowledge.\nThis could be trying to anticipate what product an online shopper might buy, based on previous purchases, in order to recommend items.\nThe technology is also behind voice-controlled virtual assistants like Apple's Siri and Amazon's Alexa, and is being used to develop systems for self-driving cars.\nAI also helps social platforms like Facebook, TikTok and X decide what posts to show users. Streaming services Spotify and Deezer use AI to suggest music.\nThere are also a number of applications in medicine, as scientists use AI to help spot cancers, review X-ray results, speed up diagnoses and identify new treatments.\n What is generative AI, and how do apps like ChatGPT and Meta AI work?\nGenerative AI is used to create new content which can seem like it has been made by a human.\nIt does this by learning from vast quantities of existing data such as online text and images.\nChatGPT and Chinese rival DeepSeek's chatbot are popular generative AI tools that can be used to produce text, images, code and more material.\nGoogle's Gemini or Meta AI can similarly hold text conversations with users.\nApps like Midjourney or Veo 3 are dedicated to creating images or video from simple text prompts.\nGenerative AI can also be used to make high-quality music.\nSongs mimicking the style or sound of famous musicians have gone viral, sometimes leaving fans confused about their authenticity.\n""]","Alexa is a voice-controlled virtual assistant developed by Amazon, and it uses AI to perform tasks that usually require human intelligence, such as processing data and following instructions.",single_hop_specific_query_synthesizer
What happened to the UnitedHealthcare CEO Brian Thompson?,"['Why is AI controversial?\nWhile acknowledging AI\'s potential, some experts are worried about the implications of its rapid growth.\nThe International Monetary Fund (IMF) has warned AI could affect nearly 40% of jobs, and worsen global financial inequality.\nProf Geoffrey Hinton, a computer scientist regarded as one of the ""godfathers"" of AI development, has expressed concern that powerful AI systems could even make humans extinct - although his fear was dismissed by his fellow ""AI godfather"", Yann LeCun.\nCritics also highlight the tech\'s potential to reproduce biased information, or discriminate against some social groups.\nThis is because much of the data used to train AI comes from public material, including social media posts or comments, which can reflect existing societal biases such as sexism or racism.\nAnd while AI programmes are growing more adept, they are still prone to errors - such as creating images of people with the wrong number of fingers or limbs.\nGenerative AI systems are known for their ability to ""hallucinate"" and assert falsehoods as fact, even sometimes inventing sources for the inaccurate information.\nApple halted a new AI feature in January after it incorrectly summarised news app notifications.\nThe BBC complained about the feature after Apple\'s AI falsely told readers that Luigi Mangione - the man accused of killing UnitedHealthcare CEO Brian Thompson - had shot himself.\nGoogle has also faced criticism over inaccurate answers produced by its AI search overviews.\nThis has added to concerns about the use of AI in schools and workplaces, where it is increasingly used to help summarise texts, write emails or essays and solve bugs in code.\nThere are worries about students using AI technology to ""cheat"" on assignments, or employees ""smuggling"" it into work.\nWriters, musicians and artists have also pushed back against the technology on ethical grounds, accusing AI developers of using their work to train systems without consent or compensation.\nThousands of creators - including Abba singer-songwriter Björn Ulvaeus, writers Ian Rankin and Joanne Harris and actress Julianne Moore - signed a statement in October 2024 calling AI a ""major, unjust threat"" to their livelihoods.\nHow does AI effect the environment?\nIt is not clear how much energy AI systems use, but some researchers estimate the industry as a whole could soon consume as much as the Netherlands.\nCreating the powerful computer chips needed to run AI programmes requires lots of power and water.\nDemand for generative AI services has also meant an increase in the number of data centres which power them.\nThese huge halls - housing thousands of racks of computer servers - use substantial amounts of energy and require large volumes of water to keep them cool.\nSome large tech companies have invested in ways to reduce or reuse the water needed, or have opted for alternative methods such as air-cooling.\nHowever, some experts and activists fear that AI will worsen water supply problems.\nThe BBC was told in February that government plans to make the UK a ""world leader"" in AI could put already stretched supplies of drinking water under strain.\nIn September 2024, Google said it would reconsider proposals for a data centre in Chile, which has struggled with drought.\n']","The BBC reported that Apple's AI falsely told readers that Luigi Mangione, the man accused of killing UnitedHealthcare CEO Brian Thompson, had shot himself.",single_hop_specific_query_synthesizer
"What is the current stance of the UK government regarding the regulation of AI technologies, and how does it compare to other countries?","['Are there laws governing AI?\nSome governments have already introduced rules governing how AI operates.\nThe EU\'s Artificial Intelligence Act places controls on high risk systems used in areas such as education, healthcare, law enforcement or elections. It bans some AI use altogether.\nGenerative AI developers in China are required to safeguard citizens\' data, and promote transparency and accuracy of information. But they are also bound by the country\'s strict censorship laws.\nIn the UK, Prime Minister Sir Keir Starmer has said the government ""will test and understand AI before we regulate it"".\nBoth the UK and US have AI Safety Institutes that aim to identify risks and evaluate advanced AI models.\nIn 2024 the two countries signed an agreement to collaborate on developing ""robust"" AI testing methods.\nHowever, in February 2025, neither country signed an international AI declaration which pledged an open, inclusive and sustainable approach to the technology.\nSeveral countries including the UK are also clamping down on use of AI systems to create deepfake nude imagery and child sexual abuse material.\nSign up for our Tech Decoded newsletter to follow the world\'s top tech stories and trends. Outside the UK? Sign up here.']","In the UK, Prime Minister Sir Keir Starmer has stated that the government ""will test and understand AI before we regulate it."" This approach contrasts with the EU's Artificial Intelligence Act, which imposes strict controls on high-risk AI systems in sectors like education and healthcare, and even bans certain AI uses. Additionally, while the UK and US have established AI Safety Institutes to identify risks and evaluate advanced AI models, they did not sign an international AI declaration in February 2025 that advocated for an open and sustainable approach to AI technology. Furthermore, the UK, along with several other countries, is taking measures to restrict the use of AI systems for creating deepfake nude imagery and child sexual abuse material.",single_hop_specific_query_synthesizer
How does the GDPR impact the transparency and accountability of algorithms used by municipal agencies in New York City?,"['<1-hop>\n\nAI ethics and transparency\nAlgorithms embed ethical considerations and value choices into program decisions. As such, these systems raise questions concerning the criteria used in automated decisionmaking. Some people want to have a better understanding of how algorithms function and what choices are being made.44\nIn the United States, many urban schools use algorithms for enrollment decisions based on a variety of considerations, such as parent preferences, neighborhood qualities, income level, and demographic background. According to Brookings researcher Jon Valant, the New Orleans–based Bricolage Academy “gives priority to economically disadvantaged applicants for up to 33 percent of available seats. In practice, though, most cities have opted for categories that prioritize siblings of current students, children of school employees, and families that live in school’s broad geographic area.”45 Enrollment choices can be expected to be very different when considerations of this sort come into play.\nDepending on how AI systems are set up, they can facilitate the redlining of mortgage applications, help people discriminate against individuals they don’t like, or help screen or build rosters of individuals based on unfair criteria. The types of considerations that go into programming decisions matter a lot in terms of how the systems operate and how they affect customers.46\nFor these reasons, the EU is implementing the General Data Protection Regulation (GDPR) in May 2018. The rules specify that people have “the right to opt out of personally tailored ads” and “can contest ‘legal or similarly significant’ decisions made by algorithms and appeal for human intervention” in the form of an explanation of how the algorithm generated a particular outcome. Each guideline is designed to ensure the protection of personal data and provide individuals with information on how the “black box” operates.47\nLegal liability\nThere are questions concerning the legal liability of AI systems. If there are harms or infractions (or fatalities in the case of driverless cars), the operators of the algorithm likely will fall under product liability rules. A body of case law has shown that the situation’s facts and circumstances determine liability and influence the kind of penalties that are imposed. Those can range from civil fines to imprisonment for major harms.48 The Uber-related fatality in Arizona will be an important test case for legal liability. The state actively recruited Uber to test its autonomous vehicles and gave the company considerable latitude in terms of road testing. It remains to be seen if there will be lawsuits in this case and who is sued: the human backup driver, the state of Arizona, the Phoenix suburb where the accident took place, Uber, software developers, or the auto manufacturer. Given the multiple people and organizations involved in the road testing, there are many legal questions to be resolved.', '<2-hop>\n\nEngage with state and local officials\nStates and localities also are taking action on AI. For example, the New York City Council unanimously passed a bill that directed the mayor to form a taskforce that would “monitor the fairness and validity of algorithms used by municipal agencies.”60 The city employs algorithms to “determine if a lower bail will be assigned to an indigent defendant, where firehouses are established, student placement for public schools, assessing teacher performance, identifying Medicaid fraud and determine where crime will happen next.”61\nAccording to the legislation’s developers, city officials want to know how these algorithms work and make sure there is sufficient AI transparency and accountability. In addition, there is concern regarding the fairness and biases of AI algorithms, so the taskforce has been directed to analyze these issues and make recommendations regarding future usage. It is scheduled to report back to the mayor on a range of AI policy, legal, and regulatory issues by late 2019.\nSome observers already are worrying that the taskforce won’t go far enough in holding algorithms accountable. For example, Julia Powles of Cornell Tech and New York University argues that the bill originally required companies to make the AI source code available to the public for inspection, and that there be simulations of its decisionmaking using actual data. After criticism of those provisions, however, former Councilman James Vacca dropped the requirements in favor of a task force studying these issues. He and other city officials were concerned that publication of proprietary information on algorithms would slow innovation and make it difficult to find AI vendors who would work with the city.62 It remains to be seen how this local task force will balance issues of innovation, privacy, and transparency.\n Regulate broad objectives more than specific algorithms\nThe European Union has taken a restrictive stance on these issues of data collection and analysis.63 It has rules limiting the ability of companies from collecting data on road conditions and mapping street views. Because many of these countries worry that people’s personal information in unencrypted Wi-Fi networks are swept up in overall data collection, the EU has fined technology firms, demanded copies of data, and placed limits on the material collected.64 This has made it more difficult for technology companies operating there to develop the high-definition maps required for autonomous vehicles.\nThe GDPR being implemented in Europe place severe restrictions on the use of artificial intelligence and machine learning. According to published guidelines, “Regulations prohibit any automated decision that ‘significantly affects’ EU citizens. This includes techniques that evaluates a person’s ‘performance at work, economic situation, health, personal preferences, interests, reliability, behavior, location, or movements.’”65 In addition, these new rules give citizens the right to review how digital services made specific algorithmic choices affecting people.\nBy taking a restrictive stance on issues of data collection and analysis, the European Union is putting its manufacturers and software designers at a significant disadvantage to the rest of the world.\nIf interpreted stringently, these rules will make it difficult for European software designers (and American designers who work with European counterparts) to incorporate artificial intelligence and high-definition mapping in autonomous vehicles. Central to navigation in these cars and trucks is tracking location and movements. Without high-definition maps containing geo-coded data and the deep learning that makes use of this information, fully autonomous driving will stagnate in Europe. Through this and other data protection actions, the European Union is putting its manufacturers and software designers at a significant disadvantage to the rest of the world.\nIt makes more sense to think about the broad objectives desired in AI and enact policies that advance them, as opposed to governments trying to crack open the “black boxes” and see exactly how specific algorithms operate. Regulating individual algorithms will limit innovation and make it difficult for companies to make use of artificial intelligence.\n']","The GDPR impacts the transparency and accountability of algorithms used by municipal agencies in New York City by imposing strict regulations on automated decisions that significantly affect individuals. This includes the requirement for individuals to have the right to contest decisions made by algorithms and to receive explanations of how these decisions were made. As New York City employs algorithms for various critical functions, such as determining bail for defendants and assessing teacher performance, the GDPR's emphasis on transparency aligns with the city's efforts to monitor the fairness and validity of these algorithms. The taskforce established by the New York City Council aims to analyze these issues and ensure that AI systems operate fairly and transparently, reflecting the principles outlined in the GDPR.",multi_hop_specific_query_synthesizer
What are the trends in the usage of ChatGPT for Technical Help and how does it compare to other conversation topics over time?,"['<1-hop>\n\n37% of messages are work-related for users with less than a bachelor’s degree, compared to 46% for users with exactly a bachelor’s degree and 48% for those with some graduate education. Those differences are cut roughly in half after adjusting for other characteristics, but they are still statistically significant at the less than 1 percent level. Educated users are more likely to send work-related messages. Panel B explores variation by education in user intent.Askingconstitutes about 49% of messages for users with less than a bachelor’s degree, with little variation for more educated users. After regression adjustment, we find that users with a graduate degree are about two percentage points more likely to use ChatGPT forAskingmessages, a difference that is statistically significant at the 5% level. Prior to regression adjustment, the frequency ofDoingmessages is increasing in education. However, this pattern reverses after adjusting for other characteristics such as occupation. Users with a graduate degree are about 1.6 percentage points less likely to sendDoingmessages than users with less than a bachelor’s degree, and the difference is statistically significant at the 10% level. Panel C studies variation by education in the frequency of four different conversation topics – Practical Guidance,Seeking Information,Technical Help, andWriting. We find only modest differ- ences by education across most of these categories. The one exception is that the share of messages related toWritingis increasing in relation to education. 28 Panel A.Work Related Panel B1.Asking. Panel B2.Doing. Panel B3.Expressing. Figure 22:(continued on next page) 29 Panel C1.Writing. Panel C2.Technical Help. Panel C3.Seeking Information. Panel C4.Practical Guidance. Figure 22:Variation in ChatGPT usage by education. Each plot shows unadjusted vs. regression-adjusted estimates, with 95% confidence intervals. We regress each message share on education and occupation, control- ling for the following covariates: age, whether the name was typically masculine or feminine, seniority within role, company size, and industry. (To guarantee user privacy, we coarsen all covariates to broad categories and programmatically enforce that each group has at least 100 members prior to running the regression) We add the coefficients on each education and occupation category to the unadjusted value for the reference category and compute 95% confidence intervals using the standard errors from the regression coefficients. The sample for this regression is the approximately 40,000 users of the original 130,000 sample whose publicly available occupation was not blank or consisted of strictly special characters (as determined by a classification script). Shares for each user are calculated by randomly sampling up to six conversations attributed to the user from May 2024 through July 2025. 30 6.5 Variation by Occupation Figure 23 presents variation in ChatGPT usage by user occupation. Due to privacy-preserving aggre- gation limits, we report results for the following broad occupation categories – (1) all nonprofessional occupations, including administrative, clerical, service, and blue-collar occupations; (2) computer- related occupations; (3) engineering and science occupations; (4) management and business occupa- tions; and (5) all other professional occupations, including law, education, and health care. 26 As above, the left-hand side of the figure shows unadjusted comparisons and the right-hand side presents the coefficients on each occupation category from a regression of message shares on age, whether the name was typically masculine or feminine, education, occupation categories, job seniority, firm size, and industry. Users in highly paid professional and technical occupations are more likely to use ChatGPT for work.27 Panel A shows that the unadjusted work shares are 57% for computer-related occupations; 50% for management and business; 48% for engineering and science; 44% for other professional oc- cupations; and only 40% for all non-professional occupations. Regression adjustment moves these figures around slightly, but the gaps by occupation remain highly statistically significant. Users in highly-paid professional occupations are more likely to send work-related messages. Because work usage is so different by occupation, we restrict the sample only to work-related messages in Panels B and C. Panel B presents the share of work-related messages that areAsking messages, by occupation. We find that users in highly paid professional occupations are more likely to use ChatGPT forAskingrather thanDoing. 28 This is especially true in scientific and technical occupations. 47% of the work-related messages sent by users employed in computer-related occupa-', '<2-hop>\n\nWhat are the topics of ChatGPT conversations?\nWe modify a classifier used by internal research teams at OpenAI that identifies which capabilities\nthe user is requesting from ChatGPT. The classifier itself directly assigns the user’s query into one\nof 24 categories. We aggregate these 24 categories into seven topical groupings (the full conversation-\ncategorization prompt is given in Appendix A):\nTopic Conversation Category\nWriting Edit or Critique Provided Text\nPersonal Writing or Communication\nTranslation\nArgument or Summary Generation\nWrite Fiction\nPractical Guidance How-To Advice\nTutoring or Teaching\nCreative Ideation\nHealth, Fitness, Beauty, or Self-Care\nTechnical Help Mathematical Calculation\nData Analysis\n13\x0cTopic Conversation Category\nComputer Programming\nMultimedia Create an Image\nAnalyze an Image\nGenerate or Retrieve Other Media\nSeeking Information Specific Info\nPurchasable Products\nCooking and Recipes\nSelf-Expression Greetings and Chitchat\nRelationships and Personal Reflection\nGames and Role Play\nOther/Unknown Asking About the Model\nOther\nUnclear\nTable 3:Coarse Conversation Topics and Underlying Classifier Categories\nFigure 7 shows the composition of user messages over time. The three most common Conversation\nTopics arePractical Guidance,Seeking Information, andWriting, collectively accounting for about\n77% of all ChatGPT conversations.Practical Guidancehas remained constant at roughly 29% of\noverall usage.Writinghas declined from 36% of all usage in July 2024 to 24% a year later.Seeking\nInformationhas grown from 14% to 24% of all usage over the same period. The share ofTechnical\nHelpdeclined from 12% from all usage in July 2024 to around 5% a year later – this may be because\nthe use of LLMs for programming has grown very rapidly through the API (outside of ChatGPT),\nfor AI assistance in code editing and for autonomous programming agents (e.g. Codex).Multimedia\ngrew from 2% to just over 7%, with a large spike in April 2025 after ChatGPT released new image-\ngeneration capabilities: the spike attenuated but the elevated level has persisted.\nFigure 8 shows Conversation Topics, restricting the sample to only work-related messages. About\n40% of all work-related messages in July 2025 areWriting, by far the most common Conversation\nTopic.Practical Guidanceis the second most common use case at 24%.Technical Helphas declined\nfrom 18% of all work-related messages in July 2024 to just over 10% in July 2025.\nFigure 9 disaggregates four of the seven Conversation Topics into smaller groups and sums up\nmessages of each type over a one-year period. For example, the five sub-categories withinWriting\nare (in order of frequency)Editing or Critiquing Provided Text,Personal Writing or Communication,\nTranslation,Argument or Summary Generation, andWriting Fiction. Three of those five categories\n(Editing or Critiquing Provided Text,Translation, andArgument or Summary Generation) are re-\nquests to modify text that has been provided to ChatGPT by the user, whereas the other two are\nrequests to produce novel text. The former constitute two thirds of allWritingconversations, which\n14\x0cFigure 7:Share of consumer ChatGPT messages broken down by high level conversation topic, according\nto the mapping in Table 3. Values are averaged over a 28 day lagging window.']","The usage of ChatGPT for Technical Help has shown a decline from 12% of all usage in July 2024 to around 5% a year later. This decrease may be attributed to the rapid growth of using large language models (LLMs) for programming through APIs, which has shifted the focus away from ChatGPT for technical assistance. In contrast, the three most common conversation topics overall are Practical Guidance, Seeking Information, and Writing, which collectively account for about 77% of all ChatGPT conversations. Specifically, Practical Guidance has remained constant at roughly 29% of overall usage, while Seeking Information has grown from 14% to 24% over the same period. Writing has also seen a decline from 36% to 24% of all usage.",multi_hop_specific_query_synthesizer
What trends in user interactions and gender representation are observed in ChatGPT usage by June 2025?,"['<1-hop>\n\nHowever, in the first half of 2025, we see the share of active users with typically feminine and typically\nmasculine names reach near-parity. By June 2025 we observe active users are more likely to have\ntypically feminine names. This suggests that gender gaps in ChatGPT usage have closed substantially\nover time.\nWe also study differences in usage topics. Users with typically female first names are relatively more\nlikely to send messages related toWritingandPractical Guidance. By contrast, users with typically\nmale first names are more likely to use ChatGPT forTechnical Help,Seeking Out Information, and\nMultimedia(e.g., modifying or creating images).\n 6.2 Variation by Age\nA subset of users self-report their age when registering for OpenAI. Among those who self-report their\nage, around 46% of the messages in our dataset are accounted for by users 18-25.\nA higher share of messages are work-related for older users. Work-related messages comprised\napproximately 23% of messages for users under age 26, with this share increasing with age. The\none exception is users who self-attest to being 66 years-old or older, with only 16% of their classified\nmessages being work-related. The plot below shows trends in the share of work-related messages by\nage group. ChatGPT usage has become less work-related over time for users of all ages.\n25\x0cFigure 18:Breakdown of weekly active users by typically masculine and typically feminine first names. We\ndraw on a uniform sample of 1.1M ChatGPT accounts, subject to the same user exclusion principles as other\ndatasets we analyze. Note that this is a separate sample than those described in Section 3. First names\nare classified as typically masculine or typically feminine using public aggregated datasets of name-gender\nassociations.\nFigure 19:Difference in share of topic prevalence in messages by users with typically masculine/feminine\nfirst name. We draw on a uniform sample of 1.1M ChatGPT accounts, subject to the same user exclusion\nprinciples as other datasets we analyze. Note that this is a separate sample than those described in Section\n3. First names are classified as typically masculine or typically feminine using public aggregated datasets\nof name-gender associations. Topics are aggregated groupings from a classifier whose prompt we provide in\nAppendix A.\n26\x0cFigure 20:Likelihood that a message is work related, conditioned on self-reported user age. Messages are\nidentified as work related using an automated classifier. As with our other samples (see Section 3), users who\nself-report an age under 18 are excluded from analysis. Values are averaged over a 28 day lagging window.\nShares are calculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024\nthrough June 26, 2025. Observations are reweighted to reflect total message volumes on a given day.\n', '<2-hop>\n\n5.5 Quality of Interactions\nWe additionally used automated classifiers to study the user’s apparent satisfaction with the chatbot’s\nresponse to their request. OurInteraction Qualityclassifier looks for an expression of satisfaction or\ndissatisfaction in the user’s subsequent message in the same conversation (if one exists), with three\npossible categories:Good,Bad, andUnknown. 23\nFigure 16 plots the overall growth of messages in these three buckets. In late 2024Goodinteractions\nwere about three times as common asBadinteractions, butGoodinteractions grew much more rapidly\nover the next nine months, and by July 2025 they were more than four times more common.\nFigure 16:Interaction quality shares, based on automated sentiment analysis of thenext responseprovided\nby the user. See Appendix B to understand how this classifier was validated. Values are averaged over a 28\nday lagging window. Shares are calculated from a sample of approximately 1.1 million sampled conversations\nfrom May 15, 2024 through June 26, 2025. Observations are reweighted to reflect total message volumes on a\ngiven day. Sampling details available in Section 3.\nDetails on the validation of this classifier, along with measurements of how it correlates with\nexplicit thumbs up/thumbs down annotations from users, are included in Appendix B.\nFigure 17 shows the ratio of good-to-bad messages by conversation topic and interaction type, as\nrated by Interaction Quality. Panel A shows thatSelf-Expressionis the highest rated topic, with a\ngood-to-bad ratio of more than seven, consistent with the growth in this category.Multimediaand\nTechnical Helphave the lowest good-to-bad ratios (1.7 and 2.7 respectively). Panel B shows that\nAskingmessages are substantially more likely to receive a good rating thanDoingorExpressing\nmessages.\n23For this classifier we do not disclose the prompt.\n23\x0cFigure 17:AverageGoodtoBadratio for user interactions by Conversation Topic (Panel A) and Ask-\ning/Doing/Expressing classification (Panel B). The prompts for each of these automated classifiers (with the\nexception of interaction quality) are available in Appendix A. Values represent the average ratio from May 15,\n2024 through June 26, 2025, where observations are reweighted to reflect total message volumes on a given\nday. Sampling details available in Section 3.\n24\x0c']","By June 2025, the share of active users with typically feminine and typically masculine names reached near-parity, indicating that gender gaps in ChatGPT usage have closed substantially over time. Additionally, users with typically female first names were more likely to engage in topics related to Writing and Practical Guidance, while those with typically male first names tended to seek Technical Help, Information, and Multimedia. Furthermore, the quality of interactions improved, with 'Good' interactions growing rapidly, becoming more than four times as common as 'Bad' interactions by July 2025.",multi_hop_specific_query_synthesizer
"What are the main conversation topics users engage with ChatGPT, and how do these relate to user intent in terms of asking for information or performing tasks?","['<1-hop>\n\nFigure 9 disaggregates four of the seven Conversation Topics into smaller groups and sums up\nmessages of each type over a one-year period. For example, the five sub-categories withinWriting\nare (in order of frequency)Editing or Critiquing Provided Text,Personal Writing or Communication,\nTranslation,Argument or Summary Generation, andWriting Fiction. Three of those five categories\n(Editing or Critiquing Provided Text,Translation, andArgument or Summary Generation) are re-\nquests to modify text that has been provided to ChatGPT by the user, whereas the other two are\nrequests to produce novel text. The former constitute two thirds of allWritingconversations, which\n14\x0cFigure 7:Share of consumer ChatGPT messages broken down by high level conversation topic, according\nto the mapping in Table 3. Values are averaged over a 28 day lagging window. Shares are calculated from\na sample of approximately 1.1 million sampled conversations from May 15, 2024 through June 26, 2025.\nObservations are reweighted to reflect total message volumes on a given day. Sampling details available in\nSection 3.\nFigure 8:Share ofwork relatedconsumer ChatGPT messages broken down by high level conversation\ntopic, according to the mapping in Table 3. Values are averaged over a 28 day lagging window. Shares are\ncalculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024 through June\n26, 2025. Observations are reweighted to reflect total message volumes on a given day. Sampling details\navailable in Section 3.\n15\x0csuggests that most userWritingconversations with ChatGPT are requests to modify user inputs\nrather than to create something new. Education is a major use case for ChatGPT. 10.2% of all user\nmessages and 36% ofPractical Guidancemessages are requests forTutoring or Teaching. Another\nlarge share - 8.5% in total and 30% ofPractical Guidance- is general how-to advice on a variety\nof topics.Technical HelpincludesComputer Programming(4.2% of messages),Mathematical Calcu-\nlations(3%), andData Analysis(0.4%). Looking at the topic ofSelf-Expression, only 2.4% of all\nChatGPT messages are aboutRelationships and Personal Reflection(1.9%) orGames and Role Play\n(0.4%).\nWhile users can seek information and advice from traditional web search engines as well as from\nChatGPT, the ability to produce writing, software code, spreadsheets, and other digital products\ndistinguishes generative AI from existing technologies. ChatGPT is also more flexible than web\nsearch even for traditional applications likeSeeking InformationandPractical Guidance, because\nusers receive customized responses (e.g., tailored workout plans, new product ideas, ideas for fantasy\nfootball team names) that represent newly generated content or novel modification of user-provided\ncontent and follow-up requests.\nFigure 9:Breakdown of granular conversation topic shares within the coarse mapping defined in Table 3. The\nunderlying classifier prompt is available in Appendix A. Each bin reports a percentage of the total population.\nShares are calculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024\nthrough June 26, 2025. Observations are reweighted to reflect total message volumes on a given day. Sampling\ndetails available in Section 3.\n', '<2-hop>\n\n5.3 User Intent\nExisting studies of the economic impacts of generative AI focus almost exclusively on the potential\nfor AI to perform workplace tasks, either augmenting or automating human labor (e.g. Eloundou et\nal. (2025), Handa et al. (2025), Tomlinson et al. (2025)). However, generative AI is a highly flexible\n16\x0ctechnology that can be used in many different ways. In order to learn more about how people seek to\nuse generative AI at work and outside of work, we introduce a classifier that is designed to measure the\ntype of output the user hopes to receive. Specifically, we classify messages according to user intent,\ncoding up conversations according to a simple Asking,  Doing, or  Expressingrubric. The critical part\nof our classification prompt is as follows:\nIntent Prompt\nAskingAsking is seeking information or advice that will help the user be better\ninformed or make better decisions, either at work, at school, or in their\npersonal life. (e.g. “Who was president after Lincoln?”, “How do I create a\nbudget for this quarter?”, “What was the inflation rate last year?”,\n“What’s the difference between correlation and causation?”, “What should I\nlook for when choosing a health plan during open enrollment?”).\nDoingDoing messages request that ChatGPT perform tasks for the user. User is\ndrafting an email, writing code, etc. Classify messages as “doing” if they\ninclude requests for output that is created primarily by the model. (e.g.\n“Rewrite this email to make it more formal”, “Draft a report summarizing\nthe use cases of ChatGPT”, “Produce a project timeline with milestones\nand risks in a table”, “Extract companies, people, and dates from this text\ninto CSV.”, “Write a Dockerfile and a minimal docker-compose.yml for\nthis app.”)\nExpressingExpressing statements are neither asking for information, nor for the\nchatbot to perform a task.\nConceptually,Doingconversations are delivering output that can be plugged into a production\nprocess, whileAskingconversations support decision-making but do not produce output directly, and\nExpressingconversations have little or no economic content.\n Figure 10 shows the share of messages by each intent type in our sample. 49% of user messages\nareAsking, 40% areDoing, and 11% areExpressing. The figure also shows the relationship with\nour Topic classification: the two taxonomies are correlated but not redundant:Askingqueries are\nmore likely to bePractical GuidanceandSeeking Information.Doingqueries are disproportionately\nWritingandMultimedia.Expressingqueries are disproportionatelySelf-Expression. However, the\noverlap is imperfect. For example, within thePractical Guidancetopic, anAskingmessage might\nbe advice about how to recover from a sports injury given a user’s personal history, while aDoing\nmessage might request ChatGPT to produce a customized recovery and training plan that could be\nprinted or saved. WithinTechnical Help, anAskingmessage might request help understanding how\nto debug some code, while aDoingmessage might ask ChatGPT to write code for the user directly.\nFigure 11 presents shares ofAsking/Doing/Expressingjust for work-related messages.Doing\nconstitutes nearly 56% of work-related queries, compared to 35% forAskingand 9% forExpressing.\nNearly 35% of all work-related queries areDoingmessages related toWriting.DoingandAsking\ncomprise equal shares ofTechnical Helpqueries.\n17\x0cFigure 10:Breakdown of Conversation Topics by Asking/Doing/Expressing category, with topic columns\nsorted by relative share of ”Doing” messages. Prompts for these automated classifiers are available in Appendix\nA. For a detailed breakdown of conversation topic contents, see Table 3. Each bin reports a percentage of\nthe total population.', '<3-hop>\n\n5.5 Quality of Interactions\nWe additionally used automated classifiers to study the user’s apparent satisfaction with the chatbot’s\nresponse to their request. OurInteraction Qualityclassifier looks for an expression of satisfaction or\ndissatisfaction in the user’s subsequent message in the same conversation (if one exists), with three\npossible categories:Good,Bad, andUnknown. 23\nFigure 16 plots the overall growth of messages in these three buckets. In late 2024Goodinteractions\nwere about three times as common asBadinteractions, butGoodinteractions grew much more rapidly\nover the next nine months, and by July 2025 they were more than four times more common.\nFigure 16:Interaction quality shares, based on automated sentiment analysis of thenext responseprovided\nby the user. See Appendix B to understand how this classifier was validated. Values are averaged over a 28\nday lagging window. Shares are calculated from a sample of approximately 1.1 million sampled conversations\nfrom May 15, 2024 through June 26, 2025. Observations are reweighted to reflect total message volumes on a\ngiven day. Sampling details available in Section 3.\nDetails on the validation of this classifier, along with measurements of how it correlates with\nexplicit thumbs up/thumbs down annotations from users, are included in Appendix B.\nFigure 17 shows the ratio of good-to-bad messages by conversation topic and interaction type, as\nrated by Interaction Quality. Panel A shows thatSelf-Expressionis the highest rated topic, with a\ngood-to-bad ratio of more than seven, consistent with the growth in this category.Multimediaand\nTechnical Helphave the lowest good-to-bad ratios (1.7 and 2.7 respectively). Panel B shows that\nAskingmessages are substantially more likely to receive a good rating thanDoingorExpressing\nmessages.\n23For this classifier we do not disclose the prompt.\n23\x0cFigure 17:AverageGoodtoBadratio for user interactions by Conversation Topic (Panel A) and Ask-\ning/Doing/Expressing classification (Panel B). The prompts for each of these automated classifiers (with the\nexception of interaction quality) are available in Appendix A. Values represent the average ratio from May 15,\n2024 through June 26, 2025, where observations are reweighted to reflect total message volumes on a given\nday. Sampling details available in Section 3.\n24\x0c']","Users engage with ChatGPT primarily through conversation topics such as Writing, which includes sub-categories like Editing or Critiquing Provided Text and Argument or Summary Generation. Most of these conversations are requests to modify user inputs rather than to create new content. Additionally, user intent is classified into three categories: Asking, Doing, and Expressing. Asking messages, which seek information or advice, constitute 49% of user messages, while Doing messages, which request tasks to be performed by ChatGPT, make up 40%. This indicates that a significant portion of user interactions is focused on obtaining practical guidance and information, aligning with the prevalent conversation topics.",multi_hop_abstract_query_synthesizer
How does the quality of interactions with ChatGPT at work relate to its usage for decision-making and problem-solving?,"['<1-hop>\n\nOverall, the majority of ChatGPT usage\nat work appears to be focused on two broad functions: 1) obtaining, documenting, and interpreting\ninformation; and 2) making decisions, giving advice, solving problems, and thinking creatively.\n20\x0cFigure 14:GWA Shares of 1.1M ChatGPT Messages. Messages are classified as pertaining to one of 332\nO*NET IWAs, orAmbiguoususing the prompt provided in the Appendix. IWAs were then aggregated to\nGWAs using the O*NET Work Activities taxonomy. Message sample from May 15, 2024 through June 26,\n2025. We do not show the shares for the following GWAs as there were fewer than 100 users sending messages\nfor each category and group them intoSuppressed.\n21\x0cFigure 15:GWA Shares of approximately 366,000 Work-Classified Messages. Messages are classified as\npertaining to one of 332 O*NET IWAs orAmbiguous. IWAs were then aggregated to GWAs using the\nO*NET Work Activities taxonomy. Messages were also additionally classified as pertaining to work or non-\nwork. GWA shares are shown only for work-classified messages. Message sample from May 15, 2024 through\nJune 26, 2025. We do not show the shares for the following GWAs as there were fewer than 100 users sending\nmessages for each category and group them intoSuppressed. Prompts are provided in the Appendix.\n22\x0c', '<2-hop>\n\n5.5 Quality of Interactions\nWe additionally used automated classifiers to study the user’s apparent satisfaction with the chatbot’s\nresponse to their request. OurInteraction Qualityclassifier looks for an expression of satisfaction or\ndissatisfaction in the user’s subsequent message in the same conversation (if one exists), with three\npossible categories:Good,Bad, andUnknown. 23\nFigure 16 plots the overall growth of messages in these three buckets. In late 2024Goodinteractions\nwere about three times as common asBadinteractions, butGoodinteractions grew much more rapidly\nover the next nine months, and by July 2025 they were more than four times more common.\nFigure 16:Interaction quality shares, based on automated sentiment analysis of thenext responseprovided\nby the user. See Appendix B to understand how this classifier was validated. Values are averaged over a 28\nday lagging window. Shares are calculated from a sample of approximately 1.1 million sampled conversations\nfrom May 15, 2024 through June 26, 2025. Observations are reweighted to reflect total message volumes on a\ngiven day. Sampling details available in Section 3.\nDetails on the validation of this classifier, along with measurements of how it correlates with\nexplicit thumbs up/thumbs down annotations from users, are included in Appendix B.\nFigure 17 shows the ratio of good-to-bad messages by conversation topic and interaction type, as\nrated by Interaction Quality. Panel A shows thatSelf-Expressionis the highest rated topic, with a\ngood-to-bad ratio of more than seven, consistent with the growth in this category.Multimediaand\nTechnical Helphave the lowest good-to-bad ratios (1.7 and 2.7 respectively). Panel B shows that\nAskingmessages are substantially more likely to receive a good rating thanDoingorExpressing\nmessages.\n23For this classifier we do not disclose the prompt.\n23\x0cFigure 17:AverageGoodtoBadratio for user interactions by Conversation Topic (Panel A) and Ask-\ning/Doing/Expressing classification (Panel B). The prompts for each of these automated classifiers (with the\nexception of interaction quality) are available in Appendix A. Values represent the average ratio from May 15,\n2024 through June 26, 2025, where observations are reweighted to reflect total message volumes on a given\nday. Sampling details available in Section 3.\n24\x0c']","The quality of interactions with ChatGPT at work is closely related to its usage for decision-making and problem-solving. The majority of ChatGPT usage focuses on obtaining, documenting, and interpreting information, as well as making decisions and solving problems. Automated classifiers indicate that user satisfaction with ChatGPT's responses has improved over time, with 'Good' interactions becoming significantly more common than 'Bad' interactions. This suggests that as users engage with ChatGPT for decision-making and problem-solving, the quality of these interactions has a positive impact on their overall experience.",multi_hop_abstract_query_synthesizer
"What are the trends in ChatGPT message counts and how do they reflect demographic variation in usage, particularly regarding gender and age?","['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","The trends in ChatGPT message counts indicate a significant increase in overall usage, with non-work-related messages growing faster and now representing more than 70% of all consumer messages. In June 2025, for instance, there were 2,627 million total messages, with 1,911 million being non-work-related. Regarding demographic variation, the gender gap in ChatGPT usage has narrowed, with active users with typically masculine first names dropping from 80% shortly after release to 48% by June 2025. Additionally, nearly half of all messages were sent by users under the age of 26, suggesting a younger demographic is increasingly engaging with ChatGPT. These trends highlight the evolving landscape of ChatGPT usage across different demographics.",multi_hop_abstract_query_synthesizer
"What are the implications of artificial intelligence on jobs and the environment, and how do these concerns relate to the ongoing AI controversy?","[""<1-hop>\n\nWhat is AI, how does it work and why are some people concerned about it?\nArtificial intelligence (AI) has increasingly become part of everyday life over the past decade.\nIt is being used to personalise social media feeds, spot friends and family in smartphone photos and pave the way for medical breakthroughs.\nBut the rise of chatbots like OpenAI's ChatGPT and Meta AI has been accompanied by concern about the technology's environmental impact, ethical implications and data use.\n What is AI and what is it used for?\nAI allows computers to process large amounts of data, identify patterns and follow detailed instructions about what to do with that information.\nComputers cannot think, empathise or reason.\nHowever, scientists have developed systems that can perform tasks which usually require human intelligence, trying to replicate how people acquire and use knowledge.\nThis could be trying to anticipate what product an online shopper might buy, based on previous purchases, in order to recommend items.\nThe technology is also behind voice-controlled virtual assistants like Apple's Siri and Amazon's Alexa, and is being used to develop systems for self-driving cars.\nAI also helps social platforms like Facebook, TikTok and X decide what posts to show users. Streaming services Spotify and Deezer use AI to suggest music.\nThere are also a number of applications in medicine, as scientists use AI to help spot cancers, review X-ray results, speed up diagnoses and identify new treatments.\n What is generative AI, and how do apps like ChatGPT and Meta AI work?\nGenerative AI is used to create new content which can seem like it has been made by a human.\nIt does this by learning from vast quantities of existing data such as online text and images.\nChatGPT and Chinese rival DeepSeek's chatbot are popular generative AI tools that can be used to produce text, images, code and more material.\nGoogle's Gemini or Meta AI can similarly hold text conversations with users.\nApps like Midjourney or Veo 3 are dedicated to creating images or video from simple text prompts.\nGenerative AI can also be used to make high-quality music.\nSongs mimicking the style or sound of famous musicians have gone viral, sometimes leaving fans confused about their authenticity.\n"", '<2-hop>\n\nWhy is AI controversial?\nWhile acknowledging AI\'s potential, some experts are worried about the implications of its rapid growth.\nThe International Monetary Fund (IMF) has warned AI could affect nearly 40% of jobs, and worsen global financial inequality.\nProf Geoffrey Hinton, a computer scientist regarded as one of the ""godfathers"" of AI development, has expressed concern that powerful AI systems could even make humans extinct - although his fear was dismissed by his fellow ""AI godfather"", Yann LeCun.\nCritics also highlight the tech\'s potential to reproduce biased information, or discriminate against some social groups.\nThis is because much of the data used to train AI comes from public material, including social media posts or comments, which can reflect existing societal biases such as sexism or racism.\nAnd while AI programmes are growing more adept, they are still prone to errors - such as creating images of people with the wrong number of fingers or limbs.\nGenerative AI systems are known for their ability to ""hallucinate"" and assert falsehoods as fact, even sometimes inventing sources for the inaccurate information.\nApple halted a new AI feature in January after it incorrectly summarised news app notifications.\nThe BBC complained about the feature after Apple\'s AI falsely told readers that Luigi Mangione - the man accused of killing UnitedHealthcare CEO Brian Thompson - had shot himself.\nGoogle has also faced criticism over inaccurate answers produced by its AI search overviews.\nThis has added to concerns about the use of AI in schools and workplaces, where it is increasingly used to help summarise texts, write emails or essays and solve bugs in code.\nThere are worries about students using AI technology to ""cheat"" on assignments, or employees ""smuggling"" it into work.\nWriters, musicians and artists have also pushed back against the technology on ethical grounds, accusing AI developers of using their work to train systems without consent or compensation.\nThousands of creators - including Abba singer-songwriter Björn Ulvaeus, writers Ian Rankin and Joanne Harris and actress Julianne Moore - signed a statement in October 2024 calling AI a ""major, unjust threat"" to their livelihoods.\nHow does AI effect the environment?\nIt is not clear how much energy AI systems use, but some researchers estimate the industry as a whole could soon consume as much as the Netherlands.\nCreating the powerful computer chips needed to run AI programmes requires lots of power and water.\nDemand for generative AI services has also meant an increase in the number of data centres which power them.\nThese huge halls - housing thousands of racks of computer servers - use substantial amounts of energy and require large volumes of water to keep them cool.\nSome large tech companies have invested in ways to reduce or reuse the water needed, or have opted for alternative methods such as air-cooling.\nHowever, some experts and activists fear that AI will worsen water supply problems.\nThe BBC was told in February that government plans to make the UK a ""world leader"" in AI could put already stretched supplies of drinking water under strain.\nIn September 2024, Google said it would reconsider proposals for a data centre in Chile, which has struggled with drought.\n', '<3-hop>\n\nConclusion\nTo summarize, the world is on the cusp of revolutionizing many sectors through artificial intelligence and data analytics. There already are significant deployments in finance, national security, health care, criminal justice, transportation, and smart cities that have altered decisionmaking, business models, risk mitigation, and system performance. These developments are generating substantial economic and social benefits.\nThe world is on the cusp of revolutionizing many sectors through artificial intelligence, but the way AI systems are developed need to be better understood due to the major implications these technologies will have for society as a whole.\nYet the manner in which AI systems unfold has major implications for society as a whole. It matters how policy issues are addressed, ethical conflicts are reconciled, legal realities are resolved, and how much transparency is required in AI and data analytic solutions.74 Human choices about software development affect the way in which decisions are made and the manner in which they are integrated into organizational routines. Exactly how these processes are executed need to be better understood because they will have substantial impact on the general public soon, and for the foreseeable future. AI may well be a revolution in human affairs, and become the single most influential human innovation in history.\nNote: We appreciate the research assistance of Grace Gilberg, Jack Karsten, Hillary Schaub, and Kristjan Tomasson on this project.\nThe Brookings Institution is a nonprofit organization devoted to independent research and policy solutions. Its mission is to conduct high-quality, independent research and, based on that research, to provide innovative, practical recommendations for policymakers and the public. The conclusions and recommendations of any Brookings publication are solely those of its author(s), and do not reflect the views of the Institution, its management, or its other scholars.\nSupport for this publication was generously provided by Amazon. Brookings recognizes that the value it provides is in its absolute commitment to quality, independence, and impact. Activities supported by its donors reflect this commitment.\nJohn R. Allen is a member of the Board of Advisors of Amida Technology and on the Board of Directors of Spark Cognition. Both companies work in fields discussed in this piece.\n-\nFootnotes\n- Thomas Davenport, Jeff Loucks, and David Schatsky, “Bullish on the Business Value of Cognitive” (Deloitte, 2017), p. 3 (www2.deloitte.com/us/en/pages/deloitte-analytics/articles/cognitive-technology-adoption-survey.html).\n- Luke Dormehl, Thinking Machines: The Quest for Artificial Intelligence—and Where It’s Taking Us Next (New York: Penguin–TarcherPerigee, 2017).\n- Shubhendu and Vijay, “Applicability of Artificial Intelligence in Different Fields of Life.”\n- Ibid.\n- Andrew McAfee and Erik Brynjolfsson, Machine Platform Crowd: Harnessing Our Digital Future (New York: Norton, 2017).\n- Portions of this paper draw on Darrell M. West, The Future of Work: Robots, AI, and Automation, Brookings Institution Press, 2018.\n- PriceWaterhouseCoopers, “Sizing the Prize: What’s the Real Value of AI for Your Business and How Can You Capitalise?” 2017.\n- Dominic Barton, Jonathan Woetzel, Jeongmin Seong, and Qinzheng Tian, “Artificial Intelligence: Implications for China” (New York: McKinsey Global Institute, April 2017), p. 1.\n- Nathaniel Popper, “Stocks and Bots,” New York Times Magazine, February 28, 2016.\n- Ibid.\n- Ibid.\n- Michael Lewis, Flash Boys: A Wall Street Revolt (New York: Norton, 2015).\n- Cade Metz, “In Quantum Computing Race, Yale Professors Battle Tech Giants,” New York Times, November 14, 2017, p. B3.\n- Executive Office of the President, “Artificial Intelligence, Automation, and the Economy,” December 2016, pp. 27-28.\n- Christian Davenport, “Future Wars May Depend as Much on Algorithms as on Ammunition, Report Says,” Washington Post, December 3, 2017.\n- Ibid.\n- John R. Allen and Amir Husain, “On Hyperwar,” Naval Institute Proceedings, July 17, 2017, pp. 30-36.', '<4-hop>\n\nAI will reconfigure how society and the economy operate, and there needs to be “big picture” thinking on what this will mean for ethics, governance, and societal impact. People will need the ability to think broadly about many questions and integrate knowledge from a number of different areas.\nOne example of new ways to prepare students for a digital future is IBM’s Teacher Advisor program, utilizing Watson’s free online tools to help teachers bring the latest knowledge into the classroom. They enable instructors to develop new lesson plans in STEM and non-STEM fields, find relevant instructional videos, and help students get the most out of the classroom.58 As such, they are precursors of new educational environments that need to be created.\n Create a federal AI advisory committee\nFederal officials need to think about how they deal with artificial intelligence. As noted previously, there are many issues ranging from the need for improved data access to addressing issues of bias and discrimination. It is vital that these and other concerns be considered so we gain the full benefits of this emerging technology.\nIn order to move forward in this area, several members of Congress have introduced the “Future of Artificial Intelligence Act,” a bill designed to establish broad policy and legal principles for AI. It proposes the secretary of commerce create a federal advisory committee on the development and implementation of artificial intelligence. The legislation provides a mechanism for the federal government to get advice on ways to promote a “climate of investment and innovation to ensure the global competitiveness of the United States,” “optimize the development of artificial intelligence to address the potential growth, restructuring, or other changes in the United States workforce,” “support the unbiased development and application of artificial intelligence,” and “protect the privacy rights of individuals.”59\nAmong the specific questions the committee is asked to address include the following: competitiveness, workforce impact, education, ethics training, data sharing, international cooperation, accountability, machine learning bias, rural impact, government efficiency, investment climate, job impact, bias, and consumer impact. The committee is directed to submit a report to Congress and the administration 540 days after enactment regarding any legislative or administrative action needed on AI.\nThis legislation is a step in the right direction, although the field is moving so rapidly that we would recommend shortening the reporting timeline from 540 days to 180 days. Waiting nearly two years for a committee report will certainly result in missed opportunities and a lack of action on important issues. Given rapid advances in the field, having a much quicker turnaround time on the committee analysis would be quite beneficial.\n']","The implications of artificial intelligence (AI) on jobs are significant, with the International Monetary Fund (IMF) warning that AI could affect nearly 40% of jobs and exacerbate global financial inequality. This concern is echoed by experts like Prof Geoffrey Hinton, who has expressed fears that powerful AI systems could even threaten human existence. Additionally, the controversy surrounding AI includes worries about its potential to reproduce biased information and discriminate against certain social groups, as much of the data used to train AI reflects existing societal biases. On the environmental front, the energy consumption of AI systems is also a concern, with estimates suggesting that the industry could soon consume as much energy as the Netherlands. The creation of powerful computer chips for AI requires substantial power and water, and the demand for generative AI services has led to an increase in data centers, which consume large amounts of energy and water. These intertwined issues highlight the ethical and societal implications of AI advancements, making it a controversial topic in today's discourse.",multi_hop_abstract_query_synthesizer
