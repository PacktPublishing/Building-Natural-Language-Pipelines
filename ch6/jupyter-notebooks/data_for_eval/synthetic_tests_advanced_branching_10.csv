user_input,reference_contexts,reference,synthesizer_name
Wut is Meta AI and why do peeple have concerns about it?,"[""What is AI, how does it work and why are some people concerned about it?\nArtificial intelligence (AI) has increasingly become part of everyday life over the past decade.\nIt is being used to personalise social media feeds, spot friends and family in smartphone photos and pave the way for medical breakthroughs.\nBut the rise of chatbots like OpenAI's ChatGPT and Meta AI has been accompanied by concern about the technology's environmental impact, ethical implications and data use.\n What is AI and what is it used for?\nAI allows computers to process large amounts of data, identify patterns and follow detailed instructions about what to do with that information.\nComputers cannot think, empathise or reason.\nHowever, scientists have developed systems that can perform tasks which usually require human intelligence, trying to replicate how people acquire and use knowledge.\nThis could be trying to anticipate what product an online shopper might buy, based on previous purchases, in order to recommend items.\nThe technology is also behind voice-controlled virtual assistants like Apple's Siri and Amazon's Alexa, and is being used to develop systems for self-driving cars.\nAI also helps social platforms like Facebook, TikTok and X decide what posts to show users. Streaming services Spotify and Deezer use AI to suggest music.\nThere are also a number of applications in medicine, as scientists use AI to help spot cancers, review X-ray results, speed up diagnoses and identify new treatments.\n What is generative AI, and how do apps like ChatGPT and Meta AI work?\nGenerative AI is used to create new content which can seem like it has been made by a human.\nIt does this by learning from vast quantities of existing data such as online text and images.\nChatGPT and Chinese rival DeepSeek's chatbot are popular generative AI tools that can be used to produce text, images, code and more material.\nGoogle's Gemini or Meta AI can similarly hold text conversations with users.\nApps like Midjourney or Veo 3 are dedicated to creating images or video from simple text prompts.\nGenerative AI can also be used to make high-quality music.\nSongs mimicking the style or sound of famous musicians have gone viral, sometimes leaving fans confused about their authenticity.\n""]","Meta AI is a generative AI tool that can hold text conversations with users, similar to other popular generative AI tools like ChatGPT. However, the rise of Meta AI has been accompanied by concerns regarding the technology's environmental impact, ethical implications, and data use.",single_hop_specific_query_synthesizer
What are the implications of AI technology on UnitedHealthcare and its CEO Brian Thompson?,"['Why is AI controversial?\nWhile acknowledging AI\'s potential, some experts are worried about the implications of its rapid growth.\nThe International Monetary Fund (IMF) has warned AI could affect nearly 40% of jobs, and worsen global financial inequality.\nProf Geoffrey Hinton, a computer scientist regarded as one of the ""godfathers"" of AI development, has expressed concern that powerful AI systems could even make humans extinct - although his fear was dismissed by his fellow ""AI godfather"", Yann LeCun.\nCritics also highlight the tech\'s potential to reproduce biased information, or discriminate against some social groups.\nThis is because much of the data used to train AI comes from public material, including social media posts or comments, which can reflect existing societal biases such as sexism or racism.\nAnd while AI programmes are growing more adept, they are still prone to errors - such as creating images of people with the wrong number of fingers or limbs.\nGenerative AI systems are known for their ability to ""hallucinate"" and assert falsehoods as fact, even sometimes inventing sources for the inaccurate information.\nApple halted a new AI feature in January after it incorrectly summarised news app notifications.\nThe BBC complained about the feature after Apple\'s AI falsely told readers that Luigi Mangione - the man accused of killing UnitedHealthcare CEO Brian Thompson - had shot himself.\nGoogle has also faced criticism over inaccurate answers produced by its AI search overviews.\nThis has added to concerns about the use of AI in schools and workplaces, where it is increasingly used to help summarise texts, write emails or essays and solve bugs in code.\nThere are worries about students using AI technology to ""cheat"" on assignments, or employees ""smuggling"" it into work.\nWriters, musicians and artists have also pushed back against the technology on ethical grounds, accusing AI developers of using their work to train systems without consent or compensation.\nThousands of creators - including Abba singer-songwriter Björn Ulvaeus, writers Ian Rankin and Joanne Harris and actress Julianne Moore - signed a statement in October 2024 calling AI a ""major, unjust threat"" to their livelihoods.\nHow does AI effect the environment?\nIt is not clear how much energy AI systems use, but some researchers estimate the industry as a whole could soon consume as much as the Netherlands.\nCreating the powerful computer chips needed to run AI programmes requires lots of power and water.\nDemand for generative AI services has also meant an increase in the number of data centres which power them.\nThese huge halls - housing thousands of racks of computer servers - use substantial amounts of energy and require large volumes of water to keep them cool.\nSome large tech companies have invested in ways to reduce or reuse the water needed, or have opted for alternative methods such as air-cooling.\nHowever, some experts and activists fear that AI will worsen water supply problems.\nThe BBC was told in February that government plans to make the UK a ""world leader"" in AI could put already stretched supplies of drinking water under strain.\nIn September 2024, Google said it would reconsider proposals for a data centre in Chile, which has struggled with drought.\n']","The controversy surrounding AI technology includes concerns about its potential to produce inaccurate information, as highlighted by an incident where Apple's AI falsely reported that Luigi Mangione had shot himself, which was related to the case of UnitedHealthcare CEO Brian Thompson's death. This incident underscores the risks associated with AI's ability to generate misleading narratives, raising ethical questions about its use in sensitive contexts.",single_hop_specific_query_synthesizer
What does the Artificial Intelligence Act regulate?,"['Are there laws governing AI?\nSome governments have already introduced rules governing how AI operates.\nThe EU\'s Artificial Intelligence Act places controls on high risk systems used in areas such as education, healthcare, law enforcement or elections. It bans some AI use altogether.\nGenerative AI developers in China are required to safeguard citizens\' data, and promote transparency and accuracy of information. But they are also bound by the country\'s strict censorship laws.\nIn the UK, Prime Minister Sir Keir Starmer has said the government ""will test and understand AI before we regulate it"".\nBoth the UK and US have AI Safety Institutes that aim to identify risks and evaluate advanced AI models.\nIn 2024 the two countries signed an agreement to collaborate on developing ""robust"" AI testing methods.\nHowever, in February 2025, neither country signed an international AI declaration which pledged an open, inclusive and sustainable approach to the technology.\nSeveral countries including the UK are also clamping down on use of AI systems to create deepfake nude imagery and child sexual abuse material.\nSign up for our Tech Decoded newsletter to follow the world\'s top tech stories and trends. Outside the UK? Sign up here.']","The EU's Artificial Intelligence Act places controls on high risk systems used in areas such as education, healthcare, law enforcement, or elections, and it bans some AI use altogether.",single_hop_specific_query_synthesizer
"What steps are federal officials considering to address the implications of artificial intelligence on national security, particularly in the context of creating a federal AI advisory committee?",['<1-hop>\n\nCreate a federal AI advisory committee\nFederal officials need to think about how they deal with artificial intelligence.'],Federal officials are considering the creation of a federal AI advisory committee as a step to address the implications of artificial intelligence on national security. This committee would help guide how officials deal with the challenges posed by AI advancements in modern conflict and cybersecurity.,multi_hop_specific_query_synthesizer
"What are the trends in user satisfaction regarding Technical Help interactions with ChatGPT, and how do they compare to other conversation topics?","['<1-hop>\n\n5.5 Quality of Interactions\nWe additionally used automated classifiers to study the user’s apparent satisfaction with the chatbot’s\nresponse to their request. OurInteraction Qualityclassifier looks for an expression of satisfaction or\ndissatisfaction in the user’s subsequent message in the same conversation (if one exists), with three\npossible categories:Good,Bad, andUnknown. 23\nFigure 16 plots the overall growth of messages in these three buckets. In late 2024Goodinteractions\nwere about three times as common asBadinteractions, butGoodinteractions grew much more rapidly\nover the next nine months, and by July 2025 they were more than four times more common.\nFigure 16:Interaction quality shares, based on automated sentiment analysis of thenext responseprovided\nby the user. See Appendix B to understand how this classifier was validated. Values are averaged over a 28\nday lagging window. Shares are calculated from a sample of approximately 1.1 million sampled conversations\nfrom May 15, 2024 through June 26, 2025. Observations are reweighted to reflect total message volumes on a\ngiven day. Sampling details available in Section 3.\nDetails on the validation of this classifier, along with measurements of how it correlates with\nexplicit thumbs up/thumbs down annotations from users, are included in Appendix B.\nFigure 17 shows the ratio of good-to-bad messages by conversation topic and interaction type, as\nrated by Interaction Quality. Panel A shows thatSelf-Expressionis the highest rated topic, with a\ngood-to-bad ratio of more than seven, consistent with the growth in this category.Multimediaand\nTechnical Helphave the lowest good-to-bad ratios (1.7 and 2.7 respectively). Panel B shows that\nAskingmessages are substantially more likely to receive a good rating thanDoingorExpressing\nmessages.\n23For this classifier we do not disclose the prompt.\n23\x0cFigure 17:AverageGoodtoBadratio for user interactions by Conversation Topic (Panel A) and Ask-\ning/Doing/Expressing classification (Panel B). The prompts for each of these automated classifiers (with the\nexception of interaction quality) are available in Appendix A. Values represent the average ratio from May 15,\n2024 through June 26, 2025, where observations are reweighted to reflect total message volumes on a given\nday. Sampling details available in Section 3.\n24\x0c', '<2-hop>\n\nWhat are the topics of ChatGPT conversations?\nWe modify a classifier used by internal research teams at OpenAI that identifies which capabilities\nthe user is requesting from ChatGPT. The classifier itself directly assigns the user’s query into one\nof 24 categories. We aggregate these 24 categories into seven topical groupings (the full conversation-\ncategorization prompt is given in Appendix A):\nTopic Conversation Category\nWriting Edit or Critique Provided Text\nPersonal Writing or Communication\nTranslation\nArgument or Summary Generation\nWrite Fiction\nPractical Guidance How-To Advice\nTutoring or Teaching\nCreative Ideation\nHealth, Fitness, Beauty, or Self-Care\nTechnical Help Mathematical Calculation\nData Analysis\n13\x0cTopic Conversation Category\nComputer Programming\nMultimedia Create an Image\nAnalyze an Image\nGenerate or Retrieve Other Media\nSeeking Information Specific Info\nPurchasable Products\nCooking and Recipes\nSelf-Expression Greetings and Chitchat\nRelationships and Personal Reflection\nGames and Role Play\nOther/Unknown Asking About the Model\nOther\nUnclear\nTable 3:Coarse Conversation Topics and Underlying Classifier Categories\nFigure 7 shows the composition of user messages over time. The three most common Conversation\nTopics arePractical Guidance,Seeking Information, andWriting, collectively accounting for about\n77% of all ChatGPT conversations.Practical Guidancehas remained constant at roughly 29% of\noverall usage.Writinghas declined from 36% of all usage in July 2024 to 24% a year later.Seeking\nInformationhas grown from 14% to 24% of all usage over the same period. The share ofTechnical\nHelpdeclined from 12% from all usage in July 2024 to around 5% a year later – this may be because\nthe use of LLMs for programming has grown very rapidly through the API (outside of ChatGPT),\nfor AI assistance in code editing and for autonomous programming agents (e.g. Codex).Multimedia\ngrew from 2% to just over 7%, with a large spike in April 2025 after ChatGPT released new image-\ngeneration capabilities: the spike attenuated but the elevated level has persisted.\nFigure 8 shows Conversation Topics, restricting the sample to only work-related messages. About\n40% of all work-related messages in July 2025 areWriting, by far the most common Conversation\nTopic.Practical Guidanceis the second most common use case at 24%.Technical Helphas declined\nfrom 18% of all work-related messages in July 2024 to just over 10% in July 2025.\nFigure 9 disaggregates four of the seven Conversation Topics into smaller groups and sums up\nmessages of each type over a one-year period. For example, the five sub-categories withinWriting\nare (in order of frequency)Editing or Critiquing Provided Text,Personal Writing or Communication,\nTranslation,Argument or Summary Generation, andWriting Fiction. Three of those five categories\n(Editing or Critiquing Provided Text,Translation, andArgument or Summary Generation) are re-\nquests to modify text that has been provided to ChatGPT by the user, whereas the other two are\nrequests to produce novel text. The former constitute two thirds of allWritingconversations, which\n14\x0cFigure 7:Share of consumer ChatGPT messages broken down by high level conversation topic, according\nto the mapping in Table 3. Values are averaged over a 28 day lagging window.']","User satisfaction regarding Technical Help interactions with ChatGPT has shown a good-to-bad ratio of 1.7, indicating that while there are more good interactions than bad, the satisfaction level is lower compared to other topics. In contrast, Self-Expression has the highest good-to-bad ratio of more than seven, while Practical Guidance has a ratio of 2.7. This suggests that users are generally more satisfied with Self-Expression interactions than with Technical Help.",multi_hop_specific_query_synthesizer
How does the quality of interactions in Technical Help compare to other conversation topics based on user satisfaction?,"['<1-hop>\n\n5.5 Quality of Interactions\nWe additionally used automated classifiers to study the user’s apparent satisfaction with the chatbot’s\nresponse to their request. OurInteraction Qualityclassifier looks for an expression of satisfaction or\ndissatisfaction in the user’s subsequent message in the same conversation (if one exists), with three\npossible categories:Good,Bad, andUnknown. 23\nFigure 16 plots the overall growth of messages in these three buckets. In late 2024Goodinteractions\nwere about three times as common asBadinteractions, butGoodinteractions grew much more rapidly\nover the next nine months, and by July 2025 they were more than four times more common.\nFigure 16:Interaction quality shares, based on automated sentiment analysis of thenext responseprovided\nby the user. See Appendix B to understand how this classifier was validated. Values are averaged over a 28\nday lagging window. Shares are calculated from a sample of approximately 1.1 million sampled conversations\nfrom May 15, 2024 through June 26, 2025. Observations are reweighted to reflect total message volumes on a\ngiven day. Sampling details available in Section 3.\nDetails on the validation of this classifier, along with measurements of how it correlates with\nexplicit thumbs up/thumbs down annotations from users, are included in Appendix B.\nFigure 17 shows the ratio of good-to-bad messages by conversation topic and interaction type, as\nrated by Interaction Quality. Panel A shows thatSelf-Expressionis the highest rated topic, with a\ngood-to-bad ratio of more than seven, consistent with the growth in this category.Multimediaand\nTechnical Helphave the lowest good-to-bad ratios (1.7 and 2.7 respectively). Panel B shows that\nAskingmessages are substantially more likely to receive a good rating thanDoingorExpressing\nmessages.\n23For this classifier we do not disclose the prompt.\n23\x0cFigure 17:AverageGoodtoBadratio for user interactions by Conversation Topic (Panel A) and Ask-\ning/Doing/Expressing classification (Panel B). The prompts for each of these automated classifiers (with the\nexception of interaction quality) are available in Appendix A. Values represent the average ratio from May 15,\n2024 through June 26, 2025, where observations are reweighted to reflect total message volumes on a given\nday. Sampling details available in Section 3.\n24\x0c', '<2-hop>\n\n37% of messages are work-related for users with less than a bachelor’s degree, compared to 46% for users with exactly a bachelor’s degree and 48% for those with some graduate education. Those differences are cut roughly in half after adjusting for other characteristics, but they are still statistically significant at the less than 1 percent level. Educated users are more likely to send work-related messages. Panel B explores variation by education in user intent.Askingconstitutes about 49% of messages for users with less than a bachelor’s degree, with little variation for more educated users. After regression adjustment, we find that users with a graduate degree are about two percentage points more likely to use ChatGPT forAskingmessages, a difference that is statistically significant at the 5% level. Prior to regression adjustment, the frequency ofDoingmessages is increasing in education. However, this pattern reverses after adjusting for other characteristics such as occupation. Users with a graduate degree are about 1.6 percentage points less likely to sendDoingmessages than users with less than a bachelor’s degree, and the difference is statistically significant at the 10% level. Panel C studies variation by education in the frequency of four different conversation topics – Practical Guidance,Seeking Information,Technical Help, andWriting. We find only modest differ- ences by education across most of these categories. The one exception is that the share of messages related toWritingis increasing in relation to education. 28 Panel A.Work Related Panel B1.Asking. Panel B2.Doing. Panel B3.Expressing. Figure 22:(continued on next page) 29 Panel C1.Writing. Panel C2.Technical Help. Panel C3.Seeking Information. Panel C4.Practical Guidance. Figure 22:Variation in ChatGPT usage by education. Each plot shows unadjusted vs. regression-adjusted estimates, with 95% confidence intervals. We regress each message share on education and occupation, control- ling for the following covariates: age, whether the name was typically masculine or feminine, seniority within role, company size, and industry. (To guarantee user privacy, we coarsen all covariates to broad categories and programmatically enforce that each group has at least 100 members prior to running the regression) We add the coefficients on each education and occupation category to the unadjusted value for the reference category and compute 95% confidence intervals using the standard errors from the regression coefficients. The sample for this regression is the approximately 40,000 users of the original 130,000 sample whose publicly available occupation was not blank or consisted of strictly special characters (as determined by a classification script). Shares for each user are calculated by randomly sampling up to six conversations attributed to the user from May 2024 through July 2025. 30 6.5 Variation by Occupation Figure 23 presents variation in ChatGPT usage by user occupation. Due to privacy-preserving aggre- gation limits, we report results for the following broad occupation categories – (1) all nonprofessional occupations, including administrative, clerical, service, and blue-collar occupations; (2) computer- related occupations; (3) engineering and science occupations; (4) management and business occupa- tions; and (5) all other professional occupations, including law, education, and health care. 26 As above, the left-hand side of the figure shows unadjusted comparisons and the right-hand side presents the coefficients on each occupation category from a regression of message shares on age, whether the name was typically masculine or feminine, education, occupation categories, job seniority, firm size, and industry. Users in highly paid professional and technical occupations are more likely to use ChatGPT for work.27 Panel A shows that the unadjusted work shares are 57% for computer-related occupations; 50% for management and business; 48% for engineering and science; 44% for other professional oc- cupations; and only 40% for all non-professional occupations. Regression adjustment moves these figures around slightly, but the gaps by occupation remain highly statistically significant. Users in highly-paid professional occupations are more likely to send work-related messages. Because work usage is so different by occupation, we restrict the sample only to work-related messages in Panels B and C. Panel B presents the share of work-related messages that areAsking messages, by occupation. We find that users in highly paid professional occupations are more likely to use ChatGPT forAskingrather thanDoing. 28 This is especially true in scientific and technical occupations. 47% of the work-related messages sent by users employed in computer-related occupa-']","The quality of interactions in Technical Help has a lower good-to-bad ratio of 2.7 compared to other conversation topics. For instance, Self-Expression has the highest good-to-bad ratio of more than seven, indicating that users express significantly more satisfaction in that category. In contrast, Technical Help and Multimedia topics have the lowest ratios, suggesting that users are less satisfied with the responses they receive in these areas.",multi_hop_specific_query_synthesizer
"What are the ethical implications and environmental concerns associated with the rapid growth of artificial intelligence (AI), as highlighted by experts?","[""<1-hop>\n\nWhat is AI, how does it work and why are some people concerned about it?\nArtificial intelligence (AI) has increasingly become part of everyday life over the past decade.\nIt is being used to personalise social media feeds, spot friends and family in smartphone photos and pave the way for medical breakthroughs.\nBut the rise of chatbots like OpenAI's ChatGPT and Meta AI has been accompanied by concern about the technology's environmental impact, ethical implications and data use.\n What is AI and what is it used for?\nAI allows computers to process large amounts of data, identify patterns and follow detailed instructions about what to do with that information.\nComputers cannot think, empathise or reason.\nHowever, scientists have developed systems that can perform tasks which usually require human intelligence, trying to replicate how people acquire and use knowledge.\nThis could be trying to anticipate what product an online shopper might buy, based on previous purchases, in order to recommend items.\nThe technology is also behind voice-controlled virtual assistants like Apple's Siri and Amazon's Alexa, and is being used to develop systems for self-driving cars.\nAI also helps social platforms like Facebook, TikTok and X decide what posts to show users. Streaming services Spotify and Deezer use AI to suggest music.\nThere are also a number of applications in medicine, as scientists use AI to help spot cancers, review X-ray results, speed up diagnoses and identify new treatments.\n What is generative AI, and how do apps like ChatGPT and Meta AI work?\nGenerative AI is used to create new content which can seem like it has been made by a human.\nIt does this by learning from vast quantities of existing data such as online text and images.\nChatGPT and Chinese rival DeepSeek's chatbot are popular generative AI tools that can be used to produce text, images, code and more material.\nGoogle's Gemini or Meta AI can similarly hold text conversations with users.\nApps like Midjourney or Veo 3 are dedicated to creating images or video from simple text prompts.\nGenerative AI can also be used to make high-quality music.\nSongs mimicking the style or sound of famous musicians have gone viral, sometimes leaving fans confused about their authenticity.\n"", '<2-hop>\n\nWhy is AI controversial?\nWhile acknowledging AI\'s potential, some experts are worried about the implications of its rapid growth.\nThe International Monetary Fund (IMF) has warned AI could affect nearly 40% of jobs, and worsen global financial inequality.\nProf Geoffrey Hinton, a computer scientist regarded as one of the ""godfathers"" of AI development, has expressed concern that powerful AI systems could even make humans extinct - although his fear was dismissed by his fellow ""AI godfather"", Yann LeCun.\nCritics also highlight the tech\'s potential to reproduce biased information, or discriminate against some social groups.\nThis is because much of the data used to train AI comes from public material, including social media posts or comments, which can reflect existing societal biases such as sexism or racism.\nAnd while AI programmes are growing more adept, they are still prone to errors - such as creating images of people with the wrong number of fingers or limbs.\nGenerative AI systems are known for their ability to ""hallucinate"" and assert falsehoods as fact, even sometimes inventing sources for the inaccurate information.\nApple halted a new AI feature in January after it incorrectly summarised news app notifications.\nThe BBC complained about the feature after Apple\'s AI falsely told readers that Luigi Mangione - the man accused of killing UnitedHealthcare CEO Brian Thompson - had shot himself.\nGoogle has also faced criticism over inaccurate answers produced by its AI search overviews.\nThis has added to concerns about the use of AI in schools and workplaces, where it is increasingly used to help summarise texts, write emails or essays and solve bugs in code.\nThere are worries about students using AI technology to ""cheat"" on assignments, or employees ""smuggling"" it into work.\nWriters, musicians and artists have also pushed back against the technology on ethical grounds, accusing AI developers of using their work to train systems without consent or compensation.\nThousands of creators - including Abba singer-songwriter Björn Ulvaeus, writers Ian Rankin and Joanne Harris and actress Julianne Moore - signed a statement in October 2024 calling AI a ""major, unjust threat"" to their livelihoods.\nHow does AI effect the environment?\nIt is not clear how much energy AI systems use, but some researchers estimate the industry as a whole could soon consume as much as the Netherlands.\nCreating the powerful computer chips needed to run AI programmes requires lots of power and water.\nDemand for generative AI services has also meant an increase in the number of data centres which power them.\nThese huge halls - housing thousands of racks of computer servers - use substantial amounts of energy and require large volumes of water to keep them cool.\nSome large tech companies have invested in ways to reduce or reuse the water needed, or have opted for alternative methods such as air-cooling.\nHowever, some experts and activists fear that AI will worsen water supply problems.\nThe BBC was told in February that government plans to make the UK a ""world leader"" in AI could put already stretched supplies of drinking water under strain.\nIn September 2024, Google said it would reconsider proposals for a data centre in Chile, which has struggled with drought.\n']","The rapid growth of artificial intelligence (AI) raises several ethical implications and environmental concerns. Experts have warned that AI could affect nearly 40% of jobs and worsen global financial inequality. Concerns have also been raised about AI's potential to reproduce biased information and discriminate against social groups, as much of the data used to train AI reflects existing societal biases such as sexism or racism. Additionally, generative AI systems are known for their tendency to 'hallucinate' and assert falsehoods as fact, leading to inaccuracies in information. On the environmental front, the energy consumption of AI systems is a significant concern, with estimates suggesting that the industry could soon consume as much energy as the Netherlands. The creation of powerful computer chips for AI requires substantial power and water, and the demand for generative AI services has led to an increase in data centers, which consume large amounts of energy and water. This has raised fears about the impact of AI on water supply issues, particularly in regions already facing drought.",multi_hop_abstract_query_synthesizer
"How do the user message classifications relate to the growth trends observed in ChatGPT user cohorts, particularly regarding messages related to paid work versus non-work-related messages?","['<1-hop>\n\nThe yellow line represents the first cohort of ChatGPT users: their usage declined somewhat over\n2023, but started growing again in late 2024 and is now higher than it has ever been. The pink line\nrepresents messages from users who signed up in Q3 of 2023 or earlier, and so thedifferencebetween\n20Note that we expect our counts of distinct accounts to somewhat exceed distinct people when one person has two\naccounts (or, for logged-out users, one person using two devices). For logged-in users, the count is based on distinct\nlogin credentials (email addresses), and one person may have multiple accounts. For logged-out users, the count is based\non distinct browser cookies; this would double-count people if someone returns to ChatGPT after clearing their cookies,\nor if they access ChatGPT with two different devices in the same week.\n10\x0cFigure 4:Daily message volumes from ChatGPT consumer plans (Free, Plus, Pro), split by sign-up date of\nthe requesting user. Reported values are moving averages of the past 90 days. Y-axis is an index normalized\nto the reported value for ”All Cohorts” at the end of Q1 2024 (April 1, 2024).\nthe yellow and pink lines represents the messages sent by users who signed up in Q2 and Q3 of 2023.\nThere has been dramatic growth in message volume both by new cohorts of users, and from growth\nin existing cohorts.\nFigure 5 normalizes each cohort, plotting daily messages per weekly active user. Each line rep-\nresents an individual cohort (instead of a cumulative cohort, as in Figure 4). The figure shows that\nearlier sign-ups have consistently had higher usage, but that usage has also consistently grown within\nevery cohort, which we interpret as due to both (1) improvements in the capabilities of the models,\nand (2) users slowly discovering new uses for existing capabilities.\n5  How ChatGPT is Used\nWe next report on thecontentof ChatGPT conversations using a variety of different taxonomies. For\neach taxonomy we describe a “prompt” which defines a set of categories, and then apply an LLM\nto map each message to a category. Our categories often apply to the user’sintention, rather than\nthe text of the conversation, and as such we never directly observe the ground truth. Nevertheless\nthe classifier results can be interpreted as the best-guess inferences that a human would make: the\nguesses from the LLM correlate highly with human guesses from the same prompt, and we get similar\nqualitative results when the prompt includes a third category for “uncertain.”\n11\x0cFigure 5:Daily messages sent per weekly active user, split by sign-up cohort. Sample only considers users of\nChatGPT consumer plans (Free, Plus, Pro). Reported values are moving averages of the past 90 days and are\nreported starting 90 days after the cohort is fully formed. Y-axis is an index normalized to the first reported\nvalue for the Q1 2023 cohort.\n5.1 ', '<2-hop>\n\nWhat share of ChatGPT queries are related to paid work?\nWe label each user message in our dataset based on whether it appears to be related to work, using\nan LLM classifier. The critical part of the prompt is as follows: 21\nDoes the last user message of this conversation transcript seem likely to be related to doing\nsome work/employment? Answer with one of the following:\n(1) likely part of work (e.g., “rewrite this HR complaint”)\n(0) likely not part of work (e.g., “does ice reduce pimples?”)\nTable 1 shows that both types of queries grew rapidly between June 2024 and June 2025, however\nnon-work-related messages grew faster: 53% of messages were not related to work in June 2024, which\nclimbed to 73% by June 2025.\nFigure 6 plots the share of non-work messages decomposed by cumulative sign-up cohorts. Succes-\nsive cohorts have had a higher share of non-work messages, but also within each cohort their non-work\nuse has increased. Comparing the share among all users (black line) to the share among the earliest\ncohort of users (yellow line), we can see that they track very closely.\n21See Appendix A for the full prompt, see Appendix B for validation.\n12\x0cFigure 6:The solid black line represents the probability that a messages on a given day is not related to\nwork, as determined by an automated classifier. Values are averaged over a 28-day lagging window. The\ndotted orange line shows the same calculation, but conditioned on messages being from users who first used\nChatGPT during or before Q2 of 2024. The remaining lines are defined similarly for successive quarters, with\ncoloring cooling for more recent cohorts. Counts are calculated from a sample of approximately 1.1 million\nsampled conversations from May 15, 2024 through June 26, 2025. Observations are reweighted to reflect total\nmessage volumes on a given day. Sampling details available in Section 3.\n5.2 ']","The user message classifications indicate that both work-related and non-work-related messages grew rapidly between June 2024 and June 2025. However, non-work-related messages experienced a faster growth rate, increasing from 53% of messages not related to work in June 2024 to 73% by June 2025. This trend is reflected in the user cohorts, where the earlier cohorts consistently showed higher usage, but all cohorts demonstrated growth in non-work-related messages. The yellow line in the user cohort data represents the first cohort of ChatGPT users, whose usage declined somewhat in 2023 but began to grow again in late 2024, indicating that as users discover new uses for existing capabilities, the classification of messages also evolves, highlighting the dynamic nature of user engagement with ChatGPT.",multi_hop_abstract_query_synthesizer
"What trends can be observed in the user message classification of ChatGPT cohorts, particularly regarding the share of messages related to paid work versus non-work-related messages?","['<1-hop>\n\nThe yellow line represents the first cohort of ChatGPT users: their usage declined somewhat over\n2023, but started growing again in late 2024 and is now higher than it has ever been. The pink line\nrepresents messages from users who signed up in Q3 of 2023 or earlier, and so thedifferencebetween\n20Note that we expect our counts of distinct accounts to somewhat exceed distinct people when one person has two\naccounts (or, for logged-out users, one person using two devices). For logged-in users, the count is based on distinct\nlogin credentials (email addresses), and one person may have multiple accounts. For logged-out users, the count is based\non distinct browser cookies; this would double-count people if someone returns to ChatGPT after clearing their cookies,\nor if they access ChatGPT with two different devices in the same week.\n10\x0cFigure 4:Daily message volumes from ChatGPT consumer plans (Free, Plus, Pro), split by sign-up date of\nthe requesting user. Reported values are moving averages of the past 90 days. Y-axis is an index normalized\nto the reported value for ”All Cohorts” at the end of Q1 2024 (April 1, 2024).\nthe yellow and pink lines represents the messages sent by users who signed up in Q2 and Q3 of 2023.\nThere has been dramatic growth in message volume both by new cohorts of users, and from growth\nin existing cohorts.\nFigure 5 normalizes each cohort, plotting daily messages per weekly active user. Each line rep-\nresents an individual cohort (instead of a cumulative cohort, as in Figure 4). The figure shows that\nearlier sign-ups have consistently had higher usage, but that usage has also consistently grown within\nevery cohort, which we interpret as due to both (1) improvements in the capabilities of the models,\nand (2) users slowly discovering new uses for existing capabilities.\n5  How ChatGPT is Used\nWe next report on thecontentof ChatGPT conversations using a variety of different taxonomies. For\neach taxonomy we describe a “prompt” which defines a set of categories, and then apply an LLM\nto map each message to a category. Our categories often apply to the user’sintention, rather than\nthe text of the conversation, and as such we never directly observe the ground truth. Nevertheless\nthe classifier results can be interpreted as the best-guess inferences that a human would make: the\nguesses from the LLM correlate highly with human guesses from the same prompt, and we get similar\nqualitative results when the prompt includes a third category for “uncertain.”\n11\x0cFigure 5:Daily messages sent per weekly active user, split by sign-up cohort. Sample only considers users of\nChatGPT consumer plans (Free, Plus, Pro). Reported values are moving averages of the past 90 days and are\nreported starting 90 days after the cohort is fully formed. Y-axis is an index normalized to the first reported\nvalue for the Q1 2023 cohort.\n5.1 ', '<2-hop>\n\nWhat share of ChatGPT queries are related to paid work?\nWe label each user message in our dataset based on whether it appears to be related to work, using\nan LLM classifier. The critical part of the prompt is as follows: 21\nDoes the last user message of this conversation transcript seem likely to be related to doing\nsome work/employment? Answer with one of the following:\n(1) likely part of work (e.g., “rewrite this HR complaint”)\n(0) likely not part of work (e.g., “does ice reduce pimples?”)\nTable 1 shows that both types of queries grew rapidly between June 2024 and June 2025, however\nnon-work-related messages grew faster: 53% of messages were not related to work in June 2024, which\nclimbed to 73% by June 2025.\nFigure 6 plots the share of non-work messages decomposed by cumulative sign-up cohorts. Succes-\nsive cohorts have had a higher share of non-work messages, but also within each cohort their non-work\nuse has increased. Comparing the share among all users (black line) to the share among the earliest\ncohort of users (yellow line), we can see that they track very closely.\n21See Appendix A for the full prompt, see Appendix B for validation.\n12\x0cFigure 6:The solid black line represents the probability that a messages on a given day is not related to\nwork, as determined by an automated classifier. Values are averaged over a 28-day lagging window. The\ndotted orange line shows the same calculation, but conditioned on messages being from users who first used\nChatGPT during or before Q2 of 2024. The remaining lines are defined similarly for successive quarters, with\ncoloring cooling for more recent cohorts. Counts are calculated from a sample of approximately 1.1 million\nsampled conversations from May 15, 2024 through June 26, 2025. Observations are reweighted to reflect total\nmessage volumes on a given day. Sampling details available in Section 3.\n5.2 ']","The trends observed in the user message classification of ChatGPT cohorts indicate that both work-related and non-work-related messages grew rapidly between June 2024 and June 2025. However, non-work-related messages grew at a faster rate. Specifically, 53% of messages were not related to work in June 2024, which increased to 73% by June 2025. Additionally, the analysis shows that successive cohorts of users have a higher share of non-work messages, and within each cohort, the non-work usage has also increased over time.",multi_hop_abstract_query_synthesizer
"In what ways do the challenges of data access problems impact the implementation of smart city initiatives, particularly in relation to ethical considerations and the promotion of responsible AI practices?","['<1-hop>\n\nSmart cities\nMetropolitan governments are using AI to improve urban service delivery. For example, according to Kevin Desouza, Rashmi Krishnamurthy, and Gregory Dawson:\nThe Cincinnati Fire Department is using data analytics to optimize medical emergency responses. The new analytics system recommends to the dispatcher an appropriate response to a medical emergency call—whether a patient can be treated on-site or needs to be taken to the hospital—by taking into account several factors, such as the type of call, location, weather, and similar calls.34\nSince it fields 80,000 requests each year, Cincinnati officials are deploying this technology to prioritize responses and determine the best ways to handle emergencies. They see AI as a way to deal with large volumes of data and figure out efficient ways of responding to public requests. Rather than address service issues in an ad hoc manner, authorities are trying to be proactive in how they provide urban services.\nCincinnati is not alone. A number of metropolitan areas are adopting smart city applications that use AI to improve service delivery, environmental planning, resource management, energy utilization, and crime prevention, among other things. For its smart cities index, the magazine Fast Company ranked American locales and found Seattle, Boston, San Francisco, Washington, D.C., and New York City as the top adopters. Seattle, for example, has embraced sustainability and is using AI to manage energy usage and resource management. Boston has launched a “City Hall To Go” that makes sure underserved communities receive needed public services. It also has deployed “cameras and inductive loops to manage traffic and acoustic sensors to identify gun shots.” San Francisco has certified 203 buildings as meeting LEED sustainability standards.35\nThrough these and other means, metropolitan areas are leading the country in the deployment of AI solutions. Indeed, according to a National League of Cities report, 66 percent of American cities are investing in smart city technology. Among the top applications noted in the report are “smart meters for utilities, intelligent traffic signals, e-governance applications, Wi-Fi kiosks, and radio frequency identification sensors in pavement.”36\n Policy, regulatory, and ethical issues\nThese examples from a variety of sectors demonstrate how AI is transforming many walks of human existence. The increasing penetration of AI and autonomous devices into many aspects of life is altering basic operations and decisionmaking within organizations, and improving efficiency and response times.\nAt the same time, though, these developments raise important policy, regulatory, and ethical issues. For example, how should we promote data access? How do we guard against biased or unfair data used in algorithms? What types of ethical principles are introduced through software programming, and how transparent should designers be about their choices? What about questions of legal liability in cases where algorithms cause harm?37\nThe increasing penetration of AI into many aspects of life is altering decisionmaking within organizations and improving efficiency. At the same time, though, these developments raise important policy, regulatory, and ethical issues.\n', '<2-hop>\n\nData access problems\nThe key to getting the most out of AI is having a “data-friendly ecosystem with unified standards and cross-platform sharing.” AI depends on data that can be analyzed in real time and brought to bear on concrete problems. Having data that are “accessible for exploration” in the research community is a prerequisite for successful AI development.38\nAccording to a McKinsey Global Institute study, nations that promote open data sources and data sharing are the ones most likely to see AI advances. In this regard, the United States has a substantial advantage over China. Global ratings on data openness show that U.S. ranks eighth overall in the world, compared to 93 for China.39\nBut right now, the United States does not have a coherent national data strategy. There are few protocols for promoting research access or platforms that make it possible to gain new insights from proprietary data. It is not always clear who owns data or how much belongs in the public sphere. These uncertainties limit the innovation economy and act as a drag on academic research. In the following section, we outline ways to improve data access for researchers.\n Biases in data and algorithms\nIn some instances, certain AI systems are thought to have enabled discriminatory or biased practices.40 For example, Airbnb has been accused of having homeowners on its platform who discriminate against racial minorities. A research project undertaken by the Harvard Business School found that “Airbnb users with distinctly African American names were roughly 16 percent less likely to be accepted as guests than those with distinctly white names.”41\nRacial issues also come up with facial recognition software. Most such systems operate by comparing a person’s face to a range of faces in a large database. As pointed out by Joy Buolamwini of the Algorithmic Justice League, “If your facial recognition data contains mostly Caucasian faces, that’s what your program will learn to recognize.”42 Unless the databases have access to diverse data, these programs perform poorly when attempting to recognize African-American or Asian-American features.\nMany historical data sets reflect traditional values, which may or may not represent the preferences wanted in a current system. As Buolamwini notes, such an approach risks repeating inequities of the past:\nThe rise of automation and the increased reliance on algorithms for high-stakes decisions such as whether someone get insurance or not, your likelihood to default on a loan or somebody’s risk of recidivism means this is something that needs to be addressed. Even admissions decisions are increasingly automated—what school our children go to and what opportunities they have. We don’t have to bring the structural inequalities of the past into the future we create.43\n']","The challenges of data access problems significantly impact the implementation of smart city initiatives by creating barriers to effective AI deployment. A data-friendly ecosystem with unified standards and cross-platform sharing is essential for AI to analyze real-time data and address concrete urban issues. However, the lack of a coherent national data strategy in the United States limits research access and innovation, which are crucial for advancing smart city technologies. Furthermore, ethical considerations arise when discussing data ownership and the public sphere, as uncertainties in these areas can hinder the responsible use of AI. For instance, if data used in smart city applications is biased or unfair, it can lead to discriminatory practices, undermining the very goals of improving urban services. Thus, addressing data access problems is vital not only for enhancing the efficiency of smart cities but also for ensuring that AI technologies are implemented ethically and responsibly.",multi_hop_abstract_query_synthesizer
