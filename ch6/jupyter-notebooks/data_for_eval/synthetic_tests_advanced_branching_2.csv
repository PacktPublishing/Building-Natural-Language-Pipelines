user_input,reference_contexts,reference,synthesizer_name
What role does TikTok play in the context of artificial intelligence and social media?,"[""What is AI, how does it work and why are some people concerned about it?\nArtificial intelligence (AI) has increasingly become part of everyday life over the past decade.\nIt is being used to personalise social media feeds, spot friends and family in smartphone photos and pave the way for medical breakthroughs.\nBut the rise of chatbots like OpenAI's ChatGPT and Meta AI has been accompanied by concern about the technology's environmental impact, ethical implications and data use.\n What is AI and what is it used for?\nAI allows computers to process large amounts of data, identify patterns and follow detailed instructions about what to do with that information.\nComputers cannot think, empathise or reason.\nHowever, scientists have developed systems that can perform tasks which usually require human intelligence, trying to replicate how people acquire and use knowledge.\nThis could be trying to anticipate what product an online shopper might buy, based on previous purchases, in order to recommend items.\nThe technology is also behind voice-controlled virtual assistants like Apple's Siri and Amazon's Alexa, and is being used to develop systems for self-driving cars.\nAI also helps social platforms like Facebook, TikTok and X decide what posts to show users. Streaming services Spotify and Deezer use AI to suggest music.\nThere are also a number of applications in medicine, as scientists use AI to help spot cancers, review X-ray results, speed up diagnoses and identify new treatments.\n What is generative AI, and how do apps like ChatGPT and Meta AI work?\nGenerative AI is used to create new content which can seem like it has been made by a human.\nIt does this by learning from vast quantities of existing data such as online text and images.\nChatGPT and Chinese rival DeepSeek's chatbot are popular generative AI tools that can be used to produce text, images, code and more material.\nGoogle's Gemini or Meta AI can similarly hold text conversations with users.\nApps like Midjourney or Veo 3 are dedicated to creating images or video from simple text prompts.\nGenerative AI can also be used to make high-quality music.\nSongs mimicking the style or sound of famous musicians have gone viral, sometimes leaving fans confused about their authenticity.\n""]","TikTok, along with other social platforms like Facebook and X, uses AI to determine what posts to show users, thereby personalizing their social media experience.",single_hop_specific_query_synthesizer
How does the use of automated classifiers ensure privacy while analyzing message content in the context of national defense?,"['<1-hop>\n\nPrivacy via Automated Classifiers.No one looked at the content of messages while conducting\nanalysis for this paper. All analysis of message content was performed via automated LLM-based\nclassifiers run on de-identified and PII-scrubbed message data (see Figure 1). The messages are first\nscrubbed of PII using an internal LLM-based tool,17 and then classified according to classifiers defined\nover a controlled label space—the most precise classifier we use on the message-level data set is the\nO*NET Intermediate Work Activities taxonomy, which we augment to end up with 333 categories.\nWe introduce technical and procedural frictions that prevent accidental access to the underlying text\n(for example, interfaces that do not render message text to researchers).\nOur classifications aim to discern the intent of a given message, and thus we include the prior 10\nmessages in a conversation as context. 18 For an example, see Table 2.\n Stand-Alone Message Message with Prior Context\n[user]: “10 more” [user]: “give me 3 cultural activities to do with teens”\n[assistant]: “1. Visit a museum . . . ” (truncated)\n[user]: “10 more”\nTable 2:Illustration of Context-Augmented Message Classifications (Synthetic Example). The left column\nshows a standalone message to be classified, and the right column shows the prior context included in the\nclassification of the message on the left.\nWe truncate each message to a maximum of 5,000 characters, because long context windows could\ninduce variability in the quality of the classification (Liu et al., 2023). We classify each message\nwith the “gpt-5-mini” model, with the exception ofInteraction Quality,which uses “gpt-5,” using the\nprompts listed in Appendix A.\n17Internal analyses show that the tool,Privacy Filter, has substantial alignment with human judgment.']","The use of automated classifiers ensures privacy while analyzing message content by conducting the analysis on de-identified and PII-scrubbed message data. No one looks at the content of the messages directly; instead, the analysis is performed via automated LLM-based classifiers. This process includes scrubbing messages of personally identifiable information (PII) using an internal LLM-based tool, and implementing technical and procedural frictions that prevent accidental access to the underlying text. The classifiers discern the intent of messages by including prior context, which further protects individual privacy.",multi_hop_specific_query_synthesizer
"How do Context-Augmented Message Classifications ensure user privacy while analyzing employment data, and what protocols are in place to maintain this privacy during the classification process?","['<1-hop>\n\n” (truncated)\n[user]: “10 more”\nTable 2:Illustration of Context-Augmented Message Classifications (Synthetic Example). The left column\nshows a standalone message to be classified, and the right column shows the prior context included in the\nclassification of the message on the left.\nWe truncate each message to a maximum of 5,000 characters, because long context windows could\ninduce variability in the quality of the classification (Liu et al., 2023). We classify each message\nwith the “gpt-5-mini” model, with the exception ofInteraction Quality,which uses “gpt-5,” using the\nprompts listed in Appendix A.\n17Internal analyses show that the tool,Privacy Filter, has substantial alignment with human judgment.\n18In the case ofInteraction Quality,we additionally include the next two messages in the conversation as context.\n7\x0cWe validated each of the classification prompts by comparing model classification decisions against\nhuman-judged classifications of a sample of conversations from the publicly available WildChat dataset\n(Zhao et al., 2024), a set of conversations with a third-party chatbot which users affirmatively gave\ntheir assent to share publicly for research purposes. 19 Appendix B provides detail on our validation\napproach and performance relative to human judgment. For additional transparency, we classify\na sample of 100,000 public WildChat messages and provide those data in this paper’s replication\npackage.\n 3.3 Employment Dataset\nWe conduct limited analyses of aggregated employment categories based on publicly available data\nfor a sample of consumer ChatGPT users. This sample included approximately 130,000 Free, Plus,\nand Pro users, and the employment categories were aggregated by a vendor working through a secure\nData Clean Room (DCR). For this analysis, we use the same exclusion criteria as for the message-level\ndatasets: we exclude deactivated users, banned users, users who have opted out of training, and users\nwhose self-reported age is under 18. Because the data was only available for a subset of users the\nresults may not be representative of the full pool of users.\nDescription.The employment data, which is aggregated from publicly available sources, includes\nindustry, occupations coarsened to O*NET categories, seniority level, company size, and education\ninformation that is limited to the degree attained. A vendor working within a DCR procured this\ndataset, restricted us to running only aggregated queries against it through the DCR, and deleted it\nupon the study’s completion.\n', '<2-hop>\n\nPrivacy via a Data Clean Room.We never directly accessed user-level demographic records.\nAll analysis of employment data was executed exclusively within a secure DCR that permits only\npre-approved aggregate computations across independently held datasets; neither party can view or\nexport the other party’s underlying records. We governed the DCR with strict protocols: To execute\nany query that touched the external demographic data, we first obtained explicit sign-off from a\ncommittee of 6 coauthors and then submitted the notebook to our data partner for approval; only\napproved notebooks could run in the DCR (see Figure 2).\nOur partner enforced strict aggregation limits: they only approved code that returned cells meeting\na threshold of 100 users. Consequently, no individual rows or narrowly defined categories were ever\nvisible to researchers. For example, if 99 users had the occupation “anesthesiologist,” any occupation-\nlevel output would place those users into a “suppressed” category, or place these observations in a\ncoarsened category (e.g. “medical professionals”) rather than reporting a separate cell of anesthesiol-\nogists.\n19The dataset was collected from a third party chatbot using OpenAI’s LLMs via their API.\n8\x0cFigure 2:Illustration of Aggregated Employment Category Analysis via a Data Clean Room. All queries run\nin the Data Clean Room must be approved by our data partner, enforcing a strict aggregation threshold (100\nobservations). As a result, researchers cannot access user-level employment data, only aggregated employment\ncategories.\n', '<3-hop>\n\nPrivacy via Automated Classifiers.No one looked at the content of messages while conducting\nanalysis for this paper. All analysis of message content was performed via automated LLM-based\nclassifiers run on de-identified and PII-scrubbed message data (see Figure 1). The messages are first\nscrubbed of PII using an internal LLM-based tool,17 and then classified according to classifiers defined\nover a controlled label space—the most precise classifier we use on the message-level data set is the\nO*NET Intermediate Work Activities taxonomy, which we augment to end up with 333 categories.\nWe introduce technical and procedural frictions that prevent accidental access to the underlying text\n(for example, interfaces that do not render message text to researchers).\nOur classifications aim to discern the intent of a given message, and thus we include the prior 10\nmessages in a conversation as context. 18 For an example, see Table 2.\n Stand-Alone Message Message with Prior Context\n[user]: “10 more” [user]: “give me 3 cultural activities to do with teens”\n[assistant]: “1. Visit a museum . . . ” (truncated)\n[user]: “10 more”\nTable 2:Illustration of Context-Augmented Message Classifications (Synthetic Example). The left column\nshows a standalone message to be classified, and the right column shows the prior context included in the\nclassification of the message on the left.\nWe truncate each message to a maximum of 5,000 characters, because long context windows could\ninduce variability in the quality of the classification (Liu et al., 2023). We classify each message\nwith the “gpt-5-mini” model, with the exception ofInteraction Quality,which uses “gpt-5,” using the\nprompts listed in Appendix A.\n17Internal analyses show that the tool,Privacy Filter, has substantial alignment with human judgment.']","Context-Augmented Message Classifications ensure user privacy by utilizing a Data Clean Room (DCR) for all analyses of employment data. This DCR allows only pre-approved aggregate computations across independently held datasets, preventing any direct access to user-level demographic records. Strict protocols govern the DCR, requiring explicit sign-off from a committee before executing any queries that touch external demographic data. Additionally, the analysis of message content is performed via automated LLM-based classifiers on de-identified and PII-scrubbed message data, ensuring that no individual messages are viewed by researchers. The classifiers are designed to discern the intent of messages while including prior context to enhance classification accuracy, all while maintaining strict aggregation limits to protect user identities.",multi_hop_abstract_query_synthesizer
