user_input,reference_contexts,reference,synthesizer_name
Wut is Alexa and how does it use AI?,"[""What is AI, how does it work and why are some people concerned about it?\nArtificial intelligence (AI) has increasingly become part of everyday life over the past decade.\nIt is being used to personalise social media feeds, spot friends and family in smartphone photos and pave the way for medical breakthroughs.\nBut the rise of chatbots like OpenAI's ChatGPT and Meta AI has been accompanied by concern about the technology's environmental impact, ethical implications and data use.\n What is AI and what is it used for?\nAI allows computers to process large amounts of data, identify patterns and follow detailed instructions about what to do with that information.\nComputers cannot think, empathise or reason.\nHowever, scientists have developed systems that can perform tasks which usually require human intelligence, trying to replicate how people acquire and use knowledge.\nThis could be trying to anticipate what product an online shopper might buy, based on previous purchases, in order to recommend items.\nThe technology is also behind voice-controlled virtual assistants like Apple's Siri and Amazon's Alexa, and is being used to develop systems for self-driving cars.\nAI also helps social platforms like Facebook, TikTok and X decide what posts to show users. Streaming services Spotify and Deezer use AI to suggest music.\nThere are also a number of applications in medicine, as scientists use AI to help spot cancers, review X-ray results, speed up diagnoses and identify new treatments.\n What is generative AI, and how do apps like ChatGPT and Meta AI work?\nGenerative AI is used to create new content which can seem like it has been made by a human.\nIt does this by learning from vast quantities of existing data such as online text and images.\nChatGPT and Chinese rival DeepSeek's chatbot are popular generative AI tools that can be used to produce text, images, code and more material.\nGoogle's Gemini or Meta AI can similarly hold text conversations with users.\nApps like Midjourney or Veo 3 are dedicated to creating images or video from simple text prompts.\nGenerative AI can also be used to make high-quality music.\nSongs mimicking the style or sound of famous musicians have gone viral, sometimes leaving fans confused about their authenticity.\n""]",Alexa is a voice-controlled virtual assistant developed by Amazon that uses artificial intelligence to process data and respond to user commands.,single_hop_specific_query_synthesizer
"What trends in user engagement with ChatGPT were observed in 2023, particularly regarding the first cohort of users?","['<1-hop>\n\n4 The Growth of ChatGPT\nChatGPT was released to the public on November 30, 2022 as a “research preview,” and by December\n5 it had more than one million registered users. Figure 3 reports the growth of overall weekly active\nusers (WAU) on consumer plans over time. ChatGPT had more than 100 million logged-in WAU after\none year, and almost 350 million after two years. By the end of July 2025, ChatGPT had more than\n700 million total WAU, nearly 10% of the world’s adult population. 20\nFigure 3:Weekly active ChatGPT users on consumer plans (Free, Plus, Pro), shown as point-in-time\nsnapshots every six months, November 2022–September 2025.\nFigure 4 presents growth in the total messages sent by users over time. The solid line shows that\nbetween July 2024 and July 2025, the number of messages sent grew by a factor of more than 5.\nFigure 4 also shows the contribution of individual cohorts of users to aggregate message volume.\nThe yellow line represents the first cohort of ChatGPT users: their usage declined somewhat over\n2023, but started growing again in late 2024 and is now higher than it has ever been. The pink line\nrepresents messages from users who signed up in Q3 of 2023 or earlier, and so thedifferencebetween\n20Note that we expect our counts of distinct accounts to somewhat exceed distinct people when one person has two\naccounts (or, for logged-out users, one person using two devices). For logged-in users, the count is based on distinct\nlogin credentials (email addresses), and one person may have multiple accounts. For logged-out users, the count is based\non distinct browser cookies; this would double-count people if someone returns to ChatGPT after clearing their cookies,\nor if they access ChatGPT with two different devices in the same week.\n10\x0cFigure 4:Daily message volumes from ChatGPT consumer plans (Free, Plus, Pro), split by sign-up date of\nthe requesting user.', '<2-hop>\n\n” (truncated)\n[user]: “10 more”\nTable 2:Illustration of Context-Augmented Message Classifications (Synthetic Example). The left column\nshows a standalone message to be classified, and the right column shows the prior context included in the\nclassification of the message on the left.\nWe truncate each message to a maximum of 5,000 characters, because long context windows could\ninduce variability in the quality of the classification (Liu et al., 2023). We classify each message\nwith the “gpt-5-mini” model, with the exception ofInteraction Quality,which uses “gpt-5,” using the\nprompts listed in Appendix A.\n17Internal analyses show that the tool,Privacy Filter, has substantial alignment with human judgment.\n18In the case ofInteraction Quality,we additionally include the next two messages in the conversation as context.\n7\x0cWe validated each of the classification prompts by comparing model classification decisions against\nhuman-judged classifications of a sample of conversations from the publicly available WildChat dataset\n(Zhao et al., 2024), a set of conversations with a third-party chatbot which users affirmatively gave\ntheir assent to share publicly for research purposes. 19 Appendix B provides detail on our validation\napproach and performance relative to human judgment. For additional transparency, we classify\na sample of 100,000 public WildChat messages and provide those data in this paper’s replication\npackage.\n 3.3 Employment Dataset\nWe conduct limited analyses of aggregated employment categories based on publicly available data\nfor a sample of consumer ChatGPT users. This sample included approximately 130,000 Free, Plus,\nand Pro users, and the employment categories were aggregated by a vendor working through a secure\nData Clean Room (DCR). For this analysis, we use the same exclusion criteria as for the message-level\ndatasets: we exclude deactivated users, banned users, users who have opted out of training, and users\nwhose self-reported age is under 18. Because the data was only available for a subset of users the\nresults may not be representative of the full pool of users.\nDescription.The employment data, which is aggregated from publicly available sources, includes\nindustry, occupations coarsened to O*NET categories, seniority level, company size, and education\ninformation that is limited to the degree attained. A vendor working within a DCR procured this\ndataset, restricted us to running only aggregated queries against it through the DCR, and deleted it\nupon the study’s completion.\n']","In 2023, the first cohort of ChatGPT users experienced a decline in usage; however, this trend reversed in late 2024, leading to a higher engagement level than ever before. This indicates a significant fluctuation in user engagement patterns over the year.",multi_hop_specific_query_synthesizer
"What are the implications of artificial intelligence on user satisfaction in educational contexts, and how does this relate to the effectiveness of tools like ChatGPT?","['<1-hop>\n\n27-28.\n- Christian Davenport, “ Future Wars May Depend as Much on Algorithms as on Ammunition, Report Says,” Washington Post, December 3, 2017.\n- Ibid.\n- John R. Allen and Amir Husain, “On Hyperwar,” Naval Institute Proceedings, July 17, 2017, pp. 30-36.\n- Paul Mozur, “ China Sets Goal to Lead in Artificial Intelligence,” New York Times, July 21, 2017, p. B1.\n- Paul Mozur and John Markoff, “Is China Outsmarting American Artificial Intelligence?” New York Times, May 28, 2017.\n- Economist, “ America v China: The Battle for Digital Supremacy,” March 15, 2018.\n- Rasmus Rothe, “Applying Deep Learning to Real-World Problems,” Medium, May 23, 2017.\n- Eric Horvitz, “Reflections on the Status and Future of Artificial Intelligence,” Testimony before the U.S. Senate Subcommittee on Space, Science, and Competitiveness, November 30, 2016, p. 5.\n- Jeff Asher and Rob Arthur, “Inside the Algorithm That Tries to Predict Gun Violence in Chicago,” New York Times Upshot, June 13, 2017.\n- Caleb Watney, “It’s Time for our Justice System to Embrace Artificial Intelligence,” TechTank (blog), Brookings Institution, July 20, 2017.\n- Asher and Arthur, “Inside the Algorithm That Tries to Predict Gun Violence in Chicago.”\n- Paul Mozur and Keith Bradsher, “China’s A.I. Advances Help Its Tech Industry, and State Security,” New York Times, December 3, 2017.\n- Simon Denyer, “China’s Watchful Eye,” Washington Post, January 7, 2018.\n- Cameron Kerry and Jack Karsten, “Gauging Investment in Self-Driving Cars,” Brookings Institution, October 16, 2017.\n- Portions of this section are drawn from Darrell M. West, “Driverless Cars in China, Europe, Japan, Korea, and the United States,” Brookings Institution, September 2016.\n- Ibid.\n- Yuming Ge, Xiaoman Liu, Libo Tang, and Darrell M. West, “ Smart Transportation in China and the United States,” Center for Technology Innovation, Brookings Institution, December 2017.\n- Peter Holley, “Uber Signs Deal to Buy 24,000 Autonomous Vehicles from Volvo,” Washington Post, November 20, 2017.\n- Daisuke Wakabayashi, “Self-Driving Uber Car Kills Pedestrian in Arizona, Where Robots Roam,” New York Times, March 19, 2018.\n- Kevin Desouza, Rashmi Krishnamurthy, and Gregory Dawson, “Learning from Public Sector Experimentation with Artificial Intelligence,” TechTank (blog), Brookings Institution, June 23, 2017.\n- Boyd Cohen, “The 10 Smartest Cities in North America,” Fast Company, November 14, 2013.\n- Teena Maddox, “66% of US Cities Are Investing in Smart City Technology,” TechRepublic, November 6, 2017.\n- Osonde Osoba and William Welser IV, “The Risks of Artificial Intelligence to Security and the Future of Work” (Santa Monica, Calif.: RAND Corp., December 2017) (www.rand.org/pubs/perspectives/PE237.html).\n- Ibid., p. 7.\n- Dominic Barton, Jonathan Woetzel, Jeongmin Seong, and Qinzheng Tian, “', '<2-hop>\n\nArtificial Intelligence: Implications for China” (New York: McKinsey Global Institute, April 2017), p. 7.\n- Executive Office of the President, “Preparing for the Future of Artificial Intelligence,” October 2016, pp. 30-31.\n- Elaine Glusac, “As Airbnb Grows, So Do Claims of Discrimination,” New York Times, June 21, 2016.\n- “Joy Buolamwini,” Bloomberg Businessweek, July 3, 2017, p. 80.\n- Ibid.\n- Mark Purdy and Paul Daugherty, “Why Artificial Intelligence is the Future of Growth,” Accenture, 2016.\n- Jon Valant, “Integrating Charter Schools and Choice-Based Education Systems,” Brown Center Chalkboard blog, Brookings Institution, June 23, 2017.\n- Tucker, “‘A White Mask Worked Better.’”\n- Cliff Kuang, “Can A.I. Be Taught to Explain Itself?” New York Times Magazine, November 21, 2017.\n- Yale Law School Information Society Project, “Governing Machine Learning,” September 2017.\n- Katie Benner, “Airbnb Vows to Fight Racism, But Its Users Can’t Sue to Prompt Fairness,” New York Times, June 19, 2016.\n- Executive Office of the President, “Artificial Intelligence, Automation, and the Economy” and “Preparing for the Future of Artificial Intelligence.”\n- Nancy Scolar, “Facebook’s Next Project: American Inequality,” Politico, February 19, 2018.\n- Darrell M. West, “What Internet Search Data Reveals about Donald Trump’s First Year in Office,” Brookings Institution policy report, January 17, 2018.\n- Ian Buck, “Testimony before the House Committee on Oversight and Government Reform Subcommittee on Information Technology,” February 14, 2018.\n- Keith Nakasone, “Testimony before the House Committee on Oversight and Government Reform Subcommittee on Information Technology,” March 7, 2018.\n- Greg Brockman, “The Dawn of Artificial Intelligence,” Testimony before U.S. Senate Subcommittee on Space, Science, and Competitiveness, November 30, 2016.\n- Amir Khosrowshahi, “Testimony before the House Committee on Oversight and Government Reform Subcommittee on Information Technology,” February 14, 2018.\n- James Kurose, “Testimony before the House Committee on Oversight and Government Reform Subcommittee on Information Technology,” March 7, 2018.\n- Stephen Noonoo, “Teachers Can Now Use IBM’s Watson to Search for Free Lesson Plans,” EdSurge, September 13, 2017.\n- Congress.gov, “H.R. 4625 FUTURE of Artificial Intelligence Act of 2017,” December 12, 2017.\n- Elizabeth Zima, “Could New York City’s AI Transparency Bill Be a Model for the Country?” Government Technology, January 4, 2018.', '<3-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ']","The implications of artificial intelligence on user satisfaction in educational contexts are significant, as AI tools like ChatGPT can enhance communication patterns and effectiveness. Research indicates that user satisfaction can be partially inferred from explicit feedback, such as thumbs-up or thumbs-down ratings. In a sample of conversations, 86% of feedback was thumbs-up, suggesting a positive reception of AI interactions. This correlation between user ratings and interaction quality highlights the potential of AI to improve educational experiences by providing effective and satisfactory communication.",multi_hop_abstract_query_synthesizer
