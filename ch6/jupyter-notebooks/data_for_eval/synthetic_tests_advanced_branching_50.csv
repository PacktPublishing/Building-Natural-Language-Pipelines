user_input,reference_contexts,reference,synthesizer_name
Wht is AI used for?,"['What is AI, how does it work and why are some people concerned about it?\nArtificial intelligence (AI) has increasingly become part of everyday life over the past decade.\nIt is being used to personalise social media feeds, spot friends and family in smartphone photos and pave the way for medical breakthroughs.\nBut the rise of chatbots like OpenAI\'s ChatGPT and Meta AI has been accompanied by concern about the technology\'s environmental impact, ethical implications and data use.\n What is AI and what is it used for?\nAI allows computers to process large amounts of data, identify patterns and follow detailed instructions about what to do with that information.\nComputers cannot think, empathise or reason.\nHowever, scientists have developed systems that can perform tasks which usually require human intelligence, trying to replicate how people acquire and use knowledge.\nThis could be trying to anticipate what product an online shopper might buy, based on previous purchases, in order to recommend items.\nThe technology is also behind voice-controlled virtual assistants like Apple\'s Siri and Amazon\'s Alexa, and is being used to develop systems for self-driving cars.\nAI also helps social platforms like Facebook, TikTok and X decide what posts to show users. Streaming services Spotify and Deezer use AI to suggest music.\nThere are also a number of applications in medicine, as scientists use AI to help spot cancers, review X-ray results, speed up diagnoses and identify new treatments.\n What is generative AI, and how do apps like ChatGPT and Meta AI work?\nGenerative AI is used to create new content which can seem like it has been made by a human.\nIt does this by learning from vast quantities of existing data such as online text and images.\nChatGPT and Chinese rival DeepSeek\'s chatbot are popular generative AI tools that can be used to produce text, images, code and more material.\nGoogle\'s Gemini or Meta AI can similarly hold text conversations with users.\nApps like Midjourney or Veo 3 are dedicated to creating images or video from simple text prompts.\nGenerative AI can also be used to make high-quality music.\nSongs mimicking the style or sound of famous musicians have gone viral, sometimes leaving fans confused about their authenticity.\n Why is AI controversial?\nWhile acknowledging AI\'s potential, some experts are worried about the implications of its rapid growth.\nThe International Monetary Fund (IMF) has warned AI could affect nearly 40% of jobs, and worsen global financial inequality.\nProf Geoffrey Hinton, a computer scientist regarded as one of the ""godfathers"" of AI development, has expressed concern that powerful AI systems could even make humans extinct - although his fear was dismissed by his fellow ""AI godfather"", Yann LeCun.\nCritics also highlight the tech\'s potential to reproduce biased information, or discriminate against some social groups.\nThis is because much of the data used to train AI comes from public material, including social media posts or comments, which can reflect existing societal biases such as sexism or racism.\nAnd while AI programmes are growing more adept, they are still prone to errors - such as creating images of people with the wrong number of fingers or limbs.\nGenerative AI systems are known for their ability to ""hallucinate"" and assert falsehoods as fact, even sometimes inventing sources for the inaccurate information.\nApple halted a new AI feature in January after it incorrectly summarised news app notifications.\nThe BBC complained about the feature after Apple\'s AI falsely told readers that Luigi Mangione - the man accused of killing UnitedHealthcare CEO Brian Thompson - had shot himself.\nGoogle has also faced criticism over inaccurate answers produced by its AI search overviews.\nThis has added to concerns about the use of AI in schools and workplaces, where it is increasingly used to help summarise texts, write emails or essays and solve bugs in code.\nThere are worries about students using AI technology to ""cheat"" on assignments, or employees ""smuggling"" it into work.\nWriters, musicians and artists have also pushed back against the technology on ethical grounds, accusing AI developers of using their work to train systems without consent or compensation.\nThousands of creators - including Abba singer-songwriter Björn Ulvaeus, writers Ian Rankin and Joanne Harris and actress Julianne Moore - signed a statement in October 2024 calling AI a ""major, unjust threat"" to their livelihoods.\n']","AI is used to process large amounts of data, identify patterns, and follow detailed instructions. It helps personalize social media feeds, spot friends and family in photos, recommend products to online shoppers, and powers voice-controlled virtual assistants like Siri and Alexa. Additionally, AI is applied in medicine to spot cancers, review X-ray results, speed up diagnoses, and identify new treatments.",single_hop_specific_query_synthesizer
What are the main regulations imposed by the EU on AI systems?,"['How does AI effect the environment?\nIt is not clear how much energy AI systems use, but some researchers estimate the industry as a whole could soon consume as much as the Netherlands.\nCreating the powerful computer chips needed to run AI programmes requires lots of power and water.\nDemand for generative AI services has also meant an increase in the number of data centres which power them.\nThese huge halls - housing thousands of racks of computer servers - use substantial amounts of energy and require large volumes of water to keep them cool.\nSome large tech companies have invested in ways to reduce or reuse the water needed, or have opted for alternative methods such as air-cooling.\nHowever, some experts and activists fear that AI will worsen water supply problems.\nThe BBC was told in February that government plans to make the UK a ""world leader"" in AI could put already stretched supplies of drinking water under strain.\nIn September 2024, Google said it would reconsider proposals for a data centre in Chile, which has struggled with drought.\n Are there laws governing AI?\nSome governments have already introduced rules governing how AI operates.\nThe EU\'s Artificial Intelligence Act places controls on high risk systems used in areas such as education, healthcare, law enforcement or elections. It bans some AI use altogether.\nGenerative AI developers in China are required to safeguard citizens\' data, and promote transparency and accuracy of information. But they are also bound by the country\'s strict censorship laws.\nIn the UK, Prime Minister Sir Keir Starmer has said the government ""will test and understand AI before we regulate it"".\nBoth the UK and US have AI Safety Institutes that aim to identify risks and evaluate advanced AI models.\nIn 2024 the two countries signed an agreement to collaborate on developing ""robust"" AI testing methods.\nHowever, in February 2025, neither country signed an international AI declaration which pledged an open, inclusive and sustainable approach to the technology.\nSeveral countries including the UK are also clamping down on use of AI systems to create deepfake nude imagery and child sexual abuse material.\nSign up for our Tech Decoded newsletter to follow the world\'s top tech stories and trends. Outside the UK? Sign up here.']","The EU's Artificial Intelligence Act places controls on high-risk systems used in areas such as education, healthcare, law enforcement, or elections, and it bans some AI use altogether.",single_hop_specific_query_synthesizer
How does the regulatory approach of the European Union differ from that of the U.S. in relation to artificial intelligence?,"['This article was published in 2018. To read more recent content from Brookings on Artificial Intelligence, please visit the AI topic page.\nMost people are not very familiar with the concept of artificial intelligence (AI). As an illustration, when 1,500 senior business leaders in the United States in 2017 were asked about AI, only 17 percent said they were familiar with it.1 A number of them were not sure what it was or how it would affect their particular companies. They understood there was considerable potential for altering business processes, but were not clear how AI could be deployed within their own organizations.\nDespite its widespread lack of familiarity, AI is a technology that is transforming every walk of life. It is a wide-ranging tool that enables people to rethink how we integrate information, analyze data, and use the resulting insights to improve decisionmaking. Our hope through this comprehensive overview is to explain AI to an audience of policymakers, opinion leaders, and interested observers, and demonstrate how AI already is altering the world and raising important questions for society, the economy, and governance.\nIn this paper, we discuss novel applications in finance, national security, health care, criminal justice, transportation, and smart cities, and address issues such as data access problems, algorithmic bias, AI ethics and transparency, and legal liability for AI decisions. We contrast the regulatory approaches of the U.S. and European Union, and close by making a number of recommendations for getting the most out of AI while still protecting important human values.2\nIn order to maximize AI benefits, we recommend nine steps for going forward:\n- Encourage greater data access for researchers without compromising users’ personal privacy,\n- invest more government funding in unclassified AI research,\n- promote new models of digital education and AI workforce development so employees have the skills needed in the 21st-century economy,\n- create a federal AI advisory committee to make policy recommendations,\n- engage with state and local officials so they enact effective policies,\n- regulate broad AI principles rather than specific algorithms,\n- take bias complaints seriously so AI does not replicate historic injustice, unfairness, or discrimination in data or algorithms,\n- maintain mechanisms for human oversight and control, and\n- penalize malicious AI behavior and promote cybersecurity.\n Qualities of artificial intelligence\nAlthough there is no uniformly agreed upon definition, AI generally is thought to refer to “machines that respond to stimulation consistent with traditional responses from humans, given the human capacity for contemplation, judgment and intention.”3 According to researchers Shubhendu and Vijay, these software systems “make decisions which normally require [a] human level of expertise” and help people anticipate problems or deal with issues as they come up.4 As such, they operate in an intentional, intelligent, and adaptive manner.\n']","The paper contrasts the regulatory approaches of the U.S. and the European Union, discussing how each region addresses issues related to artificial intelligence, including data access problems, algorithmic bias, AI ethics and transparency, and legal liability for AI decisions.",single_hop_specific_query_synthesizer
What role does Vijay play in the context of artificial intelligence?,"['Intelligence, please visit the AI topic page.\nMost people are not very familiar with the concept of artificial intelligence (AI). As an illustration, when 1,500 senior business leaders in the United States in 2017 were asked about AI, only 17 percent said they were familiar with it.1 A number of them were not sure what it was or how it would affect their particular companies. They understood there was considerable potential for altering business processes, but were not clear how AI could be deployed within their own organizations.\nDespite its widespread lack of familiarity, AI is a technology that is transforming every walk of life. It is a wide-ranging tool that enables people to rethink how we integrate information, analyze data, and use the resulting insights to improve decisionmaking. Our hope through this comprehensive overview is to explain AI to an audience of policymakers, opinion leaders, and interested observers, and demonstrate how AI already is altering the world and raising important questions for society, the economy, and governance.\nIn this paper, we discuss novel applications in finance, national security, health care, criminal justice, transportation, and smart cities, and address issues such as data access problems, algorithmic bias, AI ethics and transparency, and legal liability for AI decisions. We contrast the regulatory approaches of the U.S. and European Union, and close by making a number of recommendations for getting the most out of AI while still protecting important human values.2\nIn order to maximize AI benefits, we recommend nine steps for going forward:\n- Encourage greater data access for researchers without compromising users’ personal privacy,\n- invest more government funding in unclassified AI research,\n- promote new models of digital education and AI workforce development so employees have the skills needed in the 21st-century economy,\n- create a federal AI advisory committee to make policy recommendations,\n- engage with state and local officials so they enact effective policies,\n- regulate broad AI principles rather than specific algorithms,\n- take bias complaints seriously so AI does not replicate historic injustice, unfairness, or discrimination in data or algorithms,\n- maintain mechanisms for human oversight and control, and\n- penalize malicious AI behavior and promote cybersecurity.\nQualities of artificial intelligence\nAlthough there is no uniformly agreed upon definition, AI generally is thought to refer to “machines that respond to stimulation consistent with traditional responses from humans, given the human capacity for contemplation, judgment and intention.”3 According to researchers Shubhendu and Vijay, these software systems “make decisions which normally require [a] human level of expertise” and help people anticipate problems or deal with issues as they come up.4 As such, they operate in an intentional, intelligent, and adaptive manner.\nIntentionality\nArtificial intelligence algorithms are designed to make decisions, often using real-time data. They are unlike passive machines that are capable only of mechanical or predetermined responses. Using sensors, digital data, or remote inputs, they combine information from a variety of different sources, analyze the material instantly, and act on the insights derived from those data. With massive improvements in storage systems, processing speeds, and analytic techniques, they are capable of tremendous sophistication in analysis and decisionmaking.\nArtificial intelligence is already altering the world and raising important questions for society, the economy, and governance.\nIntelligence\nAI generally is undertaken in conjunction with machine learning and data analytics.5 Machine learning takes data and looks for underlying trends. If it spots something that is relevant for a practical problem, software designers can take that knowledge and use it to analyze specific issues. All that is required are data that are sufficiently robust that algorithms can discern useful patterns. Data can come in the form of digital information, satellite imagery, visual information, text, or unstructured data.\n']","According to researchers Shubhendu and Vijay, these software systems 'make decisions which normally require [a] human level of expertise' and help people anticipate problems or deal with issues as they come up.",single_hop_specific_query_synthesizer
Can you tell me how much economic development AI is expected to bring to Oceania by 2030?,"['Applications in diverse sectors AI is not a futuristic vision, but rather something that is here today and being integrated with and deployed into a variety of sectors. This includes fields such as finance, national security, health care, criminal justice, transportation, and smart cities. There are numerous examples where AI already is making an impact on the world and augmenting human capabilities in significant ways.6 One of the reasons for the growing role of AI is the tremendous opportunities for economic development that it presents. A project undertaken by PriceWaterhouseCoopers estimated that “artificial intelligence technologies could increase global GDP by $15.7 trillion, a full 14%, by 2030.”7 That includes advances of $7 trillion in China, $3.7 trillion in North America, $1.8 trillion in Northern Europe, $1.2 trillion for Africa and Oceania, $0.9 trillion in the rest of Asia outside of China, $0.7 trillion in Southern Europe, and $0.5 trillion in Latin America. China is making rapid strides because it has set a national goal of investing $150 billion in AI and becoming the global leader in this area by 2030. Meanwhile, a McKinsey Global Institute study of China found that “AI-led automation can give the Chinese economy a productivity injection that would add 0.8 to 1.4 percentage points to GDP growth annually, depending on the speed of adoption.”8 Although its authors found that China currently lags the United States and the United Kingdom in AI deployment, the sheer size of its AI market gives that country tremendous opportunities for pilot testing and future development. Finance Investments in financial AI in the United States tripled between 2013 and 2014 to a total of $12.2 billion.9 According to observers in that sector, “Decisions about loans are now being made by software that can take into account a variety of finely parsed data about a borrower, rather than just a credit score and a background check.”10 In addition, there are so-called robo-advisers that “create personalized investment portfolios, obviating the need for stockbrokers and financial advisers.”11 These advances are designed to take the emotion out of investing and undertake decisions based on analytical considerations, and make these choices in a matter of minutes. A prominent example of this is taking place in stock exchanges, where high-frequency trading by machines has replaced much of human decisionmaking. People submit buy and sell orders, and computers match them in the blink of an eye without human intervention. Machines can spot trading inefficiencies or market differentials on a very small scale and execute trades that make money according to investor instructions.12 Powered in some places by advanced computing, these tools have much greater capacities for storing information because of their emphasis not on a zero or a one, but on “quantum bits” that can store multiple values in each location.13 That dramatically increases storage capacity and decreases processing times. Fraud detection represents another way AI is helpful in financial systems. It sometimes is difficult to discern fraudulent activities in large organizations, but AI can identify abnormalities, outliers, or deviant cases requiring additional investigation. That helps managers find problems early in the cycle, before they reach dangerous levels.14 National security AI plays a substantial role in national defense. Through its Project Maven, the American military is deploying AI “to sift through the massive troves of data and video captured by surveillance and then alert human analysts of patterns or when there is abnormal or suspicious activity.”15 According to Deputy Secretary of Defense Patrick Shanahan, the goal of emerging technologies in this area is “to meet our warfighters’ needs and to increase [the] speed and agility [of] technology development and procurement.”16 Artificial intelligence will accelerate the traditional process of warfare so rapidly that a new term has been coined: hyperwar. The big data analytics associated with AI will profoundly affect intelligence analysis, as massive amounts of data are sifted in near real time—if not eventually in real time—thereby providing commanders and their staffs a level of intelligence analysis and productivity heretofore unseen. Command and control will similarly be affected as human commanders delegate certain routine, and in special circumstances, key decisions to AI platforms, reducing dramatically the time associated with the decision and subsequent action. In the end, warfare is a time competitive process, where the side able to decide the fastest and move most quickly to execution will generally prevail. Indeed, artificially intelligent intelligence systems, tied to AI-assisted command and control systems, can move decision support and decisionmaking to a speed vastly superior to the speeds of the traditional means of waging war. So fast will be this process, especially if coupled to automatic decisions to launch artificially intelligent autonomous weapons systems capable of lethal outcomes, that a new term has been coined specifically to embrace the speed at which war will be waged: hyperwar. While the ethical and legal debate is raging over whether America will ever wage war']","AI is projected to contribute $1.2 trillion to Oceania's economy by 2030, as part of the overall estimated increase of $15.7 trillion in global GDP due to artificial intelligence technologies.",single_hop_specific_query_synthesizer
How does cybersecurity relate to the challenges posed by AI in warfare?,"['Adaptability\nAI systems have the ability to learn and adapt as they make decisions. In the transportation area, for example, semi-autonomous vehicles have tools that let drivers and vehicles know about upcoming congestion, potholes, highway construction, or other possible traffic impediments. Vehicles can take advantage of the experience of other vehicles on the road, without human involvement, and the entire corpus of their achieved “experience” is immediately and fully transferable to other similarly configured vehicles. Their advanced algorithms, sensors, and cameras incorporate experience in current operations, and use dashboards and visual displays to present information in real time so human drivers are able to make sense of ongoing traffic and vehicular conditions. And in the case of fully autonomous vehicles, advanced systems can completely control the car or truck, and make all the navigational decisions.\n with artificially intelligent autonomous lethal systems, the Chinese and Russians are not nearly so mired in this debate, and we should anticipate our need to defend against these systems operating at hyperwar speeds. The challenge in the West of where to position “humans in the loop” in a hyperwar scenario will ultimately dictate the West’s capacity to be competitive in this new form of conflict.17 Just as AI will profoundly affect the speed of warfare, the proliferation of zero day or zero second cyber threats as well as polymorphic malware will challenge even the most sophisticated signature-based cyber protection. This forces significant improvement to existing cyber defenses. Increasingly, vulnerable systems are migrating, and will need to shift to a layered approach to cybersecurity with cloud-based, cognitive AI platforms. This approach moves the community toward a “thinking” defensive capability that can defend networks through constant training on known threats. This capability includes DNA-level analysis of heretofore unknown code, with the possibility of recognizing and stopping inbound malicious code by recognizing a string component of the file.']","Cybersecurity is challenged by the proliferation of zero day or zero second cyber threats and polymorphic malware, which can outpace even the most sophisticated signature-based cyber protection. This necessitates significant improvements to existing cyber defenses, particularly as vulnerable systems migrate to a layered approach with cloud-based, cognitive AI platforms.",single_hop_specific_query_synthesizer
What role did Petya play in cybersecurity challenges?,"['The challenge in the West of where to position “humans in the loop” in a hyperwar scenario will ultimately dictate the West’s capacity to be competitive in this new form of conflict.17\nJust as AI will profoundly affect the speed of warfare, the proliferation of zero day or zero second cyber threats as well as polymorphic malware will challenge even the most sophisticated signature-based cyber protection. This forces significant improvement to existing cyber defenses. Increasingly, vulnerable systems are migrating, and will need to shift to a layered approach to cybersecurity with cloud-based, cognitive AI platforms. This approach moves the community toward a “thinking” defensive capability that can defend networks through constant training on known threats. This capability includes DNA-level analysis of heretofore unknown code, with the possibility of recognizing and stopping inbound malicious code by recognizing a string component of the file. This is how certain key U.S.-based systems stopped the debilitating “WannaCry” and “Petya” viruses.\nPreparing for hyperwar and defending critical cyber networks must become a high priority because China, Russia, North Korea, and other countries are putting substantial resources into AI. In 2017, China’s State Council issued a plan for the country to “build a domestic industry worth almost $150 billion” by 2030.18 As an example of the possibilities, the Chinese search firm Baidu has pioneered a facial recognition application that finds missing people. In addition, cities such as Shenzhen are providing up to $1 million to support AI labs. That country hopes AI will provide security, combat terrorism, and improve speech recognition programs.19 The dual-use nature of many AI algorithms will mean AI research focused on one sector of society can be rapidly modified for use in the security sector as well.20\n Health care\nAI tools are helping designers improve computational sophistication in health care. For example, Merantix is a German company that applies deep learning to medical issues. It has an application in medical imaging that “detects lymph nodes in the human body in Computer Tomography (CT) images.”21 According to its developers, the key is labeling the nodes and identifying small lesions or growths that could be problematic. Humans can do this, but radiologists charge $100 per hour and may be able to carefully read only four images an hour. If there were 10,000 images, the cost of this process would be $250,000, which is prohibitively expensive if done by humans.\nWhat deep learning can do in this situation is train computers on data sets to learn what a normal-looking versus an irregular-appearing lymph node is. After doing that through imaging exercises and honing the accuracy of the labeling, radiological imaging specialists can apply this knowledge to actual patients and determine the extent to which someone is at risk of cancerous lymph nodes. Since only a few are likely to test positive, it is a matter of identifying the unhealthy versus healthy node.\nAI has been applied to congestive heart failure as well, an illness that afflicts 10 percent of senior citizens and costs $35 billion each year in the United States. AI tools are helpful because they “predict in advance potential challenges ahead and allocate resources to patient education, sensing, and proactive interventions that keep patients out of the hospital.”22\n']","Petya was one of the debilitating viruses that certain key U.S.-based systems managed to stop, highlighting the challenges posed by polymorphic malware and the need for significant improvements to existing cyber defenses.",single_hop_specific_query_synthesizer
How machine learning help in criminal justice and what some people think about it?,"['Criminal justice\nAI is being deployed in the criminal justice area. The city of Chicago has developed an AI-driven “Strategic Subject List” that analyzes people who have been arrested for their risk of becoming future perpetrators. It ranks 400,000 people on a scale of 0 to 500, using items such as age, criminal activity, victimization, drug arrest records, and gang affiliation. In looking at the data, analysts found that youth is a strong predictor of violence, being a shooting victim is associated with becoming a future perpetrator, gang affiliation has little predictive value, and drug arrests are not significantly associated with future criminal activity.23\nJudicial experts claim AI programs reduce human bias in law enforcement and leads to a fairer sentencing system. R Street Institute Associate Caleb Watney writes:\nEmpirically grounded questions of predictive risk analysis play to the strengths of machine learning, automated reasoning and other forms of AI. One machine-learning policy simulation concluded that such programs could be used to cut crime up to 24.8 percent with no change in jailing rates, or reduce jail populations by up to 42 percent with no increase in crime rates.24\nHowever, critics worry that AI algorithms represent “a secret system to punish citizens for crimes they haven’t yet committed. The risk scores have been used numerous times to guide large-scale roundups.”25 The fear is that such tools target people of color unfairly and have not helped Chicago reduce the murder wave that has plagued it in recent years.\nDespite these concerns, other countries are moving ahead with rapid deployment in this area. In China, for example, companies already have “considerable resources and access to voices, faces and other biometric data in vast quantities, which would help them develop their technologies.”26 New technologies make it possible to match images and voices with other types of information, and to use AI on these combined data sets to improve law enforcement and national security. Through its “Sharp Eyes” program, Chinese law enforcement is matching video images, social media activity, online purchases, travel records, and personal identity into a “police cloud.” This integrated database enables authorities to keep track of criminals, potential law-breakers, and terrorists.27 Put differently, China has become the world’s leading AI-powered surveillance state.\n']","Machine learning is used in criminal justice, like in Chicago's AI-driven 'Strategic Subject List' that analyzes arrested individuals for their risk of becoming future perpetrators. It ranks people based on factors like age and criminal activity. Some judicial experts say AI can reduce human bias and lead to fairer sentencing. A machine-learning simulation suggested it could cut crime by up to 24.8 percent without changing jailing rates. However, critics argue that AI algorithms might unfairly target people of color and have not effectively reduced crime in Chicago. Other countries, like China, are rapidly deploying AI for law enforcement, creating extensive databases to track potential law-breakers.",single_hop_specific_query_synthesizer
What Cameron Kerry say about transportation?,"['Transportation\nTransportation represents an area where AI and machine learning are producing major innovations. Research by Cameron Kerry and Jack Karsten of the Brookings Institution has found that over $80 billion was invested in autonomous vehicle technology between August 2014 and June 2017. Those investments include applications both for autonomous driving and the core technologies vital to that sector.28\nAutonomous vehicles—cars, trucks, buses, and drone delivery systems—use advanced technological capabilities. Those features include automated vehicle guidance and braking, lane-changing systems, the use of cameras and sensors for collision avoidance, the use of AI to analyze information in real time, and the use of high-performance computing and deep learning systems to adapt to new circumstances through detailed maps.29\nLight detection and ranging systems (LIDARs) and AI are key to navigation and collision avoidance. LIDAR systems combine light and radar instruments. They are mounted on the top of vehicles that use imaging in a 360-degree environment from a radar and light beams to measure the speed and distance of surrounding objects. Along with sensors placed on the front, sides, and back of the vehicle, these instruments provide information that keeps fast-moving cars and trucks in their own lane, helps them avoid other vehicles, applies brakes and steering when needed, and does so instantly so as to avoid accidents.\nAdvanced software enables cars to learn from the experiences of other vehicles on the road and adjust their guidance systems as weather, driving, or road conditions change. This means that software is the key—not the physical car or truck itself.\nSince these cameras and sensors compile a huge amount of information and need to process it instantly to avoid the car in the next lane, autonomous vehicles require high-performance computing, advanced algorithms, and deep learning systems to adapt to new scenarios. This means that software is the key, not the physical car or truck itself.30 Advanced software enables cars to learn from the experiences of other vehicles on the road and adjust their guidance systems as weather, driving, or road conditions change.31\nRide-sharing companies are very interested in autonomous vehicles. They see advantages in terms of customer service and labor productivity. All of the major ride-sharing companies are exploring driverless cars. The surge of car-sharing and taxi services—such as Uber and Lyft in the United States, Daimler’s Mytaxi and Hailo service in Great Britain, and Didi Chuxing in China—demonstrate the opportunities of this transportation option. Uber recently signed an agreement to purchase 24,000 autonomous cars from Volvo for its ride-sharing service.32\nHowever, the ride-sharing firm suffered a setback in March 2018 when one of its autonomous vehicles in Arizona hit and killed a pedestrian. Uber and several auto manufacturers immediately suspended testing and launched investigations into what went wrong and how the fatality could have occurred.33 Both industry and consumers want reassurance that the technology is safe and able to deliver on its stated promises. Unless there are persuasive answers, this accident could slow AI advancements in the transportation sector.\n']","Cameron Kerry, along with Jack Karsten, found that over $80 billion was invested in autonomous vehicle technology between August 2014 and June 2017, highlighting major innovations in the transportation sector.",single_hop_specific_query_synthesizer
Who is Gregorey Dawson and what role does he play in the context of smart cities and AI?,"['Smart cities\nMetropolitan governments are using AI to improve urban service delivery. For example, according to Kevin Desouza, Rashmi Krishnamurthy, and Gregory Dawson:\nThe Cincinnati Fire Department is using data analytics to optimize medical emergency responses. The new analytics system recommends to the dispatcher an appropriate response to a medical emergency call—whether a patient can be treated on-site or needs to be taken to the hospital—by taking into account several factors, such as the type of call, location, weather, and similar calls.34\nSince it fields 80,000 requests each year, Cincinnati officials are deploying this technology to prioritize responses and determine the best ways to handle emergencies. They see AI as a way to deal with large volumes of data and figure out efficient ways of responding to public requests. Rather than address service issues in an ad hoc manner, authorities are trying to be proactive in how they provide urban services.\n']","Gregory Dawson is mentioned in the context of smart cities, specifically in relation to how metropolitan governments are using AI to improve urban service delivery. He, along with Kevin Desouza and Rashmi Krishnamurthy, discusses the use of data analytics by the Cincinnati Fire Department to optimize medical emergency responses.",single_hop_specific_query_synthesizer
How is Seattle utilizing AI in its smart city initiatives?,"['Smart cities\nMetropolitan governments are using AI to improve urban service delivery. For example, according to Kevin Desouza, Rashmi Krishnamurthy, and Gregory Dawson:\nThe Cincinnati Fire Department is using data analytics to optimize medical emergency responses. The new analytics system recommends to the dispatcher an appropriate response to a medical emergency call—whether a patient can be treated on-site or needs to be taken to the hospital—by taking into account several factors, such as the type of call, location, weather, and similar calls.34\nSince it fields 80,000 requests each year, Cincinnati officials are deploying this technology to prioritize responses and determine the best ways to handle emergencies. They see AI as a way to deal with large volumes of data and figure out efficient ways of responding to public requests. Rather than address service issues in an ad hoc manner, authorities are trying to be proactive in how they provide urban services.\nCincinnati is not alone. A number of metropolitan areas are adopting smart city applications that use AI to improve service delivery, environmental planning, resource management, energy utilization, and crime prevention, among other things. For its smart cities index, the magazine Fast Company ranked American locales and found Seattle, Boston, San Francisco, Washington, D.C., and New York City as the top adopters. Seattle, for example, has embraced sustainability and is using AI to manage energy usage and resource management. Boston has launched a “City Hall To Go” that makes sure underserved communities receive needed public services. It also has deployed “cameras and inductive loops to manage traffic and acoustic sensors to identify gun shots.” San Francisco has certified 203 buildings as meeting LEED sustainability standards.35\nThrough these and other means, metropolitan areas are leading the country in the deployment of AI solutions. Indeed, according to a National League of Cities report, 66 percent of American cities are investing in smart city technology. Among the top applications noted in the report are “smart meters for utilities, intelligent traffic signals, e-governance applications, Wi-Fi kiosks, and radio frequency identification sensors in pavement.”36\n Policy, regulatory, and ethical issues\nThese examples from a variety of sectors demonstrate how AI is transforming many walks of human existence. The increasing penetration of AI and autonomous devices into many aspects of life is altering basic operations and decisionmaking within organizations, and improving efficiency and response times.\nAt the same time, though, these developments raise important policy, regulatory, and ethical issues. For example, how should we promote data access? How do we guard against biased or unfair data used in algorithms? What types of ethical principles are introduced through software programming, and how transparent should designers be about their choices? What about questions of legal liability in cases where algorithms cause harm?37\nThe increasing penetration of AI into many aspects of life is altering decisionmaking within organizations and improving efficiency. At the same time, though, these developments raise important policy, regulatory, and ethical issues.\n']",Seattle has embraced sustainability and is using AI to manage energy usage and resource management as part of its smart city initiatives.,single_hop_specific_query_synthesizer
How does the McKinsey Global Institute view the relationship between open data sources and AI advancements?,"['Data access problems\nThe key to getting the most out of AI is having a “data-friendly ecosystem with unified standards and cross-platform sharing.” AI depends on data that can be analyzed in real time and brought to bear on concrete problems. Having data that are “accessible for exploration” in the research community is a prerequisite for successful AI development.38\nAccording to a McKinsey Global Institute study, nations that promote open data sources and data sharing are the ones most likely to see AI advances. In this regard, the United States has a substantial advantage over China. Global ratings on data openness show that U.S. ranks eighth overall in the world, compared to 93 for China.39\nBut right now, the United States does not have a coherent national data strategy. There are few protocols for promoting research access or platforms that make it possible to gain new insights from proprietary data. It is not always clear who owns data or how much belongs in the public sphere. These uncertainties limit the innovation economy and act as a drag on academic research. In the following section, we outline ways to improve data access for researchers.\n Biases in data and algorithms\nIn some instances, certain AI systems are thought to have enabled discriminatory or biased practices.40 For example, Airbnb has been accused of having homeowners on its platform who discriminate against racial minorities. A research project undertaken by the Harvard Business School found that “Airbnb users with distinctly African American names were roughly 16 percent less likely to be accepted as guests than those with distinctly white names.”41\nRacial issues also come up with facial recognition software. Most such systems operate by comparing a person’s face to a range of faces in a large database. As pointed out by Joy Buolamwini of the Algorithmic Justice League, “If your facial recognition data contains mostly Caucasian faces, that’s what your program will learn to recognize.”42 Unless the databases have access to diverse data, these programs perform poorly when attempting to recognize African-American or Asian-American features.\nMany historical data sets reflect traditional values, which may or may not represent the preferences wanted in a current system. As Buolamwini notes, such an approach risks repeating inequities of the past:\nThe rise of automation and the increased reliance on algorithms for high-stakes decisions such as whether someone get insurance or not, your likelihood to default on a loan or somebody’s risk of recidivism means this is something that needs to be addressed. Even admissions decisions are increasingly automated—what school our children go to and what opportunities they have. We don’t have to bring the structural inequalities of the past into the future we create.43\n']","According to a McKinsey Global Institute study, nations that promote open data sources and data sharing are the ones most likely to see AI advances. The study highlights that the United States has a substantial advantage over China in this regard, as global ratings on data openness show that the U.S. ranks eighth overall in the world, compared to 93 for China.",single_hop_specific_query_synthesizer
What insights does Jon Valant provide regarding algorithmic enrollment decisions in urban schools?,"['AI ethics and transparency\nAlgorithms embed ethical considerations and value choices into program decisions. As such, these systems raise questions concerning the criteria used in automated decisionmaking. Some people want to have a better understanding of how algorithms function and what choices are being made.44\nIn the United States, many urban schools use algorithms for enrollment decisions based on a variety of considerations, such as parent preferences, neighborhood qualities, income level, and demographic background. According to Brookings researcher Jon Valant, the New Orleans–based Bricolage Academy “gives priority to economically disadvantaged applicants for up to 33 percent of available seats. In practice, though, most cities have opted for categories that prioritize siblings of current students, children of school employees, and families that live in school’s broad geographic area.”45 Enrollment choices can be expected to be very different when considerations of this sort come into play.\nDepending on how AI systems are set up, they can facilitate the redlining of mortgage applications, help people discriminate against individuals they don’t like, or help screen or build rosters of individuals based on unfair criteria. The types of considerations that go into programming decisions matter a lot in terms of how the systems operate and how they affect customers.46\nFor these reasons, the EU is implementing the General Data Protection Regulation (GDPR) in May 2018. The rules specify that people have “the right to opt out of personally tailored ads” and “can contest ‘legal or similarly significant’ decisions made by algorithms and appeal for human intervention” in the form of an explanation of how the algorithm generated a particular outcome. Each guideline is designed to ensure the protection of personal data and provide individuals with information on how the “black box” operates.47\nLegal liability\nThere are questions concerning the legal liability of AI systems. If there are harms or infractions (or fatalities in the case of driverless cars), the operators of the algorithm likely will fall under product liability rules. A body of case law has shown that the situation’s facts and circumstances determine liability and influence the kind of penalties that are imposed. Those can range from civil fines to imprisonment for major harms.48 The Uber-related fatality in Arizona will be an important test case for legal liability. The state actively recruited Uber to test its autonomous vehicles and gave the company considerable latitude in terms of road testing. It remains to be seen if there will be lawsuits in this case and who is sued: the human backup driver, the state of Arizona, the Phoenix suburb where the accident took place, Uber, software developers, or the auto manufacturer. Given the multiple people and organizations involved in the road testing, there are many legal questions to be resolved.\n']","According to Brookings researcher Jon Valant, the New Orleans–based Bricolage Academy gives priority to economically disadvantaged applicants for up to 33 percent of available seats. However, most cities have opted for categories that prioritize siblings of current students, children of school employees, and families that live in the school’s broad geographic area, which can lead to very different enrollment choices.",single_hop_specific_query_synthesizer
What legal implications arise from the Uber-related fatality in Arizona?,"['A body of case law has shown that the situation’s facts and circumstances determine liability and influence the kind of penalties that are imposed. Those can range from civil fines to imprisonment for major harms.48 The Uber-related fatality in Arizona will be an important test case for legal liability. The state actively recruited Uber to test its autonomous vehicles and gave the company considerable latitude in terms of road testing. It remains to be seen if there will be lawsuits in this case and who is sued: the human backup driver, the state of Arizona, the Phoenix suburb where the accident took place, Uber, software developers, or the auto manufacturer. Given the multiple people and organizations involved in the road testing, there are many legal questions to be resolved.\nIn non-transportation areas, digital platforms often have limited liability for what happens on their sites. For example, in the case of Airbnb, the firm “requires that people agree to waive their right to sue, or to join in any class-action lawsuit or class-action arbitration, to use the service.” By demanding that its users sacrifice basic rights, the company limits consumer protections and therefore curtails the ability of people to fight discrimination arising from unfair algorithms.49 But whether the principle of neutral networks holds up in many sectors is yet to be determined on a widespread basis.\n Recommendations\nIn order to balance innovation with basic human values, we propose a number of recommendations for moving forward with AI. This includes improving data access, increasing government investment in AI, promoting AI workforce development, creating a federal advisory committee, engaging with state and local officials to ensure they enact effective policies, regulating broad objectives as opposed to specific algorithms, taking bias seriously as an AI issue, maintaining mechanisms for human control and oversight, and penalizing malicious behavior and promoting cybersecurity.\n']","The Uber-related fatality in Arizona will serve as an important test case for legal liability, as the state's recruitment of Uber to test its autonomous vehicles and the latitude given for road testing raise multiple legal questions. It remains uncertain who may be sued in this case, including the human backup driver, the state of Arizona, the Phoenix suburb where the accident occurred, Uber, software developers, or the auto manufacturer.",single_hop_specific_query_synthesizer
How can we improve data access to enhance research on Trump and other topics?,"['Improving data access\nThe United States should develop a data strategy that promotes innovation and consumer protection. Right now, there are no uniform standards in terms of data access, data sharing, or data protection. Almost all the data are proprietary in nature and not shared very broadly with the research community, and this limits innovation and system design. AI requires data to test and improve its learning capacity.50 Without structured and unstructured data sets, it will be nearly impossible to gain the full benefits of artificial intelligence.\nIn general, the research community needs better access to government and business data, although with appropriate safeguards to make sure researchers do not misuse data in the way Cambridge Analytica did with Facebook information. There is a variety of ways researchers could gain data access. One is through voluntary agreements with companies holding proprietary data. Facebook, for example, recently announced a partnership with Stanford economist Raj Chetty to use its social media data to explore inequality.51 As part of the arrangement, researchers were required to undergo background checks and could only access data from secured sites in order to protect user privacy and security.\nIn the U.S., there are no uniform standards in terms of data access, data sharing, or data protection. Almost all the data are proprietary in nature and not shared very broadly with the research community, and this limits innovation and system design.\nGoogle long has made available search results in aggregated form for researchers and the general public. Through its “Trends” site, scholars can analyze topics such as interest in Trump, views about democracy, and perspectives on the overall economy.52 That helps people track movements in public interest and identify topics that galvanize the general public.\nTwitter makes much of its tweets available to researchers through application programming interfaces, commonly referred to as APIs. These tools help people outside the company build application software and make use of data from its social media platform. They can study patterns of social media communications and see how people are commenting on or reacting to current events.\nIn some sectors where there is a discernible public benefit, governments can facilitate collaboration by building infrastructure that shares data. For example, the National Cancer Institute has pioneered a data-sharing protocol where certified researchers can query health data it has using de-identified information drawn from clinical data, claims information, and drug therapies. That enables researchers to evaluate efficacy and effectiveness, and make recommendations regarding the best medical approaches, without compromising the privacy of individual patients.\nThere could be public-private data partnerships that combine government and business data sets to improve system performance. For example, cities could integrate information from ride-sharing services with its own material on social service locations, bus lines, mass transit, and highway congestion to improve transportation. That would help metropolitan areas deal with traffic tie-ups and assist in highway and mass transit planning.\nSome combination of these approaches would improve data access for researchers, the government, and the business community, without impinging on personal privacy. As noted by Ian Buck, the vice president of NVIDIA, “Data is the fuel that drives the AI engine. The federal government has access to vast sources of information. Opening access to that data will help us get insights that will transform the U.S. economy.”53 Through its Data.gov portal, the federal government already has put over 230,000 data sets into the public domain, and this has propelled innovation and aided improvements in AI and data analytic technologies.54 The private sector also needs to facilitate research data access so that society can achieve the full benefits of artificial intelligence.\n']","Improving data access involves developing a data strategy that promotes innovation and consumer protection. Currently, there are no uniform standards for data access, sharing, or protection, which limits innovation. Researchers need better access to government and business data, with safeguards to prevent misuse. For instance, Google provides aggregated search results on topics like Trump through its Trends site, allowing scholars to analyze public interest. Twitter also offers access to tweets via APIs, enabling studies on social media communications. Public-private partnerships could further enhance data access, combining government and business data to improve system performance.",single_hop_specific_query_synthesizer
What does Figure 15 show about the GWA shares of work-classified messages and how does it relate to the overall functions of ChatGPT usage at work?,"['<1-hop>\n\nOverall, the majority of ChatGPT usage\nat work appears to be focused on two broad functions: 1) obtaining, documenting, and interpreting\ninformation; and 2) making decisions, giving advice, solving problems, and thinking creatively.\n20\x0cFigure 14:GWA Shares of 1.1M ChatGPT Messages. Messages are classified as pertaining to one of 332\nO*NET IWAs, orAmbiguoususing the prompt provided in the Appendix. IWAs were then aggregated to\nGWAs using the O*NET Work Activities taxonomy. Message sample from May 15, 2024 through June 26,\n2025. We do not show the shares for the following GWAs as there were fewer than 100 users sending messages\nfor each category and group them intoSuppressed.\n21\x0cFigure 15:GWA Shares of approximately 366,000 Work-Classified Messages. Messages are classified as\npertaining to one of 332 O*NET IWAs orAmbiguous. IWAs were then aggregated to GWAs using the\nO*NET Work Activities taxonomy. Messages were also additionally classified as pertaining to work or non-\nwork. GWA shares are shown only for work-classified messages. Message sample from May 15, 2024 through\nJune 26, 2025. We do not show the shares for the following GWAs as there were fewer than 100 users sending\nmessages for each category and group them intoSuppressed. Prompts are provided in the Appendix.\n22\x0c']","Figure 15 shows the GWA shares of approximately 366,000 work-classified messages, which are classified as pertaining to one of 332 O*NET IWAs or as ambiguous. This classification is part of the broader context where the majority of ChatGPT usage at work focuses on two main functions: obtaining, documenting, and interpreting information, as well as making decisions, giving advice, solving problems, and thinking creatively.",multi_hop_specific_query_synthesizer
How do ethical guidelines for AI and autonomous systems relate to the need for improved cybersecurity measures against malicious behavior?,"['<1-hop>\n\nAdaptability\nAI systems have the ability to learn and adapt as they make decisions. In the transportation area, for example, semi-autonomous vehicles have tools that let drivers and vehicles know about upcoming congestion, potholes, highway construction, or other possible traffic impediments. Vehicles can take advantage of the experience of other vehicles on the road, without human involvement, and the entire corpus of their achieved “experience” is immediately and fully transferable to other similarly configured vehicles. Their advanced algorithms, sensors, and cameras incorporate experience in current operations, and use dashboards and visual displays to present information in real time so human drivers are able to make sense of ongoing traffic and vehicular conditions. And in the case of fully autonomous vehicles, advanced systems can completely control the car or truck, and make all the navigational decisions.\n with artificially intelligent autonomous lethal systems, the Chinese and Russians are not nearly so mired in this debate, and we should anticipate our need to defend against these systems operating at hyperwar speeds. The challenge in the West of where to position “humans in the loop” in a hyperwar scenario will ultimately dictate the West’s capacity to be competitive in this new form of conflict.17 Just as AI will profoundly affect the speed of warfare, the proliferation of zero day or zero second cyber threats as well as polymorphic malware will challenge even the most sophisticated signature-based cyber protection. This forces significant improvement to existing cyber defenses. Increasingly, vulnerable systems are migrating, and will need to shift to a layered approach to cybersecurity with cloud-based, cognitive AI platforms. This approach moves the community toward a “thinking” defensive capability that can defend networks through constant training on known threats. This capability includes DNA-level analysis of heretofore unknown code, with the possibility of recognizing and stopping inbound malicious code by recognizing a string component of the file.', '<2-hop>\n\nIn the same vein, the IEEE Global Initiative has ethical guidelines for AI and autonomous systems. Its experts suggest that these models be programmed with consideration for widely accepted human norms and rules for behavior. AI algorithms need to take into effect the importance of these norms, how norm conflict can be resolved, and ways these systems can be transparent about norm resolution. Software designs should be programmed for “nondeception” and “honesty,” according to ethics experts. When failures occur, there must be mitigation mechanisms to deal with the consequences. In particular, AI must be sensitive to problems such as bias, discrimination, and fairness.68\nA group of machine learning experts claim it is possible to automate ethical decisionmaking. Using the trolley problem as a moral dilemma, they ask the following question: If an autonomous car goes out of control, should it be programmed to kill its own passengers or the pedestrians who are crossing the street? They devised a “voting-based system” that asked 1.3 million people to assess alternative scenarios, summarized the overall choices, and applied the overall perspective of these individuals to a range of vehicular possibilities. That allowed them to automate ethical decisionmaking in AI algorithms, taking public preferences into account.69 This procedure, of course, does not reduce the tragedy involved in any kind of fatality, such as seen in the Uber case, but it provides a mechanism to help AI developers incorporate ethical considerations in their planning.\n Penalize malicious behavior and promote cybersecurity\nAs with any emerging technology, it is important to discourage malicious treatment designed to trick software or use it for undesirable ends.70 This is especially important given the dual-use aspects of AI, where the same tool can be used for beneficial or malicious purposes. The malevolent use of AI exposes individuals and organizations to unnecessary risks and undermines the virtues of the emerging technology. This includes behaviors such as hacking, manipulating algorithms, compromising privacy and confidentiality, or stealing identities. Efforts to hijack AI in order to solicit confidential information should be seriously penalized as a way to deter such actions.71\nIn a rapidly changing world with many entities having advanced computing capabilities, there needs to be serious attention devoted to cybersecurity. Countries have to be careful to safeguard their own systems and keep other nations from damaging their security.72 According to the U.S. Department of Homeland Security, a major American bank receives around 11 million calls a week at its service center. In order to protect its telephony from denial of service attacks, it uses a “machine learning-based policy engine [that] blocks more than 120,000 calls per month based on voice firewall policies including harassing callers, robocalls and potential fraudulent calls.”73 This represents a way in which machine learning can help defend technology systems from malevolent attacks.\n']","The ethical guidelines for AI and autonomous systems, as suggested by the IEEE Global Initiative, emphasize the importance of programming AI with widely accepted human norms and rules for behavior. This includes considerations for bias, discrimination, and fairness, which are crucial in the context of cybersecurity. As malicious behaviors such as hacking and manipulating algorithms pose significant risks, the ethical programming of AI can help mitigate these threats. By promoting transparency and nondeception in AI systems, organizations can better defend against the dual-use aspects of AI that may lead to undesirable outcomes, thereby enhancing overall cybersecurity measures.",multi_hop_specific_query_synthesizer
"What are the start and end dates of the dataset that includes usage on consumer ChatGPT Plans, specifically mentioning July 31, 2025?","['<1-hop>\n\nWe describe the contents of each dataset, the sampling procedures that produced them, and the\nprivacy protections we implemented in constructing and employing them in analysis.\n 3.1 Growth Dataset\nWe compiled a dataset covering all usage on consumer ChatGPT Plans (Free, Plus, Pro) since Chat-\nGPT’s launch in November 2022. We exclude users on non-consumer plans (Business f.k.a. Teams,\n14The exact beginning and end dates of this sample are May 15, 2024 and June 26, 2025.\n15The exact beginning and end dates of this sample are May 15, 2024 and July 31, 2025.\n5\x0cEnterprise, Education).\nFor each user and day, this dataset reports the total number of messages sent by the user on that\nday. It also reports, for each message, de-identified user metadata, including the timestamp of their\nfirst interaction with ChatGPT, the country from which their account is registered, their subscription\nplan on each day, and their self-reported age (reported in coarse 5–7-year buckets to protect user\nprivacy).\n 3.2 Classified Messages\nTo understand usage while preserving user privacy, we construct message-level datasets without any\nhuman ever reading the contents of a message. See Figure 1 for an overview of the privacy-preserving\nclassification pipeline. Messages are categorized according to 5 different LLM-based classifiers. The\nclassifiers are introduced in more detail in Section 5, their exact text is reproduced in Appendix A,\nand our validation procedure is described in Appendix B.\n Sampled From All ChatGPT Users.We uniformly sampled approximately 1.1 million conver-\nsations, and then sampled one message within each conversation, with the following restrictions:\n1. We only include messages from May 2024 to July 2025.\n2. We exclude conversations from users who opted out of sharing their messages for model training.\n3. We exclude users who self-report their age as under 18.\n4. We exclude conversations that users have deleted and from users whose accounts have been\ndeactivated or banned.\n5. We exclude logged-out users, 16 which represented a minority share of ChatGPT users over the\nsample period.\nOur sample is drawn from a table that is itself sampled, where the sampling rate varied over time.\nWe thus adjust our sampling weights to maintain a fixed ratio with aggregate messages sent.\n Sampled From a Subset of ChatGPT Users.We construct two samples of classified messages\nfrom a subset of ChatGPT users (approximately 130,000 users). This sample of users does not include\nany users who opted out of sharing their messages for training, nor does it include users whose self-\nreported age is below 18, nor does it include users who have been banned or deleted their accounts.\nThe first sample contains classifications of 1.58 million messages from this subset of users, sampled\nat the conversation level (a conversation is a series of messages between the user and chatbot). This\nsample is constructed such that the user’s representation in the data is proportional to overall message\nvolume. The second sample contains messages sent from this subset of users, sampled at the user level\nwith up to six messages from each user in the group.\n16ChatGPT became available to logged-out users in April 2024, i.e., users could use ChatGPT without signing up\nfor an account with an email address. However, messages from logged-out users are only available in our dataset from\nMarch 2025, thus for consistency we drop all messages from logged-out users.\n6\x0cFigure 1:Illustration of Privacy-Preserving Automated Classification Pipeline (Synthetic Example). Mes-\nsages are first stripped of PII via an internal LLM-based tool calledPrivacy Filter. Then they are classified by\nLLM-based automated classifiers, described in detail in Appendices A and B. Humans do not see raw messages\nor PII-scrubbed messages, only the final classifications of messages.\n']","The dataset covering all usage on consumer ChatGPT Plans has a start date of May 15, 2024, and an end date of July 31, 2025.",multi_hop_specific_query_synthesizer
"What does Figure 10 illustrate about the distribution of user messages categorized by Asking, Doing, and Expressing intents, and how does this relate to the overall user intent in generative AI applications?","['<1-hop>\n\n5.3 User Intent\nExisting studies of the economic impacts of generative AI focus almost exclusively on the potential\nfor AI to perform workplace tasks, either augmenting or automating human labor (e.g. Eloundou et\nal. (2025), Handa et al. (2025), Tomlinson et al. (2025)). However, generative AI is a highly flexible\n16\x0ctechnology that can be used in many different ways. In order to learn more about how people seek to\nuse generative AI at work and outside of work, we introduce a classifier that is designed to measure the\ntype of output the user hopes to receive. Specifically, we classify messages according to user intent,\ncoding up conversations according to a simpleAsking, Doing, or Expressingrubric. The critical part\nof our classification prompt is as follows:\n Intent Prompt\nAskingAsking is seeking information or advice that will help the user be better\ninformed or make better decisions, either at work, at school, or in their\npersonal life. (e.g. “Who was president after Lincoln?”, “How do I create a\nbudget for this quarter?”, “What was the inflation rate last year?”,\n“What’s the difference between correlation and causation?”, “What should I\nlook for when choosing a health plan during open enrollment?”).\nDoingDoing messages request that ChatGPT perform tasks for the user. User is\ndrafting an email, writing code, etc. Classify messages as “doing” if they\ninclude requests for output that is created primarily by the model. (e.g.\n“Rewrite this email to make it more formal”, “Draft a report summarizing\nthe use cases of ChatGPT”, “Produce a project timeline with milestones\nand risks in a table”, “Extract companies, people, and dates from this text\ninto CSV.”, “Write a Dockerfile and a minimal docker-compose.yml for\nthis app.”)\nExpressingExpressing statements are neither asking for information, nor for the\nchatbot to perform a task.\nConceptually,Doingconversations are delivering output that can be plugged into a production\nprocess, whileAskingconversations support decision-making but do not produce output directly, and\nExpressingconversations have little or no economic content.\n Figure 10 shows the share of messages by each intent type in our sample. 49% of user messages\nareAsking, 40% areDoing, and 11% areExpressing. The figure also shows the relationship with\nour Topic classification: the two taxonomies are correlated but not redundant:Askingqueries are\nmore likely to bePractical GuidanceandSeeking Information.Doingqueries are disproportionately\nWritingandMultimedia.Expressingqueries are disproportionatelySelf-Expression. However, the\noverlap is imperfect. For example, within thePractical Guidancetopic, anAskingmessage might\nbe advice about how to recover from a sports injury given a user’s personal history, while aDoing\nmessage might request ChatGPT to produce a customized recovery and training plan that could be\nprinted or saved. WithinTechnical Help, anAskingmessage might request help understanding how\nto debug some code, while aDoingmessage might ask ChatGPT to write code for the user directly.\nFigure 11 presents shares ofAsking/Doing/Expressingjust for work-related messages.Doing\nconstitutes nearly 56% of work-related queries, compared to 35% forAskingand 9% forExpressing.\nNearly 35% of all work-related queries areDoingmessages related toWriting.DoingandAsking\ncomprise equal shares ofTechnical Helpqueries.\n17\x0cFigure 10:Breakdown of Conversation Topics by Asking/Doing/Expressing category, with topic columns\nsorted by relative share of ”Doing” messages. Prompts for these automated classifiers are available in Appendix\nA. For a detailed breakdown of conversation topic contents, see Table 3. Each bin reports a percentage of\nthe total population. ']","Figure 10 illustrates the distribution of user messages categorized by intent types: 49% of messages are classified as Asking, 40% as Doing, and 11% as Expressing. This breakdown indicates that a significant portion of user interactions with generative AI focuses on seeking information or advice (Asking) and performing tasks (Doing). The figure also highlights the correlation between these intent types and the topics of conversation, suggesting that Asking queries are more likely to fall under Practical Guidance and Seeking Information, while Doing queries are disproportionately related to Writing and Multimedia. This distribution reflects the diverse ways users engage with generative AI, both for decision-making support and task execution.",multi_hop_specific_query_synthesizer
"What does Figure 23 reveal about the variation in ChatGPT usage by user occupation, particularly in terms of work-related messages?","['<1-hop>\n\nFigure 22:Variation in ChatGPT usage by education. Each plot shows unadjusted vs. regression-adjusted estimates, with 95% confidence intervals. We regress each message share on education and occupation, control- ling for the following covariates: age, whether the name was typically masculine or feminine, seniority within role, company size, and industry. (To guarantee user privacy, we coarsen all covariates to broad categories and programmatically enforce that each group has at least 100 members prior to running the regression) We add the coefficients on each education and occupation category to the unadjusted value for the reference category and compute 95% confidence intervals using the standard errors from the regression coefficients. The sample for this regression is the approximately 40,000 users of the original 130,000 sample whose publicly available occupation was not blank or consisted of strictly special characters (as determined by a classification script). Shares for each user are calculated by randomly sampling up to six conversations attributed to the user from May 2024 through July 2025. 30 6.5 Variation by Occupation Figure 23 presents variation in ChatGPT usage by user occupation. Due to privacy-preserving aggre- gation limits, we report results for the following broad occupation categories – (1) all nonprofessional occupations, including administrative, clerical, service, and blue-collar occupations; (2) computer- related occupations; (3) engineering and science occupations; (4) management and business occupa- tions; and (5) all other professional occupations, including law, education, and health care. 26 As above, the left-hand side of the figure shows unadjusted comparisons and the right-hand side presents the coefficients on each occupation category from a regression of message shares on age, whether the name was typically masculine or feminine, education, occupation categories, job seniority, firm size, and industry. Users in highly paid professional and technical occupations are more likely to use ChatGPT for work.27 Panel A shows that the unadjusted work shares are 57% for computer-related occupations; 50% for management and business; 48% for engineering and science; 44% for other professional oc- cupations; and only 40% for all non-professional occupations. Regression adjustment moves these figures around slightly, but the gaps by occupation remain highly statistically significant. Users in highly-paid professional occupations are more likely to send work-related messages. Because work usage is so different by occupation, we restrict the sample only to work-related messages in Panels B and C. Panel B presents the share of work-related messages that areAsking messages, by occupation. We find that users in highly paid professional occupations are more likely to use ChatGPT forAskingrather thanDoing. 28 This is especially true in scientific and technical occupations. 47% of the work-related messages sent by users employed in computer-related occupa- tions areAskingmessages, compared to only 32% for non-professional occupations. These differences shrink somewhat with regression adjustment, but remain highly statistically significant. Panel C presents results by conversation topic.Writingis especially common for users employed in management and business occupations, accounting for 52% of all work-related messages. Writing is also relatively common in non-professional and other professional occupations like education and health care, accounting for 50% and 49% of work-related messages respectively.Technical Helpconsti- tutes 37% of all work-related messages for users employed in computer-related occupations, compared to 16% in engineering and science and only about 8% for all other categories. Regression adjustment affects gaps by occupation only modestly. Overall there are stark differences in the distribution of conversation topics by user occupation, with work-related messages clearly focused on the core tasks in each job (e.g.Writingfor management and business,Technical Helpfor technical occupations). We also present data on the most common Generalized Work Activities (GWAs) associated with each broad occupation group, as measured by 2-digit Standard Occupation Classification (SOC) codes. Table 24 presents the frequency ranking of work-related messages in each SOC code of the seven most common GWAs.29 26Management and business are SOC2 codes 11 and 13. Computer-related is SOC2 code 15. Engineering and Science are SOC2 codes 17 and 19. Other Professional are SOC2 codes 21 to 29. Nonprofessional occupations are SOC codes 31 to 53. 27As discussed in Section: Data and Privacy, our dataset only includes users on ChatGPT Consumer plans. Corporate users may also use ChatGPT Business (formerly known as Teams) or ChatGPT Enterprise. 28Very few work-related messages']","Figure 23 presents variation in ChatGPT usage by user occupation, highlighting that users in highly paid professional and technical occupations are more likely to use ChatGPT for work-related messages. Specifically, it shows that 57% of work-related messages come from computer-related occupations, followed by 50% from management and business, 48% from engineering and science, and 40% from all non-professional occupations. The figure also indicates that users in these professional roles tend to send more Asking messages compared to Doing messages, with 47% of work-related messages from computer-related occupations being Asking messages, in contrast to only 32% for non-professional occupations.",multi_hop_specific_query_synthesizer
What does Figure 3 show about the growth of ChatGPT users and how does it compare to the message volume growth shown in Figure 4?,"['<1-hop>\n\n4 The Growth of ChatGPT\nChatGPT was released to the public on November 30, 2022 as a “research preview,” and by December\n5 it had more than one million registered users. Figure 3 reports the growth of overall weekly active\nusers (WAU) on consumer plans over time. ChatGPT had more than 100 million logged-in WAU after\none year, and almost 350 million after two years. By the end of July 2025, ChatGPT had more than\n700 million total WAU, nearly 10% of the world’s adult population. 20\nFigure 3:Weekly active ChatGPT users on consumer plans (Free, Plus, Pro), shown as point-in-time\nsnapshots every six months, November 2022–September 2025.\nFigure 4 presents growth in the total messages sent by users over time. The solid line shows that\nbetween July 2024 and July 2025, the number of messages sent grew by a factor of more than 5.\nFigure 4 also shows the contribution of individual cohorts of users to aggregate message volume.\nThe yellow line represents the first cohort of ChatGPT users: their usage declined somewhat over\n2023, but started growing again in late 2024 and is now higher than it has ever been. The pink line\nrepresents messages from users who signed up in Q3 of 2023 or earlier, and so thedifferencebetween\n20Note that we expect our counts of distinct accounts to somewhat exceed distinct people when one person has two\naccounts (or, for logged-out users, one person using two devices). For logged-in users, the count is based on distinct\nlogin credentials (email addresses), and one person may have multiple accounts. For logged-out users, the count is based\non distinct browser cookies; this would double-count people if someone returns to ChatGPT after clearing their cookies,\nor if they access ChatGPT with two different devices in the same week.\n10\x0cFigure 4:Daily message volumes from ChatGPT consumer plans (Free, Plus, Pro), split by sign-up date of\nthe requesting user. ']","Figure 3 shows the growth of overall weekly active users (WAU) on consumer plans for ChatGPT, indicating that it had more than 100 million logged-in WAU after one year and almost 350 million after two years. By the end of July 2025, the total WAU is projected to exceed 700 million, which is nearly 10% of the world’s adult population. In contrast, Figure 4 presents the growth in the total messages sent by users over time, highlighting that between July 2024 and July 2025, the number of messages sent grew by a factor of more than 5, indicating a significant increase in user engagement despite the fluctuations in individual user cohorts.",multi_hop_specific_query_synthesizer
"How does the GDPR impact the use of algorithms in decision-making processes, particularly in relation to AI ethics and transparency?","['<1-hop>\n\nAI ethics and transparency\nAlgorithms embed ethical considerations and value choices into program decisions. As such, these systems raise questions concerning the criteria used in automated decisionmaking. Some people want to have a better understanding of how algorithms function and what choices are being made.44\nIn the United States, many urban schools use algorithms for enrollment decisions based on a variety of considerations, such as parent preferences, neighborhood qualities, income level, and demographic background. According to Brookings researcher Jon Valant, the New Orleans–based Bricolage Academy “gives priority to economically disadvantaged applicants for up to 33 percent of available seats. In practice, though, most cities have opted for categories that prioritize siblings of current students, children of school employees, and families that live in school’s broad geographic area.”45 Enrollment choices can be expected to be very different when considerations of this sort come into play.\nDepending on how AI systems are set up, they can facilitate the redlining of mortgage applications, help people discriminate against individuals they don’t like, or help screen or build rosters of individuals based on unfair criteria. The types of considerations that go into programming decisions matter a lot in terms of how the systems operate and how they affect customers.46\nFor these reasons, the EU is implementing the General Data Protection Regulation (GDPR) in May 2018. The rules specify that people have “the right to opt out of personally tailored ads” and “can contest ‘legal or similarly significant’ decisions made by algorithms and appeal for human intervention” in the form of an explanation of how the algorithm generated a particular outcome. Each guideline is designed to ensure the protection of personal data and provide individuals with information on how the “black box” operates.47\nLegal liability\nThere are questions concerning the legal liability of AI systems. If there are harms or infractions (or fatalities in the case of driverless cars), the operators of the algorithm likely will fall under product liability rules. A body of case law has shown that the situation’s facts and circumstances determine liability and influence the kind of penalties that are imposed. Those can range from civil fines to imprisonment for major harms.48 The Uber-related fatality in Arizona will be an important test case for legal liability. The state actively recruited Uber to test its autonomous vehicles and gave the company considerable latitude in terms of road testing. It remains to be seen if there will be lawsuits in this case and who is sued: the human backup driver, the state of Arizona, the Phoenix suburb where the accident took place, Uber, software developers, or the auto manufacturer. Given the multiple people and organizations involved in the road testing, there are many legal questions to be resolved.\n', '<2-hop>\n\nEngage with state and local officials\nStates and localities also are taking action on AI. For example, the New York City Council unanimously passed a bill that directed the mayor to form a taskforce that would “monitor the fairness and validity of algorithms used by municipal agencies.”60 The city employs algorithms to “determine if a lower bail will be assigned to an indigent defendant, where firehouses are established, student placement for public schools, assessing teacher performance, identifying Medicaid fraud and determine where crime will happen next.”61\nAccording to the legislation’s developers, city officials want to know how these algorithms work and make sure there is sufficient AI transparency and accountability. In addition, there is concern regarding the fairness and biases of AI algorithms, so the taskforce has been directed to analyze these issues and make recommendations regarding future usage. It is scheduled to report back to the mayor on a range of AI policy, legal, and regulatory issues by late 2019.\nSome observers already are worrying that the taskforce won’t go far enough in holding algorithms accountable. For example, Julia Powles of Cornell Tech and New York University argues that the bill originally required companies to make the AI source code available to the public for inspection, and that there be simulations of its decisionmaking using actual data. After criticism of those provisions, however, former Councilman James Vacca dropped the requirements in favor of a task force studying these issues. He and other city officials were concerned that publication of proprietary information on algorithms would slow innovation and make it difficult to find AI vendors who would work with the city.62 It remains to be seen how this local task force will balance issues of innovation, privacy, and transparency.\n Regulate broad objectives more than specific algorithms\nThe European Union has taken a restrictive stance on these issues of data collection and analysis.63 It has rules limiting the ability of companies from collecting data on road conditions and mapping street views. Because many of these countries worry that people’s personal information in unencrypted Wi-Fi networks are swept up in overall data collection, the EU has fined technology firms, demanded copies of data, and placed limits on the material collected.64 This has made it more difficult for technology companies operating there to develop the high-definition maps required for autonomous vehicles.\nThe GDPR being implemented in Europe place severe restrictions on the use of artificial intelligence and machine learning. According to published guidelines, “Regulations prohibit any automated decision that ‘significantly affects’ EU citizens. This includes techniques that evaluates a person’s ‘performance at work, economic situation, health, personal preferences, interests, reliability, behavior, location, or movements.’”65 In addition, these new rules give citizens the right to review how digital services made specific algorithmic choices affecting people.\nBy taking a restrictive stance on issues of data collection and analysis, the European Union is putting its manufacturers and software designers at a significant disadvantage to the rest of the world.\nIf interpreted stringently, these rules will make it difficult for European software designers (and American designers who work with European counterparts) to incorporate artificial intelligence and high-definition mapping in autonomous vehicles. Central to navigation in these cars and trucks is tracking location and movements. Without high-definition maps containing geo-coded data and the deep learning that makes use of this information, fully autonomous driving will stagnate in Europe. Through this and other data protection actions, the European Union is putting its manufacturers and software designers at a significant disadvantage to the rest of the world.\nIt makes more sense to think about the broad objectives desired in AI and enact policies that advance them, as opposed to governments trying to crack open the “black boxes” and see exactly how specific algorithms operate. Regulating individual algorithms will limit innovation and make it difficult for companies to make use of artificial intelligence.\n']","The GDPR impacts the use of algorithms in decision-making processes by imposing severe restrictions on automated decisions that significantly affect EU citizens. It ensures that individuals have the right to contest legal decisions made by algorithms and to receive explanations about how these decisions were reached. This aligns with the broader themes of AI ethics and transparency, as the GDPR aims to protect personal data and provide insights into the functioning of algorithms, which are often viewed as 'black boxes.' By requiring transparency, the GDPR seeks to address ethical concerns regarding the fairness and biases inherent in algorithmic decision-making.",multi_hop_specific_query_synthesizer
What does Figure 29 illustrate regarding the bias between the model and human plurality in the context of conversation classification?,"['<1-hop>\n\nhuman–human agreement (κ= 0.66). The heatmap in Figure 25 indicates close alignment with the human plurality and limited systematic bias. B.1.2 Asking/Doing/Expressing Classifier Human annotations exhibit substantial agreement (mean human–human Cohen’sκ= 0.60), and the classifier improves on this benchmark withκ= 0.74 against the human plurality (Table 5). Figures 26 and 27 show that most confusion arises betweenAskingandDoing; the classifier is somewhat more likely than humans to assignDoing. This pattern suggests that the prominence ofAskinguse cases in our main results is unlikely to be an artifact of misclassification. B.1.3 Conversation Topic Agreement between the model and the human plurality is moderate to substantial (Cohen’sκ= 0.56), improving on the mean human–human agreement (κ= 0.47). Misclassifications are concentrated betweenSeeking InformationandPractical Guidance(Figure 28), which are conceptually adjacent categories. Relative to human annotators, the model under-labelsSeeking Information,Technical Help, andSelf-Expression, and over-labelsPractical Guidance,Multimedia, andOther(Figure 29). 32Ties were broken by a senior annotator. 53 Figure 25:Agreement between Model and Human Plurality. Figure 26:Agreement Between Model and Plurality for Asking/Doing/Expressing 54 Figure 27:Per-label Bias, Model vs Plurality for Asking/Doing/Expressing Figure 28:Agreement Between Model and Plurality for Convo-Classifier 55 Figure 29:Bias Between Model and Plurality for Convo-Classifier B.1.4 O*NET Intermediate Work Activity Two human labelers labeled 100 WildChat messages over 332 O*NET IWAs, with an additional category for when a message was ambiguous. Human labels were compared with LLM outputs. In practice, we found the ambiguous category was chosen when the user was simply greeting the model or submitted an empty prompt. In this validation set, we report Fleiss’sκfor both the direct IWA classification (κ= 0.47), as well as the GWA aggregation (κ= 0.40). When only examining human outputs we see Cohen’sκof 0.27. From review, we observe this moderate human-pair agreement due to the large number of potential classes (IWA has 332 activities) as well as inherent ambiguity in the messages. For instance, if a user in the WildChat dataset was trying to generate a fictional short story, one human label might beDevelop news, entertainment, or artistic content, while another human label could beWrite material for artistic or commercial purposes. These two IWAs also belong to different GWAs despite being conceptually similar. B.1.5 Interaction Quality Classifier Human and model annotations of interaction quality are noisy. The classifier attains only slight agree- ment with the human plurality (Cohen’sκ= 0.14), below the likewise modest mean human–human agreement (κ= 0.20; Table 5). Figures 30 and 31 show weak concordance overall and a mild tendency for the model to assignBadless frequently than humans. This contrasts with our small development set, in which GPT-5 labeledBadmore often than humans. We retain this classifier because theseκ statistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text alone. While this latent “prior” is unobserved in our validation data, it is partially observable when users provide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned 56 Figure 30:Agreement Between Model and Plurality for Interaction Quality Figure 31:Bias Between Model and Plurality for Interaction Quality 57 with user experience, we link model predictions to voluntary feedback on assistant messages. We draw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i) the assistant message received explicit feedback and (ii) the user sent a subsequent message that our classifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not be fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy user satisfaction.']","Figure 29 illustrates the bias between the model and human plurality for the conversation classifier. It indicates that the model tends to over-label categories such as Practical Guidance, Multimedia, and Other, while under-labeling categories like Seeking Information, Technical Help, and Self-Expression. This suggests a discrepancy in how the model interprets conversation topics compared to human annotators, highlighting the challenges in achieving alignment between automated classifications and human judgments.",multi_hop_specific_query_synthesizer
What does the McKinsey Global Institute say about the importance of data access for AI development and how does it compare the United States and China in this regard?,"['<1-hop>\n\nApplications in diverse sectors AI is not a futuristic vision, but rather something that is here today and being integrated with and deployed into a variety of sectors. This includes fields such as finance, national security, health care, criminal justice, transportation, and smart cities. There are numerous examples where AI already is making an impact on the world and augmenting human capabilities in significant ways.6 One of the reasons for the growing role of AI is the tremendous opportunities for economic development that it presents. A project undertaken by PriceWaterhouseCoopers estimated that “artificial intelligence technologies could increase global GDP by $15.7 trillion, a full 14%, by 2030.”7 That includes advances of $7 trillion in China, $3.7 trillion in North America, $1.8 trillion in Northern Europe, $1.2 trillion for Africa and Oceania, $0.9 trillion in the rest of Asia outside of China, $0.7 trillion in Southern Europe, and $0.5 trillion in Latin America. China is making rapid strides because it has set a national goal of investing $150 billion in AI and becoming the global leader in this area by 2030. Meanwhile, a McKinsey Global Institute study of China found that “AI-led automation can give the Chinese economy a productivity injection that would add 0.8 to 1.4 percentage points to GDP growth annually, depending on the speed of adoption.”8 Although its authors found that China currently lags the United States and the United Kingdom in AI deployment, the sheer size of its AI market gives that country tremendous opportunities for pilot testing and future development. Finance Investments in financial AI in the United States tripled between 2013 and 2014 to a total of $12.2 billion.9 According to observers in that sector, “Decisions about loans are now being made by software that can take into account a variety of finely parsed data about a borrower, rather than just a credit score and a background check.”10 In addition, there are so-called robo-advisers that “create personalized investment portfolios, obviating the need for stockbrokers and financial advisers.”11 These advances are designed to take the emotion out of investing and undertake decisions based on analytical considerations, and make these choices in a matter of minutes. A prominent example of this is taking place in stock exchanges, where high-frequency trading by machines has replaced much of human decisionmaking. People submit buy and sell orders, and computers match them in the blink of an eye without human intervention. Machines can spot trading inefficiencies or market differentials on a very small scale and execute trades that make money according to investor instructions.12 Powered in some places by advanced computing, these tools have much greater capacities for storing information because of their emphasis not on a zero or a one, but on “quantum bits” that can store multiple values in each location.13 That dramatically increases storage capacity and decreases processing times. Fraud detection represents another way AI is helpful in financial systems. It sometimes is difficult to discern fraudulent activities in large organizations, but AI can identify abnormalities, outliers, or deviant cases requiring additional investigation. That helps managers find problems early in the cycle, before they reach dangerous levels.14 National security AI plays a substantial role in national defense. Through its Project Maven, the American military is deploying AI “to sift through the massive troves of data and video captured by surveillance and then alert human analysts of patterns or when there is abnormal or suspicious activity.”15 According to Deputy Secretary of Defense Patrick Shanahan, the goal of emerging technologies in this area is “to meet our warfighters’ needs and to increase [the] speed and agility [of] technology development and procurement.”16 Artificial intelligence will accelerate the traditional process of warfare so rapidly that a new term has been coined: hyperwar. The big data analytics associated with AI will profoundly affect intelligence analysis, as massive amounts of data are sifted in near real time—if not eventually in real time—thereby providing commanders and their staffs a level of intelligence analysis and productivity heretofore unseen. Command and control will similarly be affected as human commanders delegate certain routine, and in special circumstances, key decisions to AI platforms, reducing dramatically the time associated with the decision and subsequent action. In the end, warfare is a time competitive process, where the side able to decide the fastest and move most quickly to execution will generally prevail. Indeed, artificially intelligent intelligence systems, tied to AI-assisted command and control systems, can move decision support and decisionmaking to a speed vastly superior to the speeds of the traditional means of waging war. So fast will be this process, especially if coupled to automatic decisions to launch artificially intelligent autonomous weapons systems capable of lethal outcomes, that a new term has been coined specifically to embrace the speed at which war will be waged: hyperwar. While the ethical and legal debate is raging over whether America will ever wage war', '<2-hop>\n\nData access problems\nThe key to getting the most out of AI is having a “data-friendly ecosystem with unified standards and cross-platform sharing.” AI depends on data that can be analyzed in real time and brought to bear on concrete problems. Having data that are “accessible for exploration” in the research community is a prerequisite for successful AI development.38\nAccording to a McKinsey Global Institute study, nations that promote open data sources and data sharing are the ones most likely to see AI advances. In this regard, the United States has a substantial advantage over China. Global ratings on data openness show that U.S. ranks eighth overall in the world, compared to 93 for China.39\nBut right now, the United States does not have a coherent national data strategy. There are few protocols for promoting research access or platforms that make it possible to gain new insights from proprietary data. It is not always clear who owns data or how much belongs in the public sphere. These uncertainties limit the innovation economy and act as a drag on academic research. In the following section, we outline ways to improve data access for researchers.\n Biases in data and algorithms\nIn some instances, certain AI systems are thought to have enabled discriminatory or biased practices.40 For example, Airbnb has been accused of having homeowners on its platform who discriminate against racial minorities. A research project undertaken by the Harvard Business School found that “Airbnb users with distinctly African American names were roughly 16 percent less likely to be accepted as guests than those with distinctly white names.”41\nRacial issues also come up with facial recognition software. Most such systems operate by comparing a person’s face to a range of faces in a large database. As pointed out by Joy Buolamwini of the Algorithmic Justice League, “If your facial recognition data contains mostly Caucasian faces, that’s what your program will learn to recognize.”42 Unless the databases have access to diverse data, these programs perform poorly when attempting to recognize African-American or Asian-American features.\nMany historical data sets reflect traditional values, which may or may not represent the preferences wanted in a current system. As Buolamwini notes, such an approach risks repeating inequities of the past:\nThe rise of automation and the increased reliance on algorithms for high-stakes decisions such as whether someone get insurance or not, your likelihood to default on a loan or somebody’s risk of recidivism means this is something that needs to be addressed. Even admissions decisions are increasingly automated—what school our children go to and what opportunities they have. We don’t have to bring the structural inequalities of the past into the future we create.43\n']","The McKinsey Global Institute emphasizes that having a 'data-friendly ecosystem with unified standards and cross-platform sharing' is crucial for maximizing the potential of AI. It states that nations promoting open data sources and data sharing are more likely to see advancements in AI. In this context, the United States has a significant advantage over China, ranking eighth overall in global ratings on data openness, while China ranks 93rd. However, the U.S. currently lacks a coherent national data strategy, which limits innovation and academic research.",multi_hop_specific_query_synthesizer
How does IBM's Teacher Advisor program contribute to STEM education in the context of AI's impact on society?,"['<1-hop>\n\nIncrease government investment in AI\nAccording to Greg Brockman, the co-founder of OpenAI, the U.S. federal government invests only $1.1 billion in non-classified AI technology.55 That is far lower than the amount being spent by China or other leading nations in this area of research. That shortfall is noteworthy because the economic payoffs of AI are substantial. In order to boost economic development and social innovation, federal officials need to increase investment in artificial intelligence and data analytics. Higher investment is likely to pay for itself many times over in economic and social benefits.56\n Promote digital education and workforce development\nAs AI applications accelerate across many sectors, it is vital that we reimagine our educational institutions for a world where AI will be ubiquitous and students need a different kind of training than they currently receive. Right now, many students do not receive instruction in the kinds of skills that will be needed in an AI-dominated landscape. For example, there currently are shortages of data scientists, computer scientists, engineers, coders, and platform developers. These are skills that are in short supply; unless our educational system generates more people with these capabilities, it will limit AI development.\nFor these reasons, both state and federal governments have been investing in AI human capital. For example, in 2017, the National Science Foundation funded over 6,500 graduate students in computer-related fields and has launched several new initiatives designed to encourage data and computer science at all levels from pre-K to higher and continuing education.57 The goal is to build a larger pipeline of AI and data analytic personnel so that the United States can reap the full advantages of the knowledge revolution.\nBut there also needs to be substantial changes in the process of learning itself. It is not just technical skills that are needed in an AI world but skills of critical reasoning, collaboration, design, visual display of information, and independent thinking, among others. AI will reconfigure how society and the economy operate, and there needs to be “big picture” thinking on what this will mean for ethics, governance, and societal impact. People will need the ability to think broadly about many questions and integrate knowledge from a number of different areas.\nOne example of new ways to prepare students for a digital future is IBM’s Teacher Advisor program, utilizing Watson’s free online tools to help teachers bring the latest knowledge into the classroom. They enable instructors to develop new lesson plans in STEM and non-STEM fields, find relevant instructional videos, and help students get the most out of the classroom.58 As such, they are precursors of new educational environments that need to be created.\n', '<2-hop>\n\nAI will reconfigure how society and the economy operate, and there needs to be “big picture” thinking on what this will mean for ethics, governance, and societal impact. People will need the ability to think broadly about many questions and integrate knowledge from a number of different areas.\nOne example of new ways to prepare students for a digital future is IBM’s Teacher Advisor program, utilizing Watson’s free online tools to help teachers bring the latest knowledge into the classroom. They enable instructors to develop new lesson plans in STEM and non-STEM fields, find relevant instructional videos, and help students get the most out of the classroom.58 As such, they are precursors of new educational environments that need to be created.\n Create a federal AI advisory committee\nFederal officials need to think about how they deal with artificial intelligence. As noted previously, there are many issues ranging from the need for improved data access to addressing issues of bias and discrimination. It is vital that these and other concerns be considered so we gain the full benefits of this emerging technology.\nIn order to move forward in this area, several members of Congress have introduced the “Future of Artificial Intelligence Act,” a bill designed to establish broad policy and legal principles for AI. It proposes the secretary of commerce create a federal advisory committee on the development and implementation of artificial intelligence. The legislation provides a mechanism for the federal government to get advice on ways to promote a “climate of investment and innovation to ensure the global competitiveness of the United States,” “optimize the development of artificial intelligence to address the potential growth, restructuring, or other changes in the United States workforce,” “support the unbiased development and application of artificial intelligence,” and “protect the privacy rights of individuals.”59\nAmong the specific questions the committee is asked to address include the following: competitiveness, workforce impact, education, ethics training, data sharing, international cooperation, accountability, machine learning bias, rural impact, government efficiency, investment climate, job impact, bias, and consumer impact. The committee is directed to submit a report to Congress and the administration 540 days after enactment regarding any legislative or administrative action needed on AI.\nThis legislation is a step in the right direction, although the field is moving so rapidly that we would recommend shortening the reporting timeline from 540 days to 180 days. Waiting nearly two years for a committee report will certainly result in missed opportunities and a lack of action on important issues. Given rapid advances in the field, having a much quicker turnaround time on the committee analysis would be quite beneficial.\n']","IBM's Teacher Advisor program contributes to STEM education by utilizing Watson’s free online tools to help teachers integrate the latest knowledge into the classroom. This program enables instructors to develop new lesson plans in STEM and non-STEM fields, find relevant instructional videos, and enhance student engagement. As AI reconfigures how society and the economy operate, such educational initiatives are crucial for preparing students with the necessary skills to thrive in an AI-dominated landscape.",multi_hop_specific_query_synthesizer
"What are the differences in ChatGPT usage for work-related messages among various occupations, particularly in relation to ChatGPT Business?","['<1-hop>\n\nCorporate\nusers may also use ChatGPT Business (formerly known as Teams) or ChatGPT Enterprise.\n28Very few work-related messages are classified asExpressing.\n29Appendix D contains a full report of GWA counts broken down by occupation, for both work-related ChatGPT\n31\x0cWe find remarkable similarity across occupations in how ChatGPT is used at work. For example,\nMaking Decisions and Solving Problemsis one of the two most common GWAs in every single oc-\ncupation group where at least two GWAs can be reported. 30 Similarly,Documenting and Recording\nInformationranks in the top four of all occupations.Thinking Creativelyis ranked as the third most\ncommon GWA in 10 of the 13 occupation groups where at least three GWAs can be reported. Even\nthough there are 41 GWAs, the seven most common overall are also the most common within each\noccupation group and are ranked similarly. Not surprisingly,Working with Computersis the most\ncommon GWA in computer-related occupations. In the appendix, we report the full distribution of\nGWA classifications intersected with two-digit SOC codes, as well as the most frequently requested\nGWAs out of the subset of queries which are work-related. Across all occupations, ChatGPT usage\nis broadly focused on seeking information and assistance with decision-making.\nusage and all ChatGPT usage.\n30For legal and food service occupations, we are only able to rank one of the GWAs because of user privacy protections\n- no other GWAs were requested by more than 100 users in that group.\n32\x0c Panel A.Work Related\n Panel B1.Asking. Panel B2.Doing.\nFigure 23:(continued on next page)\n33\x0c Panel C1.Writing. Panel C2.Technical Help.\n', '<2-hop>\n\nFigure 22:Variation in ChatGPT usage by education. Each plot shows unadjusted vs. regression-adjusted estimates, with 95% confidence intervals. We regress each message share on education and occupation, control- ling for the following covariates: age, whether the name was typically masculine or feminine, seniority within role, company size, and industry. (To guarantee user privacy, we coarsen all covariates to broad categories and programmatically enforce that each group has at least 100 members prior to running the regression) We add the coefficients on each education and occupation category to the unadjusted value for the reference category and compute 95% confidence intervals using the standard errors from the regression coefficients. The sample for this regression is the approximately 40,000 users of the original 130,000 sample whose publicly available occupation was not blank or consisted of strictly special characters (as determined by a classification script). Shares for each user are calculated by randomly sampling up to six conversations attributed to the user from May 2024 through July 2025. 30 6.5 Variation by Occupation Figure 23 presents variation in ChatGPT usage by user occupation. Due to privacy-preserving aggre- gation limits, we report results for the following broad occupation categories – (1) all nonprofessional occupations, including administrative, clerical, service, and blue-collar occupations; (2) computer- related occupations; (3) engineering and science occupations; (4) management and business occupa- tions; and (5) all other professional occupations, including law, education, and health care. 26 As above, the left-hand side of the figure shows unadjusted comparisons and the right-hand side presents the coefficients on each occupation category from a regression of message shares on age, whether the name was typically masculine or feminine, education, occupation categories, job seniority, firm size, and industry. Users in highly paid professional and technical occupations are more likely to use ChatGPT for work.27 Panel A shows that the unadjusted work shares are 57% for computer-related occupations; 50% for management and business; 48% for engineering and science; 44% for other professional oc- cupations; and only 40% for all non-professional occupations. Regression adjustment moves these figures around slightly, but the gaps by occupation remain highly statistically significant. Users in highly-paid professional occupations are more likely to send work-related messages. Because work usage is so different by occupation, we restrict the sample only to work-related messages in Panels B and C. Panel B presents the share of work-related messages that areAsking messages, by occupation. We find that users in highly paid professional occupations are more likely to use ChatGPT forAskingrather thanDoing. 28 This is especially true in scientific and technical occupations. 47% of the work-related messages sent by users employed in computer-related occupa- tions areAskingmessages, compared to only 32% for non-professional occupations. These differences shrink somewhat with regression adjustment, but remain highly statistically significant. Panel C presents results by conversation topic.Writingis especially common for users employed in management and business occupations, accounting for 52% of all work-related messages. Writing is also relatively common in non-professional and other professional occupations like education and health care, accounting for 50% and 49% of work-related messages respectively.Technical Helpconsti- tutes 37% of all work-related messages for users employed in computer-related occupations, compared to 16% in engineering and science and only about 8% for all other categories. Regression adjustment affects gaps by occupation only modestly. Overall there are stark differences in the distribution of conversation topics by user occupation, with work-related messages clearly focused on the core tasks in each job (e.g.Writingfor management and business,Technical Helpfor technical occupations). We also present data on the most common Generalized Work Activities (GWAs) associated with each broad occupation group, as measured by 2-digit Standard Occupation Classification (SOC) codes. Table 24 presents the frequency ranking of work-related messages in each SOC code of the seven most common GWAs.29 26Management and business are SOC2 codes 11 and 13. Computer-related is SOC2 code 15. Engineering and Science are SOC2 codes 17 and 19. Other Professional are SOC2 codes 21 to 29. Nonprofessional occupations are SOC codes 31 to 53. 27As discussed in Section: Data and Privacy, our dataset only includes users on ChatGPT Consumer plans. Corporate users may also use ChatGPT Business (formerly known as Teams) or ChatGPT Enterprise. 28Very few work-related messages']","ChatGPT usage for work-related messages varies significantly among different occupations. Users in highly paid professional and technical occupations, such as computer-related fields, are more likely to utilize ChatGPT for work, with 57% of their messages being work-related. In contrast, only 40% of messages from non-professional occupations are work-related. Additionally, users in management and business occupations tend to focus on writing, accounting for 52% of their work-related messages, while those in computer-related occupations often seek technical help, which constitutes 37% of their messages. This variation highlights the tailored use of ChatGPT Business (formerly known as Teams) and ChatGPT Enterprise among different professional groups.",multi_hop_specific_query_synthesizer
What are the differences in user intent classifications between the findings of Handa et al. (2025) and the ChatGPT usage data regarding work-related messages?,"['<1-hop>\n\n5.3 User Intent\nExisting studies of the economic impacts of generative AI focus almost exclusively on the potential\nfor AI to perform workplace tasks, either augmenting or automating human labor (e.g. Eloundou et\nal. (2025), Handa et al. (2025), Tomlinson et al. (2025)). However, generative AI is a highly flexible\n16\x0ctechnology that can be used in many different ways. In order to learn more about how people seek to\nuse generative AI at work and outside of work, we introduce a classifier that is designed to measure the\ntype of output the user hopes to receive. Specifically, we classify messages according to user intent,\ncoding up conversations according to a simpleAsking, Doing, or Expressingrubric. The critical part\nof our classification prompt is as follows:\n Intent Prompt\nAskingAsking is seeking information or advice that will help the user be better\ninformed or make better decisions, either at work, at school, or in their\npersonal life. (e.g. “Who was president after Lincoln?”, “How do I create a\nbudget for this quarter?”, “What was the inflation rate last year?”,\n“What’s the difference between correlation and causation?”, “What should I\nlook for when choosing a health plan during open enrollment?”).\nDoingDoing messages request that ChatGPT perform tasks for the user. User is\ndrafting an email, writing code, etc. Classify messages as “doing” if they\ninclude requests for output that is created primarily by the model. (e.g.\n“Rewrite this email to make it more formal”, “Draft a report summarizing\nthe use cases of ChatGPT”, “Produce a project timeline with milestones\nand risks in a table”, “Extract companies, people, and dates from this text\ninto CSV.”, “Write a Dockerfile and a minimal docker-compose.yml for\nthis app.”)\nExpressingExpressing statements are neither asking for information, nor for the\nchatbot to perform a task.\nConceptually,Doingconversations are delivering output that can be plugged into a production\nprocess, whileAskingconversations support decision-making but do not produce output directly, and\nExpressingconversations have little or no economic content.\n Figure 10 shows the share of messages by each intent type in our sample. 49% of user messages\nareAsking, 40% areDoing, and 11% areExpressing. The figure also shows the relationship with\nour Topic classification: the two taxonomies are correlated but not redundant:Askingqueries are\nmore likely to bePractical GuidanceandSeeking Information.Doingqueries are disproportionately\nWritingandMultimedia.Expressingqueries are disproportionatelySelf-Expression. However, the\noverlap is imperfect. For example, within thePractical Guidancetopic, anAskingmessage might\nbe advice about how to recover from a sports injury given a user’s personal history, while aDoing\nmessage might request ChatGPT to produce a customized recovery and training plan that could be\nprinted or saved. WithinTechnical Help, anAskingmessage might request help understanding how\nto debug some code, while aDoingmessage might ask ChatGPT to write code for the user directly.\nFigure 11 presents shares ofAsking/Doing/Expressingjust for work-related messages.Doing\nconstitutes nearly 56% of work-related queries, compared to 35% forAskingand 9% forExpressing.\nNearly 35% of all work-related queries areDoingmessages related toWriting.DoingandAsking\ncomprise equal shares ofTechnical Helpqueries.\n17\x0cFigure 10:Breakdown of Conversation Topics by Asking/Doing/Expressing category, with topic columns\nsorted by relative share of ”Doing” messages. Prompts for these automated classifiers are available in Appendix\nA. For a detailed breakdown of conversation topic contents, see Table 3. Each bin reports a percentage of\nthe total population. ', '<2-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9']","The findings of Handa et al. (2025) indicate that 37% of conversations are mapped to a 'computer and mathematical' occupation category, with a significant portion of tasks being programming or IT-related. In contrast, the ChatGPT usage data reveals that only 4.2% of messages are related to computer programming. Additionally, while Handa et al. report that 30% or more of all imputed tasks are programming-related, the ChatGPT data shows that the most common use case at work is Writing, accounting for 40% of work-related messages on average in June 2025. This discrepancy may arise from differences in user types between Claude and ChatGPT, as well as the fact that Handa et al. only includes queries that possibly involve an occupational task.",multi_hop_specific_query_synthesizer
"Wht are the concerns regarding artificial intelligence, especially in relation to biases and discrimination, and how do these issues connect to the need for transparency and human oversight in AI systems?","['<1-hop>\n\nTake biases seriously\nBias and discrimination are serious issues for AI. There already have been a number of cases of unfair treatment linked to historic data, and steps need to be undertaken to make sure that does not become prevalent in artificial intelligence. Existing statutes governing discrimination in the physical economy need to be extended to digital platforms. That will help protect consumers and build confidence in these systems as a whole.\nFor these advances to be widely adopted, more transparency is needed in how AI systems operate. Andrew Burt of Immuta argues, “The key problem confronting predictive analytics is really transparency. We’re in a world where data science operations are taking on increasingly important tasks, and the only thing holding them back is going to be how well the data scientists who train the models can explain what it is their models are doing.”66\n Maintaining mechanisms for human oversight and control\nSome individuals have argued that there needs to be avenues for humans to exercise oversight and control of AI systems. For example, Allen Institute for Artificial Intelligence CEO Oren Etzioni argues there should be rules for regulating these systems. First, he says, AI must be governed by all the laws that already have been developed for human behavior, including regulations concerning “cyberbullying, stock manipulation or terrorist threats,” as well as “entrap[ping] people into committing crimes.” Second, he believes that these systems should disclose they are automated systems and not human beings. Third, he states, “An A.I. system cannot retain or disclose confidential information without explicit approval from the source of that information.”67 His rationale is that these tools store so much data that people have to be cognizant of the privacy risks posed by AI.\nIn the same vein, the IEEE Global Initiative has ethical guidelines for AI and autonomous systems. Its experts suggest that these models be programmed with consideration for widely accepted human norms and rules for behavior. AI algorithms need to take into effect the importance of these norms, how norm conflict can be resolved, and ways these systems can be transparent about norm resolution. Software designs should be programmed for “nondeception” and “honesty,” according to ethics experts. When failures occur, there must be mitigation mechanisms to deal with the consequences. ', '<2-hop>\n\nWhat is AI, how does it work and why are some people concerned about it?\nArtificial intelligence (AI) has increasingly become part of everyday life over the past decade.\nIt is being used to personalise social media feeds, spot friends and family in smartphone photos and pave the way for medical breakthroughs.\nBut the rise of chatbots like OpenAI\'s ChatGPT and Meta AI has been accompanied by concern about the technology\'s environmental impact, ethical implications and data use.\n What is AI and what is it used for?\nAI allows computers to process large amounts of data, identify patterns and follow detailed instructions about what to do with that information.\nComputers cannot think, empathise or reason.\nHowever, scientists have developed systems that can perform tasks which usually require human intelligence, trying to replicate how people acquire and use knowledge.\nThis could be trying to anticipate what product an online shopper might buy, based on previous purchases, in order to recommend items.\nThe technology is also behind voice-controlled virtual assistants like Apple\'s Siri and Amazon\'s Alexa, and is being used to develop systems for self-driving cars.\nAI also helps social platforms like Facebook, TikTok and X decide what posts to show users. Streaming services Spotify and Deezer use AI to suggest music.\nThere are also a number of applications in medicine, as scientists use AI to help spot cancers, review X-ray results, speed up diagnoses and identify new treatments.\n What is generative AI, and how do apps like ChatGPT and Meta AI work?\nGenerative AI is used to create new content which can seem like it has been made by a human.\nIt does this by learning from vast quantities of existing data such as online text and images.\nChatGPT and Chinese rival DeepSeek\'s chatbot are popular generative AI tools that can be used to produce text, images, code and more material.\nGoogle\'s Gemini or Meta AI can similarly hold text conversations with users.\nApps like Midjourney or Veo 3 are dedicated to creating images or video from simple text prompts.\nGenerative AI can also be used to make high-quality music.\nSongs mimicking the style or sound of famous musicians have gone viral, sometimes leaving fans confused about their authenticity.\n Why is AI controversial?\nWhile acknowledging AI\'s potential, some experts are worried about the implications of its rapid growth.\nThe International Monetary Fund (IMF) has warned AI could affect nearly 40% of jobs, and worsen global financial inequality.\nProf Geoffrey Hinton, a computer scientist regarded as one of the ""godfathers"" of AI development, has expressed concern that powerful AI systems could even make humans extinct - although his fear was dismissed by his fellow ""AI godfather"", Yann LeCun.\nCritics also highlight the tech\'s potential to reproduce biased information, or discriminate against some social groups.\nThis is because much of the data used to train AI comes from public material, including social media posts or comments, which can reflect existing societal biases such as sexism or racism.\nAnd while AI programmes are growing more adept, they are still prone to errors - such as creating images of people with the wrong number of fingers or limbs.\nGenerative AI systems are known for their ability to ""hallucinate"" and assert falsehoods as fact, even sometimes inventing sources for the inaccurate information.\nApple halted a new AI feature in January after it incorrectly summarised news app notifications.\nThe BBC complained about the feature after Apple\'s AI falsely told readers that Luigi Mangione - the man accused of killing UnitedHealthcare CEO Brian Thompson - had shot himself.\nGoogle has also faced criticism over inaccurate answers produced by its AI search overviews.\nThis has added to concerns about the use of AI in schools and workplaces, where it is increasingly used to help summarise texts, write emails or essays and solve bugs in code.\nThere are worries about students using AI technology to ""cheat"" on assignments, or employees ""smuggling"" it into work.\nWriters, musicians and artists have also pushed back against the technology on ethical grounds, accusing AI developers of using their work to train systems without consent or compensation.\nThousands of creators - including Abba singer-songwriter Björn Ulvaeus, writers Ian Rankin and Joanne Harris and actress Julianne Moore - signed a statement in October 2024 calling AI a ""major, unjust threat"" to their livelihoods.\n']","Concerns regarding artificial intelligence (AI) primarily revolve around biases and discrimination, as there have been numerous instances of unfair treatment linked to historic data. This highlights the necessity for existing statutes governing discrimination in the physical economy to be extended to digital platforms, ensuring consumer protection and building confidence in AI systems. Additionally, transparency is crucial; Andrew Burt of Immuta emphasizes that the key problem confronting predictive analytics is transparency, as data science operations are increasingly important. Furthermore, there are calls for human oversight and control of AI systems, with experts like Oren Etzioni advocating for regulations that govern AI similar to those for human behavior. This includes disclosing that AI systems are automated and ensuring they do not retain or disclose confidential information without explicit approval. The IEEE Global Initiative also stresses the importance of programming AI with widely accepted human norms and rules for behavior, emphasizing nondeception and honesty in software designs. These interconnected issues underscore the need for ethical guidelines and mechanisms to mitigate the consequences of AI failures.",multi_hop_specific_query_synthesizer
What are the implications of creating a federal AI advisory committee in light of the concerns surrounding artificial intelligence's impact on jobs and ethical issues?,"['<1-hop>\n\nCreate a federal AI advisory committee\nFederal officials need to think about how they deal with artificial intelligence. ', '<2-hop>\n\nWhat is AI, how does it work and why are some people concerned about it?\nArtificial intelligence (AI) has increasingly become part of everyday life over the past decade.\nIt is being used to personalise social media feeds, spot friends and family in smartphone photos and pave the way for medical breakthroughs.\nBut the rise of chatbots like OpenAI\'s ChatGPT and Meta AI has been accompanied by concern about the technology\'s environmental impact, ethical implications and data use.\n What is AI and what is it used for?\nAI allows computers to process large amounts of data, identify patterns and follow detailed instructions about what to do with that information.\nComputers cannot think, empathise or reason.\nHowever, scientists have developed systems that can perform tasks which usually require human intelligence, trying to replicate how people acquire and use knowledge.\nThis could be trying to anticipate what product an online shopper might buy, based on previous purchases, in order to recommend items.\nThe technology is also behind voice-controlled virtual assistants like Apple\'s Siri and Amazon\'s Alexa, and is being used to develop systems for self-driving cars.\nAI also helps social platforms like Facebook, TikTok and X decide what posts to show users. Streaming services Spotify and Deezer use AI to suggest music.\nThere are also a number of applications in medicine, as scientists use AI to help spot cancers, review X-ray results, speed up diagnoses and identify new treatments.\n What is generative AI, and how do apps like ChatGPT and Meta AI work?\nGenerative AI is used to create new content which can seem like it has been made by a human.\nIt does this by learning from vast quantities of existing data such as online text and images.\nChatGPT and Chinese rival DeepSeek\'s chatbot are popular generative AI tools that can be used to produce text, images, code and more material.\nGoogle\'s Gemini or Meta AI can similarly hold text conversations with users.\nApps like Midjourney or Veo 3 are dedicated to creating images or video from simple text prompts.\nGenerative AI can also be used to make high-quality music.\nSongs mimicking the style or sound of famous musicians have gone viral, sometimes leaving fans confused about their authenticity.\n Why is AI controversial?\nWhile acknowledging AI\'s potential, some experts are worried about the implications of its rapid growth.\nThe International Monetary Fund (IMF) has warned AI could affect nearly 40% of jobs, and worsen global financial inequality.\nProf Geoffrey Hinton, a computer scientist regarded as one of the ""godfathers"" of AI development, has expressed concern that powerful AI systems could even make humans extinct - although his fear was dismissed by his fellow ""AI godfather"", Yann LeCun.\nCritics also highlight the tech\'s potential to reproduce biased information, or discriminate against some social groups.\nThis is because much of the data used to train AI comes from public material, including social media posts or comments, which can reflect existing societal biases such as sexism or racism.\nAnd while AI programmes are growing more adept, they are still prone to errors - such as creating images of people with the wrong number of fingers or limbs.\nGenerative AI systems are known for their ability to ""hallucinate"" and assert falsehoods as fact, even sometimes inventing sources for the inaccurate information.\nApple halted a new AI feature in January after it incorrectly summarised news app notifications.\nThe BBC complained about the feature after Apple\'s AI falsely told readers that Luigi Mangione - the man accused of killing UnitedHealthcare CEO Brian Thompson - had shot himself.\nGoogle has also faced criticism over inaccurate answers produced by its AI search overviews.\nThis has added to concerns about the use of AI in schools and workplaces, where it is increasingly used to help summarise texts, write emails or essays and solve bugs in code.\nThere are worries about students using AI technology to ""cheat"" on assignments, or employees ""smuggling"" it into work.\nWriters, musicians and artists have also pushed back against the technology on ethical grounds, accusing AI developers of using their work to train systems without consent or compensation.\nThousands of creators - including Abba singer-songwriter Björn Ulvaeus, writers Ian Rankin and Joanne Harris and actress Julianne Moore - signed a statement in October 2024 calling AI a ""major, unjust threat"" to their livelihoods.\n']","Creating a federal AI advisory committee is essential as federal officials need to address the growing concerns about artificial intelligence. The rise of AI has led to worries about its environmental impact, ethical implications, and data use. Experts have warned that AI could affect nearly 40% of jobs and worsen global financial inequality. Additionally, there are fears that powerful AI systems could pose existential risks to humanity. The committee could help navigate these challenges by providing guidance on the responsible development and deployment of AI technologies, ensuring that they are used ethically and do not exacerbate existing societal biases or economic disparities.",multi_hop_specific_query_synthesizer
"What does Figure 13 indicate about the share of work-related messages by user intent, particularly in relation to Doing messages?","['<1-hop>\n\nNearly 35% of all work-related queries areDoingmessages related toWriting.DoingandAsking\ncomprise equal shares ofTechnical Helpqueries.\n17\x0cFigure 10:Breakdown of Conversation Topics by Asking/Doing/Expressing category, with topic columns\nsorted by relative share of ”Doing” messages. Prompts for these automated classifiers are available in Appendix\nA. For a detailed breakdown of conversation topic contents, see Table 3. Each bin reports a percentage of\nthe total population. Shares are calculated from a sample of approximately 1.1 million sampled conversations\nfrom May 15, 2024 through June 26, 2025. Observations are reweighted to reflect total message volumes on a\ngiven day. Sampling details available in Section 3.\nFigure 11:Breakdown of Conversation Topics by Asking/Doing/Expressing category foronly work-related\nmessages, with topic columns sorted by relative share of ”Doing” messages. Prompts for these automated\nclassifiers are available in Appendix A. For a detailed breakdown of conversation topic contents, see Table 3.\nEach bin reports a percentage of the total population. Shares are calculated from a sample of approximately\n1.1 million sampled conversations from May 15, 2024 through June 26, 2025. Observations are reweighted to\nreflect total message volumes on a given day. Sampling details available in Section 3.\n18\x0cFigure 12 presents changes over time in the composition of messages by user intent. In July\n2024, usage was evenly split betweenAskingandDoing, with just under 8% of messages classified as\nExpressing.AskingandExpressinggrew much faster thanDoingover the next year, and by late June\n2025 the split was 51.6%Asking, 34.6%Doing, and 13.8%Expressing.\nFigure 12:Shares of messages classified as Asking, Doing, or Expressing by an automated ternary classifier.\nValues are averaged over a 28 day lagging window. Shares are calculated from a sample of approximately\n1.1 million sampled conversations from May 15, 2024 through June 26, 2025. Observations are reweighted to\nreflect total message volumes on a given day. Sampling details available in Section 3.\nFigure 13 presents the share of work-related messages by user intent.Doingmessages, which\naccount for approximately 40% of messages, have an even split of messages between work-related and\nnon-work related.\n']",Figure 13 indicates that Doing messages account for approximately 40% of all work-related messages. It highlights that there is an even split of messages between work-related and non-work related categories within the Doing messages.,multi_hop_specific_query_synthesizer
"What trends can be observed in ChatGPT message volume and demographic variation in usage, particularly regarding the gender gap and age distribution of users?","['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","The trends in ChatGPT message volume indicate that non-work-related messages have grown faster than work-related messages, now representing more than 70% of all consumer ChatGPT messages. In terms of demographic variation, the gender gap in ChatGPT usage has narrowed significantly, with the percentage of active users with typically masculine first names dropping from 80% shortly after release to 48% by June 2025. Additionally, nearly half of all messages sent by adults were from users under the age of 26, although age gaps have also narrowed recently. Furthermore, ChatGPT usage has seen relatively faster growth in low- and middle-income countries over the past year, and educated users in high-paying professional occupations are more likely to utilize ChatGPT for work-related tasks.",multi_hop_abstract_query_synthesizer
"How has the demographic variation in ChatGPT usage influenced the trends in message volume, particularly in relation to work-related and non-work-related messages?","['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","The demographic variation in ChatGPT usage has shown significant changes over time, particularly with the narrowing gender gap and the increasing participation of younger users. As of June 2025, the proportion of active users with typically masculine first names dropped from 80% to 48%, indicating a shift towards a more balanced gender representation. Additionally, nearly half of all messages were sent by users under the age of 26. This demographic shift coincides with a notable trend in message volume, where non-work-related messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. The decrease in work-related messages is attributed to changing usage patterns within existing user cohorts rather than a change in the composition of new users. This suggests that as younger and more diverse demographics engage with ChatGPT, the nature of the conversations is evolving, leading to an increase in non-work-related interactions while work-related messages have stabilized or decreased.",multi_hop_abstract_query_synthesizer
"What trends can be observed in ChatGPT message volume and usage across different demographics, particularly regarding the gender gap and age distribution of users?","['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","The trends in ChatGPT message volume indicate that non-work messages have grown faster than work-related messages, now representing more than 70% of all consumer ChatGPT messages. The gender gap in ChatGPT usage has narrowed significantly, with the proportion of active users with typically masculine first names dropping from 80% shortly after release to 48% by June 2025, suggesting a shift towards a more balanced user base. Additionally, nearly half of all messages sent by adults were from users under the age of 26, although age gaps have also narrowed recently. Furthermore, ChatGPT usage has seen relatively faster growth in low- and middle-income countries, and educated users in high-paying professions are more likely to utilize ChatGPT for work-related tasks.",multi_hop_abstract_query_synthesizer
"What trends can be observed in ChatGPT message volume and demographic variation in usage, particularly regarding the gender gap and age distribution of users?","['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","The trends in ChatGPT message volume indicate that non-work-related messages have grown faster than work-related messages, now representing more than 70% of all consumer ChatGPT messages. In terms of demographic variation, the gender gap in ChatGPT usage has narrowed significantly, with the proportion of active users with typically masculine first names dropping from 80% shortly after release to 48% by June 2025. Additionally, nearly half of all messages sent by adults were from users under the age of 26, although age gaps have also narrowed recently. Furthermore, ChatGPT usage has seen relatively faster growth in low- and middle-income countries over the past year, and educated users in high-paying professional occupations are more likely to use ChatGPT for work-related tasks.",multi_hop_abstract_query_synthesizer
"What trends can be observed in ChatGPT message volume and usage across different demographics, particularly regarding the narrowing gender gap and the age distribution of users?","['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","The trends in ChatGPT message volume and usage reveal significant demographic variations. Notably, the gender gap in ChatGPT usage has likely narrowed considerably, with the proportion of active users with typically masculine first names dropping from about 80% shortly after release to 48% by June 2025, indicating a shift towards a more balanced gender representation. Additionally, nearly half of all messages sent by adults were from users under the age of 26, although age gaps have also narrowed in recent months. Furthermore, ChatGPT usage has seen relatively faster growth in low- and middle-income countries over the past year, and educated users in high-paying professional occupations are more likely to utilize ChatGPT for work-related tasks. Overall, these findings highlight the evolving landscape of ChatGPT usage, reflecting both demographic shifts and changing user engagement patterns.",multi_hop_abstract_query_synthesizer
What trends can be observed in ChatGPT message volume and demographic variation in usage as of June 2025?,"['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","As of June 2025, ChatGPT message volume has shown significant growth, with non-work-related messages now representing over 70% of all consumer messages. This increase is attributed to changing usage patterns within user cohorts rather than the composition of new users. Additionally, demographic variation indicates that the gender gap in usage has narrowed, with active users now slightly more likely to have typically feminine first names. Furthermore, nearly half of all messages are sent by users under the age of 26, and usage has grown faster in low- and middle-income countries. Educated users and those in high-paying professions are more likely to utilize ChatGPT for work-related tasks.",multi_hop_abstract_query_synthesizer
What trends can be observed in ChatGPT message volume and demographic variation in usage as of June 2025?,"['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","As of June 2025, ChatGPT message volume has shown significant growth, with non-work-related messages now representing over 70% of all consumer messages. This increase is attributed to changing usage patterns within user cohorts rather than the composition of new users. Additionally, demographic variation indicates that the gender gap in usage has narrowed, with active users now slightly more likely to have typically feminine first names. Furthermore, nearly half of all messages are sent by users under the age of 26, and usage has grown faster in low- and middle-income countries. Educated users and those in high-paying professions are more likely to utilize ChatGPT for work-related tasks.",multi_hop_abstract_query_synthesizer
"What trends can be observed in ChatGPT message volume and demographic variation in usage, particularly regarding the gender gap and age distribution of users?","['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","The trends in ChatGPT message volume indicate that non-work messages have grown faster than work-related messages, now representing more than 70% of all consumer ChatGPT messages. In terms of demographic variation, the gender gap in ChatGPT usage has narrowed significantly, with the percentage of active users with typically masculine first names dropping from 80% shortly after release to 48% by June 2025. Additionally, nearly half of all messages sent by adults were from users under the age of 26, although age gaps have also narrowed recently. Furthermore, ChatGPT usage has seen relatively faster growth in low- and middle-income countries, and educated users in high-paying professional occupations are more likely to utilize ChatGPT for work-related tasks.",multi_hop_abstract_query_synthesizer
"What trends can be observed in the demographic variation of ChatGPT usage, particularly regarding gender and age, and how do these trends relate to the overall message volume and usage patterns in different contexts?","['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","The demographic variation in ChatGPT usage reveals significant trends, particularly regarding gender and age. As of June 2025, the gender gap in ChatGPT usage has narrowed considerably, with active users with typically masculine first names decreasing from 80% shortly after release to 48%. This indicates a shift towards a more balanced user base, with a slight increase in users with typically feminine first names. Additionally, nearly half of all messages sent by adults were from users under the age of 26, although age gaps have also narrowed recently. In terms of message volume, ChatGPT usage has grown continuously, with non-work-related messages increasing at a faster rate, now representing over 70% of all consumer messages. This growth in non-work messages contrasts with the demographic trends, suggesting that younger users are more engaged in non-work-related interactions. Furthermore, educated users and those in high-paying professions are more likely to utilize ChatGPT for work-related tasks, which aligns with the overall message volume trends where writing tasks account for a significant portion of work-related messages. Overall, the trends in demographic variation and message volume highlight a dynamic shift in how different user groups engage with ChatGPT across various contexts.",multi_hop_abstract_query_synthesizer
What trends can be observed in ChatGPT message volume and demographic variation in usage over time?,"['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","ChatGPT message volume has shown significant growth, with non-work-related messages increasing faster and now representing over 70% of all consumer messages. In June 2025, 1,911 million messages were non-work-related, compared to 716 million work-related messages. Additionally, demographic variation indicates that the gender gap in usage has narrowed, with active users now slightly more likely to have typically feminine first names. Furthermore, nearly half of all messages are sent by users under the age of 26, and usage has grown more rapidly in low- and middle-income countries.",multi_hop_abstract_query_synthesizer
"What trends can be observed in ChatGPT message volume and usage across different demographics, particularly regarding the gender gap and age distribution of users, and how do these trends relate to the overall increase in non-work-related messages?","['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","The trends in ChatGPT message volume and usage reveal significant demographic variations. Notably, the gender gap in ChatGPT usage has narrowed considerably, with the proportion of active users with typically masculine first names dropping from about 80% shortly after release to 48% by June 2025, indicating a shift towards a more balanced user base. Additionally, nearly half of all messages sent by adults come from users under the age of 26, although age gaps have also narrowed recently. This demographic shift coincides with a substantial increase in non-work-related messages, which now represent over 70% of all consumer ChatGPT messages. The growth in non-work messages has outpaced that of work-related messages, suggesting that while ChatGPT is utilized for professional tasks, its appeal for personal and leisure activities is becoming increasingly significant. This trend highlights the evolving nature of ChatGPT usage, where younger users and a more diverse demographic are engaging with the platform for a variety of purposes beyond traditional work-related tasks.",multi_hop_abstract_query_synthesizer
"What is the economic impact of generative AI on consumer surplus, and how does it compare to the impact of AI on productivity in paid work?","['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nIts Users Can’t Sue to Prompt Fairness,” New York Times, June 19, 2016. - Executive Office of the President, “Artificial Intelligence, Automation, and the Economy” and “Preparing for the Future of Artificial Intelligence.” - Nancy Scolar, “Facebook’s Next Project: American Inequality,” Politico, February 19, 2018. - Darrell M. West, “What Internet Search Data Reveals about Donald Trump’s First Year in Office,” Brookings Institution policy report, January 17, 2018. - Ian Buck, “Testimony before the House Committee on Oversight and Government Reform Subcommittee on Information Technology,” February 14, 2018. - Keith Nakasone, “Testimony before the House Committee on Oversight and Government Reform Subcommittee on Information Technology,” March 7, 2018. - Greg Brockman, “The Dawn of Artificial Intelligence,” Testimony before U.S. Senate Subcommittee on Space, Science, and Competitiveness, November 30, 2016. - Amir Khosrowshahi, “Testimony before the House Committee on Oversight and Government Reform Subcommittee on Information Technology,” February 14, 2018. - James Kurose, “Testimony before the House Committee on Oversight and Government Reform Subcommittee on Information Technology,” March 7, 2018. - Stephen Noonoo, “Teachers Can Now Use IBM’s Watson to Search for Free Lesson Plans,” EdSurge, September 13, 2017. - Congress.gov, “H.R. 4625 FUTURE of Artificial Intelligence Act of 2017,” December 12, 2017. - Elizabeth Zima, “Could New York City’s AI Transparency Bill Be a Model for the Country?” Government Technology, January 4, 2018.']","The economic impact of generative AI on consumer surplus is significant, with an estimated consumer surplus of at least $97 billion in 2024 alone in the US. This finding highlights that while most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activities outside of work, such as home production, is on a similar scale and possibly larger. This suggests that generative AI not only enhances productivity in work-related tasks but also contributes substantially to consumer welfare in non-work contexts.",multi_hop_abstract_query_synthesizer
What trends can be observed in ChatGPT message volume and demographic variation in usage over time?,"['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","ChatGPT message volume has shown significant growth, with non-work messages increasing faster and now representing over 70% of all consumer messages. In terms of demographic variation, the gender gap in usage has narrowed, with active users with typically masculine names dropping from 80% to 48% by June 2025. Additionally, nearly half of all messages are sent by users under the age of 26, and usage has grown more rapidly in low- and middle-income countries. Educated users and those in high-paying professions are more likely to use ChatGPT for work-related tasks.",multi_hop_abstract_query_synthesizer
"What trends can be observed in ChatGPT message volume and demographic variation in usage, particularly regarding the gender gap and age distribution of users?","['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","The trends in ChatGPT message volume indicate a significant increase in overall usage, with non-work-related messages growing faster and now representing more than 70% of all consumer messages. In terms of demographic variation, the gender gap in ChatGPT usage has narrowed considerably, with the proportion of active users with typically masculine first names dropping from 80% shortly after release to 48% by June 2025. Additionally, nearly half of all messages sent by adults were from users under the age of 26, although age gaps have also narrowed recently. This suggests a shift in the user base towards a more diverse demographic, with increased engagement from younger users and a more balanced gender representation.",multi_hop_abstract_query_synthesizer
"What is the economic impact and consumer surplus of generative AI, particularly in relation to the growth of ChatGPT usage in low- and middle-income countries?","['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","The economic impact of generative AI, particularly in the context of ChatGPT, is significant. A study estimates a consumer surplus of at least $97 billion in 2024 alone in the US, highlighting the value that users derive from generative AI technologies. Additionally, ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year, indicating that these regions are increasingly benefiting from the economic advantages provided by generative AI. This growth suggests that generative AI is not only enhancing productivity in paid work but also impacting home production and other non-work-related activities, which may have a similar or even larger economic scale.",multi_hop_abstract_query_synthesizer
"What trends can be observed in ChatGPT message volume and demographic variation in usage, particularly regarding the gender gap and age distribution of users?","['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","The trends in ChatGPT message volume indicate that non-work messages have grown faster than work-related messages, now representing more than 70% of all consumer ChatGPT messages. This growth is attributed to changing usage patterns within user cohorts rather than a shift in the composition of new users. Regarding demographic variation, the gender gap in ChatGPT usage has narrowed significantly, with the percentage of active users with typically masculine first names dropping from 80% shortly after release to 48% by June 2025. Additionally, nearly half of all messages sent by adults were from users under the age of 26, although age gaps have also narrowed recently. Furthermore, ChatGPT usage has increased more rapidly in low- and middle-income countries, and educated users in high-paying professions are more likely to utilize ChatGPT for work-related tasks.",multi_hop_abstract_query_synthesizer
"What trends can be observed in ChatGPT message volume and demographic variation in usage, particularly regarding the gender gap and age distribution of users?","['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","The trends in ChatGPT message volume indicate that non-work messages have grown faster than work-related messages, now representing more than 70% of all consumer ChatGPT messages. Additionally, the gender gap in ChatGPT usage has narrowed significantly, with the proportion of active users with typically masculine first names dropping from 80% shortly after release to 48% by June 2025, suggesting a shift towards a more balanced user demographic. Furthermore, nearly half of all messages sent by adults were from users under the age of 26, indicating a younger demographic is heavily engaged with the platform. This demographic variation highlights the evolving landscape of ChatGPT usage across different age groups and genders.",multi_hop_abstract_query_synthesizer
"What trends can be observed in ChatGPT message volume and demographic variation in usage, particularly regarding the gender gap and age distribution of users?","['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","The trends in ChatGPT message volume indicate that non-work-related messages have grown faster than work-related messages, now representing more than 70% of all consumer ChatGPT messages. In terms of demographic variation, the gender gap in ChatGPT usage has narrowed significantly, with the proportion of active users with typically masculine first names dropping from 80% shortly after release to 48% by June 2025. Additionally, nearly half of all messages sent by adults were from users under the age of 26, although age gaps have also narrowed recently. Furthermore, ChatGPT usage has seen relatively faster growth in low- and middle-income countries over the past year, and educated users in high-paying professional occupations are more likely to utilize ChatGPT for work-related tasks.",multi_hop_abstract_query_synthesizer
What trends can be observed in ChatGPT message volume and demographic variation in usage over time?,"['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","ChatGPT message volume has shown significant growth, with non-work messages increasing faster and now representing over 70% of all consumer messages. The demographic variation indicates that the gender gap in usage has narrowed, with active users now slightly more likely to have typically feminine first names. Additionally, nearly half of all messages are sent by users under the age of 26, and usage has grown more rapidly in low- and middle-income countries. Educated users and those in high-paying professions are more likely to use ChatGPT for work-related tasks.",multi_hop_abstract_query_synthesizer
"What are the trends in ChatGPT message volume and how do they relate to demographic variations in usage, particularly regarding age and gender?","['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","ChatGPT message volume has shown significant growth, with non-work messages increasing faster and now representing over 70% of all consumer messages. In June 2025, 1,911 million messages were non-work-related, compared to 716 million work-related messages. Additionally, demographic variations indicate that the gender gap in usage has narrowed, with active users with typically masculine names dropping from 80% to 48%. Furthermore, nearly half of all messages were sent by users under the age of 26, highlighting a trend of younger users engaging more with ChatGPT. This suggests that both message volume and demographic factors are evolving, with younger users and a more balanced gender representation contributing to the overall increase in usage.",multi_hop_abstract_query_synthesizer
