user_input,reference_contexts,reference,synthesizer_name
What OpenAI do?,"[""What is AI, how does it work and why are some people concerned about it?\nArtificial intelligence (AI) has increasingly become part of everyday life over the past decade.\nIt is being used to personalise social media feeds, spot friends and family in smartphone photos and pave the way for medical breakthroughs.\nBut the rise of chatbots like OpenAI's ChatGPT and Meta AI has been accompanied by concern about the technology's environmental impact, ethical implications and data use.\n What is AI and what is it used for?\nAI allows computers to process large amounts of data, identify patterns and follow detailed instructions about what to do with that information.\nComputers cannot think, empathise or reason.\nHowever, scientists have developed systems that can perform tasks which usually require human intelligence, trying to replicate how people acquire and use knowledge.\nThis could be trying to anticipate what product an online shopper might buy, based on previous purchases, in order to recommend items.\nThe technology is also behind voice-controlled virtual assistants like Apple's Siri and Amazon's Alexa, and is being used to develop systems for self-driving cars.\nAI also helps social platforms like Facebook, TikTok and X decide what posts to show users. Streaming services Spotify and Deezer use AI to suggest music.\nThere are also a number of applications in medicine, as scientists use AI to help spot cancers, review X-ray results, speed up diagnoses and identify new treatments.\n What is generative AI, and how do apps like ChatGPT and Meta AI work?\nGenerative AI is used to create new content which can seem like it has been made by a human.\nIt does this by learning from vast quantities of existing data such as online text and images.\nChatGPT and Chinese rival DeepSeek's chatbot are popular generative AI tools that can be used to produce text, images, code and more material.\nGoogle's Gemini or Meta AI can similarly hold text conversations with users.\nApps like Midjourney or Veo 3 are dedicated to creating images or video from simple text prompts.\nGenerative AI can also be used to make high-quality music.\nSongs mimicking the style or sound of famous musicians have gone viral, sometimes leaving fans confused about their authenticity.\n""]","OpenAI's ChatGPT is a generative AI tool that can produce text, images, code, and more material by learning from vast quantities of existing data such as online text and images.",single_hop_specific_query_synthesizer
"What concerns did Yann LeCun dismiss regarding the potential extinction of humans due to powerful AI systems, as expressed by his fellow AI godfather Geoffrey Hinton?","['Why is AI controversial?\nWhile acknowledging AI\'s potential, some experts are worried about the implications of its rapid growth.\nThe International Monetary Fund (IMF) has warned AI could affect nearly 40% of jobs, and worsen global financial inequality.\nProf Geoffrey Hinton, a computer scientist regarded as one of the ""godfathers"" of AI development, has expressed concern that powerful AI systems could even make humans extinct - although his fear was dismissed by his fellow ""AI godfather"", Yann LeCun.\nCritics also highlight the tech\'s potential to reproduce biased information, or discriminate against some social groups.\nThis is because much of the data used to train AI comes from public material, including social media posts or comments, which can reflect existing societal biases such as sexism or racism.\nAnd while AI programmes are growing more adept, they are still prone to errors - such as creating images of people with the wrong number of fingers or limbs.\nGenerative AI systems are known for their ability to ""hallucinate"" and assert falsehoods as fact, even sometimes inventing sources for the inaccurate information.\nApple halted a new AI feature in January after it incorrectly summarised news app notifications.\nThe BBC complained about the feature after Apple\'s AI falsely told readers that Luigi Mangione - the man accused of killing UnitedHealthcare CEO Brian Thompson - had shot himself.\nGoogle has also faced criticism over inaccurate answers produced by its AI search overviews.\nThis has added to concerns about the use of AI in schools and workplaces, where it is increasingly used to help summarise texts, write emails or essays and solve bugs in code.\nThere are worries about students using AI technology to ""cheat"" on assignments, or employees ""smuggling"" it into work.\nWriters, musicians and artists have also pushed back against the technology on ethical grounds, accusing AI developers of using their work to train systems without consent or compensation.\nThousands of creators - including Abba singer-songwriter Björn Ulvaeus, writers Ian Rankin and Joanne Harris and actress Julianne Moore - signed a statement in October 2024 calling AI a ""major, unjust threat"" to their livelihoods.\nHow does AI effect the environment?\nIt is not clear how much energy AI systems use, but some researchers estimate the industry as a whole could soon consume as much as the Netherlands.\nCreating the powerful computer chips needed to run AI programmes requires lots of power and water.\nDemand for generative AI services has also meant an increase in the number of data centres which power them.\nThese huge halls - housing thousands of racks of computer servers - use substantial amounts of energy and require large volumes of water to keep them cool.\nSome large tech companies have invested in ways to reduce or reuse the water needed, or have opted for alternative methods such as air-cooling.\nHowever, some experts and activists fear that AI will worsen water supply problems.\nThe BBC was told in February that government plans to make the UK a ""world leader"" in AI could put already stretched supplies of drinking water under strain.\nIn September 2024, Google said it would reconsider proposals for a data centre in Chile, which has struggled with drought.\n']","Yann LeCun dismissed the concerns expressed by Geoffrey Hinton regarding the potential extinction of humans due to powerful AI systems, indicating a difference in perspective among the AI experts.",single_hop_specific_query_synthesizer
"What significant developments regarding AI regulations are expected by February 2025, particularly in relation to international agreements?","['Are there laws governing AI?\nSome governments have already introduced rules governing how AI operates.\nThe EU\'s Artificial Intelligence Act places controls on high risk systems used in areas such as education, healthcare, law enforcement or elections. It bans some AI use altogether.\nGenerative AI developers in China are required to safeguard citizens\' data, and promote transparency and accuracy of information. But they are also bound by the country\'s strict censorship laws.\nIn the UK, Prime Minister Sir Keir Starmer has said the government ""will test and understand AI before we regulate it"".\nBoth the UK and US have AI Safety Institutes that aim to identify risks and evaluate advanced AI models.\nIn 2024 the two countries signed an agreement to collaborate on developing ""robust"" AI testing methods.\nHowever, in February 2025, neither country signed an international AI declaration which pledged an open, inclusive and sustainable approach to the technology.\nSeveral countries including the UK are also clamping down on use of AI systems to create deepfake nude imagery and child sexual abuse material.\nSign up for our Tech Decoded newsletter to follow the world\'s top tech stories and trends. Outside the UK? Sign up here.']","By February 2025, neither the UK nor the US signed an international AI declaration that pledged an open, inclusive, and sustainable approach to AI technology. This indicates a lack of consensus on global AI governance despite ongoing discussions and collaborations between these countries on AI testing methods.",single_hop_specific_query_synthesizer
Who is Shubhendu and what role does he play in AI?,"['This article was published in 2018. To read more recent content from Brookings on Artificial Intelligence, please visit the AI topic page.\nMost people are not very familiar with the concept of artificial intelligence (AI). As an illustration, when 1,500 senior business leaders in the United States in 2017 were asked about AI, only 17 percent said they were familiar with it.1 A number of them were not sure what it was or how it would affect their particular companies. They understood there was considerable potential for altering business processes, but were not clear how AI could be deployed within their own organizations.\nDespite its widespread lack of familiarity, AI is a technology that is transforming every walk of life. It is a wide-ranging tool that enables people to rethink how we integrate information, analyze data, and use the resulting insights to improve decisionmaking. Our hope through this comprehensive overview is to explain AI to an audience of policymakers, opinion leaders, and interested observers, and demonstrate how AI already is altering the world and raising important questions for society, the economy, and governance.\nIn this paper, we discuss novel applications in finance, national security, health care, criminal justice, transportation, and smart cities, and address issues such as data access problems, algorithmic bias, AI ethics and transparency, and legal liability for AI decisions. We contrast the regulatory approaches of the U.S. and European Union, and close by making a number of recommendations for getting the most out of AI while still protecting important human values.2\nIn order to maximize AI benefits, we recommend nine steps for going forward:\n- Encourage greater data access for researchers without compromising users’ personal privacy,\n- invest more government funding in unclassified AI research,\n- promote new models of digital education and AI workforce development so employees have the skills needed in the 21st-century economy,\n- create a federal AI advisory committee to make policy recommendations,\n- engage with state and local officials so they enact effective policies,\n- regulate broad AI principles rather than specific algorithms,\n- take bias complaints seriously so AI does not replicate historic injustice, unfairness, or discrimination in data or algorithms,\n- maintain mechanisms for human oversight and control, and\n- penalize malicious AI behavior and promote cybersecurity.\n Qualities of artificial intelligence\nAlthough there is no uniformly agreed upon definition, AI generally is thought to refer to “machines that respond to stimulation consistent with traditional responses from humans, given the human capacity for contemplation, judgment and intention.”3 According to researchers Shubhendu and Vijay, these software systems “make decisions which normally require [a] human level of expertise” and help people anticipate problems or deal with issues as they come up.4 As such, they operate in an intentional, intelligent, and adaptive manner.\n']","Shubhendu is a researcher who, along with Vijay, describes software systems that make decisions requiring human-level expertise and help people anticipate problems or deal with issues as they arise.",single_hop_specific_query_synthesizer
Can you explain how Vijay's research contributes to understanding artificial intelligence and its applications?,"['Intelligence, please visit the AI topic page.\nMost people are not very familiar with the concept of artificial intelligence (AI). As an illustration, when 1,500 senior business leaders in the United States in 2017 were asked about AI, only 17 percent said they were familiar with it.1 A number of them were not sure what it was or how it would affect their particular companies. They understood there was considerable potential for altering business processes, but were not clear how AI could be deployed within their own organizations.\nDespite its widespread lack of familiarity, AI is a technology that is transforming every walk of life. It is a wide-ranging tool that enables people to rethink how we integrate information, analyze data, and use the resulting insights to improve decisionmaking. Our hope through this comprehensive overview is to explain AI to an audience of policymakers, opinion leaders, and interested observers, and demonstrate how AI already is altering the world and raising important questions for society, the economy, and governance.\nIn this paper, we discuss novel applications in finance, national security, health care, criminal justice, transportation, and smart cities, and address issues such as data access problems, algorithmic bias, AI ethics and transparency, and legal liability for AI decisions. We contrast the regulatory approaches of the U.S. and European Union, and close by making a number of recommendations for getting the most out of AI while still protecting important human values.2\nIn order to maximize AI benefits, we recommend nine steps for going forward:\n- Encourage greater data access for researchers without compromising users’ personal privacy,\n- invest more government funding in unclassified AI research,\n- promote new models of digital education and AI workforce development so employees have the skills needed in the 21st-century economy,\n- create a federal AI advisory committee to make policy recommendations,\n- engage with state and local officials so they enact effective policies,\n- regulate broad AI principles rather than specific algorithms,\n- take bias complaints seriously so AI does not replicate historic injustice, unfairness, or discrimination in data or algorithms,\n- maintain mechanisms for human oversight and control, and\n- penalize malicious AI behavior and promote cybersecurity.\nQualities of artificial intelligence\nAlthough there is no uniformly agreed upon definition, AI generally is thought to refer to “machines that respond to stimulation consistent with traditional responses from humans, given the human capacity for contemplation, judgment and intention.”3 According to researchers Shubhendu and Vijay, these software systems “make decisions which normally require [a] human level of expertise” and help people anticipate problems or deal with issues as they come up.4 As such, they operate in an intentional, intelligent, and adaptive manner.\nIntentionality\nArtificial intelligence algorithms are designed to make decisions, often using real-time data. They are unlike passive machines that are capable only of mechanical or predetermined responses. Using sensors, digital data, or remote inputs, they combine information from a variety of different sources, analyze the material instantly, and act on the insights derived from those data. With massive improvements in storage systems, processing speeds, and analytic techniques, they are capable of tremendous sophistication in analysis and decisionmaking.\nArtificial intelligence is already altering the world and raising important questions for society, the economy, and governance.\nIntelligence\nAI generally is undertaken in conjunction with machine learning and data analytics.5 Machine learning takes data and looks for underlying trends. If it spots something that is relevant for a practical problem, software designers can take that knowledge and use it to analyze specific issues. All that is required are data that are sufficiently robust that algorithms can discern useful patterns. Data can come in the form of digital information, satellite imagery, visual information, text, or unstructured data.\n']","According to researchers Shubhendu and Vijay, artificial intelligence systems make decisions that normally require human-level expertise and help people anticipate problems or deal with issues as they arise. Their work emphasizes the intentional, intelligent, and adaptive nature of AI algorithms, which are designed to make decisions using real-time data, unlike passive machines that only provide mechanical responses.",single_hop_specific_query_synthesizer
How does PriceWaterhouseCoopers estimate the economic impact of artificial intelligence on global GDP by 2030?,"['Applications in diverse sectors AI is not a futuristic vision, but rather something that is here today and being integrated with and deployed into a variety of sectors. This includes fields such as finance, national security, health care, criminal justice, transportation, and smart cities. There are numerous examples where AI already is making an impact on the world and augmenting human capabilities in significant ways.6 One of the reasons for the growing role of AI is the tremendous opportunities for economic development that it presents. A project undertaken by PriceWaterhouseCoopers estimated that “artificial intelligence technologies could increase global GDP by $15.7 trillion, a full 14%, by 2030.”7 That includes advances of $7 trillion in China, $3.7 trillion in North America, $1.8 trillion in Northern Europe, $1.2 trillion for Africa and Oceania, $0.9 trillion in the rest of Asia outside of China, $0.7 trillion in Southern Europe, and $0.5 trillion in Latin America. China is making rapid strides because it has set a national goal of investing $150 billion in AI and becoming the global leader in this area by 2030. Meanwhile, a McKinsey Global Institute study of China found that “AI-led automation can give the Chinese economy a productivity injection that would add 0.8 to 1.4 percentage points to GDP growth annually, depending on the speed of adoption.”8 Although its authors found that China currently lags the United States and the United Kingdom in AI deployment, the sheer size of its AI market gives that country tremendous opportunities for pilot testing and future development. Finance Investments in financial AI in the United States tripled between 2013 and 2014 to a total of $12.2 billion.9 According to observers in that sector, “Decisions about loans are now being made by software that can take into account a variety of finely parsed data about a borrower, rather than just a credit score and a background check.”10 In addition, there are so-called robo-advisers that “create personalized investment portfolios, obviating the need for stockbrokers and financial advisers.”11 These advances are designed to take the emotion out of investing and undertake decisions based on analytical considerations, and make these choices in a matter of minutes. A prominent example of this is taking place in stock exchanges, where high-frequency trading by machines has replaced much of human decisionmaking. People submit buy and sell orders, and computers match them in the blink of an eye without human intervention. Machines can spot trading inefficiencies or market differentials on a very small scale and execute trades that make money according to investor instructions.12 Powered in some places by advanced computing, these tools have much greater capacities for storing information because of their emphasis not on a zero or a one, but on “quantum bits” that can store multiple values in each location.13 That dramatically increases storage capacity and decreases processing times. Fraud detection represents another way AI is helpful in financial systems. It sometimes is difficult to discern fraudulent activities in large organizations, but AI can identify abnormalities, outliers, or deviant cases requiring additional investigation. That helps managers find problems early in the cycle, before they reach dangerous levels.14 National security AI plays a substantial role in national defense. Through its Project Maven, the American military is deploying AI “to sift through the massive troves of data and video captured by surveillance and then alert human analysts of patterns or when there is abnormal or suspicious activity.”15 According to Deputy Secretary of Defense Patrick Shanahan, the goal of emerging technologies in this area is “to meet our warfighters’ needs and to increase [the] speed and agility [of] technology development and procurement.”16 Artificial intelligence will accelerate the traditional process of warfare so rapidly that a new term has been coined: hyperwar. The big data analytics associated with AI will profoundly affect intelligence analysis, as massive amounts of data are sifted in near real time—if not eventually in real time—thereby providing commanders and their staffs a level of intelligence analysis and productivity heretofore unseen. Command and control will similarly be affected as human commanders delegate certain routine, and in special circumstances, key decisions to AI platforms, reducing dramatically the time associated with the decision and subsequent action. In the end, warfare is a time competitive process, where the side able to decide the fastest and move most quickly to execution will generally prevail. Indeed, artificially intelligent intelligence systems, tied to AI-assisted command and control systems, can move decision support and decisionmaking to a speed vastly superior to the speeds of the traditional means of waging war. So fast will be this process, especially if coupled to automatic decisions to launch artificially intelligent autonomous weapons systems capable of lethal outcomes, that a new term has been coined specifically to embrace the speed at which war will be waged: hyperwar. While the ethical and legal debate is raging over whether America will ever wage war']","PriceWaterhouseCoopers estimated that artificial intelligence technologies could increase global GDP by $15.7 trillion, a full 14%, by 2030. This projection includes advances of $7 trillion in China, $3.7 trillion in North America, $1.8 trillion in Northern Europe, $1.2 trillion for Africa and Oceania, $0.9 trillion in the rest of Asia outside of China, $0.7 trillion in Southern Europe, and $0.5 trillion in Latin America.",single_hop_specific_query_synthesizer
How do cyber threats impact the development of AI systems in the context of cybersecurity?,"['Adaptability\nAI systems have the ability to learn and adapt as they make decisions. In the transportation area, for example, semi-autonomous vehicles have tools that let drivers and vehicles know about upcoming congestion, potholes, highway construction, or other possible traffic impediments. Vehicles can take advantage of the experience of other vehicles on the road, without human involvement, and the entire corpus of their achieved “experience” is immediately and fully transferable to other similarly configured vehicles. Their advanced algorithms, sensors, and cameras incorporate experience in current operations, and use dashboards and visual displays to present information in real time so human drivers are able to make sense of ongoing traffic and vehicular conditions. And in the case of fully autonomous vehicles, advanced systems can completely control the car or truck, and make all the navigational decisions.\n with artificially intelligent autonomous lethal systems, the Chinese and Russians are not nearly so mired in this debate, and we should anticipate our need to defend against these systems operating at hyperwar speeds. The challenge in the West of where to position “humans in the loop” in a hyperwar scenario will ultimately dictate the West’s capacity to be competitive in this new form of conflict.17 Just as AI will profoundly affect the speed of warfare, the proliferation of zero day or zero second cyber threats as well as polymorphic malware will challenge even the most sophisticated signature-based cyber protection. This forces significant improvement to existing cyber defenses. Increasingly, vulnerable systems are migrating, and will need to shift to a layered approach to cybersecurity with cloud-based, cognitive AI platforms. This approach moves the community toward a “thinking” defensive capability that can defend networks through constant training on known threats. This capability includes DNA-level analysis of heretofore unknown code, with the possibility of recognizing and stopping inbound malicious code by recognizing a string component of the file.']","Cyber threats, particularly zero day or zero second threats and polymorphic malware, challenge even the most sophisticated signature-based cyber protection. This necessitates significant improvements to existing cyber defenses, pushing vulnerable systems to adopt a layered approach to cybersecurity that incorporates cloud-based, cognitive AI platforms. Such an approach aims to create a 'thinking' defensive capability that can continuously train on known threats and recognize unknown malicious code.",single_hop_specific_query_synthesizer
"How is China positioning itself in the field of AI, particularly in relation to its military and cybersecurity capabilities?","['The challenge in the West of where to position “humans in the loop” in a hyperwar scenario will ultimately dictate the West’s capacity to be competitive in this new form of conflict.17\nJust as AI will profoundly affect the speed of warfare, the proliferation of zero day or zero second cyber threats as well as polymorphic malware will challenge even the most sophisticated signature-based cyber protection. This forces significant improvement to existing cyber defenses. Increasingly, vulnerable systems are migrating, and will need to shift to a layered approach to cybersecurity with cloud-based, cognitive AI platforms. This approach moves the community toward a “thinking” defensive capability that can defend networks through constant training on known threats. This capability includes DNA-level analysis of heretofore unknown code, with the possibility of recognizing and stopping inbound malicious code by recognizing a string component of the file. This is how certain key U.S.-based systems stopped the debilitating “WannaCry” and “Petya” viruses.\nPreparing for hyperwar and defending critical cyber networks must become a high priority because China, Russia, North Korea, and other countries are putting substantial resources into AI. In 2017, China’s State Council issued a plan for the country to “build a domestic industry worth almost $150 billion” by 2030.18 As an example of the possibilities, the Chinese search firm Baidu has pioneered a facial recognition application that finds missing people. In addition, cities such as Shenzhen are providing up to $1 million to support AI labs. That country hopes AI will provide security, combat terrorism, and improve speech recognition programs.19 The dual-use nature of many AI algorithms will mean AI research focused on one sector of society can be rapidly modified for use in the security sector as well.20\n Health care\nAI tools are helping designers improve computational sophistication in health care. For example, Merantix is a German company that applies deep learning to medical issues. It has an application in medical imaging that “detects lymph nodes in the human body in Computer Tomography (CT) images.”21 According to its developers, the key is labeling the nodes and identifying small lesions or growths that could be problematic. Humans can do this, but radiologists charge $100 per hour and may be able to carefully read only four images an hour. If there were 10,000 images, the cost of this process would be $250,000, which is prohibitively expensive if done by humans.\nWhat deep learning can do in this situation is train computers on data sets to learn what a normal-looking versus an irregular-appearing lymph node is. After doing that through imaging exercises and honing the accuracy of the labeling, radiological imaging specialists can apply this knowledge to actual patients and determine the extent to which someone is at risk of cancerous lymph nodes. Since only a few are likely to test positive, it is a matter of identifying the unhealthy versus healthy node.\nAI has been applied to congestive heart failure as well, an illness that afflicts 10 percent of senior citizens and costs $35 billion each year in the United States. AI tools are helpful because they “predict in advance potential challenges ahead and allocate resources to patient education, sensing, and proactive interventions that keep patients out of the hospital.”22\n']","China is positioning itself in the field of AI by investing substantial resources into its development, particularly for military and cybersecurity applications. In 2017, China's State Council issued a plan to build a domestic AI industry worth almost $150 billion by 2030. The country aims to leverage AI for security, combat terrorism, and enhance speech recognition programs. Additionally, Chinese companies like Baidu are pioneering applications such as facial recognition to find missing people, while cities like Shenzhen are providing financial support to AI labs. The dual-use nature of many AI algorithms allows for rapid modification of research focused on civilian sectors for security purposes.",single_hop_specific_query_synthesizer
What insights does Caleb Watney provide regarding the use of AI in predictive risk analysis?,"['Criminal justice\nAI is being deployed in the criminal justice area. The city of Chicago has developed an AI-driven “Strategic Subject List” that analyzes people who have been arrested for their risk of becoming future perpetrators. It ranks 400,000 people on a scale of 0 to 500, using items such as age, criminal activity, victimization, drug arrest records, and gang affiliation. In looking at the data, analysts found that youth is a strong predictor of violence, being a shooting victim is associated with becoming a future perpetrator, gang affiliation has little predictive value, and drug arrests are not significantly associated with future criminal activity.23\nJudicial experts claim AI programs reduce human bias in law enforcement and leads to a fairer sentencing system. R Street Institute Associate Caleb Watney writes:\nEmpirically grounded questions of predictive risk analysis play to the strengths of machine learning, automated reasoning and other forms of AI. One machine-learning policy simulation concluded that such programs could be used to cut crime up to 24.8 percent with no change in jailing rates, or reduce jail populations by up to 42 percent with no increase in crime rates.24\nHowever, critics worry that AI algorithms represent “a secret system to punish citizens for crimes they haven’t yet committed. The risk scores have been used numerous times to guide large-scale roundups.”25 The fear is that such tools target people of color unfairly and have not helped Chicago reduce the murder wave that has plagued it in recent years.\nDespite these concerns, other countries are moving ahead with rapid deployment in this area. In China, for example, companies already have “considerable resources and access to voices, faces and other biometric data in vast quantities, which would help them develop their technologies.”26 New technologies make it possible to match images and voices with other types of information, and to use AI on these combined data sets to improve law enforcement and national security. Through its “Sharp Eyes” program, Chinese law enforcement is matching video images, social media activity, online purchases, travel records, and personal identity into a “police cloud.” This integrated database enables authorities to keep track of criminals, potential law-breakers, and terrorists.27 Put differently, China has become the world’s leading AI-powered surveillance state.\n']","Caleb Watney states that empirically grounded questions of predictive risk analysis play to the strengths of machine learning and AI. He mentions that one machine-learning policy simulation concluded that such programs could potentially cut crime by up to 24.8 percent without changing jailing rates, or reduce jail populations by up to 42 percent without increasing crime rates.",single_hop_specific_query_synthesizer
What role does Daimler play in the autonomous vehicle market?,"['Transportation\nTransportation represents an area where AI and machine learning are producing major innovations. Research by Cameron Kerry and Jack Karsten of the Brookings Institution has found that over $80 billion was invested in autonomous vehicle technology between August 2014 and June 2017. Those investments include applications both for autonomous driving and the core technologies vital to that sector.28\nAutonomous vehicles—cars, trucks, buses, and drone delivery systems—use advanced technological capabilities. Those features include automated vehicle guidance and braking, lane-changing systems, the use of cameras and sensors for collision avoidance, the use of AI to analyze information in real time, and the use of high-performance computing and deep learning systems to adapt to new circumstances through detailed maps.29\nLight detection and ranging systems (LIDARs) and AI are key to navigation and collision avoidance. LIDAR systems combine light and radar instruments. They are mounted on the top of vehicles that use imaging in a 360-degree environment from a radar and light beams to measure the speed and distance of surrounding objects. Along with sensors placed on the front, sides, and back of the vehicle, these instruments provide information that keeps fast-moving cars and trucks in their own lane, helps them avoid other vehicles, applies brakes and steering when needed, and does so instantly so as to avoid accidents.\nAdvanced software enables cars to learn from the experiences of other vehicles on the road and adjust their guidance systems as weather, driving, or road conditions change. This means that software is the key—not the physical car or truck itself.\nSince these cameras and sensors compile a huge amount of information and need to process it instantly to avoid the car in the next lane, autonomous vehicles require high-performance computing, advanced algorithms, and deep learning systems to adapt to new scenarios. This means that software is the key, not the physical car or truck itself.30 Advanced software enables cars to learn from the experiences of other vehicles on the road and adjust their guidance systems as weather, driving, or road conditions change.31\nRide-sharing companies are very interested in autonomous vehicles. They see advantages in terms of customer service and labor productivity. All of the major ride-sharing companies are exploring driverless cars. The surge of car-sharing and taxi services—such as Uber and Lyft in the United States, Daimler’s Mytaxi and Hailo service in Great Britain, and Didi Chuxing in China—demonstrate the opportunities of this transportation option. Uber recently signed an agreement to purchase 24,000 autonomous cars from Volvo for its ride-sharing service.32\nHowever, the ride-sharing firm suffered a setback in March 2018 when one of its autonomous vehicles in Arizona hit and killed a pedestrian. Uber and several auto manufacturers immediately suspended testing and launched investigations into what went wrong and how the fatality could have occurred.33 Both industry and consumers want reassurance that the technology is safe and able to deliver on its stated promises. Unless there are persuasive answers, this accident could slow AI advancements in the transportation sector.\n']","Daimler is involved in the autonomous vehicle market through its Mytaxi and Hailo services in Great Britain, demonstrating the opportunities in ride-sharing and taxi services.",single_hop_specific_query_synthesizer
How is Cinncinati using AI for emergency responses?,"['Smart cities\nMetropolitan governments are using AI to improve urban service delivery. For example, according to Kevin Desouza, Rashmi Krishnamurthy, and Gregory Dawson:\nThe Cincinnati Fire Department is using data analytics to optimize medical emergency responses. The new analytics system recommends to the dispatcher an appropriate response to a medical emergency call—whether a patient can be treated on-site or needs to be taken to the hospital—by taking into account several factors, such as the type of call, location, weather, and similar calls.34\nSince it fields 80,000 requests each year, Cincinnati officials are deploying this technology to prioritize responses and determine the best ways to handle emergencies. They see AI as a way to deal with large volumes of data and figure out efficient ways of responding to public requests. Rather than address service issues in an ad hoc manner, authorities are trying to be proactive in how they provide urban services.\n']","The Cincinnati Fire Department is using data analytics to optimize medical emergency responses. The new analytics system recommends to the dispatcher an appropriate response to a medical emergency call by considering factors such as the type of call, location, weather, and similar calls.",single_hop_specific_query_synthesizer
What Cincinnati do with AI for emergency calls?,"['Smart cities\nMetropolitan governments are using AI to improve urban service delivery. For example, according to Kevin Desouza, Rashmi Krishnamurthy, and Gregory Dawson:\nThe Cincinnati Fire Department is using data analytics to optimize medical emergency responses. The new analytics system recommends to the dispatcher an appropriate response to a medical emergency call—whether a patient can be treated on-site or needs to be taken to the hospital—by taking into account several factors, such as the type of call, location, weather, and similar calls.34\nSince it fields 80,000 requests each year, Cincinnati officials are deploying this technology to prioritize responses and determine the best ways to handle emergencies. They see AI as a way to deal with large volumes of data and figure out efficient ways of responding to public requests. Rather than address service issues in an ad hoc manner, authorities are trying to be proactive in how they provide urban services.\nCincinnati is not alone. A number of metropolitan areas are adopting smart city applications that use AI to improve service delivery, environmental planning, resource management, energy utilization, and crime prevention, among other things. For its smart cities index, the magazine Fast Company ranked American locales and found Seattle, Boston, San Francisco, Washington, D.C., and New York City as the top adopters. Seattle, for example, has embraced sustainability and is using AI to manage energy usage and resource management. Boston has launched a “City Hall To Go” that makes sure underserved communities receive needed public services. It also has deployed “cameras and inductive loops to manage traffic and acoustic sensors to identify gun shots.” San Francisco has certified 203 buildings as meeting LEED sustainability standards.35\nThrough these and other means, metropolitan areas are leading the country in the deployment of AI solutions. Indeed, according to a National League of Cities report, 66 percent of American cities are investing in smart city technology. Among the top applications noted in the report are “smart meters for utilities, intelligent traffic signals, e-governance applications, Wi-Fi kiosks, and radio frequency identification sensors in pavement.”36\n Policy, regulatory, and ethical issues\nThese examples from a variety of sectors demonstrate how AI is transforming many walks of human existence. The increasing penetration of AI and autonomous devices into many aspects of life is altering basic operations and decisionmaking within organizations, and improving efficiency and response times.\nAt the same time, though, these developments raise important policy, regulatory, and ethical issues. For example, how should we promote data access? How do we guard against biased or unfair data used in algorithms? What types of ethical principles are introduced through software programming, and how transparent should designers be about their choices? What about questions of legal liability in cases where algorithms cause harm?37\nThe increasing penetration of AI into many aspects of life is altering decisionmaking within organizations and improving efficiency. At the same time, though, these developments raise important policy, regulatory, and ethical issues.\n']","Cincinnati Fire Department is using data analytics to optimize medical emergency responses. The new analytics system recommends to the dispatcher an appropriate response to a medical emergency call by considering factors like the type of call, location, weather, and similar calls.",single_hop_specific_query_synthesizer
"How has research from Harvard Business School highlighted biases in AI systems, particularly in relation to discrimination against racial minorities?","['Data access problems\nThe key to getting the most out of AI is having a “data-friendly ecosystem with unified standards and cross-platform sharing.” AI depends on data that can be analyzed in real time and brought to bear on concrete problems. Having data that are “accessible for exploration” in the research community is a prerequisite for successful AI development.38\nAccording to a McKinsey Global Institute study, nations that promote open data sources and data sharing are the ones most likely to see AI advances. In this regard, the United States has a substantial advantage over China. Global ratings on data openness show that U.S. ranks eighth overall in the world, compared to 93 for China.39\nBut right now, the United States does not have a coherent national data strategy. There are few protocols for promoting research access or platforms that make it possible to gain new insights from proprietary data. It is not always clear who owns data or how much belongs in the public sphere. These uncertainties limit the innovation economy and act as a drag on academic research. In the following section, we outline ways to improve data access for researchers.\n Biases in data and algorithms\nIn some instances, certain AI systems are thought to have enabled discriminatory or biased practices.40 For example, Airbnb has been accused of having homeowners on its platform who discriminate against racial minorities. A research project undertaken by the Harvard Business School found that “Airbnb users with distinctly African American names were roughly 16 percent less likely to be accepted as guests than those with distinctly white names.”41\nRacial issues also come up with facial recognition software. Most such systems operate by comparing a person’s face to a range of faces in a large database. As pointed out by Joy Buolamwini of the Algorithmic Justice League, “If your facial recognition data contains mostly Caucasian faces, that’s what your program will learn to recognize.”42 Unless the databases have access to diverse data, these programs perform poorly when attempting to recognize African-American or Asian-American features.\nMany historical data sets reflect traditional values, which may or may not represent the preferences wanted in a current system. As Buolamwini notes, such an approach risks repeating inequities of the past:\nThe rise of automation and the increased reliance on algorithms for high-stakes decisions such as whether someone get insurance or not, your likelihood to default on a loan or somebody’s risk of recidivism means this is something that needs to be addressed. Even admissions decisions are increasingly automated—what school our children go to and what opportunities they have. We don’t have to bring the structural inequalities of the past into the future we create.43\n']","A research project undertaken by the Harvard Business School found that Airbnb users with distinctly African American names were roughly 16 percent less likely to be accepted as guests than those with distinctly white names. This example illustrates how certain AI systems can enable discriminatory practices, highlighting the need for diverse data in AI development to avoid perpetuating biases.",single_hop_specific_query_synthesizer
What insights does Jon Valant provide regarding the use of algorithms in urban school enrollment decisions?,"['AI ethics and transparency\nAlgorithms embed ethical considerations and value choices into program decisions. As such, these systems raise questions concerning the criteria used in automated decisionmaking. Some people want to have a better understanding of how algorithms function and what choices are being made.44\nIn the United States, many urban schools use algorithms for enrollment decisions based on a variety of considerations, such as parent preferences, neighborhood qualities, income level, and demographic background. According to Brookings researcher Jon Valant, the New Orleans–based Bricolage Academy “gives priority to economically disadvantaged applicants for up to 33 percent of available seats. In practice, though, most cities have opted for categories that prioritize siblings of current students, children of school employees, and families that live in school’s broad geographic area.”45 Enrollment choices can be expected to be very different when considerations of this sort come into play.\nDepending on how AI systems are set up, they can facilitate the redlining of mortgage applications, help people discriminate against individuals they don’t like, or help screen or build rosters of individuals based on unfair criteria. The types of considerations that go into programming decisions matter a lot in terms of how the systems operate and how they affect customers.46\nFor these reasons, the EU is implementing the General Data Protection Regulation (GDPR) in May 2018. The rules specify that people have “the right to opt out of personally tailored ads” and “can contest ‘legal or similarly significant’ decisions made by algorithms and appeal for human intervention” in the form of an explanation of how the algorithm generated a particular outcome. Each guideline is designed to ensure the protection of personal data and provide individuals with information on how the “black box” operates.47\nLegal liability\nThere are questions concerning the legal liability of AI systems. If there are harms or infractions (or fatalities in the case of driverless cars), the operators of the algorithm likely will fall under product liability rules. A body of case law has shown that the situation’s facts and circumstances determine liability and influence the kind of penalties that are imposed. Those can range from civil fines to imprisonment for major harms.48 The Uber-related fatality in Arizona will be an important test case for legal liability. The state actively recruited Uber to test its autonomous vehicles and gave the company considerable latitude in terms of road testing. It remains to be seen if there will be lawsuits in this case and who is sued: the human backup driver, the state of Arizona, the Phoenix suburb where the accident took place, Uber, software developers, or the auto manufacturer. Given the multiple people and organizations involved in the road testing, there are many legal questions to be resolved.\n']","According to Brookings researcher Jon Valant, algorithms used in urban school enrollment decisions prioritize various factors such as parent preferences, neighborhood qualities, income level, and demographic background. For instance, the New Orleans–based Bricolage Academy gives priority to economically disadvantaged applicants for up to 33 percent of available seats. However, in practice, many cities have chosen categories that prioritize siblings of current students, children of school employees, and families living in the school's broad geographic area, which can lead to very different enrollment choices.",single_hop_specific_query_synthesizer
How does Airbnb limit consumer protections for its users?,"['A body of case law has shown that the situation’s facts and circumstances determine liability and influence the kind of penalties that are imposed. Those can range from civil fines to imprisonment for major harms.48 The Uber-related fatality in Arizona will be an important test case for legal liability. The state actively recruited Uber to test its autonomous vehicles and gave the company considerable latitude in terms of road testing. It remains to be seen if there will be lawsuits in this case and who is sued: the human backup driver, the state of Arizona, the Phoenix suburb where the accident took place, Uber, software developers, or the auto manufacturer. Given the multiple people and organizations involved in the road testing, there are many legal questions to be resolved.\nIn non-transportation areas, digital platforms often have limited liability for what happens on their sites. For example, in the case of Airbnb, the firm “requires that people agree to waive their right to sue, or to join in any class-action lawsuit or class-action arbitration, to use the service.” By demanding that its users sacrifice basic rights, the company limits consumer protections and therefore curtails the ability of people to fight discrimination arising from unfair algorithms.49 But whether the principle of neutral networks holds up in many sectors is yet to be determined on a widespread basis.\n Recommendations\nIn order to balance innovation with basic human values, we propose a number of recommendations for moving forward with AI. This includes improving data access, increasing government investment in AI, promoting AI workforce development, creating a federal advisory committee, engaging with state and local officials to ensure they enact effective policies, regulating broad objectives as opposed to specific algorithms, taking bias seriously as an AI issue, maintaining mechanisms for human control and oversight, and penalizing malicious behavior and promoting cybersecurity.\n']",Airbnb limits consumer protections by requiring users to agree to waive their right to sue or join in any class-action lawsuit or class-action arbitration in order to use the service. This demand for users to sacrifice basic rights curtails their ability to fight discrimination arising from unfair algorithms.,single_hop_specific_query_synthesizer
Wht role did Amazon play in the research and policy solutions regarding AI and its implications for society?,"['<1-hop>\n\nConclusion\nTo summarize, the world is on the cusp of revolutionizing many sectors through artificial intelligence and data analytics. There already are significant deployments in finance, national security, health care, criminal justice, transportation, and smart cities that have altered decisionmaking, business models, risk mitigation, and system performance. These developments are generating substantial economic and social benefits.\nThe world is on the cusp of revolutionizing many sectors through artificial intelligence, but the way AI systems are developed need to be better understood due to the major implications these technologies will have for society as a whole.\nYet the manner in which AI systems unfold has major implications for society as a whole. It matters how policy issues are addressed, ethical conflicts are reconciled, legal realities are resolved, and how much transparency is required in AI and data analytic solutions.74 Human choices about software development affect the way in which decisions are made and the manner in which they are integrated into organizational routines. Exactly how these processes are executed need to be better understood because they will have substantial impact on the general public soon, and for the foreseeable future. AI may well be a revolution in human affairs, and become the single most influential human innovation in history.\nNote: We appreciate the research assistance of Grace Gilberg, Jack Karsten, Hillary Schaub, and Kristjan Tomasson on this project.\nThe Brookings Institution is a nonprofit organization devoted to independent research and policy solutions. Its mission is to conduct high-quality, independent research and, based on that research, to provide innovative, practical recommendations for policymakers and the public. The conclusions and recommendations of any Brookings publication are solely those of its author(s), and do not reflect the views of the Institution, its management, or its other scholars.\nSupport for this publication was generously provided by Amazon. Brookings recognizes that the value it provides is in its absolute commitment to quality, independence, and impact. Activities supported by its donors reflect this commitment.\nJohn R. Allen is a member of the Board of Advisors of Amida Technology and on the Board of Directors of Spark Cognition. Both companies work in fields discussed in this piece.\n-\nFootnotes\n- Thomas Davenport, Jeff Loucks, and David Schatsky, “Bullish on the Business Value of Cognitive” (Deloitte, 2017), p. 3 (www2.deloitte.com/us/en/pages/deloitte-analytics/articles/cognitive-technology-adoption-survey.html).\n- Luke Dormehl, Thinking Machines: The Quest for Artificial Intelligence—and Where It’s Taking Us Next (New York: Penguin–TarcherPerigee, 2017).\n- Shubhendu and Vijay, “Applicability of Artificial Intelligence in Different Fields of Life.”\n- Ibid.\n- Andrew McAfee and Erik Brynjolfsson, Machine Platform Crowd: Harnessing Our Digital Future (New York: Norton, 2017).\n- Portions of this paper draw on Darrell M. West, The Future of Work: Robots, AI, and Automation, Brookings Institution Press, 2018.\n- PriceWaterhouseCoopers, “Sizing the Prize: What’s the Real Value of AI for Your Business and How Can You Capitalise?” 2017.\n- Dominic Barton, Jonathan Woetzel, Jeongmin Seong, and Qinzheng Tian, “Artificial Intelligence: Implications for China” (New York: McKinsey Global Institute, April 2017), p. 1.\n- Nathaniel Popper, “Stocks and Bots,” New York Times Magazine, February 28, 2016.\n- Ibid.\n- Ibid.\n- Michael Lewis, Flash Boys: A Wall Street Revolt (New York: Norton, 2015).\n- Cade Metz, “In Quantum Computing Race, Yale Professors Battle Tech Giants,” New York Times, November 14, 2017, p. B3.\n- Executive Office of the President, “Artificial Intelligence, Automation, and the Economy,” December 2016, pp. 27-28.\n- Christian Davenport, “Future Wars May Depend as Much on Algorithms as on Ammunition, Report Says,” Washington Post, December 3, 2017.\n- Ibid.\n- John R. Allen and Amir Husain, “On Hyperwar,” Naval Institute Proceedings, July 17, 2017, pp. 30-36.\n', ""<2-hop>\n\nWhat is AI, how does it work and why are some people concerned about it?\nArtificial intelligence (AI) has increasingly become part of everyday life over the past decade.\nIt is being used to personalise social media feeds, spot friends and family in smartphone photos and pave the way for medical breakthroughs.\nBut the rise of chatbots like OpenAI's ChatGPT and Meta AI has been accompanied by concern about the technology's environmental impact, ethical implications and data use.\n What is AI and what is it used for?\nAI allows computers to process large amounts of data, identify patterns and follow detailed instructions about what to do with that information.\nComputers cannot think, empathise or reason.\nHowever, scientists have developed systems that can perform tasks which usually require human intelligence, trying to replicate how people acquire and use knowledge.\nThis could be trying to anticipate what product an online shopper might buy, based on previous purchases, in order to recommend items.\nThe technology is also behind voice-controlled virtual assistants like Apple's Siri and Amazon's Alexa, and is being used to develop systems for self-driving cars.\nAI also helps social platforms like Facebook, TikTok and X decide what posts to show users. Streaming services Spotify and Deezer use AI to suggest music.\nThere are also a number of applications in medicine, as scientists use AI to help spot cancers, review X-ray results, speed up diagnoses and identify new treatments.\n What is generative AI, and how do apps like ChatGPT and Meta AI work?\nGenerative AI is used to create new content which can seem like it has been made by a human.\nIt does this by learning from vast quantities of existing data such as online text and images.\nChatGPT and Chinese rival DeepSeek's chatbot are popular generative AI tools that can be used to produce text, images, code and more material.\nGoogle's Gemini or Meta AI can similarly hold text conversations with users.\nApps like Midjourney or Veo 3 are dedicated to creating images or video from simple text prompts.\nGenerative AI can also be used to make high-quality music.\nSongs mimicking the style or sound of famous musicians have gone viral, sometimes leaving fans confused about their authenticity.\n""]","Amazon provided generous support for the publication by the Brookings Institution, which is devoted to independent research and policy solutions. This support reflects Amazon's commitment to quality, independence, and impact in the context of AI's implications for society.",multi_hop_specific_query_synthesizer
What are the key differences in the regulatory approaches to AI between the U.S. and the European Union as discussed in the context?,"['<1-hop>\n\nIntelligence, please visit the AI topic page.\nMost people are not very familiar with the concept of artificial intelligence (AI). As an illustration, when 1,500 senior business leaders in the United States in 2017 were asked about AI, only 17 percent said they were familiar with it.1 A number of them were not sure what it was or how it would affect their particular companies. They understood there was considerable potential for altering business processes, but were not clear how AI could be deployed within their own organizations.\nDespite its widespread lack of familiarity, AI is a technology that is transforming every walk of life. It is a wide-ranging tool that enables people to rethink how we integrate information, analyze data, and use the resulting insights to improve decisionmaking. Our hope through this comprehensive overview is to explain AI to an audience of policymakers, opinion leaders, and interested observers, and demonstrate how AI already is altering the world and raising important questions for society, the economy, and governance.\nIn this paper, we discuss novel applications in finance, national security, health care, criminal justice, transportation, and smart cities, and address issues such as data access problems, algorithmic bias, AI ethics and transparency, and legal liability for AI decisions. We contrast the regulatory approaches of the U.S. and European Union, and close by making a number of recommendations for getting the most out of AI while still protecting important human values.2\nIn order to maximize AI benefits, we recommend nine steps for going forward:\n- Encourage greater data access for researchers without compromising users’ personal privacy,\n- invest more government funding in unclassified AI research,\n- promote new models of digital education and AI workforce development so employees have the skills needed in the 21st-century economy,\n- create a federal AI advisory committee to make policy recommendations,\n- engage with state and local officials so they enact effective policies,\n- regulate broad AI principles rather than specific algorithms,\n- take bias complaints seriously so AI does not replicate historic injustice, unfairness, or discrimination in data or algorithms,\n- maintain mechanisms for human oversight and control, and\n- penalize malicious AI behavior and promote cybersecurity.\nQualities of artificial intelligence\nAlthough there is no uniformly agreed upon definition, AI generally is thought to refer to “machines that respond to stimulation consistent with traditional responses from humans, given the human capacity for contemplation, judgment and intention.”3 According to researchers Shubhendu and Vijay, these software systems “make decisions which normally require [a] human level of expertise” and help people anticipate problems or deal with issues as they come up.4 As such, they operate in an intentional, intelligent, and adaptive manner.\nIntentionality\nArtificial intelligence algorithms are designed to make decisions, often using real-time data. They are unlike passive machines that are capable only of mechanical or predetermined responses. Using sensors, digital data, or remote inputs, they combine information from a variety of different sources, analyze the material instantly, and act on the insights derived from those data. With massive improvements in storage systems, processing speeds, and analytic techniques, they are capable of tremendous sophistication in analysis and decisionmaking.\nArtificial intelligence is already altering the world and raising important questions for society, the economy, and governance.\nIntelligence\nAI generally is undertaken in conjunction with machine learning and data analytics.5 Machine learning takes data and looks for underlying trends. If it spots something that is relevant for a practical problem, software designers can take that knowledge and use it to analyze specific issues. All that is required are data that are sufficiently robust that algorithms can discern useful patterns. Data can come in the form of digital information, satellite imagery, visual information, text, or unstructured data.\n', '<2-hop>\n\nThis article was published in 2018. To read more recent content from Brookings on Artificial Intelligence, please visit the AI topic page.\nMost people are not very familiar with the concept of artificial intelligence (AI). As an illustration, when 1,500 senior business leaders in the United States in 2017 were asked about AI, only 17 percent said they were familiar with it.1 A number of them were not sure what it was or how it would affect their particular companies. They understood there was considerable potential for altering business processes, but were not clear how AI could be deployed within their own organizations.\nDespite its widespread lack of familiarity, AI is a technology that is transforming every walk of life. It is a wide-ranging tool that enables people to rethink how we integrate information, analyze data, and use the resulting insights to improve decisionmaking. Our hope through this comprehensive overview is to explain AI to an audience of policymakers, opinion leaders, and interested observers, and demonstrate how AI already is altering the world and raising important questions for society, the economy, and governance.\nIn this paper, we discuss novel applications in finance, national security, health care, criminal justice, transportation, and smart cities, and address issues such as data access problems, algorithmic bias, AI ethics and transparency, and legal liability for AI decisions. We contrast the regulatory approaches of the U.S. and European Union, and close by making a number of recommendations for getting the most out of AI while still protecting important human values.2\nIn order to maximize AI benefits, we recommend nine steps for going forward:\n- Encourage greater data access for researchers without compromising users’ personal privacy,\n- invest more government funding in unclassified AI research,\n- promote new models of digital education and AI workforce development so employees have the skills needed in the 21st-century economy,\n- create a federal AI advisory committee to make policy recommendations,\n- engage with state and local officials so they enact effective policies,\n- regulate broad AI principles rather than specific algorithms,\n- take bias complaints seriously so AI does not replicate historic injustice, unfairness, or discrimination in data or algorithms,\n- maintain mechanisms for human oversight and control, and\n- penalize malicious AI behavior and promote cybersecurity.\n Qualities of artificial intelligence\nAlthough there is no uniformly agreed upon definition, AI generally is thought to refer to “machines that respond to stimulation consistent with traditional responses from humans, given the human capacity for contemplation, judgment and intention.”3 According to researchers Shubhendu and Vijay, these software systems “make decisions which normally require [a] human level of expertise” and help people anticipate problems or deal with issues as they come up.4 As such, they operate in an intentional, intelligent, and adaptive manner.\n']","The context highlights that the regulatory approaches to AI differ significantly between the U.S. and the European Union. While the U.S. focuses on regulating broad AI principles rather than specific algorithms, the European Union's approach is more comprehensive, addressing issues such as data access, algorithmic bias, AI ethics, and transparency. The paper emphasizes the importance of protecting human values while maximizing the benefits of AI, suggesting that both regions need to engage with policymakers to enact effective policies.",multi_hop_specific_query_synthesizer
"How does IBM's Teacher Advisor program, which utilizes Watson's tools, contribute to the reimagining of educational institutions in the context of increasing government investment in AI?","['<1-hop>\n\nAI will reconfigure how society and the economy operate, and there needs to be “big picture” thinking on what this will mean for ethics, governance, and societal impact. People will need the ability to think broadly about many questions and integrate knowledge from a number of different areas.\nOne example of new ways to prepare students for a digital future is IBM’s Teacher Advisor program, utilizing Watson’s free online tools to help teachers bring the latest knowledge into the classroom. They enable instructors to develop new lesson plans in STEM and non-STEM fields, find relevant instructional videos, and help students get the most out of the classroom.58 As such, they are precursors of new educational environments that need to be created.\n Create a federal AI advisory committee\nFederal officials need to think about how they deal with artificial intelligence. As noted previously, there are many issues ranging from the need for improved data access to addressing issues of bias and discrimination. It is vital that these and other concerns be considered so we gain the full benefits of this emerging technology.\nIn order to move forward in this area, several members of Congress have introduced the “Future of Artificial Intelligence Act,” a bill designed to establish broad policy and legal principles for AI. It proposes the secretary of commerce create a federal advisory committee on the development and implementation of artificial intelligence. The legislation provides a mechanism for the federal government to get advice on ways to promote a “climate of investment and innovation to ensure the global competitiveness of the United States,” “optimize the development of artificial intelligence to address the potential growth, restructuring, or other changes in the United States workforce,” “support the unbiased development and application of artificial intelligence,” and “protect the privacy rights of individuals.”59\nAmong the specific questions the committee is asked to address include the following: competitiveness, workforce impact, education, ethics training, data sharing, international cooperation, accountability, machine learning bias, rural impact, government efficiency, investment climate, job impact, bias, and consumer impact. The committee is directed to submit a report to Congress and the administration 540 days after enactment regarding any legislative or administrative action needed on AI.\nThis legislation is a step in the right direction, although the field is moving so rapidly that we would recommend shortening the reporting timeline from 540 days to 180 days. Waiting nearly two years for a committee report will certainly result in missed opportunities and a lack of action on important issues. Given rapid advances in the field, having a much quicker turnaround time on the committee analysis would be quite beneficial.\n', '<2-hop>\n\nIncrease government investment in AI\nAccording to Greg Brockman, the co-founder of OpenAI, the U.S. federal government invests only $1.1 billion in non-classified AI technology.55 That is far lower than the amount being spent by China or other leading nations in this area of research. That shortfall is noteworthy because the economic payoffs of AI are substantial. In order to boost economic development and social innovation, federal officials need to increase investment in artificial intelligence and data analytics. Higher investment is likely to pay for itself many times over in economic and social benefits.56\n Promote digital education and workforce development\nAs AI applications accelerate across many sectors, it is vital that we reimagine our educational institutions for a world where AI will be ubiquitous and students need a different kind of training than they currently receive. Right now, many students do not receive instruction in the kinds of skills that will be needed in an AI-dominated landscape. For example, there currently are shortages of data scientists, computer scientists, engineers, coders, and platform developers. These are skills that are in short supply; unless our educational system generates more people with these capabilities, it will limit AI development.\nFor these reasons, both state and federal governments have been investing in AI human capital. For example, in 2017, the National Science Foundation funded over 6,500 graduate students in computer-related fields and has launched several new initiatives designed to encourage data and computer science at all levels from pre-K to higher and continuing education.57 The goal is to build a larger pipeline of AI and data analytic personnel so that the United States can reap the full advantages of the knowledge revolution.\nBut there also needs to be substantial changes in the process of learning itself. It is not just technical skills that are needed in an AI world but skills of critical reasoning, collaboration, design, visual display of information, and independent thinking, among others. AI will reconfigure how society and the economy operate, and there needs to be “big picture” thinking on what this will mean for ethics, governance, and societal impact. People will need the ability to think broadly about many questions and integrate knowledge from a number of different areas.\nOne example of new ways to prepare students for a digital future is IBM’s Teacher Advisor program, utilizing Watson’s free online tools to help teachers bring the latest knowledge into the classroom. They enable instructors to develop new lesson plans in STEM and non-STEM fields, find relevant instructional videos, and help students get the most out of the classroom.58 As such, they are precursors of new educational environments that need to be created.\n']","IBM's Teacher Advisor program, which utilizes Watson's free online tools, contributes to the reimagining of educational institutions by helping teachers develop new lesson plans in both STEM and non-STEM fields. This program is essential as it prepares students for a digital future, aligning with the need for educational reform in light of increasing government investment in AI. As the U.S. federal government seeks to boost economic development and social innovation through higher investment in artificial intelligence, initiatives like the Teacher Advisor program serve as precursors to new educational environments that will equip students with the necessary skills for an AI-dominated landscape.",multi_hop_specific_query_synthesizer
"What insights does the research by Thomas Cunningham and his co-authors provide regarding the usage patterns of ChatGPT, particularly in terms of work-related versus non-work-related messages, and how does this reflect on the economic value of AI in knowledge-intensive jobs?","['<1-hop>\n\nNBER WORKING PAPER SERIES\nHOW PEOPLE USE CHATGPT\nAaron Chatterji\nThomas Cunningham\nDavid J. Deming\nZoe Hitzig\nChristopher Ong\nCarl Yan Shan\nKevin Wadman\nWorking Paper 34255\nhttp://www.nber.org/papers/w34255\nNATIONAL BUREAU OF ECONOMIC RESEARCH\n1050 Massachusetts Avenue\nCambridge, MA 02138\nSeptember 2025\nWe acknowledge help and comments from Joshua Achiam, Hemanth Asirvatham, Ryan Beiermeister, Rachel Brown, Cassandra Duchan Solis, Jason Kwon, Elliott Mokski, Kevin Rao, Harrison Satcher, Gawesha Weeratunga, Hannah Wong, and Analytics & Insights team. We especially thank Tyna Eloundou and Pamela Mishkin who in several ways laid the foundation for this work. This study was approved by Harvard IRB (IRB25-0983). A repository containing all code run to produce the analyses in this paper is available on request. The views expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.\nAt least one co-author has disclosed additional relationships of potential relevance for this research. Further information is available online at http://www.nber.org/papers/w34255\nNBER working papers are circulated for discussion and comment purposes. They have not been peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies official NBER publications.\n© 2025 by Aaron Chatterji, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl Yan Shan, and Kevin Wadman. All rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including © notice, is given to the source.\x0cHow People Use ChatGPT\nAaron Chatterji, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl\nYan Shan, and Kevin Wadman\nNBER Working Paper No. 34255\nSeptember 2025\nJEL No. J01, O3, O4\nABSTRACT\nDespite the rapid adoption of LLM chatbots, little is known about how they are used. We document the growth of ChatGPT’s consumer product from its launch in November 2022 through July 2025, when it had been adopted by around 10% of the world’s adult population. Early adopters were disproportionately male but the gender gap has narrowed dramatically, and we find higher growth rates in lower-income countries. Using a privacy-preserving automated pipeline, we classify usage patterns within a representative sample of ChatGPT conversations. We find steady growth in work-related messages bu t even faster growth in non-work-related messages, which have grown from 53% to more than 70% of all usage. Work usage is more common for educated users in highly-paid professional occupations. We classify messages by conversation top\nic and find that “Practical Guidance,” “Seeking Information,” and “Writing” are the three most common topics and collectively account for nearly 80% of all conversations. Writing dominates work-related tasks, highlighting chatbots’ unique ability to generate digital outputs compared to traditional sear ch engines. Computer programming and self-expression both represent relatively small shares of use. Overall, we find that ChatGPT provides economic value through decision support, which is especially important in knowledge-intensive jobs.\nAaron Chatterji\nDuke University\nFuqua School of Business and OpenAI\nronnie@duke.edu\nThomas Cunningham OpenAI\ntom.cunningham@gmail.com\nDavid J. Deming\nHarvard University\nHarvard Kennedy School and NBER\ndavid_deming@harvard.edu\nZoe Hitzig\nOpenAI\nand Harvard Society of Fellows\nzhitzig@g.harvard.edu\nChristopher Ong\nHarvard University\nand OpenAI\nchristopherong@hks.harvard.edu\nCarl Yan Shan\nOpenAI\ncshan@openai.com\nKevin Wadman\nOpenAI\nkevin.wadman@c-openai.com\x0c', '<2-hop>\n\nABSTRACT Despite the rapid adoption of LLM chatbots, little is known about how they are used. We document the growth of ChatGPT’s consumer product from its launch in November 2022 through July 2025, when it had been adopted by around 10% of the world’s adult population. Early adopters were disproportionately male but the gender gap has narrowed dramatically, and we find higher growth rates in lower-income countries. Using a privacy-preserving automated pipeline, we classify usage patterns within a representative sample of ChatGPT conversations. We find steady growth in work-related messages bu t even faster growth in non-work-related messages, which have grown from 53% to more than 70% of all usage. Work usage is more common for educated users in highly-paid professional occupations. We classify messages by conversation top ic and find that “Practical Guidance,” “Seeking Information,” and “Writing” are the three most common topics and collectively account for nearly 80% of all conversations. Writing dominates work-related tasks, highlighting chatbots’ unique ability to generate digital outputs compared to traditional sear ch engines. Computer programming and self-expression both represent relatively small shares of use. Overall, we find that ChatGPT provides economic value through decision support, which is especially important in knowledge-intensive jobs. Aaron Chatterji Duke University Fuqua School of Business and OpenAI ronnie@duke.edu Thomas Cunningham OpenAI tom.cunningham@gmail.com David J. Deming Harvard University Harvard Kennedy School and NBER david_deming@harvard.edu Zoe Hitzig OpenAI and Harvard Society of Fellows zhitzig@g.harvard.edu Christopher Ong Harvard University and OpenAI christopherong@hks.harvard.edu Carl Yan Shan OpenAI cshan@openai.com Kevin Wadman OpenAI kevin.wadman@c-openai.com 1 Introduction ChatGPT launched in November 2022. By July 2025, 18 billion messages were being sent each week by 700 million users, representing around 10% of the global adult population. 1 For a new technology, this speed of global diffusion has no precedent (Bick et al., 2024). This paper studies consumer usage of ChatGPT, the first mass-market chatbot and likely the largest.2 ChatGPT is based on a Large Language Model (LLM), a type of Artificial Intelligence (AI) developed over the last decade and generally considered to represent an acceleration in AI capabilities.3 The sudden growth in LLM abilities and adoption has intensified interest in the effects of artificial intelligence on economic growth (Acemoglu, 2024; Korinek and Suh, 2024); employment (Eloundou et al., 2025); and society (Kulveit et al., 2025). However, despite the rapid adoption of LLMs, there is limited public information on how they are used. A number of surveys have measured self-reported adoption of LLMs (Bick et al., 2024; Pew Research Center, 2025); however there are reasons to expect bias in self-reports (Ling and Imas, 2025), and none of these papers have been able to directly track the quantity or nature of chatbot conversations. Two recent papers do report statistics on chatbot conversations, classified in a variety of ways (Handa et al., 2025; Tomlinson et al., 2025). We build on this work in several respects. First, the pool of users on ChatGPT is far larger, meaning we expect our data to be a closer approximation to the average chatbot user.4 Second, we use automated classifiers to report on the types of messages that users send using new classification taxonomies relative to the existing literature. Third, we report the diffusion of chatbot use across populations and the growth of different types of usage within cohorts. Fourth, we use a secure data clean room protocol to analyze aggregated employment and education categories for a sample of our users, lending new insights about differences in the types of messages sent by different groups while protecting user privacy. Our primary sample is a random selection of messages sent to ChatGPT on consumer plans (Free, Plus, Pro) between May 2024 and June 2025. 5 Messages from the user to chatbot are classified automatically using a number of different taxonomies: whether the message is used for paid work, the topic of conversation, and the type of interaction (asking, doing, or expressing), and the O*NET task the user is performing. Each taxonomy is defined in a prompt passed to an']","The research conducted by Thomas Cunningham and his co-authors documents the growth of ChatGPT's consumer product from its launch in November 2022 through July 2025, revealing that it had been adopted by around 10% of the world's adult population. The study highlights a significant shift in usage patterns, noting that while work-related messages have shown steady growth, non-work-related messages have increased even more dramatically, rising from 53% to over 70% of all usage. This trend indicates that ChatGPT is not only utilized for professional tasks but also for personal and informal communication. Furthermore, the research identifies that work usage is more prevalent among educated users in high-paying professional occupations. The most common topics of conversation include 'Practical Guidance,' 'Seeking Information,' and 'Writing,' which collectively account for nearly 80% of all interactions. This dominance of writing in work-related tasks underscores the unique capability of chatbots to generate digital outputs, thereby providing economic value through decision support, particularly in knowledge-intensive jobs.",multi_hop_specific_query_synthesizer
"Who uses ChatGPT more, men or women, and how does this change by 2025a?","['<1-hop>\n\n6 Who Uses ChatGPT\nIn this section we report basic descriptive facts about who uses consumer ChatGPT. Existing work\ndocuments variation in generative AI use by demographic groups within representative samples in\nthe U.S. (Bick et al. (2024), Hartley et al. (2025)) and within a subset of occupations in Denmark\n(Humlum and Vestergaard, 2025a). All of these papers find that generative AI is used more frequently\nby men, young people, and those with tertiary and/or graduate education.\nWe make three contributions relative to this prior literature. First, we confirm these broad demo-\ngraphic patterns in a global sample rather than a single country. Second, we provide more detail for\nselected demographics such as age, gender, and country of origin and study how gaps in each have\nchanged over time. Third, we use a secure data clean room to analyze how ChatGPT usage varies by\neducation and occupation.\n 6.1 Name Analysis\nWe investigate potential variation by gender by classifying a global random sample of over 1.1 million\nChatGPT users’ first names using public aggregated datasets of name-gender associations. We used\nthe World Gender Name Dictionary, and Social Security popular names, as well as datasets of popular\nBrazilian and Latin American names. This methodology is similar to that in (Hofstra et al., 2020)\nand (West et al., 2013). Names that were not in these datasets, or were flagged as ambiguous in the\ndatasets, or had significant disagreement amongst these datasets were classified asUnknown.\nExcludingUnknown, a significant share (around 80%) of the weekly active users (WAU) in the\nfirst few months after ChatGPT was released were by users with typically masculine first names.\nHowever, in the first half of 2025, we see the share of active users with typically feminine and typically\nmasculine names reach near-parity. By June 2025 we observe active users are more likely to have\ntypically feminine names. This suggests that gender gaps in ChatGPT usage have closed substantially\nover time.\nWe also study differences in usage topics. Users with typically female first names are relatively more\nlikely to send messages related toWritingandPractical Guidance. ']","Initially, generative AI, including ChatGPT, was used more frequently by men, particularly in the first few months after its release, where around 80% of weekly active users had typically masculine first names. However, by the first half of 2025, the share of active users with typically feminine names reached near-parity with those having typically masculine names. By June 2025, it was observed that active users were more likely to have typically feminine names, indicating that gender gaps in ChatGPT usage have closed substantially over time.",multi_hop_specific_query_synthesizer
"What are the protocols and limitations enforced in a Data Clean Room (DCR) for analyzing employment data, and how do these relate to the classification of messages in AI systems?","['<1-hop>\n\nPrivacy via a Data Clean Room.We never directly accessed user-level demographic records.\nAll analysis of employment data was executed exclusively within a secure DCR that permits only\npre-approved aggregate computations across independently held datasets; neither party can view or\nexport the other party’s underlying records. We governed the DCR with strict protocols: To execute\nany query that touched the external demographic data, we first obtained explicit sign-off from a\ncommittee of 6 coauthors and then submitted the notebook to our data partner for approval; only\napproved notebooks could run in the DCR (see Figure 2).\nOur partner enforced strict aggregation limits: they only approved code that returned cells meeting\na threshold of 100 users. Consequently, no individual rows or narrowly defined categories were ever\nvisible to researchers. For example, if 99 users had the occupation “anesthesiologist,” any occupation-\nlevel output would place those users into a “suppressed” category, or place these observations in a\ncoarsened category (e.g. “medical professionals”) rather than reporting a separate cell of anesthesiol-\nogists.\n19The dataset was collected from a third party chatbot using OpenAI’s LLMs via their API.\n8\x0cFigure 2:Illustration of Aggregated Employment Category Analysis via a Data Clean Room. All queries run\nin the Data Clean Room must be approved by our data partner, enforcing a strict aggregation threshold (100\nobservations). As a result, researchers cannot access user-level employment data, only aggregated employment\ncategories.\n', '<2-hop>\n\n” (truncated)\n[user]: “10 more”\nTable 2:Illustration of Context-Augmented Message Classifications (Synthetic Example). The left column\nshows a standalone message to be classified, and the right column shows the prior context included in the\nclassification of the message on the left.\nWe truncate each message to a maximum of 5,000 characters, because long context windows could\ninduce variability in the quality of the classification (Liu et al., 2023). We classify each message\nwith the “gpt-5-mini” model, with the exception ofInteraction Quality,which uses “gpt-5,” using the\nprompts listed in Appendix A.\n17Internal analyses show that the tool,Privacy Filter, has substantial alignment with human judgment.\n18In the case ofInteraction Quality,we additionally include the next two messages in the conversation as context.\n7\x0cWe validated each of the classification prompts by comparing model classification decisions against\nhuman-judged classifications of a sample of conversations from the publicly available WildChat dataset\n(Zhao et al., 2024), a set of conversations with a third-party chatbot which users affirmatively gave\ntheir assent to share publicly for research purposes. 19 Appendix B provides detail on our validation\napproach and performance relative to human judgment. For additional transparency, we classify\na sample of 100,000 public WildChat messages and provide those data in this paper’s replication\npackage.\n 3.3 Employment Dataset\nWe conduct limited analyses of aggregated employment categories based on publicly available data\nfor a sample of consumer ChatGPT users. This sample included approximately 130,000 Free, Plus,\nand Pro users, and the employment categories were aggregated by a vendor working through a secure\nData Clean Room (DCR). For this analysis, we use the same exclusion criteria as for the message-level\ndatasets: we exclude deactivated users, banned users, users who have opted out of training, and users\nwhose self-reported age is under 18. Because the data was only available for a subset of users the\nresults may not be representative of the full pool of users.\nDescription.The employment data, which is aggregated from publicly available sources, includes\nindustry, occupations coarsened to O*NET categories, seniority level, company size, and education\ninformation that is limited to the degree attained. A vendor working within a DCR procured this\ndataset, restricted us to running only aggregated queries against it through the DCR, and deleted it\nupon the study’s completion.\n']","In a Data Clean Room (DCR), strict protocols govern the analysis of employment data to ensure privacy. All analysis is conducted within a secure environment where user-level demographic records are never directly accessed. Queries touching external demographic data require explicit sign-off from a committee of coauthors and must be approved by the data partner. The DCR enforces aggregation limits, only allowing code that returns cells with a minimum of 100 users, thus preventing visibility of individual rows or narrowly defined categories. For instance, if there are fewer than 100 users in a specific occupation, those users are categorized into a broader group to maintain anonymity. This approach is similar to the classification of messages in AI systems, where context is truncated to avoid variability in classification quality, and human-judged classifications are used to validate model decisions. Both processes emphasize the importance of privacy and the use of aggregated data to protect individual identities.",multi_hop_specific_query_synthesizer
How does the gpt-5-mini model classify messages while ensuring privacy through automated classifiers?,"['<1-hop>\n\nPrivacy via Automated Classifiers.No one looked at the content of messages while conducting\nanalysis for this paper. All analysis of message content was performed via automated LLM-based\nclassifiers run on de-identified and PII-scrubbed message data (see Figure 1). The messages are first\nscrubbed of PII using an internal LLM-based tool,17 and then classified according to classifiers defined\nover a controlled label space—the most precise classifier we use on the message-level data set is the\nO*NET Intermediate Work Activities taxonomy, which we augment to end up with 333 categories.\nWe introduce technical and procedural frictions that prevent accidental access to the underlying text\n(for example, interfaces that do not render message text to researchers).\nOur classifications aim to discern the intent of a given message, and thus we include the prior 10\nmessages in a conversation as context. 18 For an example, see Table 2.\n Stand-Alone Message Message with Prior Context\n[user]: “10 more” [user]: “give me 3 cultural activities to do with teens”\n[assistant]: “1. Visit a museum . . . ” (truncated)\n[user]: “10 more”\nTable 2:Illustration of Context-Augmented Message Classifications (Synthetic Example). The left column\nshows a standalone message to be classified, and the right column shows the prior context included in the\nclassification of the message on the left.\nWe truncate each message to a maximum of 5,000 characters, because long context windows could\ninduce variability in the quality of the classification (Liu et al., 2023). We classify each message\nwith the “gpt-5-mini” model, with the exception ofInteraction Quality,which uses “gpt-5,” using the\nprompts listed in Appendix A.\n17Internal analyses show that the tool,Privacy Filter, has substantial alignment with human judgment.\n']","The gpt-5-mini model classifies messages by using automated LLM-based classifiers on de-identified and PII-scrubbed message data. This process involves scrubbing messages of personally identifiable information (PII) using an internal LLM-based tool before classification. The model classifies messages according to a controlled label space, specifically using the O*NET Intermediate Work Activities taxonomy, which is augmented to create 333 categories. Additionally, the classification process includes the prior 10 messages in a conversation as context to discern the intent of a given message, while technical and procedural frictions are introduced to prevent accidental access to the underlying text.",multi_hop_specific_query_synthesizer
"How does Google's approach to data access contribute to research and innovation in artificial intelligence, and what are the implications for businesses seeking to integrate AI into their operations?","['<1-hop>\n\nImproving data access\nThe United States should develop a data strategy that promotes innovation and consumer protection. Right now, there are no uniform standards in terms of data access, data sharing, or data protection. Almost all the data are proprietary in nature and not shared very broadly with the research community, and this limits innovation and system design. AI requires data to test and improve its learning capacity.50 Without structured and unstructured data sets, it will be nearly impossible to gain the full benefits of artificial intelligence.\nIn general, the research community needs better access to government and business data, although with appropriate safeguards to make sure researchers do not misuse data in the way Cambridge Analytica did with Facebook information. There is a variety of ways researchers could gain data access. One is through voluntary agreements with companies holding proprietary data. Facebook, for example, recently announced a partnership with Stanford economist Raj Chetty to use its social media data to explore inequality.51 As part of the arrangement, researchers were required to undergo background checks and could only access data from secured sites in order to protect user privacy and security.\nIn the U.S., there are no uniform standards in terms of data access, data sharing, or data protection. Almost all the data are proprietary in nature and not shared very broadly with the research community, and this limits innovation and system design.\nGoogle long has made available search results in aggregated form for researchers and the general public. Through its “Trends” site, scholars can analyze topics such as interest in Trump, views about democracy, and perspectives on the overall economy.52 That helps people track movements in public interest and identify topics that galvanize the general public.\nTwitter makes much of its tweets available to researchers through application programming interfaces, commonly referred to as APIs. These tools help people outside the company build application software and make use of data from its social media platform. They can study patterns of social media communications and see how people are commenting on or reacting to current events.\nIn some sectors where there is a discernible public benefit, governments can facilitate collaboration by building infrastructure that shares data. For example, the National Cancer Institute has pioneered a data-sharing protocol where certified researchers can query health data it has using de-identified information drawn from clinical data, claims information, and drug therapies. That enables researchers to evaluate efficacy and effectiveness, and make recommendations regarding the best medical approaches, without compromising the privacy of individual patients.\nThere could be public-private data partnerships that combine government and business data sets to improve system performance. For example, cities could integrate information from ride-sharing services with its own material on social service locations, bus lines, mass transit, and highway congestion to improve transportation. That would help metropolitan areas deal with traffic tie-ups and assist in highway and mass transit planning.\nSome combination of these approaches would improve data access for researchers, the government, and the business community, without impinging on personal privacy. As noted by Ian Buck, the vice president of NVIDIA, “Data is the fuel that drives the AI engine. The federal government has access to vast sources of information. Opening access to that data will help us get insights that will transform the U.S. economy.”53 Through its Data.gov portal, the federal government already has put over 230,000 data sets into the public domain, and this has propelled innovation and aided improvements in AI and data analytic technologies.54 The private sector also needs to facilitate research data access so that society can achieve the full benefits of artificial intelligence.\n']","Google has long made search results available in aggregated form for researchers and the general public through its 'Trends' site. This allows scholars to analyze various topics, such as public interest in political figures and economic perspectives, thereby helping to track movements in public interest and identify galvanizing topics. By providing access to such data, Google facilitates research that can lead to innovation in artificial intelligence. For businesses looking to integrate AI, this means they can leverage publicly available data to enhance their operations and decision-making processes. However, the context also highlights the need for better data access standards and partnerships between the public and private sectors to maximize the benefits of AI while ensuring consumer protection and privacy.",multi_hop_specific_query_synthesizer
What did the Brookings Institution find about investments in autonomous vehicle technology and how does that relate to AI advancements in transportation?,"['<1-hop>\n\nTransportation\nTransportation represents an area where AI and machine learning are producing major innovations. Research by Cameron Kerry and Jack Karsten of the Brookings Institution has found that over $80 billion was invested in autonomous vehicle technology between August 2014 and June 2017. Those investments include applications both for autonomous driving and the core technologies vital to that sector.28\nAutonomous vehicles—cars, trucks, buses, and drone delivery systems—use advanced technological capabilities. Those features include automated vehicle guidance and braking, lane-changing systems, the use of cameras and sensors for collision avoidance, the use of AI to analyze information in real time, and the use of high-performance computing and deep learning systems to adapt to new circumstances through detailed maps.29\nLight detection and ranging systems (LIDARs) and AI are key to navigation and collision avoidance. LIDAR systems combine light and radar instruments. They are mounted on the top of vehicles that use imaging in a 360-degree environment from a radar and light beams to measure the speed and distance of surrounding objects. Along with sensors placed on the front, sides, and back of the vehicle, these instruments provide information that keeps fast-moving cars and trucks in their own lane, helps them avoid other vehicles, applies brakes and steering when needed, and does so instantly so as to avoid accidents.\nAdvanced software enables cars to learn from the experiences of other vehicles on the road and adjust their guidance systems as weather, driving, or road conditions change. This means that software is the key—not the physical car or truck itself.\nSince these cameras and sensors compile a huge amount of information and need to process it instantly to avoid the car in the next lane, autonomous vehicles require high-performance computing, advanced algorithms, and deep learning systems to adapt to new scenarios. This means that software is the key, not the physical car or truck itself.30 Advanced software enables cars to learn from the experiences of other vehicles on the road and adjust their guidance systems as weather, driving, or road conditions change.31\nRide-sharing companies are very interested in autonomous vehicles. They see advantages in terms of customer service and labor productivity. All of the major ride-sharing companies are exploring driverless cars. The surge of car-sharing and taxi services—such as Uber and Lyft in the United States, Daimler’s Mytaxi and Hailo service in Great Britain, and Didi Chuxing in China—demonstrate the opportunities of this transportation option. Uber recently signed an agreement to purchase 24,000 autonomous cars from Volvo for its ride-sharing service.32\nHowever, the ride-sharing firm suffered a setback in March 2018 when one of its autonomous vehicles in Arizona hit and killed a pedestrian. Uber and several auto manufacturers immediately suspended testing and launched investigations into what went wrong and how the fatality could have occurred.33 Both industry and consumers want reassurance that the technology is safe and able to deliver on its stated promises. Unless there are persuasive answers, this accident could slow AI advancements in the transportation sector.\n', '<2-hop>\n\nArtificial Intelligence: Implications for China” (New York: McKinsey Global Institute, April 2017), p. 7.\n- Executive Office of the President, “Preparing for the Future of Artificial Intelligence,” October 2016, pp. 30-31.\n- Elaine Glusac, “As Airbnb Grows, So Do Claims of Discrimination,” New York Times, June 21, 2016.\n- “Joy Buolamwini,” Bloomberg Businessweek, July 3, 2017, p. 80.\n- Ibid.\n- Mark Purdy and Paul Daugherty, “Why Artificial Intelligence is the Future of Growth,” Accenture, 2016.\n- Jon Valant, “Integrating Charter Schools and Choice-Based Education Systems,” Brown Center Chalkboard blog, Brookings Institution, June 23, 2017.\n- Tucker, “‘A White Mask Worked Better.’”\n- Cliff Kuang, “Can A.I. Be Taught to Explain Itself?” New York Times Magazine, November 21, 2017.\n- Yale Law School Information Society Project, “Governing Machine Learning,” September 2017.\n- Katie Benner, “Airbnb Vows to Fight Racism, But Its Users Can’t Sue to Prompt Fairness,” New York Times, June 19, 2016.\n- Executive Office of the President, “Artificial Intelligence, Automation, and the Economy” and “Preparing for the Future of Artificial Intelligence.”\n- Nancy Scolar, “Facebook’s Next Project: American Inequality,” Politico, February 19, 2018.\n- Darrell M. West, “What Internet Search Data Reveals about Donald Trump’s First Year in Office,” Brookings Institution policy report, January 17, 2018.\n- Ian Buck, “Testimony before the House Committee on Oversight and Government Reform Subcommittee on Information Technology,” February 14, 2018.\n- Keith Nakasone, “Testimony before the House Committee on Oversight and Government Reform Subcommittee on Information Technology,” March 7, 2018.\n- Greg Brockman, “The Dawn of Artificial Intelligence,” Testimony before U.S. Senate Subcommittee on Space, Science, and Competitiveness, November 30, 2016.\n- Amir Khosrowshahi, “Testimony before the House Committee on Oversight and Government Reform Subcommittee on Information Technology,” February 14, 2018.\n- James Kurose, “Testimony before the House Committee on Oversight and Government Reform Subcommittee on Information Technology,” March 7, 2018.\n- Stephen Noonoo, “Teachers Can Now Use IBM’s Watson to Search for Free Lesson Plans,” EdSurge, September 13, 2017.\n- Congress.gov, “H.R. 4625 FUTURE of Artificial Intelligence Act of 2017,” December 12, 2017.\n- Elizabeth Zima, “Could New York City’s AI Transparency Bill Be a Model for the Country?” Government Technology, January 4, 2018.\n']","The Brookings Institution found that over $80 billion was invested in autonomous vehicle technology between August 2014 and June 2017. This investment includes applications for both autonomous driving and the core technologies vital to that sector. The advancements in AI and machine learning are producing major innovations in transportation, particularly through the development of autonomous vehicles, which utilize advanced technological capabilities such as automated vehicle guidance, collision avoidance, and real-time information analysis.",multi_hop_specific_query_synthesizer
How Cincinnati Fire Department use AI for medical emergency response and what are the ethical issues that come with using AI in urban services?,"['<1-hop>\n\nSmart cities\nMetropolitan governments are using AI to improve urban service delivery. For example, according to Kevin Desouza, Rashmi Krishnamurthy, and Gregory Dawson:\nThe Cincinnati Fire Department is using data analytics to optimize medical emergency responses. The new analytics system recommends to the dispatcher an appropriate response to a medical emergency call—whether a patient can be treated on-site or needs to be taken to the hospital—by taking into account several factors, such as the type of call, location, weather, and similar calls.34\nSince it fields 80,000 requests each year, Cincinnati officials are deploying this technology to prioritize responses and determine the best ways to handle emergencies. They see AI as a way to deal with large volumes of data and figure out efficient ways of responding to public requests. Rather than address service issues in an ad hoc manner, authorities are trying to be proactive in how they provide urban services.\nCincinnati is not alone. A number of metropolitan areas are adopting smart city applications that use AI to improve service delivery, environmental planning, resource management, energy utilization, and crime prevention, among other things. For its smart cities index, the magazine Fast Company ranked American locales and found Seattle, Boston, San Francisco, Washington, D.C., and New York City as the top adopters. Seattle, for example, has embraced sustainability and is using AI to manage energy usage and resource management. Boston has launched a “City Hall To Go” that makes sure underserved communities receive needed public services. It also has deployed “cameras and inductive loops to manage traffic and acoustic sensors to identify gun shots.” San Francisco has certified 203 buildings as meeting LEED sustainability standards.35\nThrough these and other means, metropolitan areas are leading the country in the deployment of AI solutions. Indeed, according to a National League of Cities report, 66 percent of American cities are investing in smart city technology. Among the top applications noted in the report are “smart meters for utilities, intelligent traffic signals, e-governance applications, Wi-Fi kiosks, and radio frequency identification sensors in pavement.”36\n Policy, regulatory, and ethical issues\nThese examples from a variety of sectors demonstrate how AI is transforming many walks of human existence. The increasing penetration of AI and autonomous devices into many aspects of life is altering basic operations and decisionmaking within organizations, and improving efficiency and response times.\nAt the same time, though, these developments raise important policy, regulatory, and ethical issues. For example, how should we promote data access? How do we guard against biased or unfair data used in algorithms? What types of ethical principles are introduced through software programming, and how transparent should designers be about their choices? What about questions of legal liability in cases where algorithms cause harm?37\nThe increasing penetration of AI into many aspects of life is altering decisionmaking within organizations and improving efficiency. At the same time, though, these developments raise important policy, regulatory, and ethical issues.\n', '<2-hop>\n\nSmart cities\nMetropolitan governments are using AI to improve urban service delivery. For example, according to Kevin Desouza, Rashmi Krishnamurthy, and Gregory Dawson:\nThe Cincinnati Fire Department is using data analytics to optimize medical emergency responses. The new analytics system recommends to the dispatcher an appropriate response to a medical emergency call—whether a patient can be treated on-site or needs to be taken to the hospital—by taking into account several factors, such as the type of call, location, weather, and similar calls.34\nSince it fields 80,000 requests each year, Cincinnati officials are deploying this technology to prioritize responses and determine the best ways to handle emergencies. They see AI as a way to deal with large volumes of data and figure out efficient ways of responding to public requests. Rather than address service issues in an ad hoc manner, authorities are trying to be proactive in how they provide urban services.\n']","The Cincinnati Fire Department is using data analytics to optimize medical emergency responses by recommending to dispatchers the appropriate response to a medical emergency call. This system considers various factors such as the type of call, location, weather, and similar past calls. With around 80,000 requests each year, this technology helps prioritize responses and determine the best ways to handle emergencies, allowing authorities to be proactive in urban service delivery. However, the increasing use of AI in such contexts raises important ethical issues, including concerns about data access, the potential for biased or unfair data in algorithms, the ethical principles embedded in software programming, transparency of designers' choices, and legal liability in cases where algorithms may cause harm.",multi_hop_specific_query_synthesizer
"What trends were observed in the usage of ChatGPT among different user cohorts in 2023, and how did these trends evolve by late 2024?","['<1-hop>\n\n4 The Growth of ChatGPT\nChatGPT was released to the public on November 30, 2022 as a “research preview,” and by December\n5 it had more than one million registered users. Figure 3 reports the growth of overall weekly active\nusers (WAU) on consumer plans over time. ChatGPT had more than 100 million logged-in WAU after\none year, and almost 350 million after two years. By the end of July 2025, ChatGPT had more than\n700 million total WAU, nearly 10% of the world’s adult population. 20\nFigure 3:Weekly active ChatGPT users on consumer plans (Free, Plus, Pro), shown as point-in-time\nsnapshots every six months, November 2022–September 2025.\nFigure 4 presents growth in the total messages sent by users over time. The solid line shows that\nbetween July 2024 and July 2025, the number of messages sent grew by a factor of more than 5.\nFigure 4 also shows the contribution of individual cohorts of users to aggregate message volume.\nThe yellow line represents the first cohort of ChatGPT users: their usage declined somewhat over\n2023, but started growing again in late 2024 and is now higher than it has ever been. The pink line\nrepresents messages from users who signed up in Q3 of 2023 or earlier, and so thedifferencebetween\n20Note that we expect our counts of distinct accounts to somewhat exceed distinct people when one person has two\naccounts (or, for logged-out users, one person using two devices). For logged-in users, the count is based on distinct\nlogin credentials (email addresses), and one person may have multiple accounts. For logged-out users, the count is based\non distinct browser cookies; this would double-count people if someone returns to ChatGPT after clearing their cookies,\nor if they access ChatGPT with two different devices in the same week.\n10\x0cFigure 4:Daily message volumes from ChatGPT consumer plans (Free, Plus, Pro), split by sign-up date of\nthe requesting user. ', '<2-hop>\n\nThe yellow line represents the first cohort of ChatGPT users: their usage declined somewhat over\n2023, but started growing again in late 2024 and is now higher than it has ever been. The pink line\nrepresents messages from users who signed up in Q3 of 2023 or earlier, and so thedifferencebetween\n20Note that we expect our counts of distinct accounts to somewhat exceed distinct people when one person has two\naccounts (or, for logged-out users, one person using two devices). For logged-in users, the count is based on distinct\nlogin credentials (email addresses), and one person may have multiple accounts. For logged-out users, the count is based\non distinct browser cookies; this would double-count people if someone returns to ChatGPT after clearing their cookies,\nor if they access ChatGPT with two different devices in the same week.\n10\x0cFigure 4:Daily message volumes from ChatGPT consumer plans (Free, Plus, Pro), split by sign-up date of\nthe requesting user. Reported values are moving averages of the past 90 days. Y-axis is an index normalized\nto the reported value for ”All Cohorts” at the end of Q1 2024 (April 1, 2024).\nthe yellow and pink lines represents the messages sent by users who signed up in Q2 and Q3 of 2023.\nThere has been dramatic growth in message volume both by new cohorts of users, and from growth\nin existing cohorts.\nFigure 5 normalizes each cohort, plotting daily messages per weekly active user. Each line rep-\nresents an individual cohort (instead of a cumulative cohort, as in Figure 4). The figure shows that\nearlier sign-ups have consistently had higher usage, but that usage has also consistently grown within\nevery cohort, which we interpret as due to both (1) improvements in the capabilities of the models,\nand (2) users slowly discovering new uses for existing capabilities.\n5  How ChatGPT is Used\nWe next report on thecontentof ChatGPT conversations using a variety of different taxonomies. For\neach taxonomy we describe a “prompt” which defines a set of categories, and then apply an LLM\nto map each message to a category. Our categories often apply to the user’sintention, rather than\nthe text of the conversation, and as such we never directly observe the ground truth. Nevertheless\nthe classifier results can be interpreted as the best-guess inferences that a human would make: the\nguesses from the LLM correlate highly with human guesses from the same prompt, and we get similar\nqualitative results when the prompt includes a third category for “uncertain.”\n11\x0cFigure 5:Daily messages sent per weekly active user, split by sign-up cohort. Sample only considers users of\nChatGPT consumer plans (Free, Plus, Pro). Reported values are moving averages of the past 90 days and are\nreported starting 90 days after the cohort is fully formed. Y-axis is an index normalized to the first reported\nvalue for the Q1 2023 cohort.\n5.1 ']","In 2023, the usage of ChatGPT among the first cohort of users declined somewhat, but this trend reversed in late 2024, leading to higher usage than ever before. Additionally, users who signed up in Q3 of 2023 or earlier contributed to the overall message volume, which saw dramatic growth due to both new cohorts of users and increased activity from existing cohorts. The data indicates that earlier sign-ups consistently had higher usage, and improvements in model capabilities and the discovery of new uses for existing features contributed to the growth in message volume.",multi_hop_specific_query_synthesizer
"What percentage of ChatGPT conversations are related to Practical Guidance, and how does this compare to other conversation topics over time?","['<1-hop>\n\n37% of messages are work-related\nfor users with less than a bachelor’s degree, compared to 46% for users with exactly a bachelor’s\ndegree and 48% for those with some graduate education. Those differences are cut roughly in half\nafter adjusting for other characteristics, but they are still statistically significant at the less than 1\npercent level. Educated users are more likely to send work-related messages.\nPanel B explores variation by education in user intent.Askingconstitutes about 49% of messages\nfor users with less than a bachelor’s degree, with little variation for more educated users. After\nregression adjustment, we find that users with a graduate degree are about two percentage points\nmore likely to use ChatGPT forAskingmessages, a difference that is statistically significant at the\n5% level. Prior to regression adjustment, the frequency ofDoingmessages is increasing in education.\nHowever, this pattern reverses after adjusting for other characteristics such as occupation. Users with\na graduate degree are about 1.6 percentage points less likely to sendDoingmessages than users with\nless than a bachelor’s degree, and the difference is statistically significant at the 10% level.\nPanel C studies variation by education in the frequency of four different conversation topics –\nPractical Guidance,Seeking Information,Technical Help, andWriting. We find only modest differ-\nences by education across most of these categories. The one exception is that the share of messages\nrelated toWritingis increasing in relation to education.\n28\x0cPanel A.Work Related\nPanel B1.Asking. Panel B2.Doing.\nPanel B3.Expressing.\nFigure 22:(continued on next page)\n29\x0cPanel C1.Writing. Panel C2.Technical Help.\nPanel C3.Seeking Information. Panel C4.Practical Guidance.\nFigure 22:Variation in ChatGPT usage by education. Each plot shows unadjusted vs. regression-adjusted\nestimates, with 95% confidence intervals. We regress each message share on education and occupation, control-\nling for the following covariates: age, whether the name was typically masculine or feminine, seniority within\nrole, company size, and industry. (To guarantee user privacy, we coarsen all covariates to broad categories and\nprogrammatically enforce that each group has at least 100 members prior to running the regression) We add\nthe coefficients on each education and occupation category to the unadjusted value for the reference category\nand compute 95% confidence intervals using the standard errors from the regression coefficients. The sample\nfor this regression is the approximately 40,000 users of the original 130,000 sample whose publicly available\noccupation was not blank or consisted of strictly special characters (as determined by a classification script).\nShares for each user are calculated by randomly sampling up to six conversations attributed to the user from\nMay 2024 through July 2025.\n30\x0c', '<2-hop>\n\nWhat are the topics of ChatGPT conversations?\nWe modify a classifier used by internal research teams at OpenAI that identifies which capabilities\nthe user is requesting from ChatGPT. The classifier itself directly assigns the user’s query into one\nof 24 categories. We aggregate these 24 categories into seven topical groupings (the full conversation-\ncategorization prompt is given in Appendix A):\nTopic Conversation Category\nWriting Edit or Critique Provided Text\nPersonal Writing or Communication\nTranslation\nArgument or Summary Generation\nWrite Fiction\nPractical Guidance How-To Advice\nTutoring or Teaching\nCreative Ideation\nHealth, Fitness, Beauty, or Self-Care\nTechnical Help Mathematical Calculation\nData Analysis\n13\x0cTopic Conversation Category\nComputer Programming\nMultimedia Create an Image\nAnalyze an Image\nGenerate or Retrieve Other Media\nSeeking Information Specific Info\nPurchasable Products\nCooking and Recipes\nSelf-Expression Greetings and Chitchat\nRelationships and Personal Reflection\nGames and Role Play\nOther/Unknown Asking About the Model\nOther\nUnclear\nTable 3:Coarse Conversation Topics and Underlying Classifier Categories\nFigure 7 shows the composition of user messages over time. The three most common Conversation\nTopics arePractical Guidance,Seeking Information, andWriting, collectively accounting for about\n77% of all ChatGPT conversations.Practical Guidancehas remained constant at roughly 29% of\noverall usage.Writinghas declined from 36% of all usage in July 2024 to 24% a year later.Seeking\nInformationhas grown from 14% to 24% of all usage over the same period. The share ofTechnical\nHelpdeclined from 12% from all usage in July 2024 to around 5% a year later – this may be because\nthe use of LLMs for programming has grown very rapidly through the API (outside of ChatGPT),\nfor AI assistance in code editing and for autonomous programming agents (e.g. Codex).Multimedia\ngrew from 2% to just over 7%, with a large spike in April 2025 after ChatGPT released new image-\ngeneration capabilities: the spike attenuated but the elevated level has persisted.\nFigure 8 shows Conversation Topics, restricting the sample to only work-related messages. About\n40% of all work-related messages in July 2025 areWriting, by far the most common Conversation\nTopic.Practical Guidanceis the second most common use case at 24%.Technical Helphas declined\nfrom 18% of all work-related messages in July 2024 to just over 10% in July 2025.\nFigure 9 disaggregates four of the seven Conversation Topics into smaller groups and sums up\nmessages of each type over a one-year period. For example, the five sub-categories withinWriting\nare (in order of frequency)Editing or Critiquing Provided Text,Personal Writing or Communication,\nTranslation,Argument or Summary Generation, andWriting Fiction. Three of those five categories\n(Editing or Critiquing Provided Text,Translation, andArgument or Summary Generation) are re-\nquests to modify text that has been provided to ChatGPT by the user, whereas the other two are\nrequests to produce novel text. The former constitute two thirds of allWritingconversations, which\n14\x0cFigure 7:Share of consumer ChatGPT messages broken down by high level conversation topic, according\nto the mapping in Table 3. Values are averaged over a 28 day lagging window. ']","Practical Guidance accounts for roughly 29% of overall ChatGPT usage, remaining constant over time. In comparison, Writing has declined from 36% to 24% of all usage, while Seeking Information has grown from 14% to 24% over the same period. Among work-related messages, Practical Guidance is the second most common use case at 24%, following Writing, which constitutes about 40% of all work-related messages.",multi_hop_specific_query_synthesizer
"How does the European Union's restrictive stance on data collection impact the implementation of AI technologies, and what are the broader objectives recommended for AI regulation?","['<1-hop>\n\nEngage with state and local officials\nStates and localities also are taking action on AI. For example, the New York City Council unanimously passed a bill that directed the mayor to form a taskforce that would “monitor the fairness and validity of algorithms used by municipal agencies.”60 The city employs algorithms to “determine if a lower bail will be assigned to an indigent defendant, where firehouses are established, student placement for public schools, assessing teacher performance, identifying Medicaid fraud and determine where crime will happen next.”61\nAccording to the legislation’s developers, city officials want to know how these algorithms work and make sure there is sufficient AI transparency and accountability. In addition, there is concern regarding the fairness and biases of AI algorithms, so the taskforce has been directed to analyze these issues and make recommendations regarding future usage. It is scheduled to report back to the mayor on a range of AI policy, legal, and regulatory issues by late 2019.\nSome observers already are worrying that the taskforce won’t go far enough in holding algorithms accountable. For example, Julia Powles of Cornell Tech and New York University argues that the bill originally required companies to make the AI source code available to the public for inspection, and that there be simulations of its decisionmaking using actual data. After criticism of those provisions, however, former Councilman James Vacca dropped the requirements in favor of a task force studying these issues. He and other city officials were concerned that publication of proprietary information on algorithms would slow innovation and make it difficult to find AI vendors who would work with the city.62 It remains to be seen how this local task force will balance issues of innovation, privacy, and transparency.\n Regulate broad objectives more than specific algorithms\nThe European Union has taken a restrictive stance on these issues of data collection and analysis.63 It has rules limiting the ability of companies from collecting data on road conditions and mapping street views. Because many of these countries worry that people’s personal information in unencrypted Wi-Fi networks are swept up in overall data collection, the EU has fined technology firms, demanded copies of data, and placed limits on the material collected.64 This has made it more difficult for technology companies operating there to develop the high-definition maps required for autonomous vehicles.\nThe GDPR being implemented in Europe place severe restrictions on the use of artificial intelligence and machine learning. According to published guidelines, “Regulations prohibit any automated decision that ‘significantly affects’ EU citizens. This includes techniques that evaluates a person’s ‘performance at work, economic situation, health, personal preferences, interests, reliability, behavior, location, or movements.’”65 In addition, these new rules give citizens the right to review how digital services made specific algorithmic choices affecting people.\nBy taking a restrictive stance on issues of data collection and analysis, the European Union is putting its manufacturers and software designers at a significant disadvantage to the rest of the world.\nIf interpreted stringently, these rules will make it difficult for European software designers (and American designers who work with European counterparts) to incorporate artificial intelligence and high-definition mapping in autonomous vehicles. Central to navigation in these cars and trucks is tracking location and movements. Without high-definition maps containing geo-coded data and the deep learning that makes use of this information, fully autonomous driving will stagnate in Europe. Through this and other data protection actions, the European Union is putting its manufacturers and software designers at a significant disadvantage to the rest of the world.\nIt makes more sense to think about the broad objectives desired in AI and enact policies that advance them, as opposed to governments trying to crack open the “black boxes” and see exactly how specific algorithms operate. Regulating individual algorithms will limit innovation and make it difficult for companies to make use of artificial intelligence.\n', '<2-hop>\n\nThis article was published in 2018. To read more recent content from Brookings on Artificial Intelligence, please visit the AI topic page.\nMost people are not very familiar with the concept of artificial intelligence (AI). As an illustration, when 1,500 senior business leaders in the United States in 2017 were asked about AI, only 17 percent said they were familiar with it.1 A number of them were not sure what it was or how it would affect their particular companies. They understood there was considerable potential for altering business processes, but were not clear how AI could be deployed within their own organizations.\nDespite its widespread lack of familiarity, AI is a technology that is transforming every walk of life. It is a wide-ranging tool that enables people to rethink how we integrate information, analyze data, and use the resulting insights to improve decisionmaking. Our hope through this comprehensive overview is to explain AI to an audience of policymakers, opinion leaders, and interested observers, and demonstrate how AI already is altering the world and raising important questions for society, the economy, and governance.\nIn this paper, we discuss novel applications in finance, national security, health care, criminal justice, transportation, and smart cities, and address issues such as data access problems, algorithmic bias, AI ethics and transparency, and legal liability for AI decisions. We contrast the regulatory approaches of the U.S. and European Union, and close by making a number of recommendations for getting the most out of AI while still protecting important human values.2\nIn order to maximize AI benefits, we recommend nine steps for going forward:\n- Encourage greater data access for researchers without compromising users’ personal privacy,\n- invest more government funding in unclassified AI research,\n- promote new models of digital education and AI workforce development so employees have the skills needed in the 21st-century economy,\n- create a federal AI advisory committee to make policy recommendations,\n- engage with state and local officials so they enact effective policies,\n- regulate broad AI principles rather than specific algorithms,\n- take bias complaints seriously so AI does not replicate historic injustice, unfairness, or discrimination in data or algorithms,\n- maintain mechanisms for human oversight and control, and\n- penalize malicious AI behavior and promote cybersecurity.\n Qualities of artificial intelligence\nAlthough there is no uniformly agreed upon definition, AI generally is thought to refer to “machines that respond to stimulation consistent with traditional responses from humans, given the human capacity for contemplation, judgment and intention.”3 According to researchers Shubhendu and Vijay, these software systems “make decisions which normally require [a] human level of expertise” and help people anticipate problems or deal with issues as they come up.4 As such, they operate in an intentional, intelligent, and adaptive manner.\n']","The European Union's restrictive stance on data collection significantly impacts the implementation of AI technologies by imposing severe restrictions through regulations like the GDPR, which prohibits any automated decision that 'significantly affects' EU citizens. This includes evaluations of personal performance, economic situations, and behaviors. Such regulations make it difficult for technology companies to develop necessary high-definition maps for autonomous vehicles, putting European manufacturers and software designers at a disadvantage compared to the rest of the world. To address these challenges, it is recommended to focus on broad objectives in AI regulation rather than attempting to regulate specific algorithms. This approach would promote innovation and allow companies to effectively utilize artificial intelligence while safeguarding human values.",multi_hop_specific_query_synthesizer
"What is the good-to-bad ratio for Self-Expression in user interactions, and how does it compare to the overall writing conversations?","['<1-hop>\n\n5.5 Quality of Interactions\nWe additionally used automated classifiers to study the user’s apparent satisfaction with the chatbot’s\nresponse to their request. OurInteraction Qualityclassifier looks for an expression of satisfaction or\ndissatisfaction in the user’s subsequent message in the same conversation (if one exists), with three\npossible categories:Good,Bad, andUnknown. 23\nFigure 16 plots the overall growth of messages in these three buckets. In late 2024Goodinteractions\nwere about three times as common asBadinteractions, butGoodinteractions grew much more rapidly\nover the next nine months, and by July 2025 they were more than four times more common.\nFigure 16:Interaction quality shares, based on automated sentiment analysis of thenext responseprovided\nby the user. See Appendix B to understand how this classifier was validated. Values are averaged over a 28\nday lagging window. Shares are calculated from a sample of approximately 1.1 million sampled conversations\nfrom May 15, 2024 through June 26, 2025. Observations are reweighted to reflect total message volumes on a\ngiven day. Sampling details available in Section 3.\nDetails on the validation of this classifier, along with measurements of how it correlates with\nexplicit thumbs up/thumbs down annotations from users, are included in Appendix B.\nFigure 17 shows the ratio of good-to-bad messages by conversation topic and interaction type, as\nrated by Interaction Quality. Panel A shows thatSelf-Expressionis the highest rated topic, with a\ngood-to-bad ratio of more than seven, consistent with the growth in this category.Multimediaand\nTechnical Helphave the lowest good-to-bad ratios (1.7 and 2.7 respectively). Panel B shows that\nAskingmessages are substantially more likely to receive a good rating thanDoingorExpressing\nmessages.\n23For this classifier we do not disclose the prompt.\n23\x0cFigure 17:AverageGoodtoBadratio for user interactions by Conversation Topic (Panel A) and Ask-\ning/Doing/Expressing classification (Panel B). The prompts for each of these automated classifiers (with the\nexception of interaction quality) are available in Appendix A. Values represent the average ratio from May 15,\n2024 through June 26, 2025, where observations are reweighted to reflect total message volumes on a given\nday. Sampling details available in Section 3.\n24\x0c', '<2-hop>\n\nFigure 9 disaggregates four of the seven Conversation Topics into smaller groups and sums up\nmessages of each type over a one-year period. For example, the five sub-categories withinWriting\nare (in order of frequency)Editing or Critiquing Provided Text,Personal Writing or Communication,\nTranslation,Argument or Summary Generation, andWriting Fiction. Three of those five categories\n(Editing or Critiquing Provided Text,Translation, andArgument or Summary Generation) are re-\nquests to modify text that has been provided to ChatGPT by the user, whereas the other two are\nrequests to produce novel text. The former constitute two thirds of allWritingconversations, which\n14\x0cFigure 7:Share of consumer ChatGPT messages broken down by high level conversation topic, according\nto the mapping in Table 3. Values are averaged over a 28 day lagging window. Shares are calculated from\na sample of approximately 1.1 million sampled conversations from May 15, 2024 through June 26, 2025.\nObservations are reweighted to reflect total message volumes on a given day. Sampling details available in\nSection 3.\nFigure 8:Share ofwork relatedconsumer ChatGPT messages broken down by high level conversation\ntopic, according to the mapping in Table 3. Values are averaged over a 28 day lagging window. Shares are\ncalculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024 through June\n26, 2025. Observations are reweighted to reflect total message volumes on a given day. Sampling details\navailable in Section 3.\n15\x0csuggests that most userWritingconversations with ChatGPT are requests to modify user inputs\nrather than to create something new. Education is a major use case for ChatGPT. 10.2% of all user\nmessages and 36% ofPractical Guidancemessages are requests forTutoring or Teaching. Another\nlarge share - 8.5% in total and 30% ofPractical Guidance- is general how-to advice on a variety\nof topics.Technical HelpincludesComputer Programming(4.2% of messages),Mathematical Calcu-\nlations(3%), andData Analysis(0.4%). Looking at the topic ofSelf-Expression, only 2.4% of all\nChatGPT messages are aboutRelationships and Personal Reflection(1.9%) orGames and Role Play\n(0.4%).\nWhile users can seek information and advice from traditional web search engines as well as from\nChatGPT, the ability to produce writing, software code, spreadsheets, and other digital products\ndistinguishes generative AI from existing technologies. ChatGPT is also more flexible than web\nsearch even for traditional applications likeSeeking InformationandPractical Guidance, because\nusers receive customized responses (e.g., tailored workout plans, new product ideas, ideas for fantasy\nfootball team names) that represent newly generated content or novel modification of user-provided\ncontent and follow-up requests.\nFigure 9:Breakdown of granular conversation topic shares within the coarse mapping defined in Table 3. The\nunderlying classifier prompt is available in Appendix A. Each bin reports a percentage of the total population.\nShares are calculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024\nthrough June 26, 2025. Observations are reweighted to reflect total message volumes on a given day. Sampling\ndetails available in Section 3.\n5.3 ']","The good-to-bad ratio for Self-Expression in user interactions is more than seven, indicating a high level of satisfaction. In contrast, most writing conversations consist of requests to modify user inputs rather than to create something new, suggesting that Self-Expression is rated significantly higher than the general writing interactions.",multi_hop_specific_query_synthesizer
"What are the key features and training processes of GPT-4 as a language model, and how do they contribute to its performance in generating text responses?","['<1-hop>\n\nWhat is ChatGPT?\nHere we give a simplified overview of LLMs and chatbots. For more precise details, refer to the papers\nand system cards that OpenAI has released with each model e.g., (OpenAI, 2023, 2024a, 2025b). A\nchatbot is a statistical model trained to generate a text response given some text input, so as to\nmaximize the “quality” of that response, where the quality is measured with a variety of metrics.\nIn a prototypical interaction, a user submits a plain-text message (“prompt”) and ChatGPT\nreturns the message (“response”) generated from an underlying LLM. A large set of additional features\nhave been added to ChatGPT—including the possibility for the LLM to search the web or external\ndatabases, and generate images based on text—but the exchange of text-based messages remains the\nmost typical interaction.\nSince its launch ChatGPT has used a variety of different underlying LLMs e.g., GPT-3.5, GPT-4,\nGPT-4o, o1, o3, and GPT-5. 12 In addition there are occasional updates to the model’s weights and\nto the model’s system prompt (text instructions sent to the model along with all the queries).\nAn LLM can be thought of as a function from a string of words to a probability distribution over\nthe set of all possible words (more precisely, “tokens,” which very roughly correspond to words13). The\nfunctions are implemented with deep neural nets, typically with a transformer architecture (Vaswani\net al., 2017), parameterized with billions of model “weights”. We will refer to all of ChatGPT’s models\nas language models, though most can additionally process tokens representing images, audio, or other\nmedia.\nThe weights in an LLM-based chatbot are often trained in two stages, commonly called “pre-\ntraining” and “post-training”. In the first stage (“pre-training”), the LLMs are trained to predict the\nnext word in a string, given the preceding words, over an enormous corpus of text. At that point the\nmodels are purely predictors of the likelihood of the next word given a prior context, and as such they\nhave a relatively narrow application. In the second stage (“post-training”), the models are trained to\nproduce words that comprise “good” responses to some prompt. This stage often consists of a variety\nof different strategies: fine-tuning on a dataset of queries and ideal responses, reinforcement learning\nagainst another model that is trained to grade the quality of a response (Ouyang et al., 2022), or\nreinforcement learning against a function that knows the true response to queries (OpenAI (2024b),\n12For a timeline of model launches, see Appendix C.\n13Tokenization is a way of cutting a string of text into discrete chunks, chosen to be statistically efficient. In many\ntokenization schemes, one token corresponds to roughly three-quarters of an English word.\n4\x0cLambert et al. (2024)). This second stage also typically includes a number of “safety” constraints to\navoid certain classes of response, especially those which are deemed harmful or dangerous (OpenAI,\n2025a).\nThis two-stage process has a common statistical interpretation: the first stage teaches the model a\nlatent representation of the world; the second stage fits a function using that representation (Bengio\net al., 2014). Pre-training the model to predict the next word effectively teaches the model a low-\ndimensional representation of text, representing only the key semantic features, and therefore rendering\nthe prompt-response problem tractable with a reasonable set of training examples.\nTwo common ways of evaluating chatbots are with benchmarks (batteries of questions with known\nanswers, e.g. Measuring Massive Multitask Language Understanding (Hendrycks et al., 2021)) and\ncomparisons of human preferences over two alternative responses to the same message (e.g. Chatbot\nArena (Chiang et al., 2024)).\n3 ']","GPT-4, like its predecessors, is a large language model (LLM) that operates by generating text responses based on user prompts. It utilizes a two-stage training process: the first stage, known as 'pre-training', involves predicting the next word in a string given the preceding words over a vast corpus of text. This stage helps the model develop a latent representation of the world. The second stage, 'post-training', focuses on producing high-quality responses to prompts, often involving fine-tuning on datasets of queries and ideal responses, as well as reinforcement learning techniques. Additionally, GPT-4 incorporates various features such as the ability to search the web and generate images based on text, enhancing its interaction capabilities. The model's performance is evaluated through benchmarks and human preference comparisons, ensuring that it meets quality standards in generating text.",multi_hop_specific_query_synthesizer
"How do the statistics on user satisfaction from ChatGPT users correlate with the feedback provided on assistant messages, and what does this imply about the overall interaction quality?","['<1-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ', '<2-hop>\n\nClassified Queries, Organized by Generalized Work Activity (of the query) and Occupation (of\nthe user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through July 2025. Cells\nwith contributions from fewer than 100 users are suppressed to zero. The title of one GWA is not fully shown\ndue to space constraints: “Estimating the Quantifiable Characteristics of Products, Events, or Information.”\n60\x0cFigure 34:Classified Work-Related Queries, Organized by Generalized Work Activity (of the query) and\nOccupation (of the user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through\nJuly 2025. Cells with contributions from fewer than 100 users are suppressed to zero. The title of one GWA\nis not fully shown due to space constraints: “Estimating the Quantifiable Characteristics of Products, Events,\nor Information.”\n61\x0cOccupation Group Documenting/\nRecording\nInformation\nMaking\nDecisions\nAnd Solving\nProblems\nThinking\nCreatively\nWorking\nWith\nComputers\nInterpreting\nThe Meaning\nOf\nInformation\nFor Others\nGetting\nInformation\nProviding\nConsultation\nAnd Advice\nTo Others\nManagement 3 2 4 7 5 1 6\nBusiness 3 2 6 7 4 1 5\nComputer/Math 5 4 6 1 3 2 7\nEngineering 5 3 7 4 2 1 6\nScience 2 3 6 7 4 1 5\nSocial Service 2 3 6 X 4 1 5\nLegal 2 3 6 X 4 1 5\nEducation 1 3 4 7 5 2 6\nArts/Design/Media 2 3 4 7 5 1 6\nHealth Professionals 2 5 6 X 4 1 3\nHealth Support 2 3 6 X 4 1 5\nProtective Service 2 X X X X 1 X\nFood Service 3 5 6 X 2 1 4\nPersonal Service 2 3 5 X 4 1 6\nSales 2 5 6 7 3 1 4\nAdministrative 2 4 6 8 3 1 5\nConstruction X X X X X 1 X\nInstallation/Repair X X X X X 1 X\nProduction 3 5 6 X 2 1 4\nTransportation 3 4 5 X 2 1 6\nMilitary 4 3 6 X 2 1 5\nFigure 35:']","The statistics on user satisfaction from ChatGPT users indicate that while the inherent difficulty of inferring user satisfaction from text alone exists, explicit feedback such as thumbs-up/down provides valuable insights. In a sample of conversations from June 2024 to June 2025, it was found that 86% of the feedback was thumbs-up. This suggests that conversations with thumbs-up feedback are significantly more likely to be classified as Good, with a ratio of 9.5 times compared to those with thumbs-down feedback. This correlation implies that the classifier used to assess interaction quality is more aligned with positive user experiences, highlighting the importance of user feedback in evaluating the effectiveness of ChatGPT interactions.",multi_hop_abstract_query_synthesizer
How does the automated classification of messages relate to user satisfaction and privacy measures in the analysis of chatbot interactions?,"['<1-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ', '<2-hop>\n\n3.4 Summarizing Our Approach to Privacy\nWe took measures to safeguard user privacy at every stage of analysis. To summarize, the key elements\nof our approach are:\nAutomated classification of messages.In the course of analysis, no one ever looked directly\nat the content of user messages: all of our analysis of the content of user messages is done\nthrough output of automated classifiers run on de-identified and PII-scrubbed usage data.\nAggregated employment data via a data clean room.We analyze and report aggregated\nemployment data through a secure data clean room environment: no one on the research\nteam had direct access to user-level demographic data and none of our analyses report\naggregates for groups with less than 100 users.\nIn following these measures, we aim to match or exceed the privacy protection precedents set by\nother social scientists studying chatbots and those linking digital platform data to external sources.\nWe follow the precedent established in recent analyses of chatbot conversations (Phang et al.\n(2025), Eloundou et al. (2025), Handa et al. (2025), Tomlinson et al. (2025)) that rely on automated\nclassification rather than human inspection of raw transcripts. In particular, Phang et al. (2025)’s\nstudy of affective use of ChatGPT and Eloundou et al. (2025) investigation of first-person fairness in\nchatbots both analyze ChatGPT message content via automated classifiers and emphasize classifier-\nbased labeling as a scalable, privacy-preserving approach. Anthropic’s Handa et al. (2025) used a\nsimilar approach: theirCliomethodology applies automated classifiers to large collections of conver-\nsations, classifying conversations into thousands of topics, and in their appendix they describe manual\nvalidation on sampled conversations (100 user conversations flagged for review and 100 randomly sam-\npled calibrations). Like Eloundou et al., we validate our classifiers using WildChat, a public dataset\nof user conversations.\n9\x0cOther papers have analyzed digital behavior and demographic data; we mention a few relevant\nprecedents here. Humlum and Vestergaard (2025b) and Humlum and Vestergaard (2025a), for exam-\nple, analyze large-scale surveys on chatbot use along with Danish administrative labor market data.\nChetty et al. (2022) analyze de-identified Facebook friendship graphs and anonymized IRS tax records,\naggregated at the zip code level.\n']","The automated classification of messages is crucial for assessing user satisfaction, as it allows for the analysis of user feedback without directly inspecting the content of user messages. This method ensures that user privacy is safeguarded, as all analyses are conducted on de-identified and PII-scrubbed data. The classifier's ability to proxy user satisfaction is highlighted by the correlation between thumbs-up feedback and messages classified as good. Additionally, the privacy measures taken, such as using a secure data clean room for aggregated employment data, align with the goal of maximizing user satisfaction while protecting user privacy.",multi_hop_abstract_query_synthesizer
"What trends in user satisfaction can be observed from the feedback on ChatGPT interactions, and how do these trends relate to the different user cohorts over time?","['<1-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ', '<2-hop>\n\nThe yellow line represents the first cohort of ChatGPT users: their usage declined somewhat over\n2023, but started growing again in late 2024 and is now higher than it has ever been. The pink line\nrepresents messages from users who signed up in Q3 of 2023 or earlier, and so thedifferencebetween\n20Note that we expect our counts of distinct accounts to somewhat exceed distinct people when one person has two\naccounts (or, for logged-out users, one person using two devices). For logged-in users, the count is based on distinct\nlogin credentials (email addresses), and one person may have multiple accounts. For logged-out users, the count is based\non distinct browser cookies; this would double-count people if someone returns to ChatGPT after clearing their cookies,\nor if they access ChatGPT with two different devices in the same week.\n10\x0cFigure 4:Daily message volumes from ChatGPT consumer plans (Free, Plus, Pro), split by sign-up date of\nthe requesting user. Reported values are moving averages of the past 90 days. Y-axis is an index normalized\nto the reported value for ”All Cohorts” at the end of Q1 2024 (April 1, 2024).\nthe yellow and pink lines represents the messages sent by users who signed up in Q2 and Q3 of 2023.\nThere has been dramatic growth in message volume both by new cohorts of users, and from growth\nin existing cohorts.\nFigure 5 normalizes each cohort, plotting daily messages per weekly active user. Each line rep-\nresents an individual cohort (instead of a cumulative cohort, as in Figure 4). The figure shows that\nearlier sign-ups have consistently had higher usage, but that usage has also consistently grown within\nevery cohort, which we interpret as due to both (1) improvements in the capabilities of the models,\nand (2) users slowly discovering new uses for existing capabilities.\n5  How ChatGPT is Used\nWe next report on thecontentof ChatGPT conversations using a variety of different taxonomies. For\neach taxonomy we describe a “prompt” which defines a set of categories, and then apply an LLM\nto map each message to a category. Our categories often apply to the user’sintention, rather than\nthe text of the conversation, and as such we never directly observe the ground truth. Nevertheless\nthe classifier results can be interpreted as the best-guess inferences that a human would make: the\nguesses from the LLM correlate highly with human guesses from the same prompt, and we get similar\nqualitative results when the prompt includes a third category for “uncertain.”\n11\x0cFigure 5:Daily messages sent per weekly active user, split by sign-up cohort. Sample only considers users of\nChatGPT consumer plans (Free, Plus, Pro). Reported values are moving averages of the past 90 days and are\nreported starting 90 days after the cohort is fully formed. Y-axis is an index normalized to the first reported\nvalue for the Q1 2023 cohort.\n5.1 ']","User satisfaction trends can be observed through the feedback provided on ChatGPT interactions, where 86% of the feedback was thumbs-up, indicating a generally positive user experience. The analysis of user feedback shows that conversations with thumbs-down feedback are equally likely to be classified as Good or Bad, while thumbs-up feedback is 9.5 times more likely to be followed by a message classified as Good. Additionally, the trends in user cohorts reveal that the first cohort of ChatGPT users experienced a decline in usage in 2023 but began to grow again in late 2024, surpassing previous usage levels. This growth in user engagement is attributed to improvements in model capabilities and users discovering new uses for existing features, highlighting a correlation between user satisfaction and the evolution of user cohorts over time.",multi_hop_abstract_query_synthesizer
"How does user satisfaction relate to decision making in the context of ChatGPT interactions, based on the feedback and classification data from 2024 to 2025?","['<1-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ', '<2-hop>\n\nClassified Queries, Organized by Generalized Work Activity (of the query) and Occupation (of\nthe user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through July 2025. Cells\nwith contributions from fewer than 100 users are suppressed to zero. The title of one GWA is not fully shown\ndue to space constraints: “Estimating the Quantifiable Characteristics of Products, Events, or Information.”\n60\x0cFigure 34:Classified Work-Related Queries, Organized by Generalized Work Activity (of the query) and\nOccupation (of the user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through\nJuly 2025. Cells with contributions from fewer than 100 users are suppressed to zero. The title of one GWA\nis not fully shown due to space constraints: “Estimating the Quantifiable Characteristics of Products, Events,\nor Information.”\n61\x0cOccupation Group Documenting/\nRecording\nInformation\nMaking\nDecisions\nAnd Solving\nProblems\nThinking\nCreatively\nWorking\nWith\nComputers\nInterpreting\nThe Meaning\nOf\nInformation\nFor Others\nGetting\nInformation\nProviding\nConsultation\nAnd Advice\nTo Others\nManagement 3 2 4 7 5 1 6\nBusiness 3 2 6 7 4 1 5\nComputer/Math 5 4 6 1 3 2 7\nEngineering 5 3 7 4 2 1 6\nScience 2 3 6 7 4 1 5\nSocial Service 2 3 6 X 4 1 5\nLegal 2 3 6 X 4 1 5\nEducation 1 3 4 7 5 2 6\nArts/Design/Media 2 3 4 7 5 1 6\nHealth Professionals 2 5 6 X 4 1 3\nHealth Support 2 3 6 X 4 1 5\nProtective Service 2 X X X X 1 X\nFood Service 3 5 6 X 2 1 4\nPersonal Service 2 3 5 X 4 1 6\nSales 2 5 6 7 3 1 4\nAdministrative 2 4 6 8 3 1 5\nConstruction X X X X X 1 X\nInstallation/Repair X X X X X 1 X\nProduction 3 5 6 X 2 1 4\nTransportation 3 4 5 X 2 1 6\nMilitary 4 3 6 X 2 1 5\nFigure 35:']","User satisfaction is assessed through explicit thumbs-up/down feedback, which indicates how well the classifier captures user experience. The data shows that 86% of feedback is thumbs-up, suggesting a high level of user satisfaction. Furthermore, conversations with thumbs-down feedback are equally likely to be classified as Good or Bad, while thumbs-up feedback is 9.5 times more likely to be followed by a message classified as Good. This correlation highlights that user satisfaction significantly influences decision making regarding the quality of interactions, as it informs the adjustments and improvements made to the AI's responses.",multi_hop_abstract_query_synthesizer
"How does user satisfaction among ChatGPT users correlate with the feedback provided on assistant messages, and what insights can be drawn from the classified queries of these users?","['<1-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ', '<2-hop>\n\nClassified Queries, Organized by Generalized Work Activity (of the query) and Occupation (of\nthe user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through July 2025. Cells\nwith contributions from fewer than 100 users are suppressed to zero. The title of one GWA is not fully shown\ndue to space constraints: “Estimating the Quantifiable Characteristics of Products, Events, or Information.”\n60\x0cFigure 34:Classified Work-Related Queries, Organized by Generalized Work Activity (of the query) and\nOccupation (of the user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through\nJuly 2025. Cells with contributions from fewer than 100 users are suppressed to zero. The title of one GWA\nis not fully shown due to space constraints: “Estimating the Quantifiable Characteristics of Products, Events,\nor Information.”\n61\x0cOccupation Group Documenting/\nRecording\nInformation\nMaking\nDecisions\nAnd Solving\nProblems\nThinking\nCreatively\nWorking\nWith\nComputers\nInterpreting\nThe Meaning\nOf\nInformation\nFor Others\nGetting\nInformation\nProviding\nConsultation\nAnd Advice\nTo Others\nManagement 3 2 4 7 5 1 6\nBusiness 3 2 6 7 4 1 5\nComputer/Math 5 4 6 1 3 2 7\nEngineering 5 3 7 4 2 1 6\nScience 2 3 6 7 4 1 5\nSocial Service 2 3 6 X 4 1 5\nLegal 2 3 6 X 4 1 5\nEducation 1 3 4 7 5 2 6\nArts/Design/Media 2 3 4 7 5 1 6\nHealth Professionals 2 5 6 X 4 1 3\nHealth Support 2 3 6 X 4 1 5\nProtective Service 2 X X X X 1 X\nFood Service 3 5 6 X 2 1 4\nPersonal Service 2 3 5 X 4 1 6\nSales 2 5 6 7 3 1 4\nAdministrative 2 4 6 8 3 1 5\nConstruction X X X X X 1 X\nInstallation/Repair X X X X X 1 X\nProduction 3 5 6 X 2 1 4\nTransportation 3 4 5 X 2 1 6\nMilitary 4 3 6 X 2 1 5\nFigure 35:']","User satisfaction among ChatGPT users is primarily inferred from explicit feedback, such as thumbs-up or thumbs-down ratings on assistant messages. The data indicates that 86% of all feedback is thumbs-up, suggesting a high level of user satisfaction. Furthermore, conversations that receive thumbs-down feedback are equally likely to be classified as Good or Bad, while thumbs-up feedback is 9.5 times more likely to be followed by a message classified as Good. Additionally, the classified queries from approximately 40,000 ChatGPT users reveal various work-related activities and occupations, providing insights into how different user groups engage with the assistant, which can further inform the understanding of user satisfaction.",multi_hop_abstract_query_synthesizer
"How do user satisfaction ratings correlate with work-related queries in the context of ChatGPT interactions, especially considering the feedback mechanisms in place?","['<1-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ', '<2-hop>\n\nClassified Queries, Organized by Generalized Work Activity (of the query) and Occupation (of\nthe user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through July 2025. Cells\nwith contributions from fewer than 100 users are suppressed to zero. The title of one GWA is not fully shown\ndue to space constraints: “Estimating the Quantifiable Characteristics of Products, Events, or Information.”\n60\x0cFigure 34:Classified Work-Related Queries, Organized by Generalized Work Activity (of the query) and\nOccupation (of the user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through\nJuly 2025. Cells with contributions from fewer than 100 users are suppressed to zero. The title of one GWA\nis not fully shown due to space constraints: “Estimating the Quantifiable Characteristics of Products, Events,\nor Information.”\n61\x0cOccupation Group Documenting/\nRecording\nInformation\nMaking\nDecisions\nAnd Solving\nProblems\nThinking\nCreatively\nWorking\nWith\nComputers\nInterpreting\nThe Meaning\nOf\nInformation\nFor Others\nGetting\nInformation\nProviding\nConsultation\nAnd Advice\nTo Others\nManagement 3 2 4 7 5 1 6\nBusiness 3 2 6 7 4 1 5\nComputer/Math 5 4 6 1 3 2 7\nEngineering 5 3 7 4 2 1 6\nScience 2 3 6 7 4 1 5\nSocial Service 2 3 6 X 4 1 5\nLegal 2 3 6 X 4 1 5\nEducation 1 3 4 7 5 2 6\nArts/Design/Media 2 3 4 7 5 1 6\nHealth Professionals 2 5 6 X 4 1 3\nHealth Support 2 3 6 X 4 1 5\nProtective Service 2 X X X X 1 X\nFood Service 3 5 6 X 2 1 4\nPersonal Service 2 3 5 X 4 1 6\nSales 2 5 6 7 3 1 4\nAdministrative 2 4 6 8 3 1 5\nConstruction X X X X X 1 X\nInstallation/Repair X X X X X 1 X\nProduction 3 5 6 X 2 1 4\nTransportation 3 4 5 X 2 1 6\nMilitary 4 3 6 X 2 1 5\nFigure 35:', '<3-hop>\n\nNearly 35% of all work-related queries areDoingmessages related toWriting.DoingandAsking\ncomprise equal shares ofTechnical Helpqueries.\n17\x0cFigure 10:Breakdown of Conversation Topics by Asking/Doing/Expressing category, with topic columns\nsorted by relative share of ”Doing” messages. Prompts for these automated classifiers are available in Appendix\nA. For a detailed breakdown of conversation topic contents, see Table 3. Each bin reports a percentage of\nthe total population. Shares are calculated from a sample of approximately 1.1 million sampled conversations\nfrom May 15, 2024 through June 26, 2025. Observations are reweighted to reflect total message volumes on a\ngiven day. Sampling details available in Section 3.\nFigure 11:Breakdown of Conversation Topics by Asking/Doing/Expressing category foronly work-related\nmessages, with topic columns sorted by relative share of ”Doing” messages. Prompts for these automated\nclassifiers are available in Appendix A. For a detailed breakdown of conversation topic contents, see Table 3.\nEach bin reports a percentage of the total population. Shares are calculated from a sample of approximately\n1.1 million sampled conversations from May 15, 2024 through June 26, 2025. Observations are reweighted to\nreflect total message volumes on a given day. Sampling details available in Section 3.\n18\x0cFigure 12 presents changes over time in the composition of messages by user intent. In July\n2024, usage was evenly split betweenAskingandDoing, with just under 8% of messages classified as\nExpressing.AskingandExpressinggrew much faster thanDoingover the next year, and by late June\n2025 the split was 51.6%Asking, 34.6%Doing, and 13.8%Expressing.\nFigure 12:Shares of messages classified as Asking, Doing, or Expressing by an automated ternary classifier.\nValues are averaged over a 28 day lagging window. Shares are calculated from a sample of approximately\n1.1 million sampled conversations from May 15, 2024 through June 26, 2025. Observations are reweighted to\nreflect total message volumes on a given day. Sampling details available in Section 3.\nFigure 13 presents the share of work-related messages by user intent.Doingmessages, which\naccount for approximately 40% of messages, have an even split of messages between work-related and\nnon-work related.\n']","User satisfaction ratings correlate significantly with work-related queries in ChatGPT interactions. The classifier used to assess user satisfaction relies on explicit feedback, such as thumbs-up or thumbs-down ratings, which are linked to the quality of assistant messages. Approximately 86% of feedback is thumbs-up, indicating a positive user experience. Furthermore, conversations that receive thumbs-down feedback are equally likely to be classified as good or bad, while thumbs-up feedback is 9.5 times more likely to be followed by a message classified as good. This suggests that user satisfaction is closely tied to the nature of work-related queries, as nearly 35% of all work-related queries are categorized as doing messages related to writing, highlighting the importance of effective communication in user interactions.",multi_hop_abstract_query_synthesizer
"What factors influence user satisfaction with ChatGPT, and how does ChatGPT usage vary by country?","['<1-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ', '<2-hop>\n\n6.3 Variation by Country\nWe study global patterns of ChatGPT usage by measuring the proportion of weekly consumer Chat-\nGPT users among the internet enabled population of countries with populations larger than 1 million.\nWe also exclude countries in which ChatGPT is blocked. The figure below plots this proportion in\nMay 2024 and May 2025 by GDP-per-capita deciles: countries are ranked by GDP-per-capita and split\ninto ten deciles, and the x-axis shows each decile’s median GDP-per-capita (in thousands of U.S. dol-\nlars).24 The solid line shows the median share within each decile; the shaded band is the interquartile\nrange (25th–75th percentile) of country values within that decile. Comparing May 2024 to May 2025,\nwe see that the adoption of ChatGPT grew dramatically, but also that there was disproportionate\ngrowth in low to middle-income countries ($10,000–40,000 GDP-per-capita). Overall, we find that\nmany low-to-middle income countries have experienced high growth in ChatGPT adoption.\n 6.4 Variation by Education\nWe next analyze results from matching with publicly available datasets.\nFigure 22 presents variation in ChatGPT usage by user education. Panel A shows the share of\nmessages that are work-related, for users with less than a bachelor’s degree, exactly a bachelor’s\ndegree, and some graduate education respectively.25 The left-hand side of figure 22 shows unadjusted\ncomparisons, while the right-hand side presents the coefficient on education from a regression of\n24GDP and population data are from the World Bank 2023 estimates.\n25For non-US users, we consider tertiary education to be the equivalent of a bachelor’s degree.\n27\x0cFigure 21:ChatGPT Weekly Active Users as Share of Internet Population vs GDP decile, May 2024 vs May\n2025. Point estimates are medians within each decile. Internet Using Population uses 2023 estimates from the\nWorld Bank. Shaded regions indicate the interquartile range (25th–75th percentile) of country values within\neach GDP decile.\nmessage shares on age, whether the name was typically masculine or feminine, education, occupation\ncategories, job seniority, firm size, and industry. We also include 95% confidence intervals for the\nregression-adjusted results.\nEducated users are much more likely to use ChatGPT for work. 37% of messages are work-related\nfor users with less than a bachelor’s degree, compared to 46% for users with exactly a bachelor’s\ndegree and 48% for those with some graduate education. Those differences are cut roughly in half\nafter adjusting for other characteristics, but they are still statistically significant at the less than 1\npercent level. Educated users are more likely to send work-related messages.\nPanel B explores variation by education in user intent.Askingconstitutes about 49% of messages\nfor users with less than a bachelor’s degree, with little variation for more educated users. After\nregression adjustment, we find that users with a graduate degree are about two percentage points\nmore likely to use ChatGPT forAskingmessages, a difference that is statistically significant at the\n5% level. ']","User satisfaction with ChatGPT is influenced by the feedback provided by users, where 86% of feedback is thumbs-up, indicating a positive experience. The classifier used to assess user satisfaction shows that conversations with thumbs-down feedback are equally likely to be classified as Good or Bad, while thumbs-up feedback is significantly more likely to be followed by a message classified as Good. Additionally, ChatGPT usage varies by country, with a notable increase in adoption among low to middle-income countries, particularly those with GDP-per-capita between $10,000 and $40,000, indicating a dramatic growth in usage from May 2024 to May 2025.",multi_hop_abstract_query_synthesizer
How user satisfaction affect decision making in queries from ChatGPT users?,"['<1-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ', '<2-hop>\n\nClassified Queries, Organized by Generalized Work Activity (of the query) and Occupation (of\nthe user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through July 2025. Cells\nwith contributions from fewer than 100 users are suppressed to zero. The title of one GWA is not fully shown\ndue to space constraints: “Estimating the Quantifiable Characteristics of Products, Events, or Information.”\n60\x0cFigure 34:Classified Work-Related Queries, Organized by Generalized Work Activity (of the query) and\nOccupation (of the user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through\nJuly 2025. Cells with contributions from fewer than 100 users are suppressed to zero. The title of one GWA\nis not fully shown due to space constraints: “Estimating the Quantifiable Characteristics of Products, Events,\nor Information.”\n61\x0cOccupation Group Documenting/\nRecording\nInformation\nMaking\nDecisions\nAnd Solving\nProblems\nThinking\nCreatively\nWorking\nWith\nComputers\nInterpreting\nThe Meaning\nOf\nInformation\nFor Others\nGetting\nInformation\nProviding\nConsultation\nAnd Advice\nTo Others\nManagement 3 2 4 7 5 1 6\nBusiness 3 2 6 7 4 1 5\nComputer/Math 5 4 6 1 3 2 7\nEngineering 5 3 7 4 2 1 6\nScience 2 3 6 7 4 1 5\nSocial Service 2 3 6 X 4 1 5\nLegal 2 3 6 X 4 1 5\nEducation 1 3 4 7 5 2 6\nArts/Design/Media 2 3 4 7 5 1 6\nHealth Professionals 2 5 6 X 4 1 3\nHealth Support 2 3 6 X 4 1 5\nProtective Service 2 X X X X 1 X\nFood Service 3 5 6 X 2 1 4\nPersonal Service 2 3 5 X 4 1 6\nSales 2 5 6 7 3 1 4\nAdministrative 2 4 6 8 3 1 5\nConstruction X X X X X 1 X\nInstallation/Repair X X X X X 1 X\nProduction 3 5 6 X 2 1 4\nTransportation 3 4 5 X 2 1 6\nMilitary 4 3 6 X 2 1 5\nFigure 35:']","User satisfaction is assessed through explicit thumbs-up/down feedback, which indicates how well the classifier captures user experience. Thumbs-up feedback is significantly more likely to be followed by messages classified as Good, suggesting that higher user satisfaction correlates with better decision-making outcomes in queries.",multi_hop_abstract_query_synthesizer
"What insights can be drawn about user satisfaction from the feedback of approximately 40,000 ChatGPT users between May 2024 and July 2025, and how does this relate to the classifier's ability to assess interaction quality?","['<1-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ', '<2-hop>\n\nClassified Queries, Organized by Generalized Work Activity (of the query) and Occupation (of\nthe user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through July 2025. Cells\nwith contributions from fewer than 100 users are suppressed to zero. The title of one GWA is not fully shown\ndue to space constraints: “Estimating the Quantifiable Characteristics of Products, Events, or Information.”\n60\x0cFigure 34:Classified Work-Related Queries, Organized by Generalized Work Activity (of the query) and\nOccupation (of the user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through\nJuly 2025. Cells with contributions from fewer than 100 users are suppressed to zero. The title of one GWA\nis not fully shown due to space constraints: “Estimating the Quantifiable Characteristics of Products, Events,\nor Information.”\n61\x0cOccupation Group Documenting/\nRecording\nInformation\nMaking\nDecisions\nAnd Solving\nProblems\nThinking\nCreatively\nWorking\nWith\nComputers\nInterpreting\nThe Meaning\nOf\nInformation\nFor Others\nGetting\nInformation\nProviding\nConsultation\nAnd Advice\nTo Others\nManagement 3 2 4 7 5 1 6\nBusiness 3 2 6 7 4 1 5\nComputer/Math 5 4 6 1 3 2 7\nEngineering 5 3 7 4 2 1 6\nScience 2 3 6 7 4 1 5\nSocial Service 2 3 6 X 4 1 5\nLegal 2 3 6 X 4 1 5\nEducation 1 3 4 7 5 2 6\nArts/Design/Media 2 3 4 7 5 1 6\nHealth Professionals 2 5 6 X 4 1 3\nHealth Support 2 3 6 X 4 1 5\nProtective Service 2 X X X X 1 X\nFood Service 3 5 6 X 2 1 4\nPersonal Service 2 3 5 X 4 1 6\nSales 2 5 6 7 3 1 4\nAdministrative 2 4 6 8 3 1 5\nConstruction X X X X X 1 X\nInstallation/Repair X X X X X 1 X\nProduction 3 5 6 X 2 1 4\nTransportation 3 4 5 X 2 1 6\nMilitary 4 3 6 X 2 1 5\nFigure 35:']","Insights drawn from the feedback of approximately 40,000 ChatGPT users between May 2024 and July 2025 indicate that the classifier's ability to assess interaction quality is partially validated through user feedback. The data shows that 86% of the feedback was thumbs-up, suggesting a high level of user satisfaction. Additionally, conversations that received thumbs-down feedback were equally likely to be classified as Good or Bad, while thumbs-up feedback was 9.5 times more likely to be followed by a message classified as Good. This correlation highlights the classifier's effectiveness in proxying user satisfaction, despite the inherent difficulty of inferring latent satisfaction from text alone.",multi_hop_abstract_query_synthesizer
What are the ethical concerns surrounding artificial intelligence (AI) and how do they relate to the controversy over its environmental impact?,"[""<1-hop>\n\nWhat is AI, how does it work and why are some people concerned about it?\nArtificial intelligence (AI) has increasingly become part of everyday life over the past decade.\nIt is being used to personalise social media feeds, spot friends and family in smartphone photos and pave the way for medical breakthroughs.\nBut the rise of chatbots like OpenAI's ChatGPT and Meta AI has been accompanied by concern about the technology's environmental impact, ethical implications and data use.\n What is AI and what is it used for?\nAI allows computers to process large amounts of data, identify patterns and follow detailed instructions about what to do with that information.\nComputers cannot think, empathise or reason.\nHowever, scientists have developed systems that can perform tasks which usually require human intelligence, trying to replicate how people acquire and use knowledge.\nThis could be trying to anticipate what product an online shopper might buy, based on previous purchases, in order to recommend items.\nThe technology is also behind voice-controlled virtual assistants like Apple's Siri and Amazon's Alexa, and is being used to develop systems for self-driving cars.\nAI also helps social platforms like Facebook, TikTok and X decide what posts to show users. Streaming services Spotify and Deezer use AI to suggest music.\nThere are also a number of applications in medicine, as scientists use AI to help spot cancers, review X-ray results, speed up diagnoses and identify new treatments.\n What is generative AI, and how do apps like ChatGPT and Meta AI work?\nGenerative AI is used to create new content which can seem like it has been made by a human.\nIt does this by learning from vast quantities of existing data such as online text and images.\nChatGPT and Chinese rival DeepSeek's chatbot are popular generative AI tools that can be used to produce text, images, code and more material.\nGoogle's Gemini or Meta AI can similarly hold text conversations with users.\nApps like Midjourney or Veo 3 are dedicated to creating images or video from simple text prompts.\nGenerative AI can also be used to make high-quality music.\nSongs mimicking the style or sound of famous musicians have gone viral, sometimes leaving fans confused about their authenticity.\n"", '<2-hop>\n\nWhy is AI controversial?\nWhile acknowledging AI\'s potential, some experts are worried about the implications of its rapid growth.\nThe International Monetary Fund (IMF) has warned AI could affect nearly 40% of jobs, and worsen global financial inequality.\nProf Geoffrey Hinton, a computer scientist regarded as one of the ""godfathers"" of AI development, has expressed concern that powerful AI systems could even make humans extinct - although his fear was dismissed by his fellow ""AI godfather"", Yann LeCun.\nCritics also highlight the tech\'s potential to reproduce biased information, or discriminate against some social groups.\nThis is because much of the data used to train AI comes from public material, including social media posts or comments, which can reflect existing societal biases such as sexism or racism.\nAnd while AI programmes are growing more adept, they are still prone to errors - such as creating images of people with the wrong number of fingers or limbs.\nGenerative AI systems are known for their ability to ""hallucinate"" and assert falsehoods as fact, even sometimes inventing sources for the inaccurate information.\nApple halted a new AI feature in January after it incorrectly summarised news app notifications.\nThe BBC complained about the feature after Apple\'s AI falsely told readers that Luigi Mangione - the man accused of killing UnitedHealthcare CEO Brian Thompson - had shot himself.\nGoogle has also faced criticism over inaccurate answers produced by its AI search overviews.\nThis has added to concerns about the use of AI in schools and workplaces, where it is increasingly used to help summarise texts, write emails or essays and solve bugs in code.\nThere are worries about students using AI technology to ""cheat"" on assignments, or employees ""smuggling"" it into work.\nWriters, musicians and artists have also pushed back against the technology on ethical grounds, accusing AI developers of using their work to train systems without consent or compensation.\nThousands of creators - including Abba singer-songwriter Björn Ulvaeus, writers Ian Rankin and Joanne Harris and actress Julianne Moore - signed a statement in October 2024 calling AI a ""major, unjust threat"" to their livelihoods.\nHow does AI effect the environment?\nIt is not clear how much energy AI systems use, but some researchers estimate the industry as a whole could soon consume as much as the Netherlands.\nCreating the powerful computer chips needed to run AI programmes requires lots of power and water.\nDemand for generative AI services has also meant an increase in the number of data centres which power them.\nThese huge halls - housing thousands of racks of computer servers - use substantial amounts of energy and require large volumes of water to keep them cool.\nSome large tech companies have invested in ways to reduce or reuse the water needed, or have opted for alternative methods such as air-cooling.\nHowever, some experts and activists fear that AI will worsen water supply problems.\nThe BBC was told in February that government plans to make the UK a ""world leader"" in AI could put already stretched supplies of drinking water under strain.\nIn September 2024, Google said it would reconsider proposals for a data centre in Chile, which has struggled with drought.\n']","The ethical concerns surrounding artificial intelligence (AI) include its potential to reproduce biased information and discriminate against social groups, as much of the data used to train AI reflects existing societal biases such as sexism and racism. Additionally, there are worries about the implications of AI's rapid growth, including its potential to affect nearly 40% of jobs and worsen global financial inequality. The environmental impact of AI is also a significant concern, as the industry could soon consume as much energy as the Netherlands, and the creation of powerful computer chips requires substantial power and water. Critics fear that the demand for generative AI services will exacerbate water supply problems, particularly in regions already facing drought, highlighting the interconnectedness of ethical and environmental issues in the discourse surrounding AI.",multi_hop_abstract_query_synthesizer
"What ethical guidelines for AI are suggested by the IEEE Global Initiative, and how do these relate to user privacy measures in automated message analysis?","['<1-hop>\n\nIn the same vein, the IEEE Global Initiative has ethical guidelines for AI and autonomous systems. Its experts suggest that these models be programmed with consideration for widely accepted human norms and rules for behavior. AI algorithms need to take into effect the importance of these norms, how norm conflict can be resolved, and ways these systems can be transparent about norm resolution. Software designs should be programmed for “nondeception” and “honesty,” according to ethics experts. When failures occur, there must be mitigation mechanisms to deal with the consequences. In particular, AI must be sensitive to problems such as bias, discrimination, and fairness.68\nA group of machine learning experts claim it is possible to automate ethical decisionmaking. Using the trolley problem as a moral dilemma, they ask the following question: If an autonomous car goes out of control, should it be programmed to kill its own passengers or the pedestrians who are crossing the street? They devised a “voting-based system” that asked 1.3 million people to assess alternative scenarios, summarized the overall choices, and applied the overall perspective of these individuals to a range of vehicular possibilities. That allowed them to automate ethical decisionmaking in AI algorithms, taking public preferences into account.69 This procedure, of course, does not reduce the tragedy involved in any kind of fatality, such as seen in the Uber case, but it provides a mechanism to help AI developers incorporate ethical considerations in their planning.\n Penalize malicious behavior and promote cybersecurity\nAs with any emerging technology, it is important to discourage malicious treatment designed to trick software or use it for undesirable ends.70 This is especially important given the dual-use aspects of AI, where the same tool can be used for beneficial or malicious purposes. The malevolent use of AI exposes individuals and organizations to unnecessary risks and undermines the virtues of the emerging technology. This includes behaviors such as hacking, manipulating algorithms, compromising privacy and confidentiality, or stealing identities. Efforts to hijack AI in order to solicit confidential information should be seriously penalized as a way to deter such actions.71\nIn a rapidly changing world with many entities having advanced computing capabilities, there needs to be serious attention devoted to cybersecurity. Countries have to be careful to safeguard their own systems and keep other nations from damaging their security.72 According to the U.S. Department of Homeland Security, a major American bank receives around 11 million calls a week at its service center. In order to protect its telephony from denial of service attacks, it uses a “machine learning-based policy engine [that] blocks more than 120,000 calls per month based on voice firewall policies including harassing callers, robocalls and potential fraudulent calls.”73 This represents a way in which machine learning can help defend technology systems from malevolent attacks.\n', '<2-hop>\n\n3.4 Summarizing Our Approach to Privacy\nWe took measures to safeguard user privacy at every stage of analysis. To summarize, the key elements\nof our approach are:\nAutomated classification of messages.In the course of analysis, no one ever looked directly\nat the content of user messages: all of our analysis of the content of user messages is done\nthrough output of automated classifiers run on de-identified and PII-scrubbed usage data.\nAggregated employment data via a data clean room.We analyze and report aggregated\nemployment data through a secure data clean room environment: no one on the research\nteam had direct access to user-level demographic data and none of our analyses report\naggregates for groups with less than 100 users.\nIn following these measures, we aim to match or exceed the privacy protection precedents set by\nother social scientists studying chatbots and those linking digital platform data to external sources.\nWe follow the precedent established in recent analyses of chatbot conversations (Phang et al.\n(2025), Eloundou et al. (2025), Handa et al. (2025), Tomlinson et al. (2025)) that rely on automated\nclassification rather than human inspection of raw transcripts. In particular, Phang et al. (2025)’s\nstudy of affective use of ChatGPT and Eloundou et al. (2025) investigation of first-person fairness in\nchatbots both analyze ChatGPT message content via automated classifiers and emphasize classifier-\nbased labeling as a scalable, privacy-preserving approach. Anthropic’s Handa et al. (2025) used a\nsimilar approach: theirCliomethodology applies automated classifiers to large collections of conver-\nsations, classifying conversations into thousands of topics, and in their appendix they describe manual\nvalidation on sampled conversations (100 user conversations flagged for review and 100 randomly sam-\npled calibrations). Like Eloundou et al., we validate our classifiers using WildChat, a public dataset\nof user conversations.\n9\x0cOther papers have analyzed digital behavior and demographic data; we mention a few relevant\nprecedents here. Humlum and Vestergaard (2025b) and Humlum and Vestergaard (2025a), for exam-\nple, analyze large-scale surveys on chatbot use along with Danish administrative labor market data.\nChetty et al. (2022) analyze de-identified Facebook friendship graphs and anonymized IRS tax records,\naggregated at the zip code level.\n']","The IEEE Global Initiative suggests that ethical guidelines for AI and autonomous systems should include programming models with consideration for widely accepted human norms, ensuring transparency in norm resolution, and addressing issues such as bias, discrimination, and fairness. These guidelines emphasize the importance of nondeception and honesty in AI algorithms. In relation to user privacy, measures taken during automated message analysis include the use of automated classifiers on de-identified and PII-scrubbed data, ensuring that no one directly accesses user messages. This approach aligns with the ethical guidelines by safeguarding user privacy while still allowing for the analysis of data, thus promoting ethical AI implementation.",multi_hop_abstract_query_synthesizer
How do the statistics from ChatGPT users relate to user satisfaction and the classifier's ability to assess interaction quality?,"['<1-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ', '<2-hop>\n\nClassified Queries, Organized by Generalized Work Activity (of the query) and Occupation (of\nthe user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through July 2025. Cells\nwith contributions from fewer than 100 users are suppressed to zero. The title of one GWA is not fully shown\ndue to space constraints: “Estimating the Quantifiable Characteristics of Products, Events, or Information.”\n60\x0cFigure 34:Classified Work-Related Queries, Organized by Generalized Work Activity (of the query) and\nOccupation (of the user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through\nJuly 2025. Cells with contributions from fewer than 100 users are suppressed to zero. The title of one GWA\nis not fully shown due to space constraints: “Estimating the Quantifiable Characteristics of Products, Events,\nor Information.”\n61\x0cOccupation Group Documenting/\nRecording\nInformation\nMaking\nDecisions\nAnd Solving\nProblems\nThinking\nCreatively\nWorking\nWith\nComputers\nInterpreting\nThe Meaning\nOf\nInformation\nFor Others\nGetting\nInformation\nProviding\nConsultation\nAnd Advice\nTo Others\nManagement 3 2 4 7 5 1 6\nBusiness 3 2 6 7 4 1 5\nComputer/Math 5 4 6 1 3 2 7\nEngineering 5 3 7 4 2 1 6\nScience 2 3 6 7 4 1 5\nSocial Service 2 3 6 X 4 1 5\nLegal 2 3 6 X 4 1 5\nEducation 1 3 4 7 5 2 6\nArts/Design/Media 2 3 4 7 5 1 6\nHealth Professionals 2 5 6 X 4 1 3\nHealth Support 2 3 6 X 4 1 5\nProtective Service 2 X X X X 1 X\nFood Service 3 5 6 X 2 1 4\nPersonal Service 2 3 5 X 4 1 6\nSales 2 5 6 7 3 1 4\nAdministrative 2 4 6 8 3 1 5\nConstruction X X X X X 1 X\nInstallation/Repair X X X X X 1 X\nProduction 3 5 6 X 2 1 4\nTransportation 3 4 5 X 2 1 6\nMilitary 4 3 6 X 2 1 5\nFigure 35:']","The statistics from approximately 40,000 ChatGPT users indicate that while the classifier struggles to infer user satisfaction from text alone, it can partially observe satisfaction through explicit thumbs-up/down feedback. The data shows that 86% of all feedback is thumbs-up, and conversations with thumbs-down feedback are equally likely to be classified as Good or Bad. However, thumbs-up feedback is 9.5 times more likely to be followed by a message classified as Good, suggesting a strong correlation between positive user ratings and interaction quality.",multi_hop_abstract_query_synthesizer
How user satisfaction linked to AI regulation in different countries?,"['<1-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ', '<2-hop>\n\nAre there laws governing AI?\nSome governments have already introduced rules governing how AI operates.\nThe EU\'s Artificial Intelligence Act places controls on high risk systems used in areas such as education, healthcare, law enforcement or elections. It bans some AI use altogether.\nGenerative AI developers in China are required to safeguard citizens\' data, and promote transparency and accuracy of information. But they are also bound by the country\'s strict censorship laws.\nIn the UK, Prime Minister Sir Keir Starmer has said the government ""will test and understand AI before we regulate it"".\nBoth the UK and US have AI Safety Institutes that aim to identify risks and evaluate advanced AI models.\nIn 2024 the two countries signed an agreement to collaborate on developing ""robust"" AI testing methods.\nHowever, in February 2025, neither country signed an international AI declaration which pledged an open, inclusive and sustainable approach to the technology.\nSeveral countries including the UK are also clamping down on use of AI systems to create deepfake nude imagery and child sexual abuse material.\nSign up for our Tech Decoded newsletter to follow the world\'s top tech stories and trends. Outside the UK? Sign up here.']","User satisfaction is linked to AI regulation as seen in various countries. For instance, the EU's Artificial Intelligence Act places controls on high-risk systems, which can impact user experience by ensuring safer interactions. In the UK, the government's approach to test and understand AI before regulation suggests a focus on improving user satisfaction through informed policies. Additionally, the feedback mechanism discussed in the first segment indicates that user satisfaction can be inferred from explicit feedback, which is crucial for developing regulations that prioritize user experience.",multi_hop_abstract_query_synthesizer
How user satisfaction relates to AI regulation in different countries?,"['<1-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ', '<2-hop>\n\nAre there laws governing AI?\nSome governments have already introduced rules governing how AI operates.\nThe EU\'s Artificial Intelligence Act places controls on high risk systems used in areas such as education, healthcare, law enforcement or elections. It bans some AI use altogether.\nGenerative AI developers in China are required to safeguard citizens\' data, and promote transparency and accuracy of information. But they are also bound by the country\'s strict censorship laws.\nIn the UK, Prime Minister Sir Keir Starmer has said the government ""will test and understand AI before we regulate it"".\nBoth the UK and US have AI Safety Institutes that aim to identify risks and evaluate advanced AI models.\nIn 2024 the two countries signed an agreement to collaborate on developing ""robust"" AI testing methods.\nHowever, in February 2025, neither country signed an international AI declaration which pledged an open, inclusive and sustainable approach to the technology.\nSeveral countries including the UK are also clamping down on use of AI systems to create deepfake nude imagery and child sexual abuse material.\nSign up for our Tech Decoded newsletter to follow the world\'s top tech stories and trends. Outside the UK? Sign up here.']","User satisfaction is assessed through explicit feedback on assistant messages, where 86% of feedback is thumbs-up, indicating positive user experiences. In terms of AI regulation, various countries have introduced laws governing AI operations. For instance, the EU's Artificial Intelligence Act imposes controls on high-risk systems, while China mandates data safeguarding and transparency. The UK is also exploring AI regulation, emphasizing the need to understand AI before implementing regulations. Thus, user satisfaction and AI regulation are interconnected as positive user experiences can influence the development of regulatory frameworks.",multi_hop_abstract_query_synthesizer
"How does the use of AI in urban service delivery, such as in the Cincinnati Fire Department, relate to user satisfaction based on feedback mechanisms?","['<1-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ', '<2-hop>\n\nSmart cities\nMetropolitan governments are using AI to improve urban service delivery. For example, according to Kevin Desouza, Rashmi Krishnamurthy, and Gregory Dawson:\nThe Cincinnati Fire Department is using data analytics to optimize medical emergency responses. The new analytics system recommends to the dispatcher an appropriate response to a medical emergency call—whether a patient can be treated on-site or needs to be taken to the hospital—by taking into account several factors, such as the type of call, location, weather, and similar calls.34\nSince it fields 80,000 requests each year, Cincinnati officials are deploying this technology to prioritize responses and determine the best ways to handle emergencies. They see AI as a way to deal with large volumes of data and figure out efficient ways of responding to public requests. Rather than address service issues in an ad hoc manner, authorities are trying to be proactive in how they provide urban services.\n']","The use of AI in urban service delivery, exemplified by the Cincinnati Fire Department's data analytics system, aims to enhance user satisfaction by optimizing responses to medical emergencies. This system analyzes various factors to recommend appropriate actions, thereby improving the efficiency of service delivery. The feedback mechanisms discussed in the first segment indicate that user satisfaction can be inferred from explicit thumbs-up/down feedback, with a significant correlation between positive feedback and the quality of interactions. Thus, the integration of AI in urban services not only seeks to improve operational efficiency but also aims to align with user satisfaction as indicated by the feedback received.",multi_hop_abstract_query_synthesizer
How does the feedback from ChatGPT users relate to user satisfaction and the classification of their queries over time?,"['<1-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ', '<2-hop>\n\nClassified Queries, Organized by Generalized Work Activity (of the query) and Occupation (of\nthe user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through July 2025. Cells\nwith contributions from fewer than 100 users are suppressed to zero. The title of one GWA is not fully shown\ndue to space constraints: “Estimating the Quantifiable Characteristics of Products, Events, or Information.”\n60\x0cFigure 34:Classified Work-Related Queries, Organized by Generalized Work Activity (of the query) and\nOccupation (of the user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through\nJuly 2025. Cells with contributions from fewer than 100 users are suppressed to zero. The title of one GWA\nis not fully shown due to space constraints: “Estimating the Quantifiable Characteristics of Products, Events,\nor Information.”\n61\x0cOccupation Group Documenting/\nRecording\nInformation\nMaking\nDecisions\nAnd Solving\nProblems\nThinking\nCreatively\nWorking\nWith\nComputers\nInterpreting\nThe Meaning\nOf\nInformation\nFor Others\nGetting\nInformation\nProviding\nConsultation\nAnd Advice\nTo Others\nManagement 3 2 4 7 5 1 6\nBusiness 3 2 6 7 4 1 5\nComputer/Math 5 4 6 1 3 2 7\nEngineering 5 3 7 4 2 1 6\nScience 2 3 6 7 4 1 5\nSocial Service 2 3 6 X 4 1 5\nLegal 2 3 6 X 4 1 5\nEducation 1 3 4 7 5 2 6\nArts/Design/Media 2 3 4 7 5 1 6\nHealth Professionals 2 5 6 X 4 1 3\nHealth Support 2 3 6 X 4 1 5\nProtective Service 2 X X X X 1 X\nFood Service 3 5 6 X 2 1 4\nPersonal Service 2 3 5 X 4 1 6\nSales 2 5 6 7 3 1 4\nAdministrative 2 4 6 8 3 1 5\nConstruction X X X X X 1 X\nInstallation/Repair X X X X X 1 X\nProduction 3 5 6 X 2 1 4\nTransportation 3 4 5 X 2 1 6\nMilitary 4 3 6 X 2 1 5\nFigure 35:']","The feedback from ChatGPT users is crucial in assessing user satisfaction, as it provides explicit thumbs-up/down responses that help evaluate the classifier's performance. In a sample of conversations from June 2024 to June 2025, it was found that 86% of the feedback was thumbs-up, indicating a positive user experience. Furthermore, conversations with thumbs-down feedback were equally likely to be classified as Good or Bad, while thumbs-up feedback was 9.5 times more likely to be followed by a message classified as Good. This correlation suggests that user satisfaction is closely linked to the quality of interactions, as reflected in the classified queries from approximately 40,000 ChatGPT users during the same period.",multi_hop_abstract_query_synthesizer
"How do the statistics on user satisfaction from ChatGPT users correlate with the feedback received on assistant messages, and what does this imply about the interaction quality over time?","['<1-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ', '<2-hop>\n\nClassified Queries, Organized by Generalized Work Activity (of the query) and Occupation (of\nthe user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through July 2025. Cells\nwith contributions from fewer than 100 users are suppressed to zero. The title of one GWA is not fully shown\ndue to space constraints: “Estimating the Quantifiable Characteristics of Products, Events, or Information.”\n60\x0cFigure 34:Classified Work-Related Queries, Organized by Generalized Work Activity (of the query) and\nOccupation (of the user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through\nJuly 2025. Cells with contributions from fewer than 100 users are suppressed to zero. The title of one GWA\nis not fully shown due to space constraints: “Estimating the Quantifiable Characteristics of Products, Events,\nor Information.”\n61\x0cOccupation Group Documenting/\nRecording\nInformation\nMaking\nDecisions\nAnd Solving\nProblems\nThinking\nCreatively\nWorking\nWith\nComputers\nInterpreting\nThe Meaning\nOf\nInformation\nFor Others\nGetting\nInformation\nProviding\nConsultation\nAnd Advice\nTo Others\nManagement 3 2 4 7 5 1 6\nBusiness 3 2 6 7 4 1 5\nComputer/Math 5 4 6 1 3 2 7\nEngineering 5 3 7 4 2 1 6\nScience 2 3 6 7 4 1 5\nSocial Service 2 3 6 X 4 1 5\nLegal 2 3 6 X 4 1 5\nEducation 1 3 4 7 5 2 6\nArts/Design/Media 2 3 4 7 5 1 6\nHealth Professionals 2 5 6 X 4 1 3\nHealth Support 2 3 6 X 4 1 5\nProtective Service 2 X X X X 1 X\nFood Service 3 5 6 X 2 1 4\nPersonal Service 2 3 5 X 4 1 6\nSales 2 5 6 7 3 1 4\nAdministrative 2 4 6 8 3 1 5\nConstruction X X X X X 1 X\nInstallation/Repair X X X X X 1 X\nProduction 3 5 6 X 2 1 4\nTransportation 3 4 5 X 2 1 6\nMilitary 4 3 6 X 2 1 5\nFigure 35:']","The statistics on user satisfaction from ChatGPT users indicate that while the inherent difficulty of inferring user satisfaction from text alone exists, explicit feedback such as thumbs-up/down provides valuable insights. In a sample of conversations from June 2024 to June 2025, it was found that 86% of the feedback was thumbs-up. This suggests that conversations with thumbs-up feedback are significantly more likely to be classified as Good, with a ratio of 9.5 times compared to those with thumbs-down feedback. This correlation implies that user satisfaction is closely linked to the quality of interactions, as positive feedback aligns with higher quality classifications.",multi_hop_abstract_query_synthesizer
"How does the classifier's ability to infer user satisfaction relate to decision making in various occupations, particularly in knowledge-intensive jobs?","['<1-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ', '<2-hop>\n\nClassified Queries, Organized by Generalized Work Activity (of the query) and Occupation (of\nthe user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through July 2025. Cells\nwith contributions from fewer than 100 users are suppressed to zero. The title of one GWA is not fully shown\ndue to space constraints: “Estimating the Quantifiable Characteristics of Products, Events, or Information.”\n60\x0cFigure 34:Classified Work-Related Queries, Organized by Generalized Work Activity (of the query) and\nOccupation (of the user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through\nJuly 2025. Cells with contributions from fewer than 100 users are suppressed to zero. The title of one GWA\nis not fully shown due to space constraints: “Estimating the Quantifiable Characteristics of Products, Events,\nor Information.”\n61\x0cOccupation Group Documenting/\nRecording\nInformation\nMaking\nDecisions\nAnd Solving\nProblems\nThinking\nCreatively\nWorking\nWith\nComputers\nInterpreting\nThe Meaning\nOf\nInformation\nFor Others\nGetting\nInformation\nProviding\nConsultation\nAnd Advice\nTo Others\nManagement 3 2 4 7 5 1 6\nBusiness 3 2 6 7 4 1 5\nComputer/Math 5 4 6 1 3 2 7\nEngineering 5 3 7 4 2 1 6\nScience 2 3 6 7 4 1 5\nSocial Service 2 3 6 X 4 1 5\nLegal 2 3 6 X 4 1 5\nEducation 1 3 4 7 5 2 6\nArts/Design/Media 2 3 4 7 5 1 6\nHealth Professionals 2 5 6 X 4 1 3\nHealth Support 2 3 6 X 4 1 5\nProtective Service 2 X X X X 1 X\nFood Service 3 5 6 X 2 1 4\nPersonal Service 2 3 5 X 4 1 6\nSales 2 5 6 7 3 1 4\nAdministrative 2 4 6 8 3 1 5\nConstruction X X X X X 1 X\nInstallation/Repair X X X X X 1 X\nProduction 3 5 6 X 2 1 4\nTransportation 3 4 5 X 2 1 6\nMilitary 4 3 6 X 2 1 5\nFigure 35:', '<3-hop>\n\nThis is consistent with the fact that almost half of all ChatGPT usage is\neitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than\n9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles),\nand so we believe it likely resulted in an unrepresentative distribution of use cases.\n10Among those with names commonly associated with a particular gender.\n11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against\npublic conversation data.\n3\x0cDoing, and thatAskingmessages are consistently rated as having higher quality both by a classifier\nthat measures user satisfaction and from direct user feedback.\nHow does ChatGPT provide economic value, and for whom is its value the greatest? We argue that\nChatGPT likely improves worker output by providingdecision support, which is especially important in\nknowledge-intensive jobs where better decision-making increases productivity (Deming, 2021; Caplin et\nal., 2023). This explains whyAskingis relatively more common for educated users who are employed\nin highly-paid, professional occupations. Our findings are most consistent with Ide and Talamas\n(2025), who develop a model where AI agents can serve either asco-workersthat produce output or\nasco-pilotsthat give advice and improve the productivity of human problem-solving.\n2 ']","The classifier's ability to infer user satisfaction is linked to decision making in various occupations by providing insights into user feedback. The classifier captures a signal aligned with user experience by linking model predictions to voluntary feedback on assistant messages. This is particularly relevant in knowledge-intensive jobs, where better decision-making can enhance productivity. The data shows that conversations with thumbs-up feedback are significantly more likely to be classified as good, indicating that user satisfaction directly influences the quality of decision-making support provided by AI.",multi_hop_abstract_query_synthesizer
How does the feedback from ChatGPT users relate to user satisfaction and the classification of their queries over time?,"['<1-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ', '<2-hop>\n\nClassified Queries, Organized by Generalized Work Activity (of the query) and Occupation (of\nthe user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through July 2025. Cells\nwith contributions from fewer than 100 users are suppressed to zero. The title of one GWA is not fully shown\ndue to space constraints: “Estimating the Quantifiable Characteristics of Products, Events, or Information.”\n60\x0cFigure 34:Classified Work-Related Queries, Organized by Generalized Work Activity (of the query) and\nOccupation (of the user). Queries are from approximately 40,000 ChatGPT users, from May 2024 through\nJuly 2025. Cells with contributions from fewer than 100 users are suppressed to zero. The title of one GWA\nis not fully shown due to space constraints: “Estimating the Quantifiable Characteristics of Products, Events,\nor Information.”\n61\x0cOccupation Group Documenting/\nRecording\nInformation\nMaking\nDecisions\nAnd Solving\nProblems\nThinking\nCreatively\nWorking\nWith\nComputers\nInterpreting\nThe Meaning\nOf\nInformation\nFor Others\nGetting\nInformation\nProviding\nConsultation\nAnd Advice\nTo Others\nManagement 3 2 4 7 5 1 6\nBusiness 3 2 6 7 4 1 5\nComputer/Math 5 4 6 1 3 2 7\nEngineering 5 3 7 4 2 1 6\nScience 2 3 6 7 4 1 5\nSocial Service 2 3 6 X 4 1 5\nLegal 2 3 6 X 4 1 5\nEducation 1 3 4 7 5 2 6\nArts/Design/Media 2 3 4 7 5 1 6\nHealth Professionals 2 5 6 X 4 1 3\nHealth Support 2 3 6 X 4 1 5\nProtective Service 2 X X X X 1 X\nFood Service 3 5 6 X 2 1 4\nPersonal Service 2 3 5 X 4 1 6\nSales 2 5 6 7 3 1 4\nAdministrative 2 4 6 8 3 1 5\nConstruction X X X X X 1 X\nInstallation/Repair X X X X X 1 X\nProduction 3 5 6 X 2 1 4\nTransportation 3 4 5 X 2 1 6\nMilitary 4 3 6 X 2 1 5\nFigure 35:']","The feedback from ChatGPT users is crucial in assessing user satisfaction, as it provides explicit thumbs-up/down responses that help evaluate the classifier's performance. From a sample of conversations between June 2024 and June 2025, it was found that 86% of the feedback was thumbs-up, indicating a positive user experience. Additionally, conversations with thumbs-down feedback were equally likely to be classified as Good or Bad, while thumbs-up feedback was 9.5 times more likely to be followed by a message classified as Good. This correlation suggests that user satisfaction is closely linked to the quality of interactions, which can be further analyzed through the classified queries from approximately 40,000 ChatGPT users during the same period.",multi_hop_abstract_query_synthesizer
"How does user satisfaction vary among different occupations using ChatGPT, and what are the implications for its usage in professional settings?","['<1-hop>\n\nWe retain this classifier because theseκ\nstatistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text\nalone.\nWhile this latent “prior” is unobserved in our validation data, it is partially observable when users\nprovide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned\n56\x0cFigure 30:Agreement Between Model and Plurality for Interaction Quality\nFigure 31:Bias Between Model and Plurality for Interaction Quality\n57\x0cwith user experience, we link model predictions to voluntary feedback on assistant messages. We\ndraw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i)\nthe assistant message received explicit feedback and (ii) the user sent a subsequent message that our\nclassifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not\nbe fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy\nuser satisfaction.\nFigure 32 shows thatUnknownclassifications are split roughly evenly between thumbs-down and\nthumbs-up feedback. Thumbs-up comprises 86% of all feedback. Conversations with thumbs-down\nfeedback are about equally likely to be classified asGoodorBad, whereas thumbs-up feedback is 9.5\ntimes more likely to be followed by a message classified asGood.\nFigure 32:Correlation of User Rating and Interaction Quality Annotation\n58\x0cC  Appendix: ChatGPT Timeline\ndate event\n2022-11-30 Public launch of ChatGPT as a “research preview” (using GPT-3.5)\n2023-02-01 Launch of ChatGPT Plus subscription\n2023-03-14 Launch of GPT-4 in ChatGPT Plus\n2024-04-01 Launch of logged-out ChatGPT\n2024-05-13 Launch of GPT-4o in ChatGPT Free and Plus\n2024-09-12 Launch of o1-preview and o1-mini in ChatGPT Plus\n2024-12-01 Launch of o1-pro in ChatGPT\n2024-12-05 Launch of ChatGPT Pro subscription\n2025-01-03 Launch of o3-mini in ChatGPT\n2025-03-25 Launch of GPT-4o image generation\n2025-04-16 Launch of o3 and o4-mini\n2025-06-10 Launch of o3-pro\n2025-08-07 Launch of GPT-5 in ChatGPT\n59\x0cD ', '<2-hop>\n\n6.5 Variation by Occupation\nFigure 23 presents variation in ChatGPT usage by user occupation. Due to privacy-preserving aggre-\ngation limits, we report results for the following broad occupation categories – (1) all nonprofessional\noccupations, including administrative, clerical, service, and blue-collar occupations; (2) computer-\nrelated occupations; (3) engineering and science occupations; (4) management and business occupa-\ntions; and (5) all other professional occupations, including law, education, and health care. 26 As\nabove, the left-hand side of the figure shows unadjusted comparisons and the right-hand side presents\nthe coefficients on each occupation category from a regression of message shares on age, whether the\nname was typically masculine or feminine, education, occupation categories, job seniority, firm size,\nand industry.\nUsers in highly paid professional and technical occupations are more likely to use ChatGPT for\nwork.27 Panel A shows that the unadjusted work shares are 57% for computer-related occupations;\n50% for management and business; 48% for engineering and science; 44% for other professional oc-\ncupations; and only 40% for all non-professional occupations. Regression adjustment moves these\nfigures around slightly, but the gaps by occupation remain highly statistically significant. Users in\nhighly-paid professional occupations are more likely to send work-related messages.\nBecause work usage is so different by occupation, we restrict the sample only to work-related\nmessages in Panels B and C. Panel B presents the share of work-related messages that areAsking\nmessages, by occupation. We find that users in highly paid professional occupations are more likely\nto use ChatGPT forAskingrather thanDoing. 28 This is especially true in scientific and technical\noccupations. 47% of the work-related messages sent by users employed in computer-related occupa-\ntions areAskingmessages, compared to only 32% for non-professional occupations. These differences\nshrink somewhat with regression adjustment, but remain highly statistically significant.\nPanel C presents results by conversation topic.Writingis especially common for users employed\nin management and business occupations, accounting for 52% of all work-related messages. Writing\nis also relatively common in non-professional and other professional occupations like education and\nhealth care, accounting for 50% and 49% of work-related messages respectively.Technical Helpconsti-\ntutes 37% of all work-related messages for users employed in computer-related occupations, compared\nto 16% in engineering and science and only about 8% for all other categories. Regression adjustment\naffects gaps by occupation only modestly. Overall there are stark differences in the distribution of\nconversation topics by user occupation, with work-related messages clearly focused on the core tasks\nin each job (e.g.Writingfor management and business,Technical Helpfor technical occupations).\nWe also present data on the most common Generalized Work Activities (GWAs) associated with\neach broad occupation group, as measured by 2-digit Standard Occupation Classification (SOC) codes.\nTable 24 presents the frequency ranking of work-related messages in each SOC code of the seven most\ncommon GWAs.29\n26Management and business are SOC2 codes 11 and 13. Computer-related is SOC2 code 15. Engineering and Science\nare SOC2 codes 17 and 19. Other Professional are SOC2 codes 21 to 29. Nonprofessional occupations are SOC codes\n31 to 53.\n27As discussed in Section: Data and Privacy, our dataset only includes users on ChatGPT Consumer plans. Corporate\nusers may also use ChatGPT Business (formerly known as Teams) or ChatGPT Enterprise.\n28Very few work-related messages are classified asExpressing.\n29Appendix D contains a full report of GWA counts broken down by occupation, for both work-related ChatGPT\n31\x0cWe find remarkable similarity across occupations in how ChatGPT is used at work. For example,\nMaking Decisions and Solving Problemsis one of the two most common GWAs in every single oc-\ncupation group where at least two GWAs can be reported. 30 Similarly,Documenting and Recording\nInformationranks in the top four of all occupations.Thinking Creativelyis ranked as the third most\ncommon GWA in 10 of the 13 occupation groups where at least three GWAs can be reported. ']","User satisfaction with ChatGPT is assessed through explicit feedback, where 86% of feedback is thumbs-up, indicating a positive user experience. The variation in ChatGPT usage by occupation shows that users in highly paid professional and technical occupations are more likely to use ChatGPT for work-related tasks. For instance, 57% of users in computer-related occupations send work-related messages, with a significant focus on Asking messages. This suggests that user satisfaction is closely linked to the nature of the tasks performed, with professional users finding ChatGPT particularly useful for decision-making and problem-solving.",multi_hop_abstract_query_synthesizer
