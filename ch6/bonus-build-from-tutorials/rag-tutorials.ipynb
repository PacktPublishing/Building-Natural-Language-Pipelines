{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x3253448f0>\n",
       "ðŸš… Components\n",
       "  - link_fetcher: LinkContentFetcher\n",
       "  - converter: HTMLToDocument\n",
       "  - splitter: DocumentSplitter\n",
       "  - embedder: SentenceTransformersDocumentEmbedder\n",
       "  - writer: DocumentWriter\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - link_fetcher.streams -> converter.sources (List[ByteStream])\n",
       "  - converter.documents -> splitter.documents (List[Document])\n",
       "  - splitter.documents -> embedder.documents (List[Document])\n",
       "  - embedder.documents -> writer.documents (List[Document])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.fetchers import LinkContentFetcher\n",
    "from haystack.components.converters import HTMLToDocument\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.document_stores.types import DuplicatePolicy\n",
    "\n",
    "\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "link_fetcher = LinkContentFetcher()\n",
    "converter = HTMLToDocument()\n",
    "splitter = DocumentSplitter(split_length=150, split_overlap=5, split_by=\"sentence\")\n",
    "embedder = SentenceTransformersDocumentEmbedder()\n",
    "writer = DocumentWriter(document_store=document_store, \n",
    "                        policy=DuplicatePolicy.OVERWRITE)\n",
    "\n",
    "indexing_pipeline = Pipeline()\n",
    "indexing_pipeline.add_component(\"link_fetcher\", link_fetcher)\n",
    "indexing_pipeline.add_component(\"converter\", converter)\n",
    "indexing_pipeline.add_component(\"splitter\", splitter)\n",
    "indexing_pipeline.add_component(\"embedder\", embedder)\n",
    "indexing_pipeline.add_component(\"writer\", writer)\n",
    "\n",
    "indexing_pipeline.connect(\"link_fetcher\", \"converter\")\n",
    "indexing_pipeline.connect(\"converter\", \"splitter\")\n",
    "indexing_pipeline.connect(\"splitter\", \"embedder\")\n",
    "indexing_pipeline.connect(\"embedder\", \"writer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'writer': {'documents_written': 19}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexing_pipeline.run(data={\"link_fetcher\":{\"urls\": [\"https://haystack.deepset.ai/integrations/elasticsearch-document-store\",\n",
    "                                                    \"https://haystack.deepset.ai/tutorials/27_first_rag_pipeline/\",\n",
    "                                                     \"https://haystack.deepset.ai/tutorials/28_structured_output_with_loop/\",\n",
    "                                                     \"https://haystack.deepset.ai/tutorials/36_building_fallbacks_with_conditional_routing/\",\n",
    "                                                     \"https://haystack.deepset.ai/tutorials/40_building_chat_application_with_function_calling/\",\n",
    "                                                     \"https://haystack.deepset.ai/tutorials/42_sentence_window_retriever/\",\n",
    "                                                     \"https://haystack.deepset.ai/tutorials/41_query_classification_with_transformerstextrouter_and_transformerszeroshottextrouter/\",\n",
    "                                                     \"https://haystack.deepset.ai/tutorials/31_metadata_filtering/\",\n",
    "                                                     \"https://haystack.deepset.ai/tutorials/30_file_type_preprocessing_index_pipeline/\",\n",
    "                                                    \"https://haystack.deepset.ai/tutorials/39_embedding_metadata_for_improved_retrieval/\",\n",
    "                                                    \"https://haystack.deepset.ai/tutorials/29_serializing_pipelines/\",\n",
    "                                                    \"https://haystack.deepset.ai/tutorials/34_extractive_qa_pipeline/\",\n",
    "                                                    \"https://haystack.deepset.ai/tutorials/33_hybrid_retrieval/\",\n",
    "                                                    \"https://haystack.deepset.ai/tutorials/32_classifying_documents_and_queries_by_language/\",\n",
    "                                                    \"https://haystack.deepset.ai/tutorials/35_evaluating_rag_pipelines/\",\n",
    "                                                    \"https://haystack.deepset.ai/tutorials/37_simplifying_pipeline_inputs_with_multiplexer/\"]}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"./../.env\")\n",
    "\n",
    "open_ai_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "\n",
    "######## Complete this section #############\n",
    "prompt_template = \"\"\"\n",
    "You are an expert Python software engineer, you are asked to write code, \n",
    "explain code and you use the context provided to generate accurate and functional code along with clear explanations.\n",
    "After you define a class, you also provide examples of using the class and its methods.\n",
    "You must only use information from the given documents and cite the documents you used by mentioning their URL in the answer.\n",
    "For example, begin your answer with â€˜As stated in URL, ...â€™.\n",
    "If the documents do not contain the answer to the question, say that â€˜Answer is unknown.â€™\n",
    "Context:\n",
    "{% for doc in documents %}\n",
    "    Document: {{ doc.content }} URL: {{ doc.meta['url'] }} \\n\n",
    "{% endfor %};\n",
    "Question: {{query}}\n",
    "\\nAs stated in\n",
    "\"\"\"\n",
    "prompt_builder = PromptBuilder(prompt_template)\n",
    "############################################\n",
    "query_embedder = SentenceTransformersTextEmbedder()\n",
    "retriever = InMemoryEmbeddingRetriever(document_store=document_store, top_k=2)\n",
    "llm = OpenAIGenerator(model='gpt-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x3253666c0>\n",
       "ðŸš… Components\n",
       "  - query_embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - query_embedder.embedding -> retriever.query_embedding (List[float])\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "pipeline.add_component(instance=query_embedder, name=\"query_embedder\")\n",
    "pipeline.add_component(instance=retriever, name=\"retriever\")\n",
    "pipeline.add_component(instance=prompt_builder, name=\"prompt_builder\")\n",
    "pipeline.add_component(instance=llm, name=\"llm\")\n",
    "\n",
    "pipeline.connect(\"query_embedder.embedding\", \"retriever.query_embedding\")\n",
    "pipeline.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
    "pipeline.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "question = \"Write a pipeline that connects to Elastic Search and answers questions about its knowledge, the pipeline\\\n",
    "    should include a prompt template with instructions and the template should iterate over all documents in the \\\n",
    "        context\"\n",
    "result = pipeline.run(data={\"query_embedder\": {\"text\": question}, \"prompt_builder\": {\"query\": question}})\n",
    "print(result['llm']['replies'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (haystack-nlp)",
   "language": "python",
   "name": "haystack-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
