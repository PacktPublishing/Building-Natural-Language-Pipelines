{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building question-and-answer pipelines for complex knowledge bases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build an indexing pipeline from Haystack's documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x3253448f0>\n",
       "🚅 Components\n",
       "  - link_fetcher: LinkContentFetcher\n",
       "  - converter: HTMLToDocument\n",
       "  - splitter: DocumentSplitter\n",
       "  - embedder: SentenceTransformersDocumentEmbedder\n",
       "  - writer: DocumentWriter\n",
       "🛤️ Connections\n",
       "  - link_fetcher.streams -> converter.sources (List[ByteStream])\n",
       "  - converter.documents -> splitter.documents (List[Document])\n",
       "  - splitter.documents -> embedder.documents (List[Document])\n",
       "  - embedder.documents -> writer.documents (List[Document])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.fetchers import LinkContentFetcher\n",
    "from haystack.components.converters import HTMLToDocument\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.document_stores.types import DuplicatePolicy\n",
    "\n",
    "\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "link_fetcher = LinkContentFetcher()\n",
    "converter = HTMLToDocument()\n",
    "splitter = DocumentSplitter(split_length=150, split_overlap=5, split_by=\"sentence\")\n",
    "embedder = SentenceTransformersDocumentEmbedder()\n",
    "writer = DocumentWriter(document_store=document_store, \n",
    "                        policy=DuplicatePolicy.OVERWRITE)\n",
    "\n",
    "indexing_pipeline = Pipeline()\n",
    "indexing_pipeline.add_component(\"link_fetcher\", link_fetcher)\n",
    "indexing_pipeline.add_component(\"converter\", converter)\n",
    "indexing_pipeline.add_component(\"splitter\", splitter)\n",
    "indexing_pipeline.add_component(\"embedder\", embedder)\n",
    "indexing_pipeline.add_component(\"writer\", writer)\n",
    "\n",
    "indexing_pipeline.connect(\"link_fetcher\", \"converter\")\n",
    "indexing_pipeline.connect(\"converter\", \"splitter\")\n",
    "indexing_pipeline.connect(\"splitter\", \"embedder\")\n",
    "indexing_pipeline.connect(\"embedder\", \"writer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing_pipeline.draw(\"indexing_complex_knowledge.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Populate the document store with relevant links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'writer': {'documents_written': 19}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexing_pipeline.run(data={\"link_fetcher\":{\"urls\": [\"https://haystack.deepset.ai/integrations/elasticsearch-document-store\",\n",
    "                                                    \"https://haystack.deepset.ai/tutorials/27_first_rag_pipeline/\",\n",
    "                                                     \"https://haystack.deepset.ai/tutorials/28_structured_output_with_loop/\",\n",
    "                                                     \"https://haystack.deepset.ai/tutorials/36_building_fallbacks_with_conditional_routing/\",\n",
    "                                                     \"https://haystack.deepset.ai/tutorials/40_building_chat_application_with_function_calling/\",\n",
    "                                                     \"https://haystack.deepset.ai/tutorials/42_sentence_window_retriever/\",\n",
    "                                                     \"https://haystack.deepset.ai/tutorials/41_query_classification_with_transformerstextrouter_and_transformerszeroshottextrouter/\",\n",
    "                                                     \"https://haystack.deepset.ai/tutorials/31_metadata_filtering/\",\n",
    "                                                     \"https://haystack.deepset.ai/tutorials/30_file_type_preprocessing_index_pipeline/\",\n",
    "                                                    \"https://haystack.deepset.ai/tutorials/39_embedding_metadata_for_improved_retrieval/\",\n",
    "                                                    \"https://haystack.deepset.ai/tutorials/29_serializing_pipelines/\",\n",
    "                                                    \"https://haystack.deepset.ai/tutorials/34_extractive_qa_pipeline/\",\n",
    "                                                    \"https://haystack.deepset.ai/tutorials/33_hybrid_retrieval/\",\n",
    "                                                    \"https://haystack.deepset.ai/tutorials/32_classifying_documents_and_queries_by_language/\",\n",
    "                                                    \"https://haystack.deepset.ai/tutorials/35_evaluating_rag_pipelines/\",\n",
    "                                                    \"https://haystack.deepset.ai/tutorials/37_simplifying_pipeline_inputs_with_multiplexer/\"]}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"./../.env\")\n",
    "\n",
    "open_ai_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer questions using prompt templating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "\n",
    "######## Complete this section #############\n",
    "prompt_template = \"\"\"\n",
    "You are an expert Python software engineer, you are asked to write code, \n",
    "explain code and you use the context provided to generate accurate and functional code along with clear explanations.\n",
    "After you define a class, you also provide examples of using the class and its methods.\n",
    "You must only use information from the given documents and cite the documents you used by mentioning their URL in the answer.\n",
    "For example, begin your answer with ‘As stated in URL, ...’.\n",
    "If the documents do not contain the answer to the question, say that ‘Answer is unknown.’\n",
    "Context:\n",
    "{% for doc in documents %}\n",
    "    Document: {{ doc.content }} URL: {{ doc.meta['url'] }} \\n\n",
    "{% endfor %};\n",
    "Question: {{query}}\n",
    "\\nAs stated in\n",
    "\"\"\"\n",
    "prompt_builder = PromptBuilder(prompt_template)\n",
    "############################################\n",
    "query_embedder = SentenceTransformersTextEmbedder()\n",
    "retriever = InMemoryEmbeddingRetriever(document_store=document_store, top_k=2)\n",
    "llm = OpenAIGenerator(model='gpt-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x3253666c0>\n",
       "🚅 Components\n",
       "  - query_embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "🛤️ Connections\n",
       "  - query_embedder.embedding -> retriever.query_embedding (List[float])\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "pipeline.add_component(instance=query_embedder, name=\"query_embedder\")\n",
    "pipeline.add_component(instance=retriever, name=\"retriever\")\n",
    "pipeline.add_component(instance=prompt_builder, name=\"prompt_builder\")\n",
    "pipeline.add_component(instance=llm, name=\"llm\")\n",
    "\n",
    "pipeline.connect(\"query_embedder.embedding\", \"retriever.query_embedding\")\n",
    "pipeline.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
    "pipeline.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.draw(\"answer_generation_pipeline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[](./indexing_complex_knowledge.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://haystack.deepset.ai/integrations/elasticsearch-document-store and https://haystack.deepset.ai/tutorials/27_first_rag_pipeline/, here's how to use Elasticsearch with Haystack in a pipeline:\n",
      "\n",
      "First, install the necessary packages:\n",
      "```python\n",
      "pip install elasticsearch-haystack\n",
      "pip install \"datasets>=2.6.1\"\n",
      "pip install \"sentence-transformers>=3.0.0\"\n",
      "```\n",
      "\n",
      "Then, you can use the following code to create the pipeline:\n",
      "\n",
      "```python\n",
      "from haystack import Pipeline, Document\n",
      "from haystack.document_stores.elasticsearch import ElasticsearchDocumentStore\n",
      "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
      "from haystack_integrations.components.retrievers.elasticsearch import ElasticsearchEmbeddingRetriever\n",
      "from haystack.components.generators import OpenAIGenerator\n",
      "from haystack.components.builders import PromptBuilder\n",
      "\n",
      "# Initialize ElasticsearchDocumentStore\n",
      "document_store = ElasticsearchDocumentStore(hosts = \"http://localhost:9200\")\n",
      "\n",
      "# Initialize a text embedder to create an embedding for the user query.\n",
      "text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "\n",
      "# Initialize retriever\n",
      "retriever = ElasticsearchEmbeddingRetriever(document_store=document_store)\n",
      "\n",
      "# Define the template prompt\n",
      "template = \"\"\"\n",
      "Given the following information, answer the question.\n",
      "Context:\n",
      "{% for document in documents %}\n",
      "{{ document.content }}\n",
      "{% endfor %}\n",
      "Question: {{question}}\n",
      "Answer:\n",
      "\"\"\"\n",
      "prompt_builder = PromptBuilder(template=template)\n",
      "\n",
      "# Initialize Generator (Replace 'your-api-key' with your OpenAI API Key)\n",
      "generator = OpenAIGenerator(model=\"gpt-4o-mini\")\n",
      "generator.api_key = 'your-api-key'\n",
      "\n",
      "# Build the Pipeline\n",
      "query_pipeline = Pipeline()\n",
      "query_pipeline.add_component(\"text_embedder\", text_embedder)\n",
      "query_pipeline.add_component(\"retriever\", retriever)\n",
      "query_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
      "query_pipeline.add_component(\"llm\", generator)\n",
      "query_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
      "query_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
      "query_pipeline.connect(\"prompt_builder\", \"llm\")\n",
      "\n",
      "# Running the pipeline\n",
      "question = \"What is Elasticsearch?\"\n",
      "response = basic_rag_pipeline.run({\"text_embedder\": {\"text\": question}, \"prompt_builder\": {\"question\": question}})\n",
      "print(response[\"llm\"][\"replies\"][0])\n",
      "```\n",
      "This script does the following:\n",
      "1. Initializes a connection to ElasticsearchDocumentStore \n",
      "2. Defines a Sentence Transformers text embedder for embedding the user query.\n",
      "3. Initializes the ElasticsearchEmbeddingRetriever to fetch relevant documents.\n",
      "4. Defines a template for generating prompts for the language model.\n",
      "5. Initializes an OpenAIGenerator for generating responses.\n",
      "6. Builds a pipeline with these components, connecting each component to its subsequent component.\n",
      "7. Finally, it runs the query pipeline with a given question and prints out the response.\n"
     ]
    }
   ],
   "source": [
    "question = \"Write a pipeline that connects to Elastic Search and answers questions about its knowledge, the pipeline\\\n",
    "    should include a prompt template with instructions and the template should iterate over all documents in the \\\n",
    "        context\"\n",
    "result = pipeline.run(data={\"query_embedder\": {\"text\": question}, \"prompt_builder\": {\"query\": question}})\n",
    "print(result['llm']['replies'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (haystack-nlp)",
   "language": "python",
   "name": "haystack-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
