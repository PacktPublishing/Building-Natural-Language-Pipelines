{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de4ea5e",
   "metadata": {},
   "source": [
    "üîß **Setup Required**: Before running this notebook, please follow the [setup instructions](../README.md#setup-instructions) to configure your environment and API keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dad9b8",
   "metadata": {},
   "source": [
    "# Knowledge Graph and Synthetic Data Generation Pipelines\n",
    "\n",
    "This notebook demonstrates how to build comprehensive pipelines for:\n",
    "1. **Knowledge Graph Creation** - Converting documents into structured knowledge representations\n",
    "2. **Synthetic Test Data Generation** - Creating question-answer pairs for evaluation\n",
    "3. **Multi-Source Processing** - Working with PDFs, web content, and other document types\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will understand:\n",
    "- How to build end-to-end Haystack pipelines for knowledge extraction\n",
    "- The relationship between knowledge graphs and test data generation\n",
    "- Best practices for processing different document formats\n",
    "- How to evaluate and validate synthetic datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb2f063",
   "metadata": {},
   "source": [
    "## Part 1: PDF Processing Pipeline\n",
    "\n",
    "### Overview\n",
    "In this section, we'll build a comprehensive pipeline that:\n",
    "1. **Extracts content** from PDF files using Haystack's PyPDFToDocument converter\n",
    "2. **Preprocesses the text** with cleaning and splitting components\n",
    "3. **Creates a knowledge graph** from the processed documents\n",
    "4. **Generates synthetic test data** using the knowledge graph\n",
    "\n",
    "### Key Components\n",
    "- **PyPDFToDocument**: Converts PDF files to Haystack Document objects\n",
    "- **DocumentCleaner**: Removes extra whitespaces and empty lines\n",
    "- **DocumentSplitter**: Breaks documents into manageable chunks\n",
    "- **KnowledgeGraphGenerator**: Creates structured knowledge representations\n",
    "- **SyntheticTestGenerator**: Produces question-answer pairs for evaluation\n",
    "\n",
    "### Why This Approach?\n",
    "Using knowledge graphs as an intermediate step improves the quality of synthetic test generation because:\n",
    "- Knowledge graphs capture relationships between entities\n",
    "- They provide structured context for question generation\n",
    "- The resulting questions are more coherent and factually grounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c86671d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurafunderburk/Documents/GitHub/Building-Natural-Language-Pipelines/ch5/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x15eee1e80>\n",
       "üöÖ Components\n",
       "  - pdf_converter: PyPDFToDocument\n",
       "  - doc_cleaner: DocumentCleaner\n",
       "  - doc_splitter: DocumentSplitter\n",
       "  - doc_converter: DocumentToLangChainConverter\n",
       "  - kg_generator: KnowledgeGraphGenerator\n",
       "  - test_generator: SyntheticTestGenerator\n",
       "  - test_saver: TestDatasetSaver\n",
       "üõ§Ô∏è Connections\n",
       "  - pdf_converter.documents -> doc_cleaner.documents (list[Document])\n",
       "  - doc_cleaner.documents -> doc_splitter.documents (list[Document])\n",
       "  - doc_splitter.documents -> doc_converter.documents (list[Document])\n",
       "  - doc_converter.langchain_documents -> kg_generator.documents (List[Document])\n",
       "  - doc_converter.langchain_documents -> test_generator.documents (List[Document])\n",
       "  - kg_generator.knowledge_graph -> test_generator.knowledge_graph (KnowledgeGraph)\n",
       "  - test_generator.testset -> test_saver.testset (DataFrame)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from haystack import Pipeline\n",
    "from haystack.components.converters import PyPDFToDocument\n",
    "from haystack.components.preprocessors import (\n",
    "    DocumentCleaner,\n",
    "    DocumentSplitter)\n",
    "from pathlib import Path\n",
    "from scripts.knowledge_graph_component import KnowledgeGraphGenerator\n",
    "from scripts.synthetic_test_components import SyntheticTestGenerator,\\\n",
    "                                                TestDatasetSaver,\\\n",
    "                                                    DocumentToLangChainConverter\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(\"./.env\")\n",
    "\n",
    "        \n",
    "# Create pipeline components\n",
    "pdf_converter = PyPDFToDocument()\n",
    "doc_cleaner = DocumentCleaner(remove_empty_lines=True,\n",
    "                                remove_extra_whitespaces=True)\n",
    "doc_splitter = DocumentSplitter(split_by=\"sentence\",\n",
    "                                split_length=50,\n",
    "                                split_overlap=5)\n",
    "doc_converter = DocumentToLangChainConverter()\n",
    "kg_generator = KnowledgeGraphGenerator(apply_transforms=True)\n",
    "\n",
    "\n",
    "test_generator = SyntheticTestGenerator(\n",
    "    testset_size=10,  \n",
    "    llm_model=\"gpt-4o-mini\",\n",
    "    query_distribution=[\n",
    "        (\"single_hop\", 0.25), \n",
    "        (\"multi_hop_specific\", 0.25),\n",
    "        (\"multi_hop_abstract\", 0.5)\n",
    "    ],\n",
    "    # Optional: Add max_testset_size=5 if you want to limit due to API constraints\n",
    "    # max_testset_size=5  # Uncomment this line if you experience API timeouts\n",
    ")\n",
    "test_saver = TestDatasetSaver(\"data_for_eval/synthetic_tests_10_from_pdf.csv\")\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_component(\"pdf_converter\", pdf_converter)\n",
    "pipeline.add_component(\"doc_cleaner\", doc_cleaner)\n",
    "pipeline.add_component(\"doc_splitter\", doc_splitter)\n",
    "pipeline.add_component(\"doc_converter\", doc_converter)\n",
    "pipeline.add_component(\"kg_generator\", kg_generator)\n",
    "pipeline.add_component(\"test_generator\", test_generator)\n",
    "pipeline.add_component(\"test_saver\", test_saver)\n",
    "\n",
    "# Connect components in sequence\n",
    "pipeline.connect(\"pdf_converter.documents\", \"doc_cleaner.documents\")\n",
    "pipeline.connect(\"doc_cleaner.documents\", \"doc_splitter.documents\")\n",
    "pipeline.connect(\"doc_splitter.documents\", \"doc_converter.documents\")\n",
    "pipeline.connect(\"doc_converter.langchain_documents\", \"kg_generator.documents\")\n",
    "pipeline.connect(\"kg_generator.knowledge_graph\", \"test_generator.knowledge_graph\")\n",
    "pipeline.connect(\"doc_converter.langchain_documents\", \"test_generator.documents\")\n",
    "pipeline.connect(\"test_generator.testset\", \"test_saver.testset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24b94f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlinesExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:08<00:00,  1.97it/s]\n",
      "Applying HeadlinesExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:08<00:00,  1.97it/s]\n",
      "Applying HeadlineSplitter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:00<00:00, 386.45it/s]\n",
      "Applying SummaryExtractor:   0%|          | 0/17 [00:00<?, ?it/s]\n",
      "Applying SummaryExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.53it/s]\n",
      "Applying SummaryExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.53it/s]\n",
      "Applying CustomNodeFilter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:24<00:00,  2.01it/s]\n",
      "Applying EmbeddingExtractor:   0%|          | 0/17 [00:00<?, ?it/s]\n",
      "Applying EmbeddingExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:04<00:00,  4.00it/s]\n",
      "Applying EmbeddingExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:04<00:00,  4.00it/s]\n",
      "Applying ThemesExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [00:22<00:00,  1.99it/s]\n",
      "Applying ThemesExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [00:22<00:00,  1.99it/s]\n",
      "Applying NERExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [00:21<00:00,  2.12it/s]\n",
      "Applying CosineSimilarityBuilder: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 242.07it/s]\n",
      "Applying OverlapScoreBuilder:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Applying CosineSimilarityBuilder: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 242.07it/s]\n",
      "Applying OverlapScoreBuilder: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 77.62it/s]\n",
      "\n",
      "Generating personas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.28it/s]\n",
      "Generating personas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.28it/s]\n",
      "Generating Scenarios: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:18<00:00,  6.19s/it]\n",
      "Generating Scenarios: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:18<00:00,  6.19s/it]\n",
      "Generating Samples: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:06<00:00,  1.57it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Pipeline Results:\n",
      "  üìÑ Documents Processed: 17\n",
      "  üß† Knowledge Graph Nodes: 17\n",
      "  üß™ Test Cases Generated: 11\n",
      "  üîß Generation Method: knowledge_graph\n"
     ]
    }
   ],
   "source": [
    "# Prepare input data - convert PDF files to ByteStream objects\n",
    "pdf_sources = [Path(\"./data_for_indexing/howpeopleuseai.pdf\")]\n",
    "result = pipeline.run({\n",
    "            \"pdf_converter\": {\"sources\": pdf_sources}\n",
    "        })\n",
    "        \n",
    "print(\"\\nüìä Pipeline Results:\")\n",
    "print(f\"  üìÑ Documents Processed: {result['doc_converter']['document_count']}\")\n",
    "print(f\"  üß† Knowledge Graph Nodes: {result['kg_generator']['node_count']}\")\n",
    "print(f\"  üß™ Test Cases Generated: {result['test_generator']['testset_size']}\")\n",
    "print(f\"  üîß Generation Method: {result['test_generator']['generation_method']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60c699f",
   "metadata": {},
   "source": [
    "### Understanding the Pipeline Architecture\n",
    "\n",
    "The pipeline we're building follows this flow:\n",
    "\n",
    "```\n",
    "PDF File ‚Üí PDF Converter ‚Üí Document Cleaner ‚Üí Document Splitter \n",
    "    ‚Üì\n",
    "Document Converter ‚Üí Knowledge Graph Generator\n",
    "    ‚Üì                         ‚Üì\n",
    "Test Generator ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê\n",
    "    ‚Üì\n",
    "Test Dataset Saver\n",
    "```\n",
    "\n",
    "**Key Design Decisions:**\n",
    "\n",
    "1. **Document Processing Chain**: We clean and split documents before knowledge graph generation to ensure high-quality input\n",
    "2. **Dual Input to Test Generator**: Both the knowledge graph and original documents are provided to enable fallback generation methods\n",
    "3. **Configurable Test Distribution**: We can control the types of questions generated (single-hop vs multi-hop)\n",
    "\n",
    "**Pipeline Parameters Explained:**\n",
    "- `testset_size=10`: Number of question-answer pairs to generate\n",
    "- `split_length=50`: Number of sentences per document chunk\n",
    "- `query_distribution`: Controls complexity of generated questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5689774",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.draw(path=\"./images/knowledgegraph_sdg_pipeline_pdf.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e83c9a",
   "metadata": {},
   "source": [
    "![](./images/knowledgegraph_sdg_pipeline_pdf.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1429d2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Synthetic Tests Sample:\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wut is Harverd Unversity's role in the study o...</td>\n",
       "      <td>['NBER WORKING PAPER SERIES\\nHOW PEOPLE USE CH...</td>\n",
       "      <td>Harvard University is represented by co-author...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What role does Duke University play in the res...</td>\n",
       "      <td>['ABSTRACT Despite the rapid adoption of LLM c...</td>\n",
       "      <td>Duke University is represented in the research...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How has OpenAI's ChatGPT impacted message volu...</td>\n",
       "      <td>['to classify messages without any human seein...</td>\n",
       "      <td>OpenAI's ChatGPT has shown significant growth ...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does Appendix B describe regarding the va...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\n3.2 Classified Messages\\nTo under...</td>\n",
       "      <td>Appendix B describes the validation procedure ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What does the Zao-Sanders (2025) study reveal ...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nTeams, Enterprise, Education), wh...</td>\n",
       "      <td>The Zao-Sanders (2025) study estimates that th...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Wut is Harverd Unversity's role in the study o...   \n",
       "1  What role does Duke University play in the res...   \n",
       "2  How has OpenAI's ChatGPT impacted message volu...   \n",
       "3  What does Appendix B describe regarding the va...   \n",
       "4  What does the Zao-Sanders (2025) study reveal ...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  ['NBER WORKING PAPER SERIES\\nHOW PEOPLE USE CH...   \n",
       "1  ['ABSTRACT Despite the rapid adoption of LLM c...   \n",
       "2  ['to classify messages without any human seein...   \n",
       "3  ['<1-hop>\\n\\n3.2 Classified Messages\\nTo under...   \n",
       "4  ['<1-hop>\\n\\nTeams, Enterprise, Education), wh...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Harvard University is represented by co-author...   \n",
       "1  Duke University is represented in the research...   \n",
       "2  OpenAI's ChatGPT has shown significant growth ...   \n",
       "3  Appendix B describes the validation procedure ...   \n",
       "4  The Zao-Sanders (2025) study estimates that th...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0  single_hop_specific_query_synthesizer  \n",
       "1  single_hop_specific_query_synthesizer  \n",
       "2  single_hop_specific_query_synthesizer  \n",
       "3   multi_hop_specific_query_synthesizer  \n",
       "4   multi_hop_specific_query_synthesizer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the IWA ID and explanation for a user ...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nTask details Your response should...</td>\n",
       "      <td>The IWA ID for a user asking to create a sprea...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How has the usage of ChatGPT evolved among dif...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nNBER WORKING PAPER SERIES\\nHOW PE...</td>\n",
       "      <td>The usage of ChatGPT has evolved significantly...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does the usage of ChatGPT differ between w...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nNBER WORKING PAPER SERIES\\nHOW PE...</td>\n",
       "      <td>The usage of ChatGPT shows a significant diffe...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What are classifier prompts used for in the co...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nOuyang, Long, Jeff Wu, Xu Jiang, ...</td>\n",
       "      <td>Classifier prompts are used to classify messag...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How has the usage of ChatGPT evolved since its...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nNBER WORKING PAPER SERIES\\nHOW PE...</td>\n",
       "      <td>Since its launch in November 2022, the usage o...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "6   What is the IWA ID and explanation for a user ...   \n",
       "7   How has the usage of ChatGPT evolved among dif...   \n",
       "8   How does the usage of ChatGPT differ between w...   \n",
       "9   What are classifier prompts used for in the co...   \n",
       "10  How has the usage of ChatGPT evolved since its...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "6   ['<1-hop>\\n\\nTask details Your response should...   \n",
       "7   ['<1-hop>\\n\\nNBER WORKING PAPER SERIES\\nHOW PE...   \n",
       "8   ['<1-hop>\\n\\nNBER WORKING PAPER SERIES\\nHOW PE...   \n",
       "9   ['<1-hop>\\n\\nOuyang, Long, Jeff Wu, Xu Jiang, ...   \n",
       "10  ['<1-hop>\\n\\nNBER WORKING PAPER SERIES\\nHOW PE...   \n",
       "\n",
       "                                            reference  \\\n",
       "6   The IWA ID for a user asking to create a sprea...   \n",
       "7   The usage of ChatGPT has evolved significantly...   \n",
       "8   The usage of ChatGPT shows a significant diffe...   \n",
       "9   Classifier prompts are used to classify messag...   \n",
       "10  Since its launch in November 2022, the usage o...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_abstract_query_synthesizer  \n",
       "9   multi_hop_abstract_query_synthesizer  \n",
       "10  multi_hop_abstract_query_synthesizer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and display the generated synthetic tests\n",
    "test_file_path = \"data_for_eval/synthetic_tests_10_from_pdf.csv\"\n",
    "\n",
    "if os.path.exists(test_file_path):\n",
    "    synthetic_tests_df = pd.read_csv(test_file_path)\n",
    "    print(\"\\nüß™ Synthetic Tests Sample:\")\n",
    "    print(\"First 5 rows:\")\n",
    "    display(synthetic_tests_df.head())\n",
    "    print(\"Last 5 rows:\")\n",
    "    display(synthetic_tests_df.tail())\n",
    "else:\n",
    "    print(\"‚ùå Synthetic test file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced14565",
   "metadata": {},
   "source": [
    "### Analyzing the Generated Test Dataset\n",
    "\n",
    "Now let's examine the synthetic test data that was generated from our PDF processing pipeline.\n",
    "\n",
    "**What to Look For:**\n",
    "- **Question Quality**: Are the questions grammatically correct and meaningful?\n",
    "- **Answer Accuracy**: Do the answers correctly reflect the source material?\n",
    "- **Question Types**: Notice the variety of single-hop and multi-hop questions\n",
    "- **Context Relevance**: Check if the reference contexts support the answers\n",
    "\n",
    "**Common Question Types You'll See:**\n",
    "1. **Single-hop questions**: Direct factual queries (e.g., \"What is X?\")\n",
    "2. **Multi-hop specific**: Questions requiring connecting specific facts\n",
    "3. **Multi-hop abstract**: Questions requiring broader reasoning across multiple concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ebd922",
   "metadata": {},
   "source": [
    "## Part 2: Web Content Processing Pipeline\n",
    "\n",
    "### Overview\n",
    "In this section, we'll adapt our pipeline to work with web content instead of PDF files. This demonstrates the flexibility of Haystack pipelines and how the same knowledge graph generation approach can work across different content sources.\n",
    "\n",
    "### Key Differences from PDF Processing\n",
    "1. **LinkContentFetcher**: Retrieves content directly from URLs\n",
    "2. **HTMLToDocument**: Converts HTML content to Haystack Documents\n",
    "3. **Same Processing Chain**: The rest of the pipeline remains identical\n",
    "\n",
    "### Real-World Applications\n",
    "This approach is particularly useful for:\n",
    "- **Documentation Analysis**: Processing online documentation and creating test datasets\n",
    "- **Content Monitoring**: Regularly generating tests from updated web content  \n",
    "- **Multi-Source Knowledge**: Combining web content with other document types\n",
    "- **Research Applications**: Creating datasets from academic papers, blog posts, etc.\n",
    "\n",
    "### Technical Considerations\n",
    "- **Rate Limiting**: Be mindful of website rate limits when fetching content\n",
    "- **Content Quality**: Web content may require more aggressive cleaning\n",
    "- **Dynamic Content**: Some websites use JavaScript; static HTML fetching may miss content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f162b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x15f4f11c0>\n",
       "üöÖ Components\n",
       "  - fetcher: LinkContentFetcher\n",
       "  - converter: HTMLToDocument\n",
       "  - doc_cleaner: DocumentCleaner\n",
       "  - doc_splitter: DocumentSplitter\n",
       "  - doc_converter: DocumentToLangChainConverter\n",
       "  - kg_generator: KnowledgeGraphGenerator\n",
       "  - test_generator: SyntheticTestGenerator\n",
       "  - test_saver: TestDatasetSaver\n",
       "üõ§Ô∏è Connections\n",
       "  - fetcher.streams -> converter.sources (list[ByteStream])\n",
       "  - converter.documents -> doc_cleaner.documents (list[Document])\n",
       "  - doc_cleaner.documents -> doc_splitter.documents (list[Document])\n",
       "  - doc_splitter.documents -> doc_converter.documents (list[Document])\n",
       "  - doc_converter.langchain_documents -> kg_generator.documents (List[Document])\n",
       "  - doc_converter.langchain_documents -> test_generator.documents (List[Document])\n",
       "  - kg_generator.knowledge_graph -> test_generator.knowledge_graph (KnowledgeGraph)\n",
       "  - test_generator.testset -> test_saver.testset (DataFrame)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack.components.fetchers import LinkContentFetcher\n",
    "from haystack.components.converters import HTMLToDocument\n",
    "\n",
    "fetcher = LinkContentFetcher()\n",
    "converter = HTMLToDocument()\n",
    "doc_cleaner = DocumentCleaner(remove_empty_lines=True,\n",
    "                                      remove_extra_whitespaces=True)\n",
    "doc_splitter = DocumentSplitter(split_by=\"sentence\",\n",
    "                                split_length=50,\n",
    "                                split_overlap=5)\n",
    "doc_converter = DocumentToLangChainConverter()\n",
    "kg_generator = KnowledgeGraphGenerator(apply_transforms=True)\n",
    "test_generator = SyntheticTestGenerator(\n",
    "            testset_size=10,  \n",
    "            llm_model=\"gpt-4o-mini\",\n",
    "            query_distribution=[\n",
    "                (\"single_hop\", 0.25), \n",
    "                (\"multi_hop_specific\", 0.25),\n",
    "                (\"multi_hop_abstract\", 0.5)\n",
    "            ]\n",
    "        )\n",
    "test_saver = TestDatasetSaver(\"data_for_eval/synthetic_tests_10_from_html_page.csv\")\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_component(\"fetcher\", fetcher)\n",
    "pipeline.add_component(\"converter\", converter)\n",
    "pipeline.add_component(\"doc_cleaner\", doc_cleaner)\n",
    "pipeline.add_component(\"doc_splitter\", doc_splitter)\n",
    "pipeline.add_component(\"doc_converter\", doc_converter)\n",
    "pipeline.add_component(\"kg_generator\", kg_generator)\n",
    "pipeline.add_component(\"test_generator\", test_generator)\n",
    "pipeline.add_component(\"test_saver\", test_saver)\n",
    "\n",
    "# Connect components in sequence\n",
    "pipeline.connect(\"fetcher.streams\", \"converter.sources\")\n",
    "pipeline.connect(\"converter.documents\", \"doc_cleaner.documents\")\n",
    "pipeline.connect(\"doc_cleaner.documents\", \"doc_splitter.documents\")\n",
    "pipeline.connect(\"doc_splitter.documents\", \"doc_converter.documents\")\n",
    "pipeline.connect(\"doc_converter.langchain_documents\", \"kg_generator.documents\")\n",
    "pipeline.connect(\"kg_generator.knowledge_graph\", \"test_generator.knowledge_graph\")\n",
    "pipeline.connect(\"doc_converter.langchain_documents\", \"test_generator.documents\")\n",
    "pipeline.connect(\"test_generator.testset\", \"test_saver.testset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90dfe9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlinesExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.19s/it]\n",
      "Applying HeadlineSplitter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 481.91it/s]\n",
      "Applying HeadlinesExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.19s/it]\n",
      "Applying HeadlineSplitter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 481.91it/s]\n",
      "Applying SummaryExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.14s/it]\n",
      "Applying SummaryExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.14s/it]\n",
      "Applying CustomNodeFilter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.77it/s]\n",
      "Applying CustomNodeFilter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.77it/s]\n",
      "Applying EmbeddingExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  3.10it/s]\n",
      "Applying EmbeddingExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  3.10it/s]\n",
      "Applying ThemesExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:05<00:00,  1.18it/s]\n",
      "Applying ThemesExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:05<00:00,  1.18it/s]\n",
      "Applying NERExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.45it/s]\n",
      "Applying CosineSimilarityBuilder: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 932.90it/s]\n",
      "Applying NERExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.45it/s]1.57it/s]\n",
      "Applying CosineSimilarityBuilder: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 932.90it/s]\n",
      "Applying OverlapScoreBuilder: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 1831.57it/s]\n",
      "\n",
      "Generating personas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.06it/s]\n",
      "Generating personas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.06it/s]\n",
      "Generating Scenarios: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:06<00:00,  2.04s/it]\n",
      "Generating Scenarios: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:06<00:00,  2.04s/it]\n",
      "Generating Samples: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:07<00:00,  1.53it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Pipeline Results:\n",
      "  üìÑ Documents Processed: 2\n",
      "  üß† Knowledge Graph Nodes: 2\n",
      "  üß™ Test Cases Generated: 11\n",
      "  üîß Generation Method: knowledge_graph\n"
     ]
    }
   ],
   "source": [
    "web_url = \"https://haystack.deepset.ai/blog/haystack-2-release\"\n",
    "\n",
    "result = pipeline.run({\n",
    "    \"fetcher\": {\"urls\": [web_url]}\n",
    "})\n",
    "\n",
    "print(\"\\nüìä Pipeline Results:\")\n",
    "print(f\"  üìÑ Documents Processed: {result['doc_converter']['document_count']}\")\n",
    "print(f\"  üß† Knowledge Graph Nodes: {result['kg_generator']['node_count']}\")\n",
    "print(f\"  üß™ Test Cases Generated: {result['test_generator']['testset_size']}\")\n",
    "print(f\"  üîß Generation Method: {result['test_generator']['generation_method']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa853c0",
   "metadata": {},
   "source": [
    "### Web Pipeline Architecture\n",
    "\n",
    "The web processing pipeline follows a similar structure but with adapted input components:\n",
    "\n",
    "```\n",
    "Web URL ‚Üí Link Fetcher ‚Üí HTML Converter ‚Üí Document Cleaner ‚Üí Document Splitter\n",
    "    ‚Üì\n",
    "Document Converter ‚Üí Knowledge Graph Generator  \n",
    "    ‚Üì                         ‚Üì\n",
    "Test Generator ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê\n",
    "    ‚Üì\n",
    "Test Dataset Saver\n",
    "```\n",
    "\n",
    "**Why This Works:**\n",
    "- The knowledge graph generation is **content-agnostic** - it works the same whether input comes from PDFs, web pages, or other sources\n",
    "- Document preprocessing steps ensure consistent quality regardless of input format\n",
    "- The same test generation logic produces comparable quality across all sources\n",
    "\n",
    "**Pipeline Reusability:**\n",
    "Notice how we can reuse the same components (`doc_cleaner`, `doc_splitter`, `kg_generator`, etc.) with different input sources. This demonstrates the modularity and flexibility of Haystack's component architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaea2c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.draw(path=\"./images/knowledgegraph_sdg_pipeline_html.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e528d45",
   "metadata": {},
   "source": [
    "![](./images/knowledgegraph_sdg_pipeline_html.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "508384b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Synthetic Tests Sample:\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does Python relate to Haystack 2.0?</td>\n",
       "      <td>['Haystack 2.0: The Composable Open-Source LLM...</td>\n",
       "      <td>Haystack 2.0 is an open-source Python framewor...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does Haystack 2.0 enhance AI application d...</td>\n",
       "      <td>['Composable and customizable Pipelines\\nModer...</td>\n",
       "      <td>Haystack 2.0 enhances AI application developme...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What Jina AI do for Haystack?</td>\n",
       "      <td>['A common interface for storing data - A clea...</td>\n",
       "      <td>Jina AI is one of the contributors to the Hays...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does Haystack 2.0 enhance the functionalit...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nComposable and customizable Pipel...</td>\n",
       "      <td>Haystack 2.0 enhances the functionality of AI ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does Haystack 2.0 enhance the development ...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nComposable and customizable Pipel...</td>\n",
       "      <td>Haystack 2.0 enhances the development of AI ap...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0            How does Python relate to Haystack 2.0?   \n",
       "1  How does Haystack 2.0 enhance AI application d...   \n",
       "2                      What Jina AI do for Haystack?   \n",
       "3  How does Haystack 2.0 enhance the functionalit...   \n",
       "4  How does Haystack 2.0 enhance the development ...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  ['Haystack 2.0: The Composable Open-Source LLM...   \n",
       "1  ['Composable and customizable Pipelines\\nModer...   \n",
       "2  ['A common interface for storing data - A clea...   \n",
       "3  ['<1-hop>\\n\\nComposable and customizable Pipel...   \n",
       "4  ['<1-hop>\\n\\nComposable and customizable Pipel...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Haystack 2.0 is an open-source Python framewor...   \n",
       "1  Haystack 2.0 enhances AI application developme...   \n",
       "2  Jina AI is one of the contributors to the Hays...   \n",
       "3  Haystack 2.0 enhances the functionality of AI ...   \n",
       "4  Haystack 2.0 enhances the development of AI ap...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0  single_hop_specific_query_synthesizer  \n",
       "1  single_hop_specific_query_synthesizer  \n",
       "2  single_hop_specific_query_synthesizer  \n",
       "3   multi_hop_specific_query_synthesizer  \n",
       "4   multi_hop_specific_query_synthesizer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What are the main features of Haystack 2.0 tha...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nHaystack 2.0: The Composable Open...</td>\n",
       "      <td>Haystack 2.0 introduces several main features ...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How can I use customizable pipelines in Haysta...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nHaystack 2.0: The Composable Open...</td>\n",
       "      <td>To use customizable pipelines in Haystack 2.0 ...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does Haystack 2.0 optimize and evaluate pr...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nHaystack 2.0: The Composable Open...</td>\n",
       "      <td>Haystack 2.0 optimizes and evaluates productio...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What are the key features of Haystack 2.0 that...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nHaystack 2.0: The Composable Open...</td>\n",
       "      <td>Haystack 2.0 introduces several key features t...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>In what ways does Haystack 2.0 enhance product...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nHaystack 2.0: The Composable Open...</td>\n",
       "      <td>Haystack 2.0 enhances production optimization ...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "6   What are the main features of Haystack 2.0 tha...   \n",
       "7   How can I use customizable pipelines in Haysta...   \n",
       "8   How does Haystack 2.0 optimize and evaluate pr...   \n",
       "9   What are the key features of Haystack 2.0 that...   \n",
       "10  In what ways does Haystack 2.0 enhance product...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "6   ['<1-hop>\\n\\nHaystack 2.0: The Composable Open...   \n",
       "7   ['<1-hop>\\n\\nHaystack 2.0: The Composable Open...   \n",
       "8   ['<1-hop>\\n\\nHaystack 2.0: The Composable Open...   \n",
       "9   ['<1-hop>\\n\\nHaystack 2.0: The Composable Open...   \n",
       "10  ['<1-hop>\\n\\nHaystack 2.0: The Composable Open...   \n",
       "\n",
       "                                            reference  \\\n",
       "6   Haystack 2.0 introduces several main features ...   \n",
       "7   To use customizable pipelines in Haystack 2.0 ...   \n",
       "8   Haystack 2.0 optimizes and evaluates productio...   \n",
       "9   Haystack 2.0 introduces several key features t...   \n",
       "10  Haystack 2.0 enhances production optimization ...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_abstract_query_synthesizer  \n",
       "9   multi_hop_abstract_query_synthesizer  \n",
       "10  multi_hop_abstract_query_synthesizer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and display the generated synthetic tests\n",
    "test_file_path = \"data_for_eval/synthetic_tests_10_from_html_page.csv\"\n",
    "\n",
    "if os.path.exists(test_file_path):\n",
    "    synthetic_tests_df = pd.read_csv(test_file_path)\n",
    "    print(\"\\nüß™ Synthetic Tests Sample:\")\n",
    "    print(\"First 5 rows:\")\n",
    "    display(synthetic_tests_df.head())\n",
    "    print(\"Last 5 rows:\")\n",
    "    display(synthetic_tests_df.tail())\n",
    "else:\n",
    "    print(\"‚ùå Synthetic test file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c5727",
   "metadata": {},
   "source": [
    "### Comparing Results Across Sources\n",
    "\n",
    "Let's examine how the synthetic test generation performs when using web content versus PDF content.\n",
    "\n",
    "**Expected Differences:**\n",
    "- **Content Structure**: Web content may have different formatting and structure\n",
    "- **Question Complexity**: Depending on the source material's complexity\n",
    "- **Context Quality**: Web content might include navigation elements or ads that need filtering\n",
    "\n",
    "**Quality Assessment Checklist:**\n",
    "- [ ] Questions are grammatically correct\n",
    "- [ ] Answers are factually accurate based on the source\n",
    "- [ ] Context excerpts support the provided answers\n",
    "- [ ] Questions test different levels of comprehension\n",
    "- [ ] No duplicate or overly similar questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4ab33",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "In this notebook, we explored:\n",
    "\n",
    "1. **Knowledge Graph-Driven Test Generation**: How structured knowledge representations improve synthetic data quality\n",
    "2. **Multi-Source Processing**: Adapting the same pipeline architecture for different input types (PDFs, web content)\n",
    "3. **Pipeline Modularity**: Reusing components across different use cases while maintaining consistency\n",
    "4. **Quality Assessment**: Evaluating synthetic test datasets for accuracy and usefulness\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Knowledge graphs act as a quality filter** for test generation, producing more coherent and factually grounded questions\n",
    "- **Haystack's component architecture** enables easy adaptation between different content sources\n",
    "- **Preprocessing matters** - cleaning and splitting documents appropriately affects downstream quality\n",
    "- **Synthetic test generation** can scale evaluation efforts but requires careful quality validation\n",
    "\n",
    "### Production Considerations\n",
    "\n",
    "When moving to production, consider:\n",
    "\n",
    "1. **Quality Control**: Implement automated quality checks (see the quality control components in other notebooks)\n",
    "2. **Scalability**: Use batch processing for large document collections\n",
    "3. **Monitoring**: Track generation success rates and quality metrics over time\n",
    "4. **Cost Management**: Balance test quantity with API usage costs\n",
    "5. **Validation**: Always human-review a sample of generated tests before deployment\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-with-haystack-ch5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
