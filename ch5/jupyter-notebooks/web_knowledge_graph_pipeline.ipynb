{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7fd32a5",
   "metadata": {},
   "source": [
    "üîß **Setup Required**: Before running this notebook, please follow the [setup instructions](../README.md#setup-instructions) to configure your environment and API keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f335dcf",
   "metadata": {},
   "source": [
    "# Web Content Knowledge Graph and Synthetic Data Generation Pipeline\n",
    "\n",
    "This notebook demonstrates how to build a comprehensive pipeline for web content processing that:\n",
    "1. **Retrieves content** from web URLs using Haystack's LinkContentFetcher\n",
    "2. **Converts HTML** to structured documents using HTMLToDocument\n",
    "3. **Preprocesses the text** with cleaning and splitting components\n",
    "4. **Creates a knowledge graph** from the processed web content\n",
    "5. **Generates synthetic test data** using the knowledge graph\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will understand:\n",
    "- How to build end-to-end Haystack pipelines for web content processing\n",
    "- The differences between PDF and web content processing\n",
    "- Best practices for web scraping and content extraction\n",
    "- How web content characteristics affect synthetic test generation\n",
    "\n",
    "## Key Components for Web Processing\n",
    "- **LinkContentFetcher**: Retrieves content directly from URLs\n",
    "- **HTMLToDocument**: Converts HTML content to Haystack Documents\n",
    "- **DocumentCleaner**: Removes extra whitespaces and HTML artifacts\n",
    "- **DocumentSplitter**: Breaks web content into manageable chunks\n",
    "- **KnowledgeGraphGenerator**: Creates structured knowledge representations\n",
    "- **SyntheticTestGenerator**: Produces question-answer pairs for evaluation\n",
    "\n",
    "## Real-World Applications\n",
    "This approach is particularly useful for:\n",
    "- **Documentation Analysis**: Processing online documentation and creating test datasets\n",
    "- **Content Monitoring**: Regularly generating tests from updated web content  \n",
    "- **Multi-Source Knowledge**: Combining web content with other document types\n",
    "- **Research Applications**: Creating datasets from academic papers, blog posts, etc.\n",
    "\n",
    "## Technical Considerations\n",
    "- **Rate Limiting**: Be mindful of website rate limits when fetching content\n",
    "- **Content Quality**: Web content may require more aggressive cleaning\n",
    "- **Dynamic Content**: Some websites use JavaScript; static HTML fetching may miss content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04c41c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurafunderburk/Documents/GitHub/Building-Natural-Language-Pipelines/ch5/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Web Content Processing Pipeline created successfully!\n",
      "üåê Ready to process web content and generate knowledge graphs + synthetic tests\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from haystack import Pipeline\n",
    "from haystack.components.fetchers import LinkContentFetcher\n",
    "from haystack.components.converters import HTMLToDocument\n",
    "from haystack.components.preprocessors import (\n",
    "    DocumentCleaner,\n",
    "    DocumentSplitter)\n",
    "from pathlib import Path\n",
    "from scripts.knowledge_graph_component import KnowledgeGraphGenerator,\\\n",
    "                                                DocumentToLangChainConverter\n",
    "from scripts.synthetic_test_components import SyntheticTestGenerator,\\\n",
    "                                                TestDatasetSaver\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(\"./.env\")\n",
    "\n",
    "# Create web content processing components\n",
    "fetcher = LinkContentFetcher()\n",
    "converter = HTMLToDocument()\n",
    "doc_cleaner = DocumentCleaner(\n",
    "    remove_empty_lines=True,\n",
    "    remove_extra_whitespaces=True,\n",
    "    remove_substrings=['<1-hop>\\n\\n', '<multi-hop>\\n\\n', '<single-hop>\\n\\n', '\\n\\n\\n', '\\f', '\\r']  # Remove synthetic data generation artifacts and weird characters\n",
    ")\n",
    "doc_splitter = DocumentSplitter(split_by=\"sentence\",\n",
    "                                split_length=50,\n",
    "                                split_overlap=5)\n",
    "doc_converter = DocumentToLangChainConverter()\n",
    "kg_generator = KnowledgeGraphGenerator(apply_transforms=True)\n",
    "test_generator = SyntheticTestGenerator(\n",
    "            testset_size=10,  \n",
    "            llm_model=\"gpt-4o-mini\",\n",
    "            query_distribution=[\n",
    "                (\"single_hop\", 0.25), \n",
    "                (\"multi_hop_specific\", 0.25),\n",
    "                (\"multi_hop_abstract\", 0.5)\n",
    "            ]\n",
    "        )\n",
    "test_saver = TestDatasetSaver(\"data_for_eval/synthetic_tests_10_from_web.csv\")\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_component(\"fetcher\", fetcher)\n",
    "pipeline.add_component(\"converter\", converter)\n",
    "pipeline.add_component(\"doc_cleaner\", doc_cleaner)\n",
    "pipeline.add_component(\"doc_splitter\", doc_splitter)\n",
    "pipeline.add_component(\"doc_converter\", doc_converter)\n",
    "pipeline.add_component(\"kg_generator\", kg_generator)\n",
    "pipeline.add_component(\"test_generator\", test_generator)\n",
    "pipeline.add_component(\"test_saver\", test_saver)\n",
    "\n",
    "# Connect components in sequence\n",
    "pipeline.connect(\"fetcher.streams\", \"converter.sources\")\n",
    "pipeline.connect(\"converter.documents\", \"doc_cleaner.documents\")\n",
    "pipeline.connect(\"doc_cleaner.documents\", \"doc_splitter.documents\")\n",
    "pipeline.connect(\"doc_splitter.documents\", \"doc_converter.documents\")\n",
    "pipeline.connect(\"doc_converter.langchain_documents\", \"kg_generator.documents\")\n",
    "pipeline.connect(\"kg_generator.knowledge_graph\", \"test_generator.knowledge_graph\")\n",
    "pipeline.connect(\"doc_converter.langchain_documents\", \"test_generator.documents\")\n",
    "pipeline.connect(\"test_generator.testset\", \"test_saver.testset\")\n",
    "\n",
    "print(\"‚úÖ Web Content Processing Pipeline created successfully!\")\n",
    "print(\"üåê Ready to process web content and generate knowledge graphs + synthetic tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af764802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê Processing web content from: https://haystack.deepset.ai/blog/haystack-2-release\n",
      "This may take a moment to fetch and process the content...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlinesExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.41s/it]\n",
      "Applying HeadlinesExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.41s/it]\n",
      "Applying HeadlineSplitter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 259.53it/s]\n",
      "Applying SummaryExtractor:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Applying SummaryExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  2.95s/it]\n",
      "Applying SummaryExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  2.95s/it]\n",
      "Applying CustomNodeFilter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:05<00:00,  1.15it/s]\n",
      "Applying CustomNodeFilter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:05<00:00,  1.15it/s]\n",
      "Applying EmbeddingExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.82it/s]\n",
      "Applying EmbeddingExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.82it/s]\n",
      "Applying ThemesExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:07<00:00,  1.21s/it]\n",
      "Applying ThemesExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:07<00:00,  1.21s/it]\n",
      "Applying NERExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:05<00:00,  1.01it/s]\n",
      "Applying CosineSimilarityBuilder: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 1845.27it/s]\n",
      "Applying NERExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:05<00:00,  1.01it/s]6.75it/s]\n",
      "Applying CosineSimilarityBuilder: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 1845.27it/s]\n",
      "Applying OverlapScoreBuilder: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 2396.75it/s]\n",
      "\n",
      "Generating personas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.11s/it]\n",
      "Generating personas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.11s/it]\n",
      "Generating Scenarios: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:08<00:00,  2.77s/it]\n",
      "Generating Scenarios: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:08<00:00,  2.77s/it]\n",
      "Generating Samples: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:07<00:00,  1.51it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Pipeline Results:\n",
      "  üìÑ Documents Processed: 2\n",
      "  üß† Knowledge Graph Nodes: 2\n",
      "  üß™ Test Cases Generated: 11\n",
      "  üîß Generation Method: knowledge_graph\n"
     ]
    }
   ],
   "source": [
    "web_url = \"https://haystack.deepset.ai/blog/haystack-2-release\"\n",
    "\n",
    "print(f\"üåê Processing web content from: {web_url}\")\n",
    "print(\"This may take a moment to fetch and process the content...\")\n",
    "\n",
    "try:\n",
    "    result = pipeline.run({\n",
    "        \"fetcher\": {\"urls\": [web_url]}\n",
    "    })\n",
    "\n",
    "    print(\"\\nüìä Pipeline Results:\")\n",
    "    print(f\"  üìÑ Documents Processed: {result['doc_converter']['document_count']}\")\n",
    "    print(f\"  üß† Knowledge Graph Nodes: {result['kg_generator']['node_count']}\")\n",
    "    print(f\"  üß™ Test Cases Generated: {result['test_generator']['testset_size']}\")\n",
    "    print(f\"  üîß Generation Method: {result['test_generator']['generation_method']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error processing web content: {str(e)}\")\n",
    "    print(\"This might be due to network issues or website access restrictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed64d39",
   "metadata": {},
   "source": [
    "### Understanding the Web Content Processing Pipeline Architecture\n",
    "\n",
    "The web processing pipeline follows a similar structure to PDF processing but with adapted input components:\n",
    "\n",
    "```\n",
    "Web URL ‚Üí Link Fetcher ‚Üí HTML Converter ‚Üí Document Cleaner ‚Üí Document Splitter\n",
    "    ‚Üì\n",
    "Document Converter ‚Üí Knowledge Graph Generator  \n",
    "    ‚Üì                         ‚Üì\n",
    "Test Generator ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê\n",
    "    ‚Üì\n",
    "Test Dataset Saver\n",
    "```\n",
    "\n",
    "**Why This Works:**\n",
    "- The knowledge graph generation is **content-agnostic** - it works the same whether input comes from PDFs, web pages, or other sources\n",
    "- Document preprocessing steps ensure consistent quality regardless of input format\n",
    "- The same test generation logic produces comparable quality across all sources\n",
    "\n",
    "**Pipeline Reusability:**\n",
    "Notice how we can reuse the same components (`doc_cleaner`, `doc_splitter`, `kg_generator`, etc.) with different input sources. This demonstrates the modularity and flexibility of Haystack's component architecture.\n",
    "\n",
    "**Web-Specific Considerations:**\n",
    "- **Content Structure**: Web pages may have navigation, ads, and other non-content elements\n",
    "- **HTML Artifacts**: May require more aggressive cleaning than PDF content\n",
    "- **Dynamic Loading**: Static HTML fetching may miss JavaScript-rendered content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87b75dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∏ Pipeline diagram saved to: ./images/web_knowledge_graph_pipeline.png\n"
     ]
    }
   ],
   "source": [
    "pipeline.draw(path=\"./images/web_knowledge_graph_pipeline.png\")\n",
    "print(\"üì∏ Pipeline diagram saved to: ./images/web_knowledge_graph_pipeline.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa2db0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Synthetic Tests Sample:\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the key features and improvements int...</td>\n",
       "      <td>['Haystack 2.0: The Composable Open-Source LLM...</td>\n",
       "      <td>Haystack 2.0 introduces several key features a...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wut is AI in Haystack 2.0?</td>\n",
       "      <td>['Composable and customizable Pipelines\\nModer...</td>\n",
       "      <td>AI in Haystack 2.0 refers to the customizable ...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What role do LLMs play in modern AI applications?</td>\n",
       "      <td>['A common interface for storing data - A clea...</td>\n",
       "      <td>In modern AI applications, LLMs are used to an...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the key improvements in Haystack 2.0 ...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nA common interface for storing da...</td>\n",
       "      <td>Haystack 2.0 introduces significant improvemen...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the benefits of using Chroma in Hayst...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nThese include Chroma, Weaviate, P...</td>\n",
       "      <td>Chroma is one of the many storage services int...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What are the key features and improvements int...   \n",
       "1                         Wut is AI in Haystack 2.0?   \n",
       "2  What role do LLMs play in modern AI applications?   \n",
       "3  What are the key improvements in Haystack 2.0 ...   \n",
       "4  What are the benefits of using Chroma in Hayst...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  ['Haystack 2.0: The Composable Open-Source LLM...   \n",
       "1  ['Composable and customizable Pipelines\\nModer...   \n",
       "2  ['A common interface for storing data - A clea...   \n",
       "3  ['<1-hop>\\n\\nA common interface for storing da...   \n",
       "4  ['<1-hop>\\n\\nThese include Chroma, Weaviate, P...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Haystack 2.0 introduces several key features a...   \n",
       "1  AI in Haystack 2.0 refers to the customizable ...   \n",
       "2  In modern AI applications, LLMs are used to an...   \n",
       "3  Haystack 2.0 introduces significant improvemen...   \n",
       "4  Chroma is one of the many storage services int...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0  single_hop_specific_query_synthesizer  \n",
       "1  single_hop_specific_query_synthesizer  \n",
       "2  single_hop_specific_query_synthesizer  \n",
       "3   multi_hop_specific_query_synthesizer  \n",
       "4   multi_hop_specific_query_synthesizer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How Haystack 2.0 make user-friendly installati...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nHaystack 2.0: The Composable Open...</td>\n",
       "      <td>Haystack 2.0 makes user-friendly installation ...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How does Haystack 2.0 facilitate the developme...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nHaystack 2.0: The Composable Open...</td>\n",
       "      <td>Haystack 2.0 facilitates the development of pr...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What features in Haystack 2.0 contribute to it...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nHaystack 2.0: The Composable Open...</td>\n",
       "      <td>Haystack 2.0 offers a user-friendly installati...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How does Haystack 2.0, as an open-source frame...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nHaystack 2.0: The Composable Open...</td>\n",
       "      <td>Haystack 2.0 is an open-source Python framewor...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How can I create customizable pipelines in Hay...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nHaystack 2.0: The Composable Open...</td>\n",
       "      <td>To create customizable pipelines in Haystack 2...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "6   How Haystack 2.0 make user-friendly installati...   \n",
       "7   How does Haystack 2.0 facilitate the developme...   \n",
       "8   What features in Haystack 2.0 contribute to it...   \n",
       "9   How does Haystack 2.0, as an open-source frame...   \n",
       "10  How can I create customizable pipelines in Hay...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "6   ['<1-hop>\\n\\nHaystack 2.0: The Composable Open...   \n",
       "7   ['<1-hop>\\n\\nHaystack 2.0: The Composable Open...   \n",
       "8   ['<1-hop>\\n\\nHaystack 2.0: The Composable Open...   \n",
       "9   ['<1-hop>\\n\\nHaystack 2.0: The Composable Open...   \n",
       "10  ['<1-hop>\\n\\nHaystack 2.0: The Composable Open...   \n",
       "\n",
       "                                            reference  \\\n",
       "6   Haystack 2.0 makes user-friendly installation ...   \n",
       "7   Haystack 2.0 facilitates the development of pr...   \n",
       "8   Haystack 2.0 offers a user-friendly installati...   \n",
       "9   Haystack 2.0 is an open-source Python framewor...   \n",
       "10  To create customizable pipelines in Haystack 2...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_abstract_query_synthesizer  \n",
       "9   multi_hop_abstract_query_synthesizer  \n",
       "10  multi_hop_abstract_query_synthesizer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and display the generated synthetic tests\n",
    "test_file_path = \"data_for_eval/synthetic_tests_10_from_web.csv\"\n",
    "\n",
    "if os.path.exists(test_file_path):\n",
    "    synthetic_tests_df = pd.read_csv(test_file_path)\n",
    "    print(\"\\nüß™ Synthetic Tests Sample:\")\n",
    "    print(\"First 5 rows:\")\n",
    "    display(synthetic_tests_df.head())\n",
    "    print(\"Last 5 rows:\")\n",
    "    display(synthetic_tests_df.tail())\n",
    "else:\n",
    "    print(\"‚ùå Synthetic test file not found\")\n",
    "    print(\"Please run the previous cells to generate the test data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5e81d0",
   "metadata": {},
   "source": [
    "### Analyzing Web Content vs PDF Results\n",
    "\n",
    "Let's examine how the synthetic test generation performs when using web content versus PDF content.\n",
    "\n",
    "**Expected Differences:**\n",
    "- **Content Structure**: Web content may have different formatting and structure\n",
    "- **Question Complexity**: Depending on the source material's complexity\n",
    "- **Context Quality**: Web content might include navigation elements or ads that need filtering\n",
    "\n",
    "**Web Content Specific Benefits:**\n",
    "1. **Real-time Content**: Access to the most current information available online\n",
    "2. **Rich Media Context**: Web pages often have supplementary context that enhances understanding\n",
    "3. **Diverse Sources**: Easy to process content from multiple websites\n",
    "4. **Hyperlinked Knowledge**: Web content often contains references that enrich the knowledge graph\n",
    "\n",
    "**Potential Challenges:**\n",
    "1. **Content Quality Variability**: Web content quality can vary significantly\n",
    "2. **Noise Filtering**: Need to filter out navigation, ads, and irrelevant content\n",
    "3. **Rate Limiting**: Must respect website rate limits and robots.txt\n",
    "4. **Dynamic Content**: Some content may require JavaScript rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e345a4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "In this notebook, we successfully:\n",
    "\n",
    "1. **Built a Web Content Processing Pipeline**: Created an end-to-end pipeline specifically optimized for web content\n",
    "2. **Demonstrated Source Flexibility**: Processed content from multiple different websites\n",
    "3. **Generated Knowledge Graphs from Web Content**: Converted unstructured web content into structured knowledge representations\n",
    "4. **Produced Comparative Synthetic Test Data**: Created question-answer pairs from different web sources\n",
    "5. **Analyzed Web-Specific Characteristics**: Examined how web content affects synthetic test generation\n",
    "\n",
    "### Key Advantages of Web Content Processing\n",
    "\n",
    "- **Real-Time Content**: Access to the most current information available\n",
    "- **Diverse Sources**: Easy to process content from multiple websites in sequence\n",
    "- **Rich Context**: Web content often includes hyperlinks and references that enhance knowledge graphs\n",
    "- **Scalable Collection**: Can systematically process large numbers of web resources\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f74d2ae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-with-haystack-ch5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
