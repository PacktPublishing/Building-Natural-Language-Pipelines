{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7fd32a5",
   "metadata": {},
   "source": [
    "üîß **Setup Required**: Before running this notebook, please follow the [setup instructions](../README.md#setup-instructions) to configure your environment and API keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f335dcf",
   "metadata": {},
   "source": [
    "# Web Content Knowledge Graph and Synthetic Data Generation Pipeline\n",
    "\n",
    "This notebook demonstrates how to build a comprehensive pipeline for web content processing that:\n",
    "1. **Retrieves content** from web URLs using Haystack's LinkContentFetcher\n",
    "2. **Converts HTML** to structured documents using HTMLToDocument\n",
    "3. **Preprocesses the text** with cleaning and splitting components\n",
    "4. **Creates a knowledge graph** from the processed web content\n",
    "5. **Generates synthetic test data** using the knowledge graph\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will understand:\n",
    "- How to build end-to-end Haystack pipelines for web content processing\n",
    "- The differences between PDF and web content processing\n",
    "- Best practices for web scraping and content extraction\n",
    "- How web content characteristics affect synthetic test generation\n",
    "\n",
    "## Key Components for Web Processing\n",
    "- **LinkContentFetcher**: Retrieves content directly from URLs\n",
    "- **HTMLToDocument**: Converts HTML content to Haystack Documents\n",
    "- **DocumentCleaner**: Removes extra whitespaces and HTML artifacts\n",
    "- **DocumentSplitter**: Breaks web content into manageable chunks\n",
    "- **KnowledgeGraphGenerator**: Creates structured knowledge representations\n",
    "- **SyntheticTestGenerator**: Produces question-answer pairs for evaluation\n",
    "\n",
    "## Real-World Applications\n",
    "This approach is particularly useful for:\n",
    "- **Documentation Analysis**: Processing online documentation and creating test datasets\n",
    "- **Content Monitoring**: Regularly generating tests from updated web content  \n",
    "- **Multi-Source Knowledge**: Combining web content with other document types\n",
    "- **Research Applications**: Creating datasets from academic papers, blog posts, etc.\n",
    "\n",
    "## Technical Considerations\n",
    "- **Rate Limiting**: Be mindful of website rate limits when fetching content\n",
    "- **Content Quality**: Web content may require more aggressive cleaning\n",
    "- **Dynamic Content**: Some websites use JavaScript; static HTML fetching may miss content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04c41c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurafunderburk/Documents/GitHub/Building-Natural-Language-Pipelines/ch5/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Web Content Processing Pipeline created successfully!\n",
      "üåê Ready to process web content and generate knowledge graphs + synthetic tests\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from haystack import Pipeline\n",
    "from haystack.components.fetchers import LinkContentFetcher\n",
    "from haystack.components.converters import HTMLToDocument\n",
    "from haystack.components.preprocessors import (\n",
    "    DocumentCleaner,\n",
    "    DocumentSplitter)\n",
    "from pathlib import Path\n",
    "from scripts.knowledge_graph_component import KnowledgeGraphGenerator,\\\n",
    "                                                DocumentToLangChainConverter\n",
    "from scripts.synthetic_test_components import SyntheticTestGenerator,\\\n",
    "                                                TestDatasetSaver\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(\"./.env\")\n",
    "\n",
    "# Create web content processing components\n",
    "fetcher = LinkContentFetcher()\n",
    "converter = HTMLToDocument()\n",
    "doc_cleaner = DocumentCleaner(remove_empty_lines=True,\n",
    "                            remove_extra_whitespaces=True)\n",
    "doc_splitter = DocumentSplitter(split_by=\"sentence\",\n",
    "                                split_length=50,\n",
    "                                split_overlap=5)\n",
    "doc_converter = DocumentToLangChainConverter()\n",
    "kg_generator = KnowledgeGraphGenerator(apply_transforms=True)\n",
    "test_generator = SyntheticTestGenerator(\n",
    "            testset_size=10,  \n",
    "            llm_model=\"gpt-4o-mini\",\n",
    "            query_distribution=[\n",
    "                (\"single_hop\", 0.25), \n",
    "                (\"multi_hop_specific\", 0.25),\n",
    "                (\"multi_hop_abstract\", 0.5)\n",
    "            ]\n",
    "        )\n",
    "test_saver = TestDatasetSaver(\"data_for_eval/synthetic_tests_10_from_web.csv\")\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_component(\"fetcher\", fetcher)\n",
    "pipeline.add_component(\"converter\", converter)\n",
    "pipeline.add_component(\"doc_cleaner\", doc_cleaner)\n",
    "pipeline.add_component(\"doc_splitter\", doc_splitter)\n",
    "pipeline.add_component(\"doc_converter\", doc_converter)\n",
    "pipeline.add_component(\"kg_generator\", kg_generator)\n",
    "pipeline.add_component(\"test_generator\", test_generator)\n",
    "pipeline.add_component(\"test_saver\", test_saver)\n",
    "\n",
    "# Connect components in sequence\n",
    "pipeline.connect(\"fetcher.streams\", \"converter.sources\")\n",
    "pipeline.connect(\"converter.documents\", \"doc_cleaner.documents\")\n",
    "pipeline.connect(\"doc_cleaner.documents\", \"doc_splitter.documents\")\n",
    "pipeline.connect(\"doc_splitter.documents\", \"doc_converter.documents\")\n",
    "pipeline.connect(\"doc_converter.langchain_documents\", \"kg_generator.documents\")\n",
    "pipeline.connect(\"kg_generator.knowledge_graph\", \"test_generator.knowledge_graph\")\n",
    "pipeline.connect(\"doc_converter.langchain_documents\", \"test_generator.documents\")\n",
    "pipeline.connect(\"test_generator.testset\", \"test_saver.testset\")\n",
    "\n",
    "print(\"‚úÖ Web Content Processing Pipeline created successfully!\")\n",
    "print(\"üåê Ready to process web content and generate knowledge graphs + synthetic tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af764802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê Processing web content from: https://haystack.deepset.ai/blog/haystack-2-release\n",
      "This may take a moment to fetch and process the content...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlinesExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.28s/it]\n",
      "Applying HeadlineSplitter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 374.32it/s]\n",
      "Applying SummaryExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  2.68s/it]\n",
      "Applying CustomNodeFilter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.53it/s]\n",
      "Applying EmbeddingExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.54it/s]\n",
      "Applying ThemesExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.35it/s]\n",
      "Applying NERExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.45it/s]\n",
      "Applying CosineSimilarityBuilder: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 821.77it/s]\n",
      "Applying OverlapScoreBuilder: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 1485.76it/s]\n",
      "Generating personas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.22s/it]\n",
      "Generating Scenarios: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:06<00:00,  2.22s/it]\n",
      "Generating Samples: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:07<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Pipeline Results:\n",
      "  üìÑ Documents Processed: 2\n",
      "  üß† Knowledge Graph Nodes: 2\n",
      "  üß™ Test Cases Generated: 11\n",
      "  üîß Generation Method: knowledge_graph\n"
     ]
    }
   ],
   "source": [
    "web_url = \"https://haystack.deepset.ai/blog/haystack-2-release\"\n",
    "\n",
    "print(f\"üåê Processing web content from: {web_url}\")\n",
    "print(\"This may take a moment to fetch and process the content...\")\n",
    "\n",
    "try:\n",
    "    result = pipeline.run({\n",
    "        \"fetcher\": {\"urls\": [web_url]}\n",
    "    })\n",
    "\n",
    "    print(\"\\nüìä Pipeline Results:\")\n",
    "    print(f\"  üìÑ Documents Processed: {result['doc_converter']['document_count']}\")\n",
    "    print(f\"  üß† Knowledge Graph Nodes: {result['kg_generator']['node_count']}\")\n",
    "    print(f\"  üß™ Test Cases Generated: {result['test_generator']['testset_size']}\")\n",
    "    print(f\"  üîß Generation Method: {result['test_generator']['generation_method']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error processing web content: {str(e)}\")\n",
    "    print(\"This might be due to network issues or website access restrictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed64d39",
   "metadata": {},
   "source": [
    "### Understanding the Web Content Processing Pipeline Architecture\n",
    "\n",
    "The web processing pipeline follows a similar structure to PDF processing but with adapted input components:\n",
    "\n",
    "```\n",
    "Web URL ‚Üí Link Fetcher ‚Üí HTML Converter ‚Üí Document Cleaner ‚Üí Document Splitter\n",
    "    ‚Üì\n",
    "Document Converter ‚Üí Knowledge Graph Generator  \n",
    "    ‚Üì                         ‚Üì\n",
    "Test Generator ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê\n",
    "    ‚Üì\n",
    "Test Dataset Saver\n",
    "```\n",
    "\n",
    "**Why This Works:**\n",
    "- The knowledge graph generation is **content-agnostic** - it works the same whether input comes from PDFs, web pages, or other sources\n",
    "- Document preprocessing steps ensure consistent quality regardless of input format\n",
    "- The same test generation logic produces comparable quality across all sources\n",
    "\n",
    "**Pipeline Reusability:**\n",
    "Notice how we can reuse the same components (`doc_cleaner`, `doc_splitter`, `kg_generator`, etc.) with different input sources. This demonstrates the modularity and flexibility of Haystack's component architecture.\n",
    "\n",
    "**Web-Specific Considerations:**\n",
    "- **Content Structure**: Web pages may have navigation, ads, and other non-content elements\n",
    "- **HTML Artifacts**: May require more aggressive cleaning than PDF content\n",
    "- **Dynamic Loading**: Static HTML fetching may miss JavaScript-rendered content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87b75dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∏ Pipeline diagram saved to: ./images/web_knowledge_graph_pipeline.png\n"
     ]
    }
   ],
   "source": [
    "pipeline.draw(path=\"./images/web_knowledge_graph_pipeline.png\")\n",
    "print(\"üì∏ Pipeline diagram saved to: ./images/web_knowledge_graph_pipeline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca4fe52",
   "metadata": {},
   "source": [
    "![](./images/web_knowledge_graph_pipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa2db0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Synthetic Tests Sample:\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What significant changes were made to Haystack...</td>\n",
       "      <td>['Haystack 2.0: The Composable Open-Source LLM...</td>\n",
       "      <td>In 2023, Haystack underwent a major rework wit...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does Haystack 2.0 improve upon the limitat...</td>\n",
       "      <td>['Composable and customizable Pipelines\\nModer...</td>\n",
       "      <td>Haystack 2.0 improves upon the limitations of ...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the limitations of Haystack 1.0 in te...</td>\n",
       "      <td>['A common interface for storing data - A clea...</td>\n",
       "      <td>One important limitation in Haystack 1.0 is th...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does Haystack 2.0 improve upon the limitat...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nComposable and customizable Pipel...</td>\n",
       "      <td>Haystack 2.0 improves upon the limitations of ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does HyDE optimize the customizable compon...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nA common interface for storing da...</td>\n",
       "      <td>HyDE optimizes the customizable components in ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What significant changes were made to Haystack...   \n",
       "1  How does Haystack 2.0 improve upon the limitat...   \n",
       "2  What are the limitations of Haystack 1.0 in te...   \n",
       "3  How does Haystack 2.0 improve upon the limitat...   \n",
       "4  How does HyDE optimize the customizable compon...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  ['Haystack 2.0: The Composable Open-Source LLM...   \n",
       "1  ['Composable and customizable Pipelines\\nModer...   \n",
       "2  ['A common interface for storing data - A clea...   \n",
       "3  ['<1-hop>\\n\\nComposable and customizable Pipel...   \n",
       "4  ['<1-hop>\\n\\nA common interface for storing da...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  In 2023, Haystack underwent a major rework wit...   \n",
       "1  Haystack 2.0 improves upon the limitations of ...   \n",
       "2  One important limitation in Haystack 1.0 is th...   \n",
       "3  Haystack 2.0 improves upon the limitations of ...   \n",
       "4  HyDE optimizes the customizable components in ...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0  single_hop_specific_query_synthesizer  \n",
       "1  single_hop_specific_query_synthesizer  \n",
       "2  single_hop_specific_query_synthesizer  \n",
       "3   multi_hop_specific_query_synthesizer  \n",
       "4   multi_hop_specific_query_synthesizer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How does Haystack 2.0 enhance customization an...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nThese include Chroma, Weaviate, P...</td>\n",
       "      <td>Haystack 2.0 enhances customization and flexib...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are the key features of Haystack 2.0 that...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nThese include Chroma, Weaviate, P...</td>\n",
       "      <td>Haystack 2.0 is designed to be a flexible and ...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wht r the key features of Chroma and how can I...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nThese include Chroma, Weaviate, P...</td>\n",
       "      <td>Chroma is one of the storage solutions include...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What new documentation and tutorials are avail...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nThese include Chroma, Weaviate, P...</td>\n",
       "      <td>With the release of Haystack 2.0, a comprehens...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How does Haystack 2.0 facilitate the developme...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nThese include Chroma, Weaviate, P...</td>\n",
       "      <td>Haystack 2.0 facilitates the development of pr...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "6   How does Haystack 2.0 enhance customization an...   \n",
       "7   What are the key features of Haystack 2.0 that...   \n",
       "8   Wht r the key features of Chroma and how can I...   \n",
       "9   What new documentation and tutorials are avail...   \n",
       "10  How does Haystack 2.0 facilitate the developme...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "6   ['<1-hop>\\n\\nThese include Chroma, Weaviate, P...   \n",
       "7   ['<1-hop>\\n\\nThese include Chroma, Weaviate, P...   \n",
       "8   ['<1-hop>\\n\\nThese include Chroma, Weaviate, P...   \n",
       "9   ['<1-hop>\\n\\nThese include Chroma, Weaviate, P...   \n",
       "10  ['<1-hop>\\n\\nThese include Chroma, Weaviate, P...   \n",
       "\n",
       "                                            reference  \\\n",
       "6   Haystack 2.0 enhances customization and flexib...   \n",
       "7   Haystack 2.0 is designed to be a flexible and ...   \n",
       "8   Chroma is one of the storage solutions include...   \n",
       "9   With the release of Haystack 2.0, a comprehens...   \n",
       "10  Haystack 2.0 facilitates the development of pr...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_abstract_query_synthesizer  \n",
       "9   multi_hop_abstract_query_synthesizer  \n",
       "10  multi_hop_abstract_query_synthesizer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and display the generated synthetic tests\n",
    "test_file_path = \"data_for_eval/synthetic_tests_10_from_web.csv\"\n",
    "\n",
    "if os.path.exists(test_file_path):\n",
    "    synthetic_tests_df = pd.read_csv(test_file_path)\n",
    "    print(\"\\nüß™ Synthetic Tests Sample:\")\n",
    "    print(\"First 5 rows:\")\n",
    "    display(synthetic_tests_df.head())\n",
    "    print(\"Last 5 rows:\")\n",
    "    display(synthetic_tests_df.tail())\n",
    "else:\n",
    "    print(\"‚ùå Synthetic test file not found\")\n",
    "    print(\"Please run the previous cells to generate the test data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5e81d0",
   "metadata": {},
   "source": [
    "### Analyzing Web Content vs PDF Results\n",
    "\n",
    "Let's examine how the synthetic test generation performs when using web content versus PDF content.\n",
    "\n",
    "**Expected Differences:**\n",
    "- **Content Structure**: Web content may have different formatting and structure\n",
    "- **Question Complexity**: Depending on the source material's complexity\n",
    "- **Context Quality**: Web content might include navigation elements or ads that need filtering\n",
    "\n",
    "**Quality Assessment Checklist:**\n",
    "- [ ] Questions are grammatically correct\n",
    "- [ ] Answers are factually accurate based on the source\n",
    "- [ ] Context excerpts support the provided answers\n",
    "- [ ] Questions test different levels of comprehension\n",
    "- [ ] No duplicate or overly similar questions\n",
    "\n",
    "**Web Content Specific Benefits:**\n",
    "1. **Real-time Content**: Access to the most current information available online\n",
    "2. **Rich Media Context**: Web pages often have supplementary context that enhances understanding\n",
    "3. **Diverse Sources**: Easy to process content from multiple websites\n",
    "4. **Hyperlinked Knowledge**: Web content often contains references that enrich the knowledge graph\n",
    "\n",
    "**Potential Challenges:**\n",
    "1. **Content Quality Variability**: Web content quality can vary significantly\n",
    "2. **Noise Filtering**: Need to filter out navigation, ads, and irrelevant content\n",
    "3. **Rate Limiting**: Must respect website rate limits and robots.txt\n",
    "4. **Dynamic Content**: Some content may require JavaScript rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e345a4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "In this notebook, we successfully:\n",
    "\n",
    "1. **Built a Web Content Processing Pipeline**: Created an end-to-end pipeline specifically optimized for web content\n",
    "2. **Demonstrated Source Flexibility**: Processed content from multiple different websites\n",
    "3. **Generated Knowledge Graphs from Web Content**: Converted unstructured web content into structured knowledge representations\n",
    "4. **Produced Comparative Synthetic Test Data**: Created question-answer pairs from different web sources\n",
    "5. **Analyzed Web-Specific Characteristics**: Examined how web content affects synthetic test generation\n",
    "\n",
    "### Key Advantages of Web Content Processing\n",
    "\n",
    "- **Real-Time Content**: Access to the most current information available\n",
    "- **Diverse Sources**: Easy to process content from multiple websites in sequence\n",
    "- **Rich Context**: Web content often includes hyperlinks and references that enhance knowledge graphs\n",
    "- **Scalable Collection**: Can systematically process large numbers of web resources\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f74d2ae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-with-haystack-ch5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
