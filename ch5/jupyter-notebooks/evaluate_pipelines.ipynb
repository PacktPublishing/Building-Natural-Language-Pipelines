{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb2f063",
   "metadata": {},
   "source": [
    "## Generate a knowledge graph and question-answer pairs from a PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86671d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating synthetic test generation pipeline...\n",
      "Found 1 PDF files to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlinesExtractor: 100%|██████████| 17/17 [00:08<00:00,  2.01it/s]\n",
      "Applying HeadlineSplitter: 100%|██████████| 17/17 [00:00<00:00, 431.12it/s]\n",
      "Applying SummaryExtractor: 100%|██████████| 17/17 [00:13<00:00,  1.30it/s]\n",
      "Applying CustomNodeFilter: 100%|██████████| 49/49 [00:25<00:00,  1.94it/s]\n",
      "Applying EmbeddingExtractor: 100%|██████████| 17/17 [00:04<00:00,  4.07it/s]\n",
      "Applying ThemesExtractor: 100%|██████████| 45/45 [00:25<00:00,  1.79it/s]\n",
      "Applying NERExtractor: 100%|██████████| 45/45 [00:21<00:00,  2.06it/s]\n",
      "Applying CosineSimilarityBuilder: 100%|██████████| 1/1 [00:00<00:00, 314.04it/s]\n",
      "Applying OverlapScoreBuilder: 100%|██████████| 1/1 [00:00<00:00, 75.99it/s]\n",
      "Generating personas: 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "Generating Scenarios: 100%|██████████| 3/3 [00:20<00:00,  6.75s/it]\n",
      "Generating Samples: 100%|██████████| 11/11 [00:08<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Pipeline Results:\n",
      "  📄 Documents Processed: 17\n",
      "  🧠 Knowledge Graph Nodes: 17\n",
      "  🧪 Test Cases Generated: 11\n",
      "  🔧 Generation Method: knowledge_graph\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from haystack import Pipeline\n",
    "from haystack.components.converters import PyPDFToDocument\n",
    "from haystack.components.preprocessors import (\n",
    "    DocumentCleaner,\n",
    "    DocumentSplitter)\n",
    "from pathlib import Path\n",
    "from scripts.knowledge_graph_component import KnowledgeGraphGenerator\n",
    "from scripts.synthetic_test_components import SyntheticTestGenerator,\\\n",
    "                                                TestDatasetSaver,\\\n",
    "                                                    DocumentToLangChainConverter\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(\"./.env\")\n",
    "\n",
    "# Example: Create a complete pipeline for synthetic test generation\n",
    "data_path = \"data_for_indexing\"\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    print(\"Creating synthetic test generation pipeline...\")\n",
    "    \n",
    "    # Get PDF files from the directory\n",
    "    pdf_files = list(Path(data_path).glob(\"*.pdf\"))\n",
    "    \n",
    "    if pdf_files:\n",
    "        print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "        \n",
    "        # Create pipeline components\n",
    "        pdf_converter = PyPDFToDocument()\n",
    "        doc_cleaner = DocumentCleaner(remove_empty_lines=True,\n",
    "                                      remove_extra_whitespaces=True)\n",
    "        doc_splitter = DocumentSplitter(split_by=\"sentence\",\n",
    "                                       split_length=50,\n",
    "                                       split_overlap=5)\n",
    "        doc_converter = DocumentToLangChainConverter()\n",
    "        kg_generator = KnowledgeGraphGenerator(apply_transforms=True)\n",
    "        \n",
    "        \n",
    "        test_generator = SyntheticTestGenerator(\n",
    "            testset_size=10,  \n",
    "            llm_model=\"gpt-4o-mini\",\n",
    "            query_distribution=[\n",
    "                (\"single_hop\", 0.25), \n",
    "                (\"multi_hop_specific\", 0.25),\n",
    "                (\"multi_hop_abstract\", 0.5)\n",
    "            ],\n",
    "            # Optional: Add max_testset_size=5 if you want to limit due to API constraints\n",
    "            # max_testset_size=5  # Uncomment this line if you experience API timeouts\n",
    "        )\n",
    "        test_saver = TestDatasetSaver(\"data_for_eval/synthetic_tests_10_from_pdf.csv\")\n",
    "        \n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline()\n",
    "        pipeline.add_component(\"pdf_converter\", pdf_converter)\n",
    "        pipeline.add_component(\"doc_cleaner\", doc_cleaner)\n",
    "        pipeline.add_component(\"doc_splitter\", doc_splitter)\n",
    "        pipeline.add_component(\"doc_converter\", doc_converter)\n",
    "        pipeline.add_component(\"kg_generator\", kg_generator)\n",
    "        pipeline.add_component(\"test_generator\", test_generator)\n",
    "        pipeline.add_component(\"test_saver\", test_saver)\n",
    "        \n",
    "        # Connect components in sequence\n",
    "        pipeline.connect(\"pdf_converter.documents\", \"doc_cleaner.documents\")\n",
    "        pipeline.connect(\"doc_cleaner.documents\", \"doc_splitter.documents\")\n",
    "        pipeline.connect(\"doc_splitter.documents\", \"doc_converter.documents\")\n",
    "        pipeline.connect(\"doc_converter.langchain_documents\", \"kg_generator.documents\")\n",
    "        pipeline.connect(\"kg_generator.knowledge_graph\", \"test_generator.knowledge_graph\")\n",
    "        pipeline.connect(\"doc_converter.langchain_documents\", \"test_generator.documents\")\n",
    "        pipeline.connect(\"test_generator.testset\", \"test_saver.testset\")\n",
    "        \n",
    "        # Prepare input data - convert PDF files to ByteStream objects\n",
    "        pdf_sources = [Path(\"./data_for_indexing/howpeopleuseai.pdf\")]\n",
    "         \n",
    "        result = pipeline.run({\n",
    "            \"pdf_converter\": {\"sources\": pdf_sources}\n",
    "        })\n",
    "        \n",
    "        print(\"\\n📊 Pipeline Results:\")\n",
    "        print(f\"  📄 Documents Processed: {result['doc_converter']['document_count']}\")\n",
    "        print(f\"  🧠 Knowledge Graph Nodes: {result['kg_generator']['node_count']}\")\n",
    "        print(f\"  🧪 Test Cases Generated: {result['test_generator']['testset_size']}\")\n",
    "        print(f\"  🔧 Generation Method: {result['test_generator']['generation_method']}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ No PDF files found in data_for_indexing directory\")\n",
    "else:\n",
    "    print(\"❌ Data path 'data_for_indexing' not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1429d2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Synthetic Tests Sample:\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is Zoe Hitzig and what is her role in the ...</td>\n",
       "      <td>['NBER WORKING PAPER SERIES\\nHOW PEOPLE USE CH...</td>\n",
       "      <td>Zoe Hitzig is one of the co-authors of the NBE...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many users was ChatGPT having by July 2025?</td>\n",
       "      <td>['ABSTRACT Despite the rapid adoption of LLM c...</td>\n",
       "      <td>By July 2025, ChatGPT had 700 million users, r...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What insights does Roth provide regarding the ...</td>\n",
       "      <td>['LLM, allowing us to classify messages withou...</td>\n",
       "      <td>Roth (2025) reports that 28% of US adults used...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What trends in user engagement and message vol...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nThe yellow line represents the fi...</td>\n",
       "      <td>For ChatGPT users who signed up in 2023, parti...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What trends in user interaction quality and ge...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\n5.5 Quality of Interactions\\nWe a...</td>\n",
       "      <td>In the lead-up to June 2025, trends in user in...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Who is Zoe Hitzig and what is her role in the ...   \n",
       "1    How many users was ChatGPT having by July 2025?   \n",
       "2  What insights does Roth provide regarding the ...   \n",
       "3  What trends in user engagement and message vol...   \n",
       "4  What trends in user interaction quality and ge...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  ['NBER WORKING PAPER SERIES\\nHOW PEOPLE USE CH...   \n",
       "1  ['ABSTRACT Despite the rapid adoption of LLM c...   \n",
       "2  ['LLM, allowing us to classify messages withou...   \n",
       "3  ['<1-hop>\\n\\nThe yellow line represents the fi...   \n",
       "4  ['<1-hop>\\n\\n5.5 Quality of Interactions\\nWe a...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Zoe Hitzig is one of the co-authors of the NBE...   \n",
       "1  By July 2025, ChatGPT had 700 million users, r...   \n",
       "2  Roth (2025) reports that 28% of US adults used...   \n",
       "3  For ChatGPT users who signed up in 2023, parti...   \n",
       "4  In the lead-up to June 2025, trends in user in...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0  single_hop_specific_query_synthesizer  \n",
       "1  single_hop_specific_query_synthesizer  \n",
       "2  single_hop_specific_query_synthesizer  \n",
       "3   multi_hop_specific_query_synthesizer  \n",
       "4   multi_hop_specific_query_synthesizer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What trends can be observed in ChatGPT user co...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nThe yellow line represents the fi...</td>\n",
       "      <td>The trends observed in ChatGPT user cohorts in...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How does user satisfaction relate to data priv...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nWe retain this classifier because...</td>\n",
       "      <td>User satisfaction in ChatGPT interactions is a...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the significance of IWA ID in relation...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nTask details Your response should...</td>\n",
       "      <td>The significance of IWA ID in relation to Cohe...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What are the key patterns of ChatGPT usage amo...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nNBER WORKING PAPER SERIES\\nHOW PE...</td>\n",
       "      <td>The key patterns of ChatGPT usage reveal that ...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What insights can be drawn about user satisfac...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nOuyang, Long, Jeff Wu, Xu Jiang, ...</td>\n",
       "      <td>Insights about user satisfaction from the feed...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "6   What trends can be observed in ChatGPT user co...   \n",
       "7   How does user satisfaction relate to data priv...   \n",
       "8   What is the significance of IWA ID in relation...   \n",
       "9   What are the key patterns of ChatGPT usage amo...   \n",
       "10  What insights can be drawn about user satisfac...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "6   ['<1-hop>\\n\\nThe yellow line represents the fi...   \n",
       "7   ['<1-hop>\\n\\nWe retain this classifier because...   \n",
       "8   ['<1-hop>\\n\\nTask details Your response should...   \n",
       "9   ['<1-hop>\\n\\nNBER WORKING PAPER SERIES\\nHOW PE...   \n",
       "10  ['<1-hop>\\n\\nOuyang, Long, Jeff Wu, Xu Jiang, ...   \n",
       "\n",
       "                                            reference  \\\n",
       "6   The trends observed in ChatGPT user cohorts in...   \n",
       "7   User satisfaction in ChatGPT interactions is a...   \n",
       "8   The significance of IWA ID in relation to Cohe...   \n",
       "9   The key patterns of ChatGPT usage reveal that ...   \n",
       "10  Insights about user satisfaction from the feed...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_abstract_query_synthesizer  \n",
       "9   multi_hop_abstract_query_synthesizer  \n",
       "10  multi_hop_abstract_query_synthesizer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and display the generated synthetic tests\n",
    "test_file_path = \"data_for_eval/synthetic_tests_10_from_pdf.csv\"\n",
    "\n",
    "if os.path.exists(test_file_path):\n",
    "    synthetic_tests_df = pd.read_csv(test_file_path)\n",
    "    print(\"\\n🧪 Synthetic Tests Sample:\")\n",
    "    print(\"First 5 rows:\")\n",
    "    display(synthetic_tests_df.head())\n",
    "    print(\"Last 5 rows:\")\n",
    "    display(synthetic_tests_df.tail())\n",
    "else:\n",
    "    print(\"❌ Synthetic test file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ebd922",
   "metadata": {},
   "source": [
    "## Generate a knowledge graph and question-answer pairs from a scraped website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67f162b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlinesExtractor: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]\n",
      "Applying HeadlineSplitter: 100%|██████████| 2/2 [00:00<00:00, 442.76it/s]\n",
      "Applying SummaryExtractor: 100%|██████████| 2/2 [00:04<00:00,  2.41s/it]\n",
      "Applying CustomNodeFilter: 100%|██████████| 6/6 [00:04<00:00,  1.43it/s]\n",
      "Applying EmbeddingExtractor: 100%|██████████| 2/2 [00:00<00:00,  2.59it/s]\n",
      "Applying ThemesExtractor: 100%|██████████| 6/6 [00:05<00:00,  1.19it/s]\n",
      "Applying NERExtractor: 100%|██████████| 6/6 [00:03<00:00,  1.60it/s]\n",
      "Applying CosineSimilarityBuilder: 100%|██████████| 1/1 [00:00<00:00, 964.21it/s]\n",
      "Applying OverlapScoreBuilder: 100%|██████████| 1/1 [00:00<00:00, 1633.93it/s]\n",
      "Generating personas: 100%|██████████| 2/2 [00:02<00:00,  1.03s/it]\n",
      "Generating Scenarios: 100%|██████████| 3/3 [00:06<00:00,  2.00s/it]\n",
      "Generating Samples: 100%|██████████| 11/11 [00:07<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Pipeline Results:\n",
      "  📄 Documents Processed: 2\n",
      "  🧠 Knowledge Graph Nodes: 2\n",
      "  🧪 Test Cases Generated: 11\n",
      "  🔧 Generation Method: knowledge_graph\n"
     ]
    }
   ],
   "source": [
    "from haystack.components.fetchers import LinkContentFetcher\n",
    "from haystack.components.converters import HTMLToDocument\n",
    "\n",
    "fetcher = LinkContentFetcher()\n",
    "converter = HTMLToDocument()\n",
    "doc_cleaner = DocumentCleaner(remove_empty_lines=True,\n",
    "                                      remove_extra_whitespaces=True)\n",
    "doc_splitter = DocumentSplitter(split_by=\"sentence\",\n",
    "                                split_length=50,\n",
    "                                split_overlap=5)\n",
    "doc_converter = DocumentToLangChainConverter()\n",
    "kg_generator = KnowledgeGraphGenerator(apply_transforms=True)\n",
    "test_generator = SyntheticTestGenerator(\n",
    "            testset_size=10,  \n",
    "            llm_model=\"gpt-4o-mini\",\n",
    "            query_distribution=[\n",
    "                (\"single_hop\", 0.25), \n",
    "                (\"multi_hop_specific\", 0.25),\n",
    "                (\"multi_hop_abstract\", 0.5)\n",
    "            ]\n",
    "        )\n",
    "test_saver = TestDatasetSaver(\"data_for_eval/synthetic_tests_10_from_html_page.csv\")\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_component(\"fetcher\", fetcher)\n",
    "pipeline.add_component(\"converter\", converter)\n",
    "pipeline.add_component(\"doc_cleaner\", doc_cleaner)\n",
    "pipeline.add_component(\"doc_splitter\", doc_splitter)\n",
    "pipeline.add_component(\"doc_converter\", doc_converter)\n",
    "pipeline.add_component(\"kg_generator\", kg_generator)\n",
    "pipeline.add_component(\"test_generator\", test_generator)\n",
    "pipeline.add_component(\"test_saver\", test_saver)\n",
    "\n",
    "# Connect components in sequence\n",
    "pipeline.connect(\"fetcher.streams\", \"converter.sources\")\n",
    "pipeline.connect(\"converter.documents\", \"doc_cleaner.documents\")\n",
    "pipeline.connect(\"doc_cleaner.documents\", \"doc_splitter.documents\")\n",
    "pipeline.connect(\"doc_splitter.documents\", \"doc_converter.documents\")\n",
    "pipeline.connect(\"doc_converter.langchain_documents\", \"kg_generator.documents\")\n",
    "pipeline.connect(\"kg_generator.knowledge_graph\", \"test_generator.knowledge_graph\")\n",
    "pipeline.connect(\"doc_converter.langchain_documents\", \"test_generator.documents\")\n",
    "pipeline.connect(\"test_generator.testset\", \"test_saver.testset\")\n",
    "\n",
    "web_url = \"https://haystack.deepset.ai/blog/haystack-2-release\"\n",
    "\n",
    "result = pipeline.run({\n",
    "    \"fetcher\": {\"urls\": [web_url]}\n",
    "})\n",
    "\n",
    "print(\"\\n📊 Pipeline Results:\")\n",
    "print(f\"  📄 Documents Processed: {result['doc_converter']['document_count']}\")\n",
    "print(f\"  🧠 Knowledge Graph Nodes: {result['kg_generator']['node_count']}\")\n",
    "print(f\"  🧪 Test Cases Generated: {result['test_generator']['testset_size']}\")\n",
    "print(f\"  🔧 Generation Method: {result['test_generator']['generation_method']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "508384b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Synthetic Tests Sample:\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wen was Haystack first released?</td>\n",
       "      <td>['Haystack 2.0: The Composable Open-Source LLM...</td>\n",
       "      <td>Haystack was first officially released in 2020.</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does Haystack 2.0 improve upon the limitat...</td>\n",
       "      <td>['Composable and customizable Pipelines\\nModer...</td>\n",
       "      <td>Haystack 2.0 improves upon the limitations of ...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the key features and benefits of Asse...</td>\n",
       "      <td>['A common interface for storing data - A clea...</td>\n",
       "      <td>Assembly AI contributes to the Haystack ecosys...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the limitations of Haystack 1.0 regar...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nHaystack 2.0: The Composable Open...</td>\n",
       "      <td>Haystack 1.0 had a significant limitation in t...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What limitations of Haystack 1.0 were addresse...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nA common interface for storing da...</td>\n",
       "      <td>One important limitation in Haystack 1.0 was t...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0                   Wen was Haystack first released?   \n",
       "1  How does Haystack 2.0 improve upon the limitat...   \n",
       "2  What are the key features and benefits of Asse...   \n",
       "3  What are the limitations of Haystack 1.0 regar...   \n",
       "4  What limitations of Haystack 1.0 were addresse...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  ['Haystack 2.0: The Composable Open-Source LLM...   \n",
       "1  ['Composable and customizable Pipelines\\nModer...   \n",
       "2  ['A common interface for storing data - A clea...   \n",
       "3  ['<1-hop>\\n\\nHaystack 2.0: The Composable Open...   \n",
       "4  ['<1-hop>\\n\\nA common interface for storing da...   \n",
       "\n",
       "                                           reference  \\\n",
       "0    Haystack was first officially released in 2020.   \n",
       "1  Haystack 2.0 improves upon the limitations of ...   \n",
       "2  Assembly AI contributes to the Haystack ecosys...   \n",
       "3  Haystack 1.0 had a significant limitation in t...   \n",
       "4  One important limitation in Haystack 1.0 was t...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0  single_hop_specific_query_synthesizer  \n",
       "1  single_hop_specific_query_synthesizer  \n",
       "2  single_hop_specific_query_synthesizer  \n",
       "3   multi_hop_specific_query_synthesizer  \n",
       "4   multi_hop_specific_query_synthesizer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How does Haystack 2.0 enhance the integration ...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nHaystack 2.0: The Composable Open...</td>\n",
       "      <td>Haystack 2.0 enhances the integration of data ...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are the main features of Haystack 2.0 tha...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nHaystack 2.0: The Composable Open...</td>\n",
       "      <td>Haystack 2.0 introduces several main features ...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does Haystack 2.0 facilitate integration w...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nHaystack 2.0: The Composable Open...</td>\n",
       "      <td>Haystack 2.0 facilitates integration with mode...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What are the key features of Haystack 2.0 that...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nHaystack 2.0: The Composable Open...</td>\n",
       "      <td>Haystack 2.0 introduces several key features t...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How does Haystack 2.0 integrate with data stor...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nHaystack 2.0: The Composable Open...</td>\n",
       "      <td>Haystack 2.0 integrates with data storage serv...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "6   How does Haystack 2.0 enhance the integration ...   \n",
       "7   What are the main features of Haystack 2.0 tha...   \n",
       "8   How does Haystack 2.0 facilitate integration w...   \n",
       "9   What are the key features of Haystack 2.0 that...   \n",
       "10  How does Haystack 2.0 integrate with data stor...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "6   ['<1-hop>\\n\\nHaystack 2.0: The Composable Open...   \n",
       "7   ['<1-hop>\\n\\nHaystack 2.0: The Composable Open...   \n",
       "8   ['<1-hop>\\n\\nHaystack 2.0: The Composable Open...   \n",
       "9   ['<1-hop>\\n\\nHaystack 2.0: The Composable Open...   \n",
       "10  ['<1-hop>\\n\\nHaystack 2.0: The Composable Open...   \n",
       "\n",
       "                                            reference  \\\n",
       "6   Haystack 2.0 enhances the integration of data ...   \n",
       "7   Haystack 2.0 introduces several main features ...   \n",
       "8   Haystack 2.0 facilitates integration with mode...   \n",
       "9   Haystack 2.0 introduces several key features t...   \n",
       "10  Haystack 2.0 integrates with data storage serv...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_abstract_query_synthesizer  \n",
       "9   multi_hop_abstract_query_synthesizer  \n",
       "10  multi_hop_abstract_query_synthesizer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and display the generated synthetic tests\n",
    "test_file_path = \"data_for_eval/synthetic_tests_10_from_html_page.csv\"\n",
    "\n",
    "if os.path.exists(test_file_path):\n",
    "    synthetic_tests_df = pd.read_csv(test_file_path)\n",
    "    print(\"\\n🧪 Synthetic Tests Sample:\")\n",
    "    print(\"First 5 rows:\")\n",
    "    display(synthetic_tests_df.head())\n",
    "    print(\"Last 5 rows:\")\n",
    "    display(synthetic_tests_df.tail())\n",
    "else:\n",
    "    print(\"❌ Synthetic test file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670267c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-with-haystack-ch5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
