{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8df569be",
   "metadata": {},
   "source": [
    "🔧 **Setup Required**: Before running this notebook, please follow the [setup instructions](../README.md#setup-instructions) to configure your environment and API keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87550e7b",
   "metadata": {},
   "source": [
    "# Building Custom Components with Warm-Up Methods\n",
    "\n",
    "This notebook demonstrates how to create custom Haystack components that require initialization or pre-loading of resources. We'll focus on the `warm_up()` method, which is essential for components that need to load machine learning models, establish database connections, or perform other setup operations before processing begins.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will understand:\n",
    "\n",
    "1. **The purpose and importance of the `warm_up()` method** in Haystack components\n",
    "2. **How to implement proper resource initialization** for machine learning models\n",
    "3. **Pipeline integration** with components that require warm-up\n",
    "\n",
    "## Why Warm-Up Methods Matter\n",
    "\n",
    "### The Problem\n",
    "Many machine learning models and external services require initialization before they can process data:\n",
    "- Loading pre-trained models into memory\n",
    "- Establishing database connections\n",
    "- Downloading remote resources\n",
    "- Performing one-time computations\n",
    "\n",
    "### The Solution\n",
    "The `warm_up()` method provides a standardized way to:\n",
    "- **Separate initialization from processing logic**\n",
    "- **Ensure components are ready before pipeline execution**\n",
    "- **Avoid repeated loading of the same resources**\n",
    "- **Handle initialization errors gracefully**\n",
    "\n",
    "### Performance Benefits\n",
    "- **Faster pipeline execution** after initial warm-up\n",
    "- **Predictable memory usage** patterns\n",
    "- **Reduced latency** for subsequent operations\n",
    "- **Better error handling** during setup phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59951297",
   "metadata": {},
   "source": [
    "## Component Architecture: The `LocalEmbedderText` Example\n",
    "\n",
    "We'll start by building a custom component that embeds text using SentenceTransformers. This example illustrates the key principles of the warm-up pattern:\n",
    "\n",
    "### Key Implementation Details\n",
    "\n",
    "1. **Constructor (`__init__`)**: Sets up configuration but doesn't load heavy resources\n",
    "2. **Warm-up method (`warm_up`)**: Loads the actual model when needed\n",
    "3. **Processing method (`run`)**: Performs the main work using pre-loaded resources\n",
    "4. **State management**: Tracks whether initialization has occurred\n",
    "\n",
    "### The SentenceTransformers Use Case\n",
    "\n",
    "SentenceTransformers models are perfect for demonstrating warm-up because:\n",
    "- They require downloading and loading large model files\n",
    "- Loading can take several seconds\n",
    "- Once loaded, inference is fast\n",
    "- The same model instance can be reused for multiple texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db032cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurafunderburk/Documents/GitHub/Building-Natural-Language-Pipelines/ch5/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from haystack import component, Document\n",
    "from typing import List, Optional\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "@component\n",
    "class LocalEmbedderText:\n",
    "    def __init__(self, model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name\n",
    "        self.model: Optional = None\n",
    "\n",
    "    def warm_up(self):\n",
    "        \"\"\"\n",
    "        Loads the SentenceTransformer model. This is called only once\n",
    "        before the first run.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "\n",
    "    @component.output_types(embeddings=List[List[float]])\n",
    "    def run(self, texts: List[str]):\n",
    "        \"\"\"\n",
    "        Embeds a list of texts using the pre-loaded model.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"The model has not been loaded. Please call warm_up() before running.\")\n",
    "        \n",
    "        embeddings = self.model.encode(texts).tolist()\n",
    "        return {\"embeddings\": embeddings}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f09239",
   "metadata": {},
   "source": [
    "**Critical Design Decisions:**\n",
    "\n",
    "1. **Lazy Loading**: The model is only loaded when `warm_up()` is called, not in `__init__()`\n",
    "2. **State Checking**: The `run()` method validates that initialization has occurred\n",
    "3. **Idempotency**: Multiple calls to `warm_up()` don't reload the model\n",
    "4. **Error Handling**: Clear error messages guide users to proper usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0cca94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_embedder = LocalEmbedderText()\n",
    "local_embedder.warm_up()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4456298f",
   "metadata": {},
   "source": [
    "## Testing the Basic Component\n",
    "\n",
    "Let's test our text embedder component to understand the warm-up workflow:\n",
    "\n",
    "### Step 1: Component Initialization\n",
    "\n",
    "First, we create an instance of our component. Notice that this is fast because no heavy model loading occurs yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cca0c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_embeddings = local_embedder.run(texts=[\"This is a test sentence.\", \"Another sentence to embed.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "530586ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08429640531539917,\n",
       " 0.05795368552207947,\n",
       " 0.004493284970521927,\n",
       " 0.1058211699128151,\n",
       " 0.007083478849381208]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_embeddings['embeddings'][0][0:5]  # Display first 5 values of the first embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c0f659",
   "metadata": {},
   "source": [
    "### Step 2: Component Processing\n",
    "\n",
    "Now we can use our warmed-up component to embed text. The first call may be slightly slower due to model initialization, but subsequent calls will be fast:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf84089a",
   "metadata": {},
   "source": [
    "## Adapting for Document Processing\n",
    "\n",
    "The text-based embedder works well for simple strings, but in real-world Haystack pipelines, we typically work with `Document` objects. Let's create an adapted version that processes Document objects instead of raw text strings.\n",
    "\n",
    "### Why Document Objects Matter\n",
    "\n",
    "Haystack's `Document` class provides:\n",
    "- **Structured content storage** with metadata\n",
    "- **Pipeline compatibility** with other Haystack components  \n",
    "- **Standardized interfaces** across different component types\n",
    "- **Rich context preservation** through metadata fields\n",
    "\n",
    "### Implementation Considerations\n",
    "\n",
    "When adapting our component for Documents:\n",
    "- Extract text content from Document objects\n",
    "- Maintain the same warm-up pattern\n",
    "- Preserve component state management\n",
    "- Ensure compatibility with downstream components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1144f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "class LocalEmbedderDocs:\n",
    "    def __init__(self, model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name\n",
    "        self.model: Optional = None\n",
    "\n",
    "    def warm_up(self):\n",
    "        \"\"\"\n",
    "        Loads the SentenceTransformer model. This is called only once\n",
    "        before the first run.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "\n",
    "    @component.output_types(embeddings=List[List[float]])\n",
    "    def run(self, documents: List[Document]):\n",
    "        \"\"\"\n",
    "        Embeds a list of texts using the pre-loaded model.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"The model has not been loaded. Please call warm_up() before running.\")\n",
    "\n",
    "        texts = [doc.content for doc in documents]\n",
    "        embeddings = self.model.encode(texts).tolist()\n",
    "        return {\"embeddings\": embeddings}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ba17d2",
   "metadata": {},
   "source": [
    "### Comparing the Implementations\n",
    "\n",
    "Notice the similarities and differences between our two embedder components:\n",
    "\n",
    "**Similarities:**\n",
    "- Identical warm-up logic and state management\n",
    "- Same model loading and initialization pattern\n",
    "- Consistent error handling for uninitialized components\n",
    "- Identical embedding computation process\n",
    "\n",
    "**Key Difference:**\n",
    "- **Input processing**: `LocalEmbedderDocs` extracts text from Document objects before embedding\n",
    "- **Type annotations**: Different input types (`List[str]` vs `List[Document]`)\n",
    "- **Pipeline compatibility**: Document version integrates seamlessly with other Haystack components\n",
    "\n",
    "**Design Pattern:**\n",
    "This demonstrates a common pattern in Haystack development - creating component variants that handle different data types while maintaining the same core functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21bae03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline, Document\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.converters import PyPDFToDocument\n",
    "from haystack.components.preprocessors import (\n",
    "    DocumentCleaner,\n",
    "    DocumentSplitter,\n",
    ")\n",
    "from haystack.components.writers import DocumentWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ba160e",
   "metadata": {},
   "source": [
    "## Building a Complete Processing Pipeline\n",
    "\n",
    "Now let's integrate our custom embedder component into a comprehensive document processing pipeline. This demonstrates how components with warm-up methods work within larger workflows.\n",
    "\n",
    "### Pipeline Architecture\n",
    "\n",
    "Our pipeline will process PDF documents through several stages:\n",
    "\n",
    "1. **PDF Conversion**: Extract text content from PDF files\n",
    "2. **Document Cleaning**: Remove extra whitespace and empty lines\n",
    "3. **Document Splitting**: Break large documents into manageable chunks\n",
    "4. **Embedding Generation**: Convert text to vector representations using our custom component\n",
    "\n",
    "### Component Integration Strategy\n",
    "\n",
    "When building pipelines with custom components:\n",
    "- **Initialization order matters**: Components must be warmed up before pipeline execution\n",
    "- **Resource management**: Each component manages its own resources independently\n",
    "- **Error propagation**: Component-level errors should bubble up clearly\n",
    "- **Performance optimization**: Warm-up once, process many times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "404d814a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x35979b260>\n",
       "🚅 Components\n",
       "  - pdf_converter: PyPDFToDocument\n",
       "  - document_cleaner: DocumentCleaner\n",
       "  - document_splitter: DocumentSplitter\n",
       "  - document_embedder: LocalEmbedderDocs\n",
       "🛤️ Connections\n",
       "  - pdf_converter.documents -> document_cleaner.documents (list[Document])\n",
       "  - document_cleaner.documents -> document_splitter.documents (list[Document])\n",
       "  - document_splitter.documents -> document_embedder.documents (list[Document])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "# Initialize components\n",
    "pdf_converter = PyPDFToDocument()\n",
    "cleaner = DocumentCleaner()\n",
    "splitter = DocumentSplitter()\n",
    "doc_embedder = LocalEmbedderDocs()\n",
    "writer = DocumentWriter(document_store=document_store)\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_component(\"pdf_converter\", pdf_converter)\n",
    "pipeline.add_component(\"document_cleaner\", cleaner)\n",
    "pipeline.add_component(\"document_splitter\", splitter)\n",
    "pipeline.add_component(\"document_embedder\", doc_embedder)\n",
    "\n",
    "\n",
    "pipeline.connect(\"pdf_converter.documents\", \"document_cleaner.documents\")\n",
    "pipeline.connect(\"document_cleaner.documents\", \"document_splitter.documents\")\n",
    "pipeline.connect(\"document_splitter.documents\", \"document_embedder.documents\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef638b4",
   "metadata": {},
   "source": [
    "### Understanding Pipeline Construction\n",
    "\n",
    "Let's examine how our pipeline is structured:\n",
    "\n",
    "**Component Initialization:**\n",
    "```python\n",
    "doc_embedder = LocalEmbedderDocs()  # Custom component requiring warm-up\n",
    "```\n",
    "\n",
    "**Pipeline Assembly:**\n",
    "```python\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_component(\"document_embedder\", doc_embedder)\n",
    "```\n",
    "\n",
    "**Component Connections:**\n",
    "```python\n",
    "pipeline.connect(\"document_splitter.documents\", \"document_embedder.documents\")\n",
    "```\n",
    "\n",
    "### Important Notes About Warm-Up in Pipelines\n",
    "\n",
    "1. **Automatic Warm-Up**: Haystack automatically calls `warm_up()` on components when the pipeline runs\n",
    "2. **Order Independence**: Components are warmed up before execution regardless of connection order  \n",
    "3. **Error Handling**: Warm-up failures prevent pipeline execution and provide clear error messages\n",
    "4. **Resource Efficiency**: Each component is warmed up only once per pipeline instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "563ab33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.draw(path=\"./images/warmup_component_pipeline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a33dd9",
   "metadata": {},
   "source": [
    "## Visualizing Pipeline Architecture\n",
    "\n",
    "Let's generate a visual representation of our pipeline to understand the data flow and component relationships:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb38b77",
   "metadata": {},
   "source": [
    "![](./images/warmup_component_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86a4175",
   "metadata": {},
   "source": [
    "### Pipeline Flow Analysis\n",
    "\n",
    "The pipeline diagram shows the complete document processing workflow:\n",
    "\n",
    "**Data Flow:**\n",
    "1. **PDF Input**: Raw PDF files are fed into the pipeline\n",
    "2. **Text Extraction**: PyPDFToDocument converts PDF to text\n",
    "3. **Preprocessing**: DocumentCleaner removes formatting artifacts  \n",
    "4. **Segmentation**: DocumentSplitter creates manageable chunks\n",
    "5. **Embedding**: Our custom LocalEmbedderDocs generates vectors\n",
    "\n",
    "**Component Dependencies:**\n",
    "- Each component depends on the output of the previous stage\n",
    "- The custom embedder is the final processing step\n",
    "- No parallel processing branches in this linear pipeline\n",
    "\n",
    "**Resource Management:**\n",
    "- Only the custom embedder requires warm-up in this pipeline\n",
    "- Other components are stateless and don't need initialization\n",
    "- The embedding model is loaded once and reused for all document chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52b73448",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths_to_process = \"./data_for_indexing/howpeopleuseai.pdf\"\n",
    "embedded_docs = pipeline.run({\"pdf_converter\": {\"sources\": [file_paths_to_process]}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91734e7",
   "metadata": {},
   "source": [
    "## Running the Complete Pipeline\n",
    "\n",
    "Now let's execute our pipeline with real PDF data to see how the warm-up component performs in practice:\n",
    "\n",
    "### Execution Process\n",
    "\n",
    "When we run the pipeline, several things happen automatically:\n",
    "\n",
    "1. **Component Warm-Up Phase**: Haystack calls `warm_up()` on our custom embedder\n",
    "2. **Model Loading**: The SentenceTransformer model is downloaded and loaded into memory  \n",
    "3. **Document Processing**: The PDF is processed through each pipeline stage\n",
    "4. **Embedding Generation**: Our warmed-up component processes all document chunks efficiently\n",
    "\n",
    "### Performance Expectations\n",
    "\n",
    "- **First Run**: Slower due to model loading and potential model downloads\n",
    "- **Subsequent Runs**: Much faster since the model remains in memory\n",
    "- **Memory Usage**: Higher after warm-up due to loaded model weights\n",
    "- **Throughput**: Excellent for batch processing multiple documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1b760af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_docs['document_embedder']['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed8ee163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.04715508595108986,\n",
       " -0.08272656798362732,\n",
       " -0.017641058191657066,\n",
       " 0.03134286031126976,\n",
       " 0.029913973063230515]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs['document_embedder']['embeddings'][0][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7717f2",
   "metadata": {},
   "source": [
    "### Analyzing Pipeline Output\n",
    "\n",
    "Let's examine the results to understand what our pipeline accomplished:\n",
    "\n",
    "**Embedding Count Significance:**\n",
    "- Each number represents one document chunk that was processed\n",
    "- The count tells us how many text segments were created by the document splitter\n",
    "- Each embedding is a high-dimensional vector representing the semantic content of its chunk\n",
    "\n",
    "### Understanding the Processing Chain\n",
    "\n",
    "The pipeline took our single PDF file and:\n",
    "1. **Extracted** all text content from the PDF\n",
    "2. **Cleaned** the text by removing formatting artifacts\n",
    "3. **Split** the content into semantically coherent chunks\n",
    "4. **Embedded** each chunk into a vector representation\n",
    "\n",
    "This transformation enables:\n",
    "- **Semantic search** across document content\n",
    "- **Similarity comparisons** between different text segments  \n",
    "- **Clustering** of related content\n",
    "- **Integration** with vector databases and retrieval systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eee669c",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "In this notebook, we explored the essential concepts of building Haystack components with proper initialization patterns:\n",
    "\n",
    "1. **Warm-Up Method Implementation**: How to separate resource loading from component logic\n",
    "2. **State Management**: Proper handling of initialized vs uninitialized component states  \n",
    "3. **Pipeline Integration**: Seamless incorporation of custom components into larger workflows\n",
    "4. **Performance Optimization**: Efficient resource utilization through proper initialization timing\n",
    "\n",
    "### Key Design Principles\n",
    "\n",
    "**Separation of Concerns:**\n",
    "- `__init__()` for configuration setup\n",
    "- `warm_up()` for resource loading  \n",
    "- `run()` for core processing logic\n",
    "\n",
    "**Error Handling:**\n",
    "- Clear validation of component readiness\n",
    "- Informative error messages for common mistakes\n",
    "- Graceful handling of initialization failures\n",
    "\n",
    "**Resource Efficiency:**\n",
    "- Lazy loading of expensive resources\n",
    "- Idempotent warm-up operations\n",
    "- Proper cleanup when needed\n",
    "\n",
    "### Further Learning\n",
    "\n",
    "This example demonstrates a basic embedding component. For production use, consider exploring:\n",
    "- The official [SentenceTransformersDocumentEmbedder](https://github.com/deepset-ai/haystack/blob/main/haystack/components/embedders/sentence_transformers_document_embedder.py) implementation\n",
    "- Advanced error handling and retry mechanisms  \n",
    "- Memory optimization techniques for large models\n",
    "- Async initialization patterns for better performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-with-haystack-ch5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
