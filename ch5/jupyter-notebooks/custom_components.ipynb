{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CuvGdJNr8iV"
      },
      "source": [
        "## Building custom components with Haystack\n",
        "\n",
        "Whereas the Haystack library provides a wide range of pre-built components, it is also possible to build custom components. This notebook demonstrates how to build a custom component for Haystack.\n",
        "\n",
        "The custom component we will build is a simple one: a component that takes a list of strings as input and returns the number of words in each string. This is a simple example, but it demonstrates the basic principles of building a custom component."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install haystack-ai"
      ],
      "metadata": {
        "id": "onSVL7sIr9Qr",
        "outputId": "eb8a631b-7774-4e9a-b783-47570707d03b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting haystack-ai\n",
            "  Downloading haystack_ai-2.3.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting haystack-experimental (from haystack-ai)\n",
            "  Downloading haystack_experimental-0.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (3.1.4)\n",
            "Collecting lazy-imports (from haystack-ai)\n",
            "  Downloading lazy_imports-0.3.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (10.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (3.3)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (1.25.2)\n",
            "Collecting openai>=1.1.0 (from haystack-ai)\n",
            "  Downloading openai-1.37.1-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (2.0.3)\n",
            "Collecting posthog (from haystack-ai)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (2.8.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0 in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (8.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->haystack-ai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.1.0->haystack-ai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->haystack-ai) (2.1.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->haystack-ai) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog->haystack-ai)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->haystack-ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->haystack-ai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->haystack-ai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->haystack-ai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->haystack-ai) (2024.7.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->haystack-ai) (1.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->haystack-ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->haystack-ai) (2.20.1)\n",
            "Downloading haystack_ai-2.3.1-py3-none-any.whl (350 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m350.3/350.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.37.1-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading haystack_experimental-0.1.1-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
            "Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: monotonic, lazy-imports, h11, backoff, posthog, httpcore, httpx, openai, haystack-experimental, haystack-ai\n",
            "Successfully installed backoff-2.2.1 h11-0.14.0 haystack-ai-2.3.1 haystack-experimental-0.1.1 httpcore-1.0.5 httpx-0.27.0 lazy-imports-0.3.1 monotonic-1.6 openai-1.37.1 posthog-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "i8B0p9Hlr8iZ",
        "outputId": "ce1a1e18-8610-4221-867f-e2e444981a7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<haystack.core.pipeline.pipeline.Pipeline object at 0x7c94f9cdd750>\n",
              "🚅 Components\n",
              "  - welcome_text_generator: WelcomeTextGenerator\n",
              "  - splitter: WhitespaceSplitter\n",
              "🛤️ Connections\n",
              "  - welcome_text_generator.welcome_text -> splitter.text (str)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from typing import List\n",
        "from haystack import component, Pipeline\n",
        "\n",
        "@component\n",
        "class WelcomeTextGenerator:\n",
        "  \"\"\"\n",
        "  A component generating personal welcome message and making it upper case\n",
        "  \"\"\"\n",
        "  @component.output_types(welcome_text=str, note=str)\n",
        "  def run(self, name:str):\n",
        "    return {\"welcome_text\": ('Hello {name}, welcome to Haystack!'.format(name=name)).upper(),\n",
        "             \"note\": \"welcome message is ready\"}\n",
        "\n",
        "@component\n",
        "class WhitespaceSplitter:\n",
        "  \"\"\"\n",
        "  A component for splitting the text by whitespace\n",
        "  \"\"\"\n",
        "  @component.output_types(splitted_text=List[str])\n",
        "  def run(self, text:str):\n",
        "    return {\"splitted_text\": text.split()}\n",
        "\n",
        "from haystack import  Pipeline\n",
        "text_pipeline = Pipeline()\n",
        "text_pipeline.add_component(name=\"welcome_text_generator\", instance= WelcomeTextGenerator())\n",
        "text_pipeline.add_component(name=\"splitter\", instance= WhitespaceSplitter())\n",
        "\n",
        "text_pipeline.connect(sender=\"welcome_text_generator.welcome_text\", receiver=\"splitter.text\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "n2jcD_bZr8ib"
      },
      "outputs": [],
      "source": [
        "text_pipeline.draw(\"./text_pipeline.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCpDPg3Br8ic",
        "outputId": "21ad4098-e23b-42c3-8819-839d72457ea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['HELLO', 'JOHN', 'DOE,', 'WELCOME', 'TO', 'HAYSTACK!']\n"
          ]
        }
      ],
      "source": [
        "result = text_pipeline.run({\"welcome_text_generator\":{\"name\": \"John Doe\"}})\n",
        "\n",
        "print(result[\"splitter\"][\"splitted_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KeNCCL4r8ic",
        "outputId": "beebbc9d-e8b8-4a17-932b-dd5060268b48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'note': 'welcome message is ready'}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result['welcome_text_generator']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGeMki1Qr8id"
      },
      "source": [
        "## Incorporating custom components with existing components in a pipeline\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 Define custom component"
      ],
      "metadata": {
        "id": "uPLoKITd3Bue"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nEy8aKIJr8id"
      },
      "outputs": [],
      "source": [
        "from haystack import component, Document\n",
        "from typing import Any, Dict, List, Optional, Union\n",
        "from haystack.dataclasses import ByteStream\n",
        "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
        "from haystack.document_stores.types import DuplicatePolicy\n",
        "\n",
        "from haystack.components.preprocessors import DocumentCleaner\n",
        "from haystack.components.preprocessors import DocumentSplitter\n",
        "from haystack.components.writers import DocumentWriter\n",
        "\n",
        "@component\n",
        "class ParseHTML:\n",
        "\n",
        "    @component.output_types(documents=List[Document])\n",
        "    def run(self, sources: Dict[str, Any]) -> None:\n",
        "\n",
        "        documents = []\n",
        "        for source in sources:\n",
        "\n",
        "            for key in source:\n",
        "                if type(source[key]) == str:\n",
        "                    source[key] = self.clean_text(source[key])\n",
        "\n",
        "            if source['content'] == \"\":\n",
        "                continue\n",
        "\n",
        "            #drop content from source dictionary\n",
        "            content = source['content']\n",
        "            document = Document(content=content, meta=source)\n",
        "\n",
        "            documents.append(document)\n",
        "\n",
        "        return {\"documents\": documents}\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        # Remove HTML tags using BeautifulSoup\n",
        "        soup = BeautifulSoup(text, \"html.parser\")\n",
        "        text = soup.get_text()\n",
        "        # Remove extra whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        return text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2 Initialize components"
      ],
      "metadata": {
        "id": "sbrVpTyj2-1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parse_html = ParseHTML()\n",
        "\n",
        "document_store = InMemoryDocumentStore()\n",
        "\n",
        "document_cleaner = DocumentCleaner(\n",
        "\n",
        "                remove_empty_lines=True,\n",
        "\n",
        "                remove_extra_whitespaces=True,\n",
        "\n",
        "                remove_repeated_substrings=False)\n",
        "\n",
        "document_splitter = DocumentSplitter(split_by=\"passage\", split_length=5)\n",
        "\n",
        "document_writer = DocumentWriter(\n",
        "\n",
        "                  document_store=document_store,\n",
        "\n",
        "                  policy = DuplicatePolicy.OVERWRITE)"
      ],
      "metadata": {
        "id": "D3x1jmba2Xuc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3 Add components to the pipeline"
      ],
      "metadata": {
        "id": "OQ4JUPAi39Sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline()\n",
        "\n",
        "pipeline.add_component( \"parse_html\", parse_html)\n",
        "\n",
        "pipeline.add_component( \"document_cleaner\", document_cleaner)\n",
        "\n",
        "pipeline.add_component( \"document_splitter\", document_splitter)\n",
        "\n",
        "pipeline.add_component( \"document_writer\", document_writer)"
      ],
      "metadata": {
        "id": "FABhL1tx3_m2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4 Connect components to one another"
      ],
      "metadata": {
        "id": "ws_ABuya26Uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect components to one another\n",
        "\n",
        "pipeline.connect(\"parse_html\", \"document_cleaner\")\n",
        "\n",
        "pipeline.connect(\"document_cleaner\", \"document_splitter\")\n",
        "\n",
        "pipeline.connect(\"document_splitter\", \"document_writer\")"
      ],
      "metadata": {
        "id": "17wGlzKI2ncq",
        "outputId": "4550a470-d37e-48f7-881a-7209d8915965",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<haystack.core.pipeline.pipeline.Pipeline object at 0x7c941cc92f50>\n",
              "🚅 Components\n",
              "  - parse_html: ParseHTML\n",
              "  - document_cleaner: DocumentCleaner\n",
              "  - document_splitter: DocumentSplitter\n",
              "  - document_writer: DocumentWriter\n",
              "🛤️ Connections\n",
              "  - parse_html.documents -> document_cleaner.documents (List[Document])\n",
              "  - document_cleaner.documents -> document_splitter.documents (List[Document])\n",
              "  - document_splitter.documents -> document_writer.documents (List[Document])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.draw(\"./custom_component_pipeline.png\")"
      ],
      "metadata": {
        "id": "vRVyG2Ae3D8r"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6eKZuVC13Rf5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llm-pipelines",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}