{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b16f9261",
   "metadata": {},
   "source": [
    "🔧 **Setup Required**: Before running this notebook, please follow the [setup instructions](../README.md#setup-instructions) to configure your environment and API keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b42c4",
   "metadata": {},
   "source": [
    "# Advanced Branching Pipeline - Multi-Source Knowledge Graph Generation\n",
    "\n",
    "This notebook demonstrates how to build sophisticated branching pipelines that can:\n",
    "1. **Process Multiple Input Types**: Handle PDFs, web URLs, and other document formats simultaneously\n",
    "2. **Intelligent Routing**: Automatically route different content types through appropriate processing paths\n",
    "3. **Unified Knowledge Graphs**: Combine information from multiple sources into a single knowledge representation\n",
    "4. **Scalable Architecture**: Design patterns that can be extended to handle additional content types\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will understand:\n",
    "- How to use Haystack's `FileTypeRouter` for automatic input type detection\n",
    "- How to design branching pipelines that process heterogeneous data sources\n",
    "- How to use `DocumentJoiner` to combine processed content from multiple branches\n",
    "- Best practices for production-ready multi-source processing pipelines\n",
    "\n",
    "## Key Architectural Components\n",
    "- **FileTypeRouter**: Automatically detects input types and routes them appropriately\n",
    "- **DocumentJoiner**: Combines documents from different processing branches\n",
    "- **LinkContentFetcher + HTMLToDocument**: Web content processing branch\n",
    "- **PyPDFToDocument**: PDF processing branch\n",
    "- **Shared Processing Components**: Unified cleaning, splitting, and knowledge graph generation\n",
    "\n",
    "## Real-World Applications\n",
    "This approach is essential for:\n",
    "- **Enterprise Knowledge Management**: Processing diverse document collections\n",
    "- **Research Data Integration**: Combining academic papers, web articles, and reports\n",
    "- **Multi-Modal Content Analysis**: Handling various content formats in a single workflow\n",
    "- **Automated Content Pipelines**: Production systems that need to handle varied input types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3afc4fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from haystack import Pipeline\n",
    "from haystack.components.converters import PyPDFToDocument, HTMLToDocument\n",
    "from haystack.components.fetchers import LinkContentFetcher\n",
    "from haystack.components.routers import FileTypeRouter\n",
    "from haystack.components.joiners import DocumentJoiner\n",
    "from haystack.components.preprocessors import (\n",
    "    DocumentCleaner,\n",
    "    DocumentSplitter)\n",
    "from pathlib import Path\n",
    "from scripts.knowledge_graph_component import KnowledgeGraphGenerator\n",
    "from scripts.langchaindocument import DocumentToLangChainConverter\n",
    "from scripts.synthetic_test_components import SyntheticTestGenerator,\\\n",
    "                                                TestDatasetSaver\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c182d7",
   "metadata": {},
   "source": [
    "## Building the Advanced Branching Pipeline\n",
    "\n",
    "### Pipeline Architecture Overview\n",
    "\n",
    "Our advanced pipeline will follow this architecture:\n",
    "\n",
    "```\n",
    "Input Sources (PDF + Web URL)\n",
    "    ↓                    ↓\n",
    "FileTypeRouter    LinkContentFetcher\n",
    "    ↓                    ↓  \n",
    "PDFConverter      HTMLConverter\n",
    "    ↓                    ↓\n",
    "    └── DocumentJoiner ──┘\n",
    "            ↓\n",
    "    Document Processing Chain\n",
    "    (Cleaner → Splitter → Converter)\n",
    "            ↓\n",
    "    Knowledge Graph Generator\n",
    "            ↓\n",
    "    Synthetic Test Generator  \n",
    "            ↓\n",
    "    Test Dataset Saver\n",
    "```\n",
    "\n",
    "### Key Design Principles\n",
    "\n",
    "1. **Separation of Concerns**: Each component has a single, well-defined responsibility\n",
    "2. **Flexible Input Handling**: Can process multiple input types simultaneously\n",
    "3. **Unified Processing**: Same downstream logic regardless of input source\n",
    "4. **Extensibility**: Easy to add new input types (CSV, Word docs, etc.)\n",
    "5. **Error Isolation**: Problems with one input source don't affect others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e5ffcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x17cdafe90>\n",
       "🚅 Components\n",
       "  - file_router: FileTypeRouter\n",
       "  - link_fetcher: LinkContentFetcher\n",
       "  - pdf_converter: PyPDFToDocument\n",
       "  - html_converter: HTMLToDocument\n",
       "  - doc_joiner: DocumentJoiner\n",
       "  - doc_cleaner: DocumentCleaner\n",
       "  - doc_splitter: DocumentSplitter\n",
       "  - doc_converter: DocumentToLangChainConverter\n",
       "  - kg_generator: KnowledgeGraphGenerator\n",
       "  - test_generator: SyntheticTestGenerator\n",
       "  - test_saver: TestDatasetSaver\n",
       "🛤️ Connections\n",
       "  - file_router.application/pdf -> pdf_converter.sources (list[Union[str, Path, ByteStream]])\n",
       "  - link_fetcher.streams -> html_converter.sources (list[ByteStream])\n",
       "  - pdf_converter.documents -> doc_joiner.documents (list[Document])\n",
       "  - html_converter.documents -> doc_joiner.documents (list[Document])\n",
       "  - doc_joiner.documents -> doc_cleaner.documents (list[Document])\n",
       "  - doc_cleaner.documents -> doc_splitter.documents (list[Document])\n",
       "  - doc_splitter.documents -> doc_converter.documents (list[Document])\n",
       "  - doc_converter.langchain_documents -> kg_generator.documents (List[Document])\n",
       "  - doc_converter.langchain_documents -> test_generator.documents (List[Document])\n",
       "  - kg_generator.knowledge_graph -> test_generator.knowledge_graph (KnowledgeGraph)\n",
       "  - test_generator.testset -> test_saver.testset (DataFrame)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize pipeline\n",
    "pipeline = Pipeline()\n",
    "\n",
    "# Core routing and joining components  \n",
    "file_router = FileTypeRouter(mime_types=[\"text/plain\", \"application/pdf\", \"text/html\"])\n",
    "doc_joiner = DocumentJoiner()  # Joins documents from different branches\n",
    "\n",
    "# Input converters for each file type\n",
    "pdf_converter = PyPDFToDocument()\n",
    "html_converter = HTMLToDocument()  \n",
    "link_fetcher = LinkContentFetcher()\n",
    "\n",
    "# Shared processing components\n",
    "doc_cleaner = DocumentCleaner(\n",
    "    remove_empty_lines=True, \n",
    "    remove_extra_whitespaces=True\n",
    ")\n",
    "doc_splitter = DocumentSplitter(split_by=\"sentence\", split_length=50, split_overlap=5)\n",
    "doc_converter = DocumentToLangChainConverter()\n",
    "kg_generator = KnowledgeGraphGenerator(apply_transforms=True)\n",
    "test_generator = SyntheticTestGenerator(\n",
    "    testset_size=5,  # Larger test set for multiple sources\n",
    "    llm_model=\"gpt-4o-mini\",\n",
    "    query_distribution=[\n",
    "        (\"single_hop\", 0.3),\n",
    "        (\"multi_hop_specific\", 0.3), \n",
    "        (\"multi_hop_abstract\", 0.4)\n",
    "    ]\n",
    ")\n",
    "test_saver = TestDatasetSaver(\"data_for_eval/synthetic_tests_advanced_branching_5.csv\")\n",
    "\n",
    "# Add all components to pipeline\n",
    "pipeline.add_component(\"file_router\", file_router)\n",
    "pipeline.add_component(\"link_fetcher\", link_fetcher)\n",
    "pipeline.add_component(\"pdf_converter\", pdf_converter) \n",
    "pipeline.add_component(\"html_converter\", html_converter)\n",
    "pipeline.add_component(\"doc_joiner\", doc_joiner)\n",
    "pipeline.add_component(\"doc_cleaner\", doc_cleaner)\n",
    "pipeline.add_component(\"doc_splitter\", doc_splitter)\n",
    "pipeline.add_component(\"doc_converter\", doc_converter)\n",
    "pipeline.add_component(\"kg_generator\", kg_generator)\n",
    "pipeline.add_component(\"test_generator\", test_generator)\n",
    "pipeline.add_component(\"test_saver\", test_saver)\n",
    "\n",
    "# Connect file routing branches\n",
    "pipeline.connect(\"file_router.application/pdf\", \"pdf_converter.sources\") \n",
    "pipeline.connect(\"link_fetcher.streams\", \"html_converter.sources\")\n",
    "\n",
    "# Connect converters to joiner\n",
    "pipeline.connect(\"pdf_converter.documents\", \"doc_joiner.documents\")\n",
    "pipeline.connect(\"html_converter.documents\", \"doc_joiner.documents\")\n",
    "\n",
    "# Connect main processing path\n",
    "pipeline.connect(\"doc_joiner.documents\", \"doc_cleaner.documents\")\n",
    "pipeline.connect(\"doc_cleaner.documents\", \"doc_splitter.documents\")\n",
    "pipeline.connect(\"doc_splitter.documents\", \"doc_converter.documents\")\n",
    "pipeline.connect(\"doc_converter.langchain_documents\", \"kg_generator.documents\")\n",
    "pipeline.connect(\"kg_generator.knowledge_graph\", \"test_generator.knowledge_graph\")\n",
    "pipeline.connect(\"doc_converter.langchain_documents\", \"test_generator.documents\")\n",
    "pipeline.connect(\"test_generator.testset\", \"test_saver.testset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee4b0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlinesExtractor:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Define inputs\n",
    "pdf_file = Path(\"./data_for_indexing/howpeopleuseai.pdf\")\n",
    "web_urls = [\"https://www.bbc.com/news/articles/c2l799gxjjpo\",\n",
    "            \"https://www.brookings.edu/articles/how-artificial-intelligence-is-transforming-the-world/\"\n",
    "            ]\n",
    "\n",
    "# Run pipeline with both input types\n",
    "result = pipeline.run({\n",
    "    \"file_router\": {\"sources\": [pdf_file]},  # PDF input through FileTypeRouter\n",
    "    \"link_fetcher\": {\"urls\":web_urls }      # Web input through LinkContentFetcher\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3775608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📸 Pipeline diagram saved to: ./images/advanced_branching_kg_pipeline.png\n"
     ]
    }
   ],
   "source": [
    "# Visualize the advanced branching pipeline architecture\n",
    "pipeline.draw(path=\"./images/advanced_branching_kg_pipeline.png\")\n",
    "print(\"📸 Pipeline diagram saved to: ./images/advanced_branching_kg_pipeline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04bb1e0",
   "metadata": {},
   "source": [
    "![Advanced Branching Pipeline](./images/advanced_branching_kg_pipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0a81ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does Amazon utilize AI technologies in its...</td>\n",
       "      <td>[\"What is AI, how does it work and why are som...</td>\n",
       "      <td>Amazon utilizes AI technologies in its service...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What concerns have been raised by the BBC rega...</td>\n",
       "      <td>['Why is AI controversial?\\nWhile acknowledgin...</td>\n",
       "      <td>The BBC raised concerns about the implications...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the current regulations and approache...</td>\n",
       "      <td>['Are there laws governing AI?\\nSome governmen...</td>\n",
       "      <td>In the UK, Prime Minister Sir Keir Starmer has...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How AI can help in health care and what proble...</td>\n",
       "      <td>['This article was published in 2018. To read ...</td>\n",
       "      <td>AI is transforming health care by enabling bet...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does the European Union approach the regul...</td>\n",
       "      <td>['Intelligence, please visit the AI topic page...</td>\n",
       "      <td>The paper contrasts the regulatory approaches ...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  How does Amazon utilize AI technologies in its...   \n",
       "1  What concerns have been raised by the BBC rega...   \n",
       "2  What are the current regulations and approache...   \n",
       "3  How AI can help in health care and what proble...   \n",
       "4  How does the European Union approach the regul...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [\"What is AI, how does it work and why are som...   \n",
       "1  ['Why is AI controversial?\\nWhile acknowledgin...   \n",
       "2  ['Are there laws governing AI?\\nSome governmen...   \n",
       "3  ['This article was published in 2018. To read ...   \n",
       "4  ['Intelligence, please visit the AI topic page...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Amazon utilizes AI technologies in its service...   \n",
       "1  The BBC raised concerns about the implications...   \n",
       "2  In the UK, Prime Minister Sir Keir Starmer has...   \n",
       "3  AI is transforming health care by enabling bet...   \n",
       "4  The paper contrasts the regulatory approaches ...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0  single_hop_specific_query_synthesizer  \n",
       "1  single_hop_specific_query_synthesizer  \n",
       "2  single_hop_specific_query_synthesizer  \n",
       "3  single_hop_specific_query_synthesizer  \n",
       "4  single_hop_specific_query_synthesizer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>How has the usage of ChatGPT evolved from its ...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nNBER WORKING PAPER SERIES\\nHOW PE...</td>\n",
       "      <td>Since its launch in November 2022, the usage o...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>What demographic variations exist in ChatGPT u...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nTeams, Enterprise, Education), wh...</td>\n",
       "      <td>Demographic variations in ChatGPT usage indica...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>How is AI being utilized in both warfare and l...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nThe challenge in the West of wher...</td>\n",
       "      <td>AI is being utilized in warfare through the de...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>How does the analysis of user satisfaction rel...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nWe retain this classifier because...</td>\n",
       "      <td>The analysis of user satisfaction in ChatGPT i...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>What are classifier prompts used for in the co...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nOuyang, Long, Jeff Wu, Xu Jiang, ...</td>\n",
       "      <td>Classifier prompts are used to classify messag...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "45  How has the usage of ChatGPT evolved from its ...   \n",
       "46  What demographic variations exist in ChatGPT u...   \n",
       "47  How is AI being utilized in both warfare and l...   \n",
       "48  How does the analysis of user satisfaction rel...   \n",
       "49  What are classifier prompts used for in the co...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "45  ['<1-hop>\\n\\nNBER WORKING PAPER SERIES\\nHOW PE...   \n",
       "46  ['<1-hop>\\n\\nTeams, Enterprise, Education), wh...   \n",
       "47  ['<1-hop>\\n\\nThe challenge in the West of wher...   \n",
       "48  ['<1-hop>\\n\\nWe retain this classifier because...   \n",
       "49  ['<1-hop>\\n\\nOuyang, Long, Jeff Wu, Xu Jiang, ...   \n",
       "\n",
       "                                            reference  \\\n",
       "45  Since its launch in November 2022, the usage o...   \n",
       "46  Demographic variations in ChatGPT usage indica...   \n",
       "47  AI is being utilized in warfare through the de...   \n",
       "48  The analysis of user satisfaction in ChatGPT i...   \n",
       "49  Classifier prompts are used to classify messag...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "45  multi_hop_abstract_query_synthesizer  \n",
       "46  multi_hop_abstract_query_synthesizer  \n",
       "47  multi_hop_abstract_query_synthesizer  \n",
       "48  multi_hop_abstract_query_synthesizer  \n",
       "49  multi_hop_abstract_query_synthesizer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and analyze results from the advanced branching pipeline\n",
    "advanced_test_file = \"data_for_eval/synthetic_tests_advanced_branching_50.csv\"\n",
    "\n",
    "if os.path.exists(advanced_test_file):\n",
    "    advanced_tests_df = pd.read_csv(advanced_test_file)\n",
    "\n",
    "    display(advanced_tests_df.head())\n",
    "    display(advanced_tests_df.tail())\n",
    "\n",
    "else:\n",
    "    print(\"❌ Synthetic test file not found\")\n",
    "    print(\"Please run the previous cells to generate the test data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d8b91f",
   "metadata": {},
   "source": [
    "## Summary and Architecture Analysis\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "In this notebook, we've built increasingly sophisticated branching pipelines:\n",
    "\n",
    "1. **Basic Branching Pipeline**: PDF + Web content processing  \n",
    "2. **Production-Ready Pipeline**: Enhanced error handling and monitoring\n",
    "\n",
    "### Key Architectural Benefits\n",
    "\n",
    "1. **Modularity**: Each component has a single responsibility and can be reused\n",
    "2. **Flexibility**: Easy to add new input types (CSV, Word docs, etc.) \n",
    "3. **Scalability**: DocumentJoiner allows processing multiple sources simultaneously\n",
    "4. **Consistency**: Same processing logic regardless of input source\n",
    "5. **Error Isolation**: Problems with one input source don't affect others\n",
    "\n",
    "### Production Considerations\n",
    "\n",
    "**Advantages of Branching Pipelines:**\n",
    "- **Unified Output**: Single knowledge graph and test dataset from multiple sources\n",
    "- **Rich Context**: Cross-referencing information between different document types\n",
    "- **Operational Efficiency**: One pipeline deployment handles multiple scenarios\n",
    "- **Quality Improvement**: More diverse training data leads to better synthetic questions\n",
    "\n",
    "**When to Use Branching Pipelines:**\n",
    "- Processing heterogeneous document collections\n",
    "- Building comprehensive knowledge bases from multiple sources\n",
    "- Creating robust test datasets that cover various content types\n",
    "- Implementing production pipelines that need input flexibility\n",
    "\n",
    "\n",
    "### Extension Patterns\n",
    "\n",
    "To add new input types:\n",
    "1. Add MIME type to `FileTypeRouter`\n",
    "2. Create appropriate converter component\n",
    "3. Connect converter to `DocumentJoiner`\n",
    "4. No changes needed to downstream processing!\n",
    "\n",
    "This modular approach makes the pipeline highly maintainable and extensible for future requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a4e993",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-with-haystack-ch5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
