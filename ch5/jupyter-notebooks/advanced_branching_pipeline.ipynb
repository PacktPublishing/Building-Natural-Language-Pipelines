{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b16f9261",
   "metadata": {},
   "source": [
    "üîß **Setup Required**: Before running this notebook, please follow the [setup instructions](../README.md#setup-instructions) to configure your environment and API keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b42c4",
   "metadata": {},
   "source": [
    "# Advanced Branching Pipeline - Multi-Source Knowledge Graph Generation\n",
    "\n",
    "This notebook demonstrates how to build sophisticated branching pipelines that can:\n",
    "1. **Process Multiple Input Types**: Handle PDFs, web URLs, and other document formats simultaneously\n",
    "2. **Intelligent Routing**: Automatically route different content types through appropriate processing paths\n",
    "3. **Unified Knowledge Graphs**: Combine information from multiple sources into a single knowledge representation\n",
    "4. **Scalable Architecture**: Design patterns that can be extended to handle additional content types\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will understand:\n",
    "- How to use Haystack's `FileTypeRouter` for automatic input type detection\n",
    "- How to design branching pipelines that process heterogeneous data sources\n",
    "- How to use `DocumentJoiner` to combine processed content from multiple branches\n",
    "- Best practices for production-ready multi-source processing pipelines\n",
    "\n",
    "## Key Architectural Components\n",
    "- **FileTypeRouter**: Automatically detects input types and routes them appropriately\n",
    "- **DocumentJoiner**: Combines documents from different processing branches\n",
    "- **LinkContentFetcher + HTMLToDocument**: Web content processing branch\n",
    "- **PyPDFToDocument**: PDF processing branch\n",
    "- **Shared Processing Components**: Unified cleaning, splitting, and knowledge graph generation\n",
    "\n",
    "## Real-World Applications\n",
    "This approach is essential for:\n",
    "- **Enterprise Knowledge Management**: Processing diverse document collections\n",
    "- **Research Data Integration**: Combining academic papers, web articles, and reports\n",
    "- **Multi-Modal Content Analysis**: Handling various content formats in a single workflow\n",
    "- **Automated Content Pipelines**: Production systems that need to handle varied input types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3afc4fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurafunderburk/Documents/GitHub/Building-Natural-Language-Pipelines/ch5/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from haystack import Pipeline\n",
    "from haystack.components.converters import PyPDFToDocument, HTMLToDocument\n",
    "from haystack.components.fetchers import LinkContentFetcher\n",
    "from haystack.components.routers import FileTypeRouter\n",
    "from haystack.components.joiners import DocumentJoiner\n",
    "from haystack.components.preprocessors import (\n",
    "    DocumentCleaner,\n",
    "    DocumentSplitter)\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.embedders.openai_text_embedder import OpenAITextEmbedder\n",
    "from haystack.utils import Secret\n",
    "from pathlib import Path\n",
    "from scripts.knowledge_graph_component import KnowledgeGraphGenerator\n",
    "from scripts.langchaindocument_component import DocumentToLangChainConverter\n",
    "from scripts.synthetic_test_components import SyntheticTestGenerator, TestDatasetSaver\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "# Helper function to create fresh generator and embedder instances\n",
    "def create_llm_components():\n",
    "    \"\"\"Create fresh instances of generator and embedder.\"\"\"\n",
    "    # You can use OpenAI models:\n",
    "    generator = OpenAIGenerator(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        api_key=Secret.from_token(os.getenv(\"OPENAI_API_KEY\"))\n",
    "    )\n",
    "    embedder = OpenAITextEmbedder(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        api_key=Secret.from_token(os.getenv(\"OPENAI_API_KEY\"))\n",
    "    )\n",
    "    \n",
    "    # Or use Ollama models (uncomment to use):\n",
    "    # from haystack_integrations.components.generators.ollama import OllamaGenerator\n",
    "    # from haystack_integrations.components.embedders.ollama import OllamaTextEmbedder\n",
    "    # \n",
    "    # generator = OllamaGenerator(\n",
    "    #     model=\"mistral-nemo:12b\",\n",
    "    #     generation_kwargs={\n",
    "    #         \"num_predict\": 100,\n",
    "    #         \"temperature\": 0.9,\n",
    "    #     }\n",
    "    # )\n",
    "    # embedder = OllamaTextEmbedder(model=\"nomic-embed-text\")\n",
    "    \n",
    "    return generator, embedder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c182d7",
   "metadata": {},
   "source": [
    "## Building the Advanced Branching Pipeline\n",
    "\n",
    "### Pipeline Architecture Overview\n",
    "\n",
    "Our advanced pipeline will follow this architecture:\n",
    "\n",
    "```\n",
    "Input Sources (PDF + Web URL)\n",
    "    ‚Üì                    ‚Üì\n",
    "FileTypeRouter    LinkContentFetcher\n",
    "    ‚Üì                    ‚Üì  \n",
    "PDFConverter      HTMLConverter\n",
    "    ‚Üì                    ‚Üì\n",
    "    ‚îî‚îÄ‚îÄ DocumentJoiner ‚îÄ‚îÄ‚îò\n",
    "            ‚Üì\n",
    "    Document Processing Chain\n",
    "    (Cleaner ‚Üí Splitter ‚Üí Converter)\n",
    "            ‚Üì\n",
    "    Knowledge Graph Generator\n",
    "            ‚Üì\n",
    "    Synthetic Test Generator  \n",
    "            ‚Üì\n",
    "    Test Dataset Saver\n",
    "```\n",
    "\n",
    "### Key Design Principles\n",
    "\n",
    "1. **Separation of Concerns**: Each component has a single, well-defined responsibility\n",
    "2. **Flexible Input Handling**: Can process multiple input types simultaneously\n",
    "3. **Unified Processing**: Same downstream logic regardless of input source\n",
    "4. **Extensibility**: Easy to add new input types (CSV, Word docs, etc.)\n",
    "5. **Error Isolation**: Problems with one input source don't affect others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e5ffcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x30990c9e0>\n",
       "üöÖ Components\n",
       "  - file_router: FileTypeRouter\n",
       "  - link_fetcher: LinkContentFetcher\n",
       "  - pdf_converter: PyPDFToDocument\n",
       "  - html_converter: HTMLToDocument\n",
       "  - doc_joiner: DocumentJoiner\n",
       "  - doc_cleaner: DocumentCleaner\n",
       "  - doc_splitter: DocumentSplitter\n",
       "  - doc_converter: DocumentToLangChainConverter\n",
       "  - kg_generator: KnowledgeGraphGenerator\n",
       "  - test_generator: SyntheticTestGenerator\n",
       "  - test_saver: TestDatasetSaver\n",
       "üõ§Ô∏è Connections\n",
       "  - file_router.application/pdf -> pdf_converter.sources (list[Union[str, Path, ByteStream]])\n",
       "  - link_fetcher.streams -> html_converter.sources (list[ByteStream])\n",
       "  - pdf_converter.documents -> doc_joiner.documents (list[Document])\n",
       "  - html_converter.documents -> doc_joiner.documents (list[Document])\n",
       "  - doc_joiner.documents -> doc_cleaner.documents (list[Document])\n",
       "  - doc_cleaner.documents -> doc_splitter.documents (list[Document])\n",
       "  - doc_splitter.documents -> doc_converter.documents (list[Document])\n",
       "  - doc_converter.langchain_documents -> kg_generator.documents (List[Document])\n",
       "  - doc_converter.langchain_documents -> test_generator.documents (List[Document])\n",
       "  - kg_generator.knowledge_graph -> test_generator.knowledge_graph (KnowledgeGraph)\n",
       "  - test_generator.testset -> test_saver.testset (DataFrame)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize pipeline\n",
    "pipeline = Pipeline()\n",
    "\n",
    "# Core routing and joining components  \n",
    "file_router = FileTypeRouter(mime_types=[\"text/plain\", \"application/pdf\", \"text/html\"])\n",
    "doc_joiner = DocumentJoiner()  # Joins documents from different branches\n",
    "\n",
    "# Input converters for each file type\n",
    "pdf_converter = PyPDFToDocument()\n",
    "html_converter = HTMLToDocument()  \n",
    "link_fetcher = LinkContentFetcher()\n",
    "\n",
    "# Shared processing components\n",
    "doc_cleaner = DocumentCleaner(\n",
    "    remove_empty_lines=True, \n",
    "    remove_extra_whitespaces=True\n",
    ")\n",
    "doc_splitter = DocumentSplitter(split_by=\"sentence\", split_length=50, split_overlap=5)\n",
    "doc_converter = DocumentToLangChainConverter()\n",
    "# Create knowledge graph component with its own generator and embedder instances\n",
    "kg_gen, kg_embed = create_llm_components()\n",
    "kg_generator = KnowledgeGraphGenerator(\n",
    "    generator=kg_gen,\n",
    "    embedder=kg_embed,\n",
    "    apply_transforms=True\n",
    ")\n",
    "\n",
    "# Create test generator component with its own generator and embedder instances\n",
    "test_gen, test_embed = create_llm_components()\n",
    "test_generator = SyntheticTestGenerator(\n",
    "    generator=test_gen,\n",
    "    embedder=test_embed,\n",
    "    test_size=10,\n",
    "    query_distribution=[\n",
    "        (\"single_hop\", 0.3),\n",
    "        (\"multi_hop_specific\", 0.3),\n",
    "        (\"multi_hop_abstract\", 0.4)\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_saver = TestDatasetSaver(\"data_for_eval/synthetic_tests_advanced_branching.csv\")\n",
    "\n",
    "# Add all components to pipeline\n",
    "pipeline.add_component(\"file_router\", file_router)\n",
    "pipeline.add_component(\"link_fetcher\", link_fetcher)\n",
    "pipeline.add_component(\"pdf_converter\", pdf_converter) \n",
    "pipeline.add_component(\"html_converter\", html_converter)\n",
    "pipeline.add_component(\"doc_joiner\", doc_joiner)\n",
    "pipeline.add_component(\"doc_cleaner\", doc_cleaner)\n",
    "pipeline.add_component(\"doc_splitter\", doc_splitter)\n",
    "pipeline.add_component(\"doc_converter\", doc_converter)\n",
    "pipeline.add_component(\"kg_generator\", kg_generator)\n",
    "pipeline.add_component(\"test_generator\", test_generator)\n",
    "pipeline.add_component(\"test_saver\", test_saver)\n",
    "\n",
    "# Connect file routing branches\n",
    "pipeline.connect(\"file_router.application/pdf\", \"pdf_converter.sources\") \n",
    "pipeline.connect(\"link_fetcher.streams\", \"html_converter.sources\")\n",
    "\n",
    "# Connect converters to joiner\n",
    "pipeline.connect(\"pdf_converter.documents\", \"doc_joiner.documents\")\n",
    "pipeline.connect(\"html_converter.documents\", \"doc_joiner.documents\")\n",
    "\n",
    "# Connect main processing path\n",
    "pipeline.connect(\"doc_joiner.documents\", \"doc_cleaner.documents\")\n",
    "pipeline.connect(\"doc_cleaner.documents\", \"doc_splitter.documents\")\n",
    "pipeline.connect(\"doc_splitter.documents\", \"doc_converter.documents\")\n",
    "pipeline.connect(\"doc_converter.langchain_documents\", \"kg_generator.documents\")\n",
    "pipeline.connect(\"kg_generator.knowledge_graph\", \"test_generator.knowledge_graph\")\n",
    "pipeline.connect(\"doc_converter.langchain_documents\", \"test_generator.documents\")\n",
    "pipeline.connect(\"test_generator.testset\", \"test_saver.testset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ee4b0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlinesExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [00:07<00:00,  3.60it/s]\n",
      "Applying HeadlineSplitter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [00:00<00:00, 687.85it/s]\n",
      "Applying SummaryExtractor:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 17/27 [00:06<00:02,  4.32it/s]Property 'summary' already exists in node '897607'. Skipping!\n",
      "Applying SummaryExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:08<00:00,  3.15it/s]\n",
      "Applying CustomNodeFilter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 72/72 [00:17<00:00,  4.23it/s]\n",
      "Applying EmbeddingExtractor:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 19/27 [00:00<00:00, 33.33it/s]Property 'summary_embedding' already exists in node '897607'. Skipping!\n",
      "Applying EmbeddingExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:00<00:00, 38.69it/s]\n",
      "Applying ThemesExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:17<00:00,  3.93it/s]\n",
      "Applying NERExtractor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:16<00:00,  4.15it/s]\n",
      "Applying CosineSimilarityBuilder: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 300.39it/s]\n",
      "Applying OverlapScoreBuilder: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 35.01it/s]\n",
      "Generating personas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Generating Scenarios: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:11<00:00,  3.81s/it]\n",
      "Generating Samples: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:04<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Pipeline Results:\n",
      "  üìÑ Documents Processed: 26\n",
      "  üß† Knowledge Graph Nodes: 26\n",
      "  üß™ Test Cases Generated: 10\n",
      "  üîß Generation Method: knowledge_graph\n"
     ]
    }
   ],
   "source": [
    "# Define inputs\n",
    "pdf_file = Path(\"./data_for_indexing/howpeopleuseai.pdf\")\n",
    "web_urls = [\"https://www.bbc.com/news/articles/c2l799gxjjpo\",\n",
    "            \"https://www.brookings.edu/articles/how-artificial-intelligence-is-transforming-the-world/\"\n",
    "            ]\n",
    "\n",
    "try:\n",
    "    # Run pipeline with both input types\n",
    "    result = pipeline.run({\n",
    "    \"file_router\": {\"sources\": [pdf_file]},  # PDF input through FileTypeRouter\n",
    "    \"link_fetcher\": {\"urls\":web_urls }      # Web input through LinkContentFetcher\n",
    "})\n",
    "\n",
    "    print(\"\\nüìä Pipeline Results:\")\n",
    "    print(f\"  üìÑ Documents Processed: {result['doc_converter']['document_count']}\")\n",
    "    print(f\"  üß† Knowledge Graph Nodes: {result['kg_generator']['node_count']}\")\n",
    "    print(f\"  üß™ Test Cases Generated: {result['test_generator']['testset_size']}\")\n",
    "    print(f\"  üîß Generation Method: {result['test_generator']['generation_method']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error processing web content: {str(e)}\")\n",
    "    print(\"This might be due to network issues or website access restrictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3775608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∏ Pipeline diagram saved to: ./images/advanced_branching_kg_pipeline.png\n"
     ]
    }
   ],
   "source": [
    "# Visualize the advanced branching pipeline architecture\n",
    "pipeline.draw(path=\"./images/advanced_branching_kg_pipeline.png\")\n",
    "print(\"üì∏ Pipeline diagram saved to: ./images/advanced_branching_kg_pipeline.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0a81ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why people worried about OpenAI and its impact...</td>\n",
       "      <td>[\"What is AI, how does it work and why are som...</td>\n",
       "      <td>People are concerned about OpenAI, particularl...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What concerns has the International Monetary F...</td>\n",
       "      <td>['Why is AI controversial?\\nWhile acknowledgin...</td>\n",
       "      <td>The International Monetary Fund (IMF) has warn...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Sir Keir Starmer's stance on regulatin...</td>\n",
       "      <td>['Are there laws governing AI?\\nSome governmen...</td>\n",
       "      <td>Prime Minister Sir Keir Starmer has stated tha...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the mapping of message content to wor...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\n5.4 O*NET Work Activities\\nWe map...</td>\n",
       "      <td>The mapping of message content to work activit...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How did the user growth of ChatGPT in 2023 com...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\n4 The Growth of ChatGPT\\nChatGPT ...</td>\n",
       "      <td>In 2023, ChatGPT experienced a notable decline...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Why people worried about OpenAI and its impact...   \n",
       "1  What concerns has the International Monetary F...   \n",
       "2  What is Sir Keir Starmer's stance on regulatin...   \n",
       "3  How does the mapping of message content to wor...   \n",
       "4  How did the user growth of ChatGPT in 2023 com...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [\"What is AI, how does it work and why are som...   \n",
       "1  ['Why is AI controversial?\\nWhile acknowledgin...   \n",
       "2  ['Are there laws governing AI?\\nSome governmen...   \n",
       "3  ['<1-hop>\\n\\n5.4 O*NET Work Activities\\nWe map...   \n",
       "4  ['<1-hop>\\n\\n4 The Growth of ChatGPT\\nChatGPT ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  People are concerned about OpenAI, particularl...   \n",
       "1  The International Monetary Fund (IMF) has warn...   \n",
       "2  Prime Minister Sir Keir Starmer has stated tha...   \n",
       "3  The mapping of message content to work activit...   \n",
       "4  In 2023, ChatGPT experienced a notable decline...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0  single_hop_specific_query_synthesizer  \n",
       "1  single_hop_specific_query_synthesizer  \n",
       "2  single_hop_specific_query_synthesizer  \n",
       "3   multi_hop_specific_query_synthesizer  \n",
       "4   multi_hop_specific_query_synthesizer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What trends in user demographics and interacti...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\n6 Who Uses ChatGPT\\nIn this secti...</td>\n",
       "      <td>By mid-2025, it is expected that the demograph...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How AI ethical guidelines help in economic ben...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nIn the same vein, the IEEE Global...</td>\n",
       "      <td>The IEEE Global Initiative has established eth...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How does ChatGPT usage relate to the implement...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nThis is consistent with the fact ...</td>\n",
       "      <td>ChatGPT usage is primarily focused on providin...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How has the global diffusion of ChatGPT contri...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nNBER WORKING PAPER SERIES\\nHOW PE...</td>\n",
       "      <td>The global diffusion of ChatGPT has been unpre...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How does the establishment of a federal AI adv...</td>\n",
       "      <td>['&lt;1-hop&gt;\\n\\nAI will reconfigure how society a...</td>\n",
       "      <td>The establishment of a federal AI advisory com...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "5  What trends in user demographics and interacti...   \n",
       "6  How AI ethical guidelines help in economic ben...   \n",
       "7  How does ChatGPT usage relate to the implement...   \n",
       "8  How has the global diffusion of ChatGPT contri...   \n",
       "9  How does the establishment of a federal AI adv...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "5  ['<1-hop>\\n\\n6 Who Uses ChatGPT\\nIn this secti...   \n",
       "6  ['<1-hop>\\n\\nIn the same vein, the IEEE Global...   \n",
       "7  ['<1-hop>\\n\\nThis is consistent with the fact ...   \n",
       "8  ['<1-hop>\\n\\nNBER WORKING PAPER SERIES\\nHOW PE...   \n",
       "9  ['<1-hop>\\n\\nAI will reconfigure how society a...   \n",
       "\n",
       "                                           reference  \\\n",
       "5  By mid-2025, it is expected that the demograph...   \n",
       "6  The IEEE Global Initiative has established eth...   \n",
       "7  ChatGPT usage is primarily focused on providin...   \n",
       "8  The global diffusion of ChatGPT has been unpre...   \n",
       "9  The establishment of a federal AI advisory com...   \n",
       "\n",
       "                       synthesizer_name  \n",
       "5  multi_hop_specific_query_synthesizer  \n",
       "6  multi_hop_abstract_query_synthesizer  \n",
       "7  multi_hop_abstract_query_synthesizer  \n",
       "8  multi_hop_abstract_query_synthesizer  \n",
       "9  multi_hop_abstract_query_synthesizer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and analyze results from the advanced branching pipeline\n",
    "advanced_test_file = \"data_for_eval/synthetic_tests_advanced_branching.csv\"\n",
    "\n",
    "if os.path.exists(advanced_test_file):\n",
    "    advanced_tests_df = pd.read_csv(advanced_test_file)\n",
    "\n",
    "    display(advanced_tests_df.head())\n",
    "    display(advanced_tests_df.tail())\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Synthetic test file not found\")\n",
    "    print(\"Please run the previous cells to generate the test data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d8b91f",
   "metadata": {},
   "source": [
    "## Summary and Architecture Analysis\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "In this notebook, we've built increasingly sophisticated branching pipelines:\n",
    "\n",
    "1. **Basic Branching Pipeline**: PDF + Web content processing  \n",
    "2. **Production-Ready Pipeline**: Enhanced error handling and monitoring\n",
    "\n",
    "### Key Architectural Benefits\n",
    "\n",
    "1. **Modularity**: Each component has a single responsibility and can be reused\n",
    "2. **Flexibility**: Easy to add new input types (CSV, Word docs, etc.) \n",
    "3. **Scalability**: DocumentJoiner allows processing multiple sources simultaneously\n",
    "4. **Consistency**: Same processing logic regardless of input source\n",
    "5. **Error Isolation**: Problems with one input source don't affect others\n",
    "\n",
    "### Production Considerations\n",
    "\n",
    "**Advantages of Branching Pipelines:**\n",
    "- **Unified Output**: Single knowledge graph and test dataset from multiple sources\n",
    "- **Rich Context**: Cross-referencing information between different document types\n",
    "- **Operational Efficiency**: One pipeline deployment handles multiple scenarios\n",
    "- **Quality Improvement**: More diverse training data leads to better synthetic questions\n",
    "\n",
    "**When to Use Branching Pipelines:**\n",
    "- Processing heterogeneous document collections\n",
    "- Building comprehensive knowledge bases from multiple sources\n",
    "- Creating robust test datasets that cover various content types\n",
    "- Implementing production pipelines that need input flexibility\n",
    "\n",
    "\n",
    "### Extension Patterns\n",
    "\n",
    "To add new input types:\n",
    "1. Add MIME type to `FileTypeRouter`\n",
    "2. Create appropriate converter component\n",
    "3. Connect converter to `DocumentJoiner`\n",
    "4. No changes needed to downstream processing!\n",
    "\n",
    "This modular approach makes the pipeline highly maintainable and extensible for future requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a4e993",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-with-haystack-ch5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
