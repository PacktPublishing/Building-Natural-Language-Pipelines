user_input,reference_contexts,reference,synthesizer_name
Who is Kevin Wadman and what role does he play in the context of the NBER working paper on how people use ChatGPT?,"['NBER WORKING PAPER SERIES\nHOW PEOPLE USE CHATGPT\nAaron Chatterji\nThomas Cunningham\nDavid J. Deming\nZoe Hitzig\nChristopher Ong\nCarl Yan Shan\nKevin Wadman\nWorking Paper 34255\nhttp://www.nber.org/papers/w34255\nNATIONAL BUREAU OF ECONOMIC RESEARCH\n1050 Massachusetts Avenue\nCambridge, MA 02138\nSeptember 2025\nWe acknowledge help and comments from Joshua Achiam, Hemanth Asirvatham, Ryan Beiermeister, Rachel Brown, Cassandra Duchan Solis, Jason Kwon, Elliott Mokski, Kevin Rao, Harrison Satcher, Gawesha Weeratunga, Hannah Wong, and Analytics & Insights team. We especially thank Tyna Eloundou and Pamela Mishkin who in several ways laid the foundation for this work. This study was approved by Harvard IRB (IRB25-0983). A repository containing all code run to produce the analyses in this paper is available on request. The views expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.\nAt least one co-author has disclosed additional relationships of potential relevance for this research. Further information is available online at http://www.nber.org/papers/w34255\nNBER working papers are circulated for discussion and comment purposes. They have not been peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies official NBER publications.\n© 2025 by Aaron Chatterji, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl Yan Shan, and Kevin Wadman. All rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including © notice, is given to the source.\x0cHow People Use ChatGPT\nAaron Chatterji, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl\nYan Shan, and Kevin Wadman\nNBER Working Paper No. 34255\nSeptember 2025\nJEL No. J01, O3, O4\nABSTRACT\nDespite the rapid adoption of LLM chatbots, little is known about how they are used. We document the growth of ChatGPT’s consumer product from its launch in November 2022 through July 2025, when it had been adopted by around 10% of the world’s adult population. Early adopters were disproportionately male but the gender gap has narrowed dramatically, and we find higher growth rates in lower-income countries. Using a privacy-preserving automated pipeline, we classify usage patterns within a representative sample of ChatGPT conversations. We find steady growth in work-related messages bu t even faster growth in non-work-related messages, which have grown from 53% to more than 70% of all usage. Work usage is more common for educated users in highly-paid professional occupations. We classify messages by conversation top\nic and find that “Practical Guidance,” “Seeking Information,” and “Writing” are the three most common topics and collectively account for nearly 80% of all conversations. Writing dominates work-related tasks, highlighting chatbots’ unique ability to generate digital outputs compared to traditional sear ch engines. Computer programming and self-expression both represent relatively small shares of use. Overall, we find that ChatGPT provides economic value through decision support, which is especially important in knowledge-intensive jobs.\nAaron Chatterji\nDuke University\nFuqua School of Business and OpenAI\nronnie@duke.edu\nThomas Cunningham OpenAI\ntom.cunningham@gmail.com\nDavid J. Deming\nHarvard University\nHarvard Kennedy School and NBER\ndavid_deming@harvard.edu\nZoe Hitzig\nOpenAI\nand Harvard Society of Fellows\nzhitzig@g.harvard.edu\nChristopher Ong\nHarvard University\nand OpenAI\nchristopherong@hks.harvard.edu\nCarl Yan Shan\nOpenAI\ncshan@openai.com\nKevin Wadman\nOpenAI\nkevin.wadman@c-openai.com\x0c']",Kevin Wadman is one of the co-authors of the NBER working paper titled 'How People Use ChatGPT.' The paper documents the growth of ChatGPT's consumer product and analyzes usage patterns within a representative sample of ChatGPT conversations.,single_hop_specific_query_synthesizer
When did ChatGPT launch and how many users did it have by July 2025?,"['ABSTRACT Despite the rapid adoption of LLM chatbots, little is known about how they are used. We document the growth of ChatGPT’s consumer product from its launch in November 2022 through July 2025, when it had been adopted by around 10% of the world’s adult population. Early adopters were disproportionately male but the gender gap has narrowed dramatically, and we find higher growth rates in lower-income countries. Using a privacy-preserving automated pipeline, we classify usage patterns within a representative sample of ChatGPT conversations. We find steady growth in work-related messages bu t even faster growth in non-work-related messages, which have grown from 53% to more than 70% of all usage. Work usage is more common for educated users in highly-paid professional occupations. We classify messages by conversation top ic and find that “Practical Guidance,” “Seeking Information,” and “Writing” are the three most common topics and collectively account for nearly 80% of all conversations. Writing dominates work-related tasks, highlighting chatbots’ unique ability to generate digital outputs compared to traditional sear ch engines. Computer programming and self-expression both represent relatively small shares of use. Overall, we find that ChatGPT provides economic value through decision support, which is especially important in knowledge-intensive jobs. Aaron Chatterji Duke University Fuqua School of Business and OpenAI ronnie@duke.edu Thomas Cunningham OpenAI tom.cunningham@gmail.com David J. Deming Harvard University Harvard Kennedy School and NBER david_deming@harvard.edu Zoe Hitzig OpenAI and Harvard Society of Fellows zhitzig@g.harvard.edu Christopher Ong Harvard University and OpenAI christopherong@hks.harvard.edu Carl Yan Shan OpenAI cshan@openai.com Kevin Wadman OpenAI kevin.wadman@c-openai.com 1 Introduction ChatGPT launched in November 2022. By July 2025, 18 billion messages were being sent each week by 700 million users, representing around 10% of the global adult population. 1 For a new technology, this speed of global diffusion has no precedent (Bick et al., 2024). This paper studies consumer usage of ChatGPT, the first mass-market chatbot and likely the largest.2 ChatGPT is based on a Large Language Model (LLM), a type of Artificial Intelligence (AI) developed over the last decade and generally considered to represent an acceleration in AI capabilities.3 The sudden growth in LLM abilities and adoption has intensified interest in the effects of artificial intelligence on economic growth (Acemoglu, 2024; Korinek and Suh, 2024); employment (Eloundou et al., 2025); and society (Kulveit et al., 2025). However, despite the rapid adoption of LLMs, there is limited public information on how they are used. A number of surveys have measured self-reported adoption of LLMs (Bick et al., 2024; Pew Research Center, 2025); however there are reasons to expect bias in self-reports (Ling and Imas, 2025), and none of these papers have been able to directly track the quantity or nature of chatbot conversations. Two recent papers do report statistics on chatbot conversations, classified in a variety of ways (Handa et al., 2025; Tomlinson et al., 2025). We build on this work in several respects. First, the pool of users on ChatGPT is far larger, meaning we expect our data to be a closer approximation to the average chatbot user.4 Second, we use automated classifiers to report on the types of messages that users send using new classification taxonomies relative to the existing literature. Third, we report the diffusion of chatbot use across populations and the growth of different types of usage within cohorts. Fourth, we use a secure data clean room protocol to analyze aggregated employment and education categories for a sample of our users, lending new insights about differences in the types of messages sent by different groups while protecting user privacy. Our primary sample is a random selection of messages sent to ChatGPT on consumer plans (Free, Plus, Pro) between May 2024 and June 2025. 5 Messages from the user to chatbot are classified automatically using a number of different taxonomies: whether the message is used for paid work, the topic of conversation, and the type of interaction (asking, doing, or expressing), and the O*NET task the user is performing. Each taxonomy is defined in a prompt passed to an LLM, allowing us']","ChatGPT launched in November 2022. By July 2025, it had 700 million users, representing around 10% of the global adult population.",single_hop_specific_query_synthesizer
What info in Appendix B?,"['to classify messages without any human seeing them. We give the text of most prompts in Appendix A along with details about how the prompts were validated in Appendix B.6 The classification pipeline is protected by a series of privacy measures, detailed below, to ensure no leakage of sensitive information during the automated analysis. In a secure data clean room, we relate taxonomies of messages to aggregated employment and education categories. Table 1 shows the growth in total message volume for work and non-work usage. Both types of 1Reuters (2025), Roth (2025) 2Bick et al. (2024) report that 28% of US adults used ChatGPT in late 2024, higher than any other chatbot. 3We use the term LLM loosely here and give more details in the following section. 4Wiggers (2025) reports estimates that in April 2025 ChatGPT was receiving more than 10 times as many visitors as either Claude or Copilot. 5Our sample includes the three consumer plans (Free, Plus, or Pro). OpenAI also offers a variety of other ChatGPT plans (Business fka. Teams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day.']",Appendix B contains details about how the prompts were validated.,single_hop_specific_query_synthesizer
"What are the primary functions of ChatGPT usage at work, and how do these functions relate to the O*NET Work Activities taxonomy?","['<1-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.', '<2-hop>\n\nOverall, the majority of ChatGPT usage\nat work appears to be focused on two broad functions: 1) obtaining, documenting, and interpreting\ninformation; and 2) making decisions, giving advice, solving problems, and thinking creatively.\n20\x0cFigure 14:GWA Shares of 1.1M ChatGPT Messages. Messages are classified as pertaining to one of 332\nO*NET IWAs, orAmbiguoususing the prompt provided in the Appendix. IWAs were then aggregated to\nGWAs using the O*NET Work Activities taxonomy. Message sample from May 15, 2024 through June 26,\n2025. We do not show the shares for the following GWAs as there were fewer than 100 users sending messages\nfor each category and group them intoSuppressed.\n21\x0cFigure 15:GWA Shares of approximately 366,000 Work-Classified Messages. Messages are classified as\npertaining to one of 332 O*NET IWAs orAmbiguous. IWAs were then aggregated to GWAs using the\nO*NET Work Activities taxonomy. Messages were also additionally classified as pertaining to work or non-\nwork. GWA shares are shown only for work-classified messages. Message sample from May 15, 2024 through\nJune 26, 2025. We do not show the shares for the following GWAs as there were fewer than 100 users sending\nmessages for each category and group them intoSuppressed. Prompts are provided in the Appendix.\n22\x0c']","The primary functions of ChatGPT usage at work are focused on two broad activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. These functions align with the O*NET Work Activities taxonomy, which categorizes work-related messages into specific job characteristics. The majority of work-related messages sent via ChatGPT are associated with these activities, indicating that information-seeking and decision support are the most common use cases across various occupations.",multi_hop_specific_query_synthesizer
"What are the trends in user satisfaction regarding Technical Help interactions with ChatGPT, and how do these trends vary by education level?","['<1-hop>\n\n37% of messages are work-related\nfor users with less than a bachelor’s degree, compared to 46% for users with exactly a bachelor’s\ndegree and 48% for those with some graduate education. Those differences are cut roughly in half\nafter adjusting for other characteristics, but they are still statistically significant at the less than 1\npercent level. Educated users are more likely to send work-related messages.\nPanel B explores variation by education in user intent.Askingconstitutes about 49% of messages\nfor users with less than a bachelor’s degree, with little variation for more educated users. After\nregression adjustment, we find that users with a graduate degree are about two percentage points\nmore likely to use ChatGPT forAskingmessages, a difference that is statistically significant at the\n5% level. Prior to regression adjustment, the frequency ofDoingmessages is increasing in education.\nHowever, this pattern reverses after adjusting for other characteristics such as occupation. Users with\na graduate degree are about 1.6 percentage points less likely to sendDoingmessages than users with\nless than a bachelor’s degree, and the difference is statistically significant at the 10% level.\nPanel C studies variation by education in the frequency of four different conversation topics –\nPractical Guidance,Seeking Information,Technical Help, andWriting. We find only modest differ-\nences by education across most of these categories. The one exception is that the share of messages\nrelated toWritingis increasing in relation to education.\n28\x0cPanel A.Work Related\nPanel B1.Asking. Panel B2.Doing.\nPanel B3.Expressing.\nFigure 22:(continued on next page)\n29\x0cPanel C1.Writing. Panel C2.Technical Help.\nPanel C3.Seeking Information. Panel C4.Practical Guidance.\nFigure 22:Variation in ChatGPT usage by education. Each plot shows unadjusted vs. regression-adjusted\nestimates, with 95% confidence intervals. We regress each message share on education and occupation, control-\nling for the following covariates: age, whether the name was typically masculine or feminine, seniority within\nrole, company size, and industry. (To guarantee user privacy, we coarsen all covariates to broad categories and\nprogrammatically enforce that each group has at least 100 members prior to running the regression) We add\nthe coefficients on each education and occupation category to the unadjusted value for the reference category\nand compute 95% confidence intervals using the standard errors from the regression coefficients. The sample\nfor this regression is the approximately 40,000 users of the original 130,000 sample whose publicly available\noccupation was not blank or consisted of strictly special characters (as determined by a classification script).\nShares for each user are calculated by randomly sampling up to six conversations attributed to the user from\nMay 2024 through July 2025.\n30\x0c', '<2-hop>\n\n5.5 Quality of Interactions\nWe additionally used automated classifiers to study the user’s apparent satisfaction with the chatbot’s\nresponse to their request. OurInteraction Qualityclassifier looks for an expression of satisfaction or\ndissatisfaction in the user’s subsequent message in the same conversation (if one exists), with three\npossible categories:Good,Bad, andUnknown. 23\nFigure 16 plots the overall growth of messages in these three buckets. In late 2024Goodinteractions\nwere about three times as common asBadinteractions, butGoodinteractions grew much more rapidly\nover the next nine months, and by July 2025 they were more than four times more common.\nFigure 16:Interaction quality shares, based on automated sentiment analysis of thenext responseprovided\nby the user. See Appendix B to understand how this classifier was validated. Values are averaged over a 28\nday lagging window. Shares are calculated from a sample of approximately 1.1 million sampled conversations\nfrom May 15, 2024 through June 26, 2025. Observations are reweighted to reflect total message volumes on a\ngiven day. Sampling details available in Section 3.\nDetails on the validation of this classifier, along with measurements of how it correlates with\nexplicit thumbs up/thumbs down annotations from users, are included in Appendix B.\nFigure 17 shows the ratio of good-to-bad messages by conversation topic and interaction type, as\nrated by Interaction Quality. Panel A shows thatSelf-Expressionis the highest rated topic, with a\ngood-to-bad ratio of more than seven, consistent with the growth in this category.Multimediaand\nTechnical Helphave the lowest good-to-bad ratios (1.7 and 2.7 respectively). Panel B shows that\nAskingmessages are substantially more likely to receive a good rating thanDoingorExpressing\nmessages.\n23For this classifier we do not disclose the prompt.\n23\x0cFigure 17:AverageGoodtoBadratio for user interactions by Conversation Topic (Panel A) and Ask-\ning/Doing/Expressing classification (Panel B). The prompts for each of these automated classifiers (with the\nexception of interaction quality) are available in Appendix A. Values represent the average ratio from May 15,\n2024 through June 26, 2025, where observations are reweighted to reflect total message volumes on a given\nday. Sampling details available in Section 3.\n24\x0c']","The trends in user satisfaction regarding Technical Help interactions with ChatGPT indicate that the quality of interactions has been improving over time. In late 2024, Good interactions were about three times as common as Bad interactions, and by July 2025, Good interactions were more than four times more common. However, Technical Help had one of the lowest good-to-bad ratios at 2.7, suggesting that while there is an overall increase in satisfaction, the quality of Technical Help interactions may not be as high as other categories. Additionally, the context indicates that educated users are more likely to engage in work-related messages, which may influence their expectations and satisfaction levels when seeking Technical Help.",multi_hop_specific_query_synthesizer
"In 2025, how does the usage of ChatGPT differ between users with typically feminine names and those with typically masculine names, especially in terms of message types and work-related content?","['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nHowever, in the first half of 2025, we see the share of active users with typically feminine and typically\nmasculine names reach near-parity. By June 2025 we observe active users are more likely to have\ntypically feminine names. This suggests that gender gaps in ChatGPT usage have closed substantially\nover time.\nWe also study differences in usage topics. Users with typically female first names are relatively more\nlikely to send messages related toWritingandPractical Guidance. By contrast, users with typically\nmale first names are more likely to use ChatGPT forTechnical Help,Seeking Out Information, and\nMultimedia(e.g., modifying or creating images).\n 6.2 Variation by Age\nA subset of users self-report their age when registering for OpenAI. Among those who self-report their\nage, around 46% of the messages in our dataset are accounted for by users 18-25.\nA higher share of messages are work-related for older users. Work-related messages comprised\napproximately 23% of messages for users under age 26, with this share increasing with age. The\none exception is users who self-attest to being 66 years-old or older, with only 16% of their classified\nmessages being work-related. The plot below shows trends in the share of work-related messages by\nage group. ChatGPT usage has become less work-related over time for users of all ages.\n25\x0cFigure 18:Breakdown of weekly active users by typically masculine and typically feminine first names. We\ndraw on a uniform sample of 1.1M ChatGPT accounts, subject to the same user exclusion principles as other\ndatasets we analyze. Note that this is a separate sample than those described in Section 3. First names\nare classified as typically masculine or typically feminine using public aggregated datasets of name-gender\nassociations.\nFigure 19:Difference in share of topic prevalence in messages by users with typically masculine/feminine\nfirst name. We draw on a uniform sample of 1.1M ChatGPT accounts, subject to the same user exclusion\nprinciples as other datasets we analyze. Note that this is a separate sample than those described in Section\n3. First names are classified as typically masculine or typically feminine using public aggregated datasets\nof name-gender associations. Topics are aggregated groupings from a classifier whose prompt we provide in\nAppendix A.\n26\x0cFigure 20:Likelihood that a message is work related, conditioned on self-reported user age. Messages are\nidentified as work related using an automated classifier. As with our other samples (see Section 3), users who\nself-report an age under 18 are excluded from analysis. Values are averaged over a 28 day lagging window.\nShares are calculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024\nthrough June 26, 2025. Observations are reweighted to reflect total message volumes on a given day.\n']","In 2025, users with typically feminine names are relatively more likely to send messages related to Writing and Practical Guidance, while users with typically masculine names are more inclined to use ChatGPT for Technical Help, Seeking Out Information, and Multimedia tasks. Additionally, the share of work-related messages varies by age, with older users having a higher proportion of work-related messages. For users under age 26, work-related messages comprised approximately 23%, which increases with age, except for users aged 66 and older, who had only 16% of their messages classified as work-related. Overall, ChatGPT usage has become less work-related over time for users of all ages.",multi_hop_specific_query_synthesizer
"What are the primary conversation topics users engage with ChatGPT for, and how do these relate to user intent in educational contexts?","['<1-hop>\n\nFigure 9 disaggregates four of the seven Conversation Topics into smaller groups and sums up\nmessages of each type over a one-year period. For example, the five sub-categories withinWriting\nare (in order of frequency)Editing or Critiquing Provided Text,Personal Writing or Communication,\nTranslation,Argument or Summary Generation, andWriting Fiction. Three of those five categories\n(Editing or Critiquing Provided Text,Translation, andArgument or Summary Generation) are re-\nquests to modify text that has been provided to ChatGPT by the user, whereas the other two are\nrequests to produce novel text. The former constitute two thirds of allWritingconversations, which\n14\x0cFigure 7:Share of consumer ChatGPT messages broken down by high level conversation topic, according\nto the mapping in Table 3. Values are averaged over a 28 day lagging window. Shares are calculated from\na sample of approximately 1.1 million sampled conversations from May 15, 2024 through June 26, 2025.\nObservations are reweighted to reflect total message volumes on a given day. Sampling details available in\nSection 3.\nFigure 8:Share ofwork relatedconsumer ChatGPT messages broken down by high level conversation\ntopic, according to the mapping in Table 3. Values are averaged over a 28 day lagging window. Shares are\ncalculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024 through June\n26, 2025. Observations are reweighted to reflect total message volumes on a given day. Sampling details\navailable in Section 3.\n15\x0csuggests that most userWritingconversations with ChatGPT are requests to modify user inputs\nrather than to create something new. Education is a major use case for ChatGPT. 10.2% of all user\nmessages and 36% ofPractical Guidancemessages are requests forTutoring or Teaching. Another\nlarge share - 8.5% in total and 30% ofPractical Guidance- is general how-to advice on a variety\nof topics.Technical HelpincludesComputer Programming(4.2% of messages),Mathematical Calcu-\nlations(3%), andData Analysis(0.4%). Looking at the topic ofSelf-Expression, only 2.4% of all\nChatGPT messages are aboutRelationships and Personal Reflection(1.9%) orGames and Role Play\n(0.4%).\nWhile users can seek information and advice from traditional web search engines as well as from\nChatGPT, the ability to produce writing, software code, spreadsheets, and other digital products\ndistinguishes generative AI from existing technologies. ChatGPT is also more flexible than web\nsearch even for traditional applications likeSeeking InformationandPractical Guidance, because\nusers receive customized responses (e.g., tailored workout plans, new product ideas, ideas for fantasy\nfootball team names) that represent newly generated content or novel modification of user-provided\ncontent and follow-up requests.\nFigure 9:Breakdown of granular conversation topic shares within the coarse mapping defined in Table 3. The\nunderlying classifier prompt is available in Appendix A. Each bin reports a percentage of the total population.\nShares are calculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024\nthrough June 26, 2025. Observations are reweighted to reflect total message volumes on a given day. Sampling\ndetails available in Section 3.\n5.3 ', '<2-hop>\n\nUser Intent\nExisting studies of the economic impacts of generative AI focus almost exclusively on the potential\nfor AI to perform workplace tasks, either augmenting or automating human labor (e.g. Eloundou et\nal. (2025), Handa et al. (2025), Tomlinson et al. (2025)). However, generative AI is a highly flexible\n16\x0ctechnology that can be used in many different ways. In order to learn more about how people seek to\nuse generative AI at work and outside of work, we introduce a classifier that is designed to measure the\ntype of output the user hopes to receive. Specifically, we classify messages according to user intent,\ncoding up conversations according to a simple Asking,  Doing, or ', '<3-hop>\n\nBreakdown of Conversation Topics by Asking/Doing/Expressing category, with topic columns\nsorted by relative share of ”Doing” messages. Prompts for these automated classifiers are available in Appendix\nA. For a detailed breakdown of conversation topic contents, see Table 3. Each bin reports a percentage of\nthe total population. ']","Users primarily engage with ChatGPT for conversation topics related to Writing, where requests often involve modifying user inputs rather than creating new content. Specifically, 10.2% of all user messages and 36% of Practical Guidance messages are requests for Tutoring or Teaching. This indicates that educational contexts significantly influence user intent, as many users seek tailored advice and assistance in learning, which aligns with the flexible nature of generative AI.",multi_hop_abstract_query_synthesizer
"How did the usage patterns of ChatGPT evolve from its launch in November 2022 to July 2025, especially in terms of work-related and non-work-related messages, and what does this say about ChatGPT usage among different education levels and professions?","['<1-hop>\n\nNBER WORKING PAPER SERIES\nHOW PEOPLE USE CHATGPT\nAaron Chatterji\nThomas Cunningham\nDavid J. Deming\nZoe Hitzig\nChristopher Ong\nCarl Yan Shan\nKevin Wadman\nWorking Paper 34255\nhttp://www.nber.org/papers/w34255\nNATIONAL BUREAU OF ECONOMIC RESEARCH\n1050 Massachusetts Avenue\nCambridge, MA 02138\nSeptember 2025\nWe acknowledge help and comments from Joshua Achiam, Hemanth Asirvatham, Ryan Beiermeister, Rachel Brown, Cassandra Duchan Solis, Jason Kwon, Elliott Mokski, Kevin Rao, Harrison Satcher, Gawesha Weeratunga, Hannah Wong, and Analytics & Insights team. We especially thank Tyna Eloundou and Pamela Mishkin who in several ways laid the foundation for this work. This study was approved by Harvard IRB (IRB25-0983). A repository containing all code run to produce the analyses in this paper is available on request. The views expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.\nAt least one co-author has disclosed additional relationships of potential relevance for this research. Further information is available online at http://www.nber.org/papers/w34255\nNBER working papers are circulated for discussion and comment purposes. They have not been peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies official NBER publications.\n© 2025 by Aaron Chatterji, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl Yan Shan, and Kevin Wadman. All rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including © notice, is given to the source.\x0cHow People Use ChatGPT\nAaron Chatterji, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl\nYan Shan, and Kevin Wadman\nNBER Working Paper No. 34255\nSeptember 2025\nJEL No. J01, O3, O4\nABSTRACT\nDespite the rapid adoption of LLM chatbots, little is known about how they are used. We document the growth of ChatGPT’s consumer product from its launch in November 2022 through July 2025, when it had been adopted by around 10% of the world’s adult population. Early adopters were disproportionately male but the gender gap has narrowed dramatically, and we find higher growth rates in lower-income countries. Using a privacy-preserving automated pipeline, we classify usage patterns within a representative sample of ChatGPT conversations. We find steady growth in work-related messages bu t even faster growth in non-work-related messages, which have grown from 53% to more than 70% of all usage. Work usage is more common for educated users in highly-paid professional occupations. We classify messages by conversation top\nic and find that “Practical Guidance,” “Seeking Information,” and “Writing” are the three most common topics and collectively account for nearly 80% of all conversations. Writing dominates work-related tasks, highlighting chatbots’ unique ability to generate digital outputs compared to traditional sear ch engines. Computer programming and self-expression both represent relatively small shares of use. Overall, we find that ChatGPT provides economic value through decision support, which is especially important in knowledge-intensive jobs.\nAaron Chatterji\nDuke University\nFuqua School of Business and OpenAI\nronnie@duke.edu\nThomas Cunningham OpenAI\ntom.cunningham@gmail.com\nDavid J. Deming\nHarvard University\nHarvard Kennedy School and NBER\ndavid_deming@harvard.edu\nZoe Hitzig\nOpenAI\nand Harvard Society of Fellows\nzhitzig@g.harvard.edu\nChristopher Ong\nHarvard University\nand OpenAI\nchristopherong@hks.harvard.edu\nCarl Yan Shan\nOpenAI\ncshan@openai.com\nKevin Wadman\nOpenAI\nkevin.wadman@c-openai.com\x0c', '<2-hop>\n\nABSTRACT Despite the rapid adoption of LLM chatbots, little is known about how they are used. We document the growth of ChatGPT’s consumer product from its launch in November 2022 through July 2025, when it had been adopted by around 10% of the world’s adult population. Early adopters were disproportionately male but the gender gap has narrowed dramatically, and we find higher growth rates in lower-income countries. Using a privacy-preserving automated pipeline, we classify usage patterns within a representative sample of ChatGPT conversations. We find steady growth in work-related messages bu t even faster growth in non-work-related messages, which have grown from 53% to more than 70% of all usage. Work usage is more common for educated users in highly-paid professional occupations. We classify messages by conversation top ic and find that “Practical Guidance,” “Seeking Information,” and “Writing” are the three most common topics and collectively account for nearly 80% of all conversations. Writing dominates work-related tasks, highlighting chatbots’ unique ability to generate digital outputs compared to traditional sear ch engines. Computer programming and self-expression both represent relatively small shares of use. Overall, we find that ChatGPT provides economic value through decision support, which is especially important in knowledge-intensive jobs. Aaron Chatterji Duke University Fuqua School of Business and OpenAI ronnie@duke.edu Thomas Cunningham OpenAI tom.cunningham@gmail.com David J. Deming Harvard University Harvard Kennedy School and NBER david_deming@harvard.edu Zoe Hitzig OpenAI and Harvard Society of Fellows zhitzig@g.harvard.edu Christopher Ong Harvard University and OpenAI christopherong@hks.harvard.edu Carl Yan Shan OpenAI cshan@openai.com Kevin Wadman OpenAI kevin.wadman@c-openai.com 1 Introduction ChatGPT launched in November 2022. By July 2025, 18 billion messages were being sent each week by 700 million users, representing around 10% of the global adult population. 1 For a new technology, this speed of global diffusion has no precedent (Bick et al., 2024). This paper studies consumer usage of ChatGPT, the first mass-market chatbot and likely the largest.2 ChatGPT is based on a Large Language Model (LLM), a type of Artificial Intelligence (AI) developed over the last decade and generally considered to represent an acceleration in AI capabilities.3 The sudden growth in LLM abilities and adoption has intensified interest in the effects of artificial intelligence on economic growth (Acemoglu, 2024; Korinek and Suh, 2024); employment (Eloundou et al., 2025); and society (Kulveit et al., 2025). However, despite the rapid adoption of LLMs, there is limited public information on how they are used. A number of surveys have measured self-reported adoption of LLMs (Bick et al., 2024; Pew Research Center, 2025); however there are reasons to expect bias in self-reports (Ling and Imas, 2025), and none of these papers have been able to directly track the quantity or nature of chatbot conversations. Two recent papers do report statistics on chatbot conversations, classified in a variety of ways (Handa et al., 2025; Tomlinson et al., 2025). We build on this work in several respects. First, the pool of users on ChatGPT is far larger, meaning we expect our data to be a closer approximation to the average chatbot user.4 Second, we use automated classifiers to report on the types of messages that users send using new classification taxonomies relative to the existing literature. Third, we report the diffusion of chatbot use across populations and the growth of different types of usage within cohorts. Fourth, we use a secure data clean room protocol to analyze aggregated employment and education categories for a sample of our users, lending new insights about differences in the types of messages sent by different groups while protecting user privacy. Our primary sample is a random selection of messages sent to ChatGPT on consumer plans (Free, Plus, Pro) between May 2024 and June 2025. 5 Messages from the user to chatbot are classified automatically using a number of different taxonomies: whether the message is used for paid work, the topic of conversation, and the type of interaction (asking, doing, or expressing), and the O*NET task the user is performing. Each taxonomy is defined in a prompt passed to an LLM, allowing us']","From its launch in November 2022 to July 2025, ChatGPT saw significant growth in usage patterns. By July 2025, it had been adopted by around 10% of the world's adult population, with a notable increase in non-work-related messages, which grew from 53% to more than 70% of all usage. In contrast, work-related messages were more common among educated users in highly-paid professional occupations. The three most common topics of conversation were 'Practical Guidance,' 'Seeking Information,' and 'Writing,' which collectively accounted for nearly 80% of all conversations. This indicates that while ChatGPT is utilized for professional tasks, its primary use has shifted towards personal and informal interactions, reflecting a broader trend in how LLM chatbots are integrated into daily life.",multi_hop_abstract_query_synthesizer
How do the trends in ChatGPT user cohorts relate to the classification of user messages as work-related or not?,"['<1-hop>\n\nThe yellow line represents the first cohort of ChatGPT users: their usage declined somewhat over\n2023, but started growing again in late 2024 and is now higher than it has ever been. The pink line\nrepresents messages from users who signed up in Q3 of 2023 or earlier, and so thedifferencebetween\n20Note that we expect our counts of distinct accounts to somewhat exceed distinct people when one person has two\naccounts (or, for logged-out users, one person using two devices). For logged-in users, the count is based on distinct\nlogin credentials (email addresses), and one person may have multiple accounts. For logged-out users, the count is based\non distinct browser cookies; this would double-count people if someone returns to ChatGPT after clearing their cookies,\nor if they access ChatGPT with two different devices in the same week.\n10\x0cFigure 4:Daily message volumes from ChatGPT consumer plans (Free, Plus, Pro), split by sign-up date of\nthe requesting user. Reported values are moving averages of the past 90 days. Y-axis is an index normalized\nto the reported value for ”All Cohorts” at the end of Q1 2024 (April 1, 2024).\nthe yellow and pink lines represents the messages sent by users who signed up in Q2 and Q3 of 2023.\nThere has been dramatic growth in message volume both by new cohorts of users, and from growth\nin existing cohorts.\nFigure 5 normalizes each cohort, plotting daily messages per weekly active user. Each line rep-\nresents an individual cohort (instead of a cumulative cohort, as in Figure 4). The figure shows that\nearlier sign-ups have consistently had higher usage, but that usage has also consistently grown within\nevery cohort, which we interpret as due to both (1) improvements in the capabilities of the models,\nand (2) users slowly discovering new uses for existing capabilities.\n5  How ChatGPT is Used\nWe next report on thecontentof ChatGPT conversations using a variety of different taxonomies. For\neach taxonomy we describe a “prompt” which defines a set of categories, and then apply an LLM\nto map each message to a category. Our categories often apply to the user’sintention, rather than\nthe text of the conversation, and as such we never directly observe the ground truth. Nevertheless\nthe classifier results can be interpreted as the best-guess inferences that a human would make: the\nguesses from the LLM correlate highly with human guesses from the same prompt, and we get similar\nqualitative results when the prompt includes a third category for “uncertain.”\n11\x0cFigure 5:Daily messages sent per weekly active user, split by sign-up cohort. Sample only considers users of\nChatGPT consumer plans (Free, Plus, Pro). Reported values are moving averages of the past 90 days and are\nreported starting 90 days after the cohort is fully formed. Y-axis is an index normalized to the first reported\nvalue for the Q1 2023 cohort.\n5.1 ', '<2-hop>\n\nWhat share of ChatGPT queries are related to paid work?\nWe label each user message in our dataset based on whether it appears to be related to work, using\nan LLM classifier. The critical part of the prompt is as follows: 21\nDoes the last user message of this conversation transcript seem likely to be related to doing\nsome work/employment? Answer with one of the following:\n(1) likely part of work (e.g., “rewrite this HR complaint”)\n(0) likely not part of work (e.g., “does ice reduce pimples?”)\nTable 1 shows that both types of queries grew rapidly between June 2024 and June 2025, however\nnon-work-related messages grew faster: 53% of messages were not related to work in June 2024, which\nclimbed to 73% by June 2025.\nFigure 6 plots the share of non-work messages decomposed by cumulative sign-up cohorts. Succes-\nsive cohorts have had a higher share of non-work messages, but also within each cohort their non-work\nuse has increased. Comparing the share among all users (black line) to the share among the earliest\ncohort of users (yellow line), we can see that they track very closely.\n21See Appendix A for the full prompt, see Appendix B for validation.\n12\x0cFigure 6:The solid black line represents the probability that a messages on a given day is not related to\nwork, as determined by an automated classifier. Values are averaged over a 28-day lagging window. The\ndotted orange line shows the same calculation, but conditioned on messages being from users who first used\nChatGPT during or before Q2 of 2024. The remaining lines are defined similarly for successive quarters, with\ncoloring cooling for more recent cohorts. Counts are calculated from a sample of approximately 1.1 million\nsampled conversations from May 15, 2024 through June 26, 2025. Observations are reweighted to reflect total\nmessage volumes on a given day. Sampling details available in Section 3.\n5.2 ']","The trends in ChatGPT user cohorts indicate that while both work-related and non-work-related messages grew rapidly between June 2024 and June 2025, non-work-related messages increased at a faster rate. Specifically, the share of non-work-related messages rose from 53% in June 2024 to 73% by June 2025. This growth in non-work-related messages was observed across different user cohorts, with newer cohorts showing a higher share of such messages, suggesting that as users discover new uses for ChatGPT, the nature of their interactions is shifting.",multi_hop_abstract_query_synthesizer
"What are the primary usage patterns of ChatGPT among different education levels and professions, particularly in relation to work-related tasks and the growth of LLM chatbots?","['<1-hop>\n\nNBER WORKING PAPER SERIES\nHOW PEOPLE USE CHATGPT\nAaron Chatterji\nThomas Cunningham\nDavid J. Deming\nZoe Hitzig\nChristopher Ong\nCarl Yan Shan\nKevin Wadman\nWorking Paper 34255\nhttp://www.nber.org/papers/w34255\nNATIONAL BUREAU OF ECONOMIC RESEARCH\n1050 Massachusetts Avenue\nCambridge, MA 02138\nSeptember 2025\nWe acknowledge help and comments from Joshua Achiam, Hemanth Asirvatham, Ryan Beiermeister, Rachel Brown, Cassandra Duchan Solis, Jason Kwon, Elliott Mokski, Kevin Rao, Harrison Satcher, Gawesha Weeratunga, Hannah Wong, and Analytics & Insights team. We especially thank Tyna Eloundou and Pamela Mishkin who in several ways laid the foundation for this work. This study was approved by Harvard IRB (IRB25-0983). A repository containing all code run to produce the analyses in this paper is available on request. The views expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.\nAt least one co-author has disclosed additional relationships of potential relevance for this research. Further information is available online at http://www.nber.org/papers/w34255\nNBER working papers are circulated for discussion and comment purposes. They have not been peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies official NBER publications.\n© 2025 by Aaron Chatterji, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl Yan Shan, and Kevin Wadman. All rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including © notice, is given to the source.\x0cHow People Use ChatGPT\nAaron Chatterji, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl\nYan Shan, and Kevin Wadman\nNBER Working Paper No. 34255\nSeptember 2025\nJEL No. J01, O3, O4\nABSTRACT\nDespite the rapid adoption of LLM chatbots, little is known about how they are used. We document the growth of ChatGPT’s consumer product from its launch in November 2022 through July 2025, when it had been adopted by around 10% of the world’s adult population. Early adopters were disproportionately male but the gender gap has narrowed dramatically, and we find higher growth rates in lower-income countries. Using a privacy-preserving automated pipeline, we classify usage patterns within a representative sample of ChatGPT conversations. We find steady growth in work-related messages bu t even faster growth in non-work-related messages, which have grown from 53% to more than 70% of all usage. Work usage is more common for educated users in highly-paid professional occupations. We classify messages by conversation top\nic and find that “Practical Guidance,” “Seeking Information,” and “Writing” are the three most common topics and collectively account for nearly 80% of all conversations. Writing dominates work-related tasks, highlighting chatbots’ unique ability to generate digital outputs compared to traditional sear ch engines. Computer programming and self-expression both represent relatively small shares of use. Overall, we find that ChatGPT provides economic value through decision support, which is especially important in knowledge-intensive jobs.\nAaron Chatterji\nDuke University\nFuqua School of Business and OpenAI\nronnie@duke.edu\nThomas Cunningham OpenAI\ntom.cunningham@gmail.com\nDavid J. Deming\nHarvard University\nHarvard Kennedy School and NBER\ndavid_deming@harvard.edu\nZoe Hitzig\nOpenAI\nand Harvard Society of Fellows\nzhitzig@g.harvard.edu\nChristopher Ong\nHarvard University\nand OpenAI\nchristopherong@hks.harvard.edu\nCarl Yan Shan\nOpenAI\ncshan@openai.com\nKevin Wadman\nOpenAI\nkevin.wadman@c-openai.com\x0c', '<2-hop>\n\nABSTRACT Despite the rapid adoption of LLM chatbots, little is known about how they are used. We document the growth of ChatGPT’s consumer product from its launch in November 2022 through July 2025, when it had been adopted by around 10% of the world’s adult population. Early adopters were disproportionately male but the gender gap has narrowed dramatically, and we find higher growth rates in lower-income countries. Using a privacy-preserving automated pipeline, we classify usage patterns within a representative sample of ChatGPT conversations. We find steady growth in work-related messages bu t even faster growth in non-work-related messages, which have grown from 53% to more than 70% of all usage. Work usage is more common for educated users in highly-paid professional occupations. We classify messages by conversation top ic and find that “Practical Guidance,” “Seeking Information,” and “Writing” are the three most common topics and collectively account for nearly 80% of all conversations. Writing dominates work-related tasks, highlighting chatbots’ unique ability to generate digital outputs compared to traditional sear ch engines. Computer programming and self-expression both represent relatively small shares of use. Overall, we find that ChatGPT provides economic value through decision support, which is especially important in knowledge-intensive jobs. Aaron Chatterji Duke University Fuqua School of Business and OpenAI ronnie@duke.edu Thomas Cunningham OpenAI tom.cunningham@gmail.com David J. Deming Harvard University Harvard Kennedy School and NBER david_deming@harvard.edu Zoe Hitzig OpenAI and Harvard Society of Fellows zhitzig@g.harvard.edu Christopher Ong Harvard University and OpenAI christopherong@hks.harvard.edu Carl Yan Shan OpenAI cshan@openai.com Kevin Wadman OpenAI kevin.wadman@c-openai.com 1 Introduction ChatGPT launched in November 2022. By July 2025, 18 billion messages were being sent each week by 700 million users, representing around 10% of the global adult population. 1 For a new technology, this speed of global diffusion has no precedent (Bick et al., 2024). This paper studies consumer usage of ChatGPT, the first mass-market chatbot and likely the largest.2 ChatGPT is based on a Large Language Model (LLM), a type of Artificial Intelligence (AI) developed over the last decade and generally considered to represent an acceleration in AI capabilities.3 The sudden growth in LLM abilities and adoption has intensified interest in the effects of artificial intelligence on economic growth (Acemoglu, 2024; Korinek and Suh, 2024); employment (Eloundou et al., 2025); and society (Kulveit et al., 2025). However, despite the rapid adoption of LLMs, there is limited public information on how they are used. A number of surveys have measured self-reported adoption of LLMs (Bick et al., 2024; Pew Research Center, 2025); however there are reasons to expect bias in self-reports (Ling and Imas, 2025), and none of these papers have been able to directly track the quantity or nature of chatbot conversations. Two recent papers do report statistics on chatbot conversations, classified in a variety of ways (Handa et al., 2025; Tomlinson et al., 2025). We build on this work in several respects. First, the pool of users on ChatGPT is far larger, meaning we expect our data to be a closer approximation to the average chatbot user.4 Second, we use automated classifiers to report on the types of messages that users send using new classification taxonomies relative to the existing literature. Third, we report the diffusion of chatbot use across populations and the growth of different types of usage within cohorts. Fourth, we use a secure data clean room protocol to analyze aggregated employment and education categories for a sample of our users, lending new insights about differences in the types of messages sent by different groups while protecting user privacy. Our primary sample is a random selection of messages sent to ChatGPT on consumer plans (Free, Plus, Pro) between May 2024 and June 2025. 5 Messages from the user to chatbot are classified automatically using a number of different taxonomies: whether the message is used for paid work, the topic of conversation, and the type of interaction (asking, doing, or expressing), and the O*NET task the user is performing. Each taxonomy is defined in a prompt passed to an LLM, allowing us', '<3-hop>\n\n5.4 O*NET Work Activities\nWe map message content to work activities using the Occupational Information Network (O*NET)\nDatabase Version 29.0, similar to Tomlinson et al (2025). O*NET was developed in partnership with\nthe U.S. Department of Labor and systematically classifies jobs according to the skills, tasks, and\nwork activities required to perform them. O*NET associates each occupation with a set of tasks that\nare performed at different levels of intensity. Each task is then aggregated up to three levels of detail\n- 2,087 detailed work activities (DWAs), 332 intermediate work activities (IWAs), and 41 generalized\nwork activities (GWAs).\nTo understand the work activities associated with ChatGPT usage, we mapped messages to one\nof the 332 O*NET Intermediate Work Activities (IWA), with an additional option ofAmbiguousto\naccount for situations where the user message lacked sufficient context. 22 We then used the official\n22We drew a sample of approximately 1.1 million conversations from May 2024 to June 2025, selected a random\nmessage within each, and classified it according to the prompt in A.\n19\x0cFigure 13:Shares of Asking, Doing, and Expressing messages split by work vs. non-work. See A to review\nthe prompts used by the automated classifiers. The annotations on the right show the shares of work and\nnon-work for the full sample. Each bin reports a percentage of the total population. Shares are calculated\nfrom a sample of approximately 1.1 million sampled conversations from May 15, 2024 through June 26, 2025.\nObservations are reweighted to reflect total message volumes on a given day. Sampling details available in\nSection 3.\nO*NET taxonomy to map these classified IWAs to one of the Generalized Work Activities (GWA). We\ndo not show the shares for the following GWAs as there were fewer than 100 users sending messages\nfor each category and group them intoSuppressed.\n Figure 14 presents the share of messages that belong to each GWA, in descending order. Nearly\nhalf of all messages (45.2%) fall under just three GWAs related to information use and manipula-\ntion:Getting Information(19.3%),Interpreting the Meaning of Information for Others(13.1%), and\nDocumenting/Recording Information(12.8%). The next most common work activities areProviding\nConsultation and Advice(9.2%),Thinking Creatively(9.1%),Making Decisions and Solving Problems\n(8.5%), andWorking with Computers(4.9%). These seven GWAs collectively account for 76.9% of\nall messages.\nFigure 15 presents the distribution of GWAs for the subsample of messages we classify as work-\nrelated. Among work-related messages, the most common GWAs areDocumenting/Recording In-\nformation(18.4%),Making Decisions and Solving Problems(14.9%),Thinking Creatively(13.0%),\nWorking with Computers(10.8%),Interpreting the Meaning of Information for Others(10.1%),Get-\nting Information(9.3%), andProviding Consultation and Advice to Others(4.4%). These seven GWAs\ncollectively account for nearly 81% of work-related messages. Overall, the majority of ChatGPT usage\nat work appears to be focused on two broad functions: 1) obtaining, documenting, and interpreting\ninformation; and 2) making decisions, giving advice, solving problems, and thinking creatively.\n20\x0cFigure 14:GWA Shares of 1.1M ChatGPT Messages. Messages are classified as pertaining to one of 332\nO*NET IWAs, orAmbiguoususing the prompt provided in the Appendix. IWAs were then aggregated to\nGWAs using the O*NET Work Activities taxonomy. Message sample from May 15, 2024 through June 26,\n2025. ']","The primary usage patterns of ChatGPT reveal that work-related messages are more common among educated users in highly-paid professional occupations. The study documents that while there has been steady growth in work-related messages, there is even faster growth in non-work-related messages, which have increased from 53% to more than 70% of all usage. The most common topics of conversation include 'Practical Guidance,' 'Seeking Information,' and 'Writing,' which collectively account for nearly 80% of all conversations. Writing, in particular, dominates work-related tasks, showcasing the unique ability of chatbots to generate digital outputs compared to traditional search engines. This indicates that ChatGPT provides significant economic value through decision support, especially in knowledge-intensive jobs, reflecting the broader trends in the adoption of LLM chatbots.",multi_hop_abstract_query_synthesizer
"What are the main conversation topics users engage with ChatGPT for, and how do these relate to user intent in educational contexts?","['<1-hop>\n\nFigure 9 disaggregates four of the seven Conversation Topics into smaller groups and sums up\nmessages of each type over a one-year period. For example, the five sub-categories withinWriting\nare (in order of frequency)Editing or Critiquing Provided Text,Personal Writing or Communication,\nTranslation,Argument or Summary Generation, andWriting Fiction. Three of those five categories\n(Editing or Critiquing Provided Text,Translation, andArgument or Summary Generation) are re-\nquests to modify text that has been provided to ChatGPT by the user, whereas the other two are\nrequests to produce novel text. The former constitute two thirds of allWritingconversations, which\n14\x0cFigure 7:Share of consumer ChatGPT messages broken down by high level conversation topic, according\nto the mapping in Table 3. Values are averaged over a 28 day lagging window. Shares are calculated from\na sample of approximately 1.1 million sampled conversations from May 15, 2024 through June 26, 2025.\nObservations are reweighted to reflect total message volumes on a given day. Sampling details available in\nSection 3.\nFigure 8:Share ofwork relatedconsumer ChatGPT messages broken down by high level conversation\ntopic, according to the mapping in Table 3. Values are averaged over a 28 day lagging window. Shares are\ncalculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024 through June\n26, 2025. Observations are reweighted to reflect total message volumes on a given day. Sampling details\navailable in Section 3.\n15\x0csuggests that most userWritingconversations with ChatGPT are requests to modify user inputs\nrather than to create something new. Education is a major use case for ChatGPT. 10.2% of all user\nmessages and 36% ofPractical Guidancemessages are requests forTutoring or Teaching. Another\nlarge share - 8.5% in total and 30% ofPractical Guidance- is general how-to advice on a variety\nof topics.Technical HelpincludesComputer Programming(4.2% of messages),Mathematical Calcu-\nlations(3%), andData Analysis(0.4%). Looking at the topic ofSelf-Expression, only 2.4% of all\nChatGPT messages are aboutRelationships and Personal Reflection(1.9%) orGames and Role Play\n(0.4%).\nWhile users can seek information and advice from traditional web search engines as well as from\nChatGPT, the ability to produce writing, software code, spreadsheets, and other digital products\ndistinguishes generative AI from existing technologies. ChatGPT is also more flexible than web\nsearch even for traditional applications likeSeeking InformationandPractical Guidance, because\nusers receive customized responses (e.g., tailored workout plans, new product ideas, ideas for fantasy\nfootball team names) that represent newly generated content or novel modification of user-provided\ncontent and follow-up requests.\nFigure 9:Breakdown of granular conversation topic shares within the coarse mapping defined in Table 3. The\nunderlying classifier prompt is available in Appendix A. Each bin reports a percentage of the total population.\nShares are calculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024\nthrough June 26, 2025. Observations are reweighted to reflect total message volumes on a given day. Sampling\ndetails available in Section 3.\n5.3 ', '<2-hop>\n\nUser Intent\nExisting studies of the economic impacts of generative AI focus almost exclusively on the potential\nfor AI to perform workplace tasks, either augmenting or automating human labor (e.g. Eloundou et\nal. (2025), Handa et al. (2025), Tomlinson et al. (2025)). However, generative AI is a highly flexible\n16\x0ctechnology that can be used in many different ways. In order to learn more about how people seek to\nuse generative AI at work and outside of work, we introduce a classifier that is designed to measure the\ntype of output the user hopes to receive. Specifically, we classify messages according to user intent,\ncoding up conversations according to a simple Asking,  Doing, or ', '<3-hop>\n\nBreakdown of Conversation Topics by Asking/Doing/Expressing category, with topic columns\nsorted by relative share of ”Doing” messages. Prompts for these automated classifiers are available in Appendix\nA. For a detailed breakdown of conversation topic contents, see Table 3. Each bin reports a percentage of\nthe total population. ']","Users engage with ChatGPT primarily for conversation topics related to Writing, where requests often involve modifying existing text rather than creating new content. Specifically, 10.2% of all user messages are requests for Tutoring or Teaching, indicating a significant educational use case. Additionally, the analysis of user intent reveals that these interactions can be classified into categories such as Asking, Doing, or Expressing, which helps to understand how users seek to utilize generative AI for educational purposes.",multi_hop_abstract_query_synthesizer
