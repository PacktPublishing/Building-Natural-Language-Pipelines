user_input,reference_contexts,reference,synthesizer_name
What role does Christopher Ong play in the research on how people use ChatGPT?,"['NBER WORKING PAPER SERIES\nHOW PEOPLE USE CHATGPT\nAaron Chatterji\nThomas Cunningham\nDavid J. Deming\nZoe Hitzig\nChristopher Ong\nCarl Yan Shan\nKevin Wadman\nWorking Paper 34255\nhttp://www.nber.org/papers/w34255\nNATIONAL BUREAU OF ECONOMIC RESEARCH\n1050 Massachusetts Avenue\nCambridge, MA 02138\nSeptember 2025\nWe acknowledge help and comments from Joshua Achiam, Hemanth Asirvatham, Ryan Beiermeister, Rachel Brown, Cassandra Duchan Solis, Jason Kwon, Elliott Mokski, Kevin Rao, Harrison Satcher, Gawesha Weeratunga, Hannah Wong, and Analytics & Insights team. We especially thank Tyna Eloundou and Pamela Mishkin who in several ways laid the foundation for this work. This study was approved by Harvard IRB (IRB25-0983). A repository containing all code run to produce the analyses in this paper is available on request. The views expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.\nAt least one co-author has disclosed additional relationships of potential relevance for this research. Further information is available online at http://www.nber.org/papers/w34255\nNBER working papers are circulated for discussion and comment purposes. They have not been peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies official NBER publications.\n© 2025 by Aaron Chatterji, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl Yan Shan, and Kevin Wadman. All rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including © notice, is given to the source.\x0cHow People Use ChatGPT\nAaron Chatterji, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl\nYan Shan, and Kevin Wadman\nNBER Working Paper No. 34255\nSeptember 2025\nJEL No. J01, O3, O4\nABSTRACT\nDespite the rapid adoption of LLM chatbots, little is known about how they are used. We document the growth of ChatGPT’s consumer product from its launch in November 2022 through July 2025, when it had been adopted by around 10% of the world’s adult population. Early adopters were disproportionately male but the gender gap has narrowed dramatically, and we find higher growth rates in lower-income countries. Using a privacy-preserving automated pipeline, we classify usage patterns within a representative sample of ChatGPT conversations. We find steady growth in work-related messages bu t even faster growth in non-work-related messages, which have grown from 53% to more than 70% of all usage. Work usage is more common for educated users in highly-paid professional occupations. We classify messages by conversation top\nic and find that “Practical Guidance,” “Seeking Information,” and “Writing” are the three most common topics and collectively account for nearly 80% of all conversations. Writing dominates work-related tasks, highlighting chatbots’ unique ability to generate digital outputs compared to traditional sear ch engines. Computer programming and self-expression both represent relatively small shares of use. Overall, we find that ChatGPT provides economic value through decision support, which is especially important in knowledge-intensive jobs.\nAaron Chatterji\nDuke University\nFuqua School of Business and OpenAI\nronnie@duke.edu\nThomas Cunningham OpenAI\ntom.cunningham@gmail.com\nDavid J. Deming\nHarvard University\nHarvard Kennedy School and NBER\ndavid_deming@harvard.edu\nZoe Hitzig\nOpenAI\nand Harvard Society of Fellows\nzhitzig@g.harvard.edu\nChristopher Ong\nHarvard University\nand OpenAI\nchristopherong@hks.harvard.edu\nCarl Yan Shan\nOpenAI\ncshan@openai.com\nKevin Wadman\nOpenAI\nkevin.wadman@c-openai.com\x0c']",Christopher Ong is one of the co-authors of the NBER Working Paper No. 34255 titled 'How People Use ChatGPT.' He is affiliated with Harvard University and OpenAI.,single_hop_specific_query_synthesizer
What role does David J. Deming play in the study of ChatGPT's consumer usage?,"['ABSTRACT Despite the rapid adoption of LLM chatbots, little is known about how they are used. We document the growth of ChatGPT’s consumer product from its launch in November 2022 through July 2025, when it had been adopted by around 10% of the world’s adult population. Early adopters were disproportionately male but the gender gap has narrowed dramatically, and we find higher growth rates in lower-income countries. Using a privacy-preserving automated pipeline, we classify usage patterns within a representative sample of ChatGPT conversations. We find steady growth in work-related messages bu t even faster growth in non-work-related messages, which have grown from 53% to more than 70% of all usage. Work usage is more common for educated users in highly-paid professional occupations. We classify messages by conversation top ic and find that “Practical Guidance,” “Seeking Information,” and “Writing” are the three most common topics and collectively account for nearly 80% of all conversations. Writing dominates work-related tasks, highlighting chatbots’ unique ability to generate digital outputs compared to traditional sear ch engines. Computer programming and self-expression both represent relatively small shares of use. Overall, we find that ChatGPT provides economic value through decision support, which is especially important in knowledge-intensive jobs. Aaron Chatterji Duke University Fuqua School of Business and OpenAI ronnie@duke.edu Thomas Cunningham OpenAI tom.cunningham@gmail.com David J. Deming Harvard University Harvard Kennedy School and NBER david_deming@harvard.edu Zoe Hitzig OpenAI and Harvard Society of Fellows zhitzig@g.harvard.edu Christopher Ong Harvard University and OpenAI christopherong@hks.harvard.edu Carl Yan Shan OpenAI cshan@openai.com Kevin Wadman OpenAI kevin.wadman@c-openai.com 1 Introduction ChatGPT launched in November 2022. By July 2025, 18 billion messages were being sent each week by 700 million users, representing around 10% of the global adult population. 1 For a new technology, this speed of global diffusion has no precedent (Bick et al., 2024). This paper studies consumer usage of ChatGPT, the first mass-market chatbot and likely the largest.2 ChatGPT is based on a Large Language Model (LLM), a type of Artificial Intelligence (AI) developed over the last decade and generally considered to represent an acceleration in AI capabilities.3 The sudden growth in LLM abilities and adoption has intensified interest in the effects of artificial intelligence on economic growth (Acemoglu, 2024; Korinek and Suh, 2024); employment (Eloundou et al., 2025); and society (Kulveit et al., 2025). However, despite the rapid adoption of LLMs, there is limited public information on how they are used. A number of surveys have measured self-reported adoption of LLMs (Bick et al., 2024; Pew Research Center, 2025); however there are reasons to expect bias in self-reports (Ling and Imas, 2025), and none of these papers have been able to directly track the quantity or nature of chatbot conversations. Two recent papers do report statistics on chatbot conversations, classified in a variety of ways (Handa et al., 2025; Tomlinson et al., 2025). We build on this work in several respects. First, the pool of users on ChatGPT is far larger, meaning we expect our data to be a closer approximation to the average chatbot user.4 Second, we use automated classifiers to report on the types of messages that users send using new classification taxonomies relative to the existing literature. Third, we report the diffusion of chatbot use across populations and the growth of different types of usage within cohorts. Fourth, we use a secure data clean room protocol to analyze aggregated employment and education categories for a sample of our users, lending new insights about differences in the types of messages sent by different groups while protecting user privacy. Our primary sample is a random selection of messages sent to ChatGPT on consumer plans (Free, Plus, Pro) between May 2024 and June 2025. 5 Messages from the user to chatbot are classified automatically using a number of different taxonomies: whether the message is used for paid work, the topic of conversation, and the type of interaction (asking, doing, or expressing), and the O*NET task the user is performing. Each taxonomy is defined in a prompt passed to an LLM, allowing us']","David J. Deming is affiliated with Harvard University and the Harvard Kennedy School, and he is one of the authors of the paper that studies consumer usage of ChatGPT, documenting its growth and analyzing usage patterns.",single_hop_specific_query_synthesizer
"What are the different consumer plans available for ChatGPT, including the Pro plan?","['to classify messages without any human seeing them. We give the text of most prompts in Appendix A along with details about how the prompts were validated in Appendix B.6 The classification pipeline is protected by a series of privacy measures, detailed below, to ensure no leakage of sensitive information during the automated analysis. In a secure data clean room, we relate taxonomies of messages to aggregated employment and education categories. Table 1 shows the growth in total message volume for work and non-work usage. Both types of 1Reuters (2025), Roth (2025) 2Bick et al. (2024) report that 28% of US adults used ChatGPT in late 2024, higher than any other chatbot. 3We use the term LLM loosely here and give more details in the following section. 4Wiggers (2025) reports estimates that in April 2025 ChatGPT was receiving more than 10 times as many visitors as either Claude or Copilot. 5Our sample includes the three consumer plans (Free, Plus, or Pro). OpenAI also offers a variety of other ChatGPT plans (Business fka. Teams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day.']","OpenAI offers a variety of consumer plans for ChatGPT, which include Free, Plus, and Pro. Additionally, there are other plans such as Business (formerly known as Teams), Enterprise, and Education, but these are not included in the sample.",single_hop_specific_query_synthesizer
"What is the estimated economic surplus generated by US users of ChatGPT, and how does this relate to the increasing volume of non-work messages?","['<1-hop>\n\nto classify messages without any human seeing them. We give the text of most prompts in Appendix A along with details about how the prompts were validated in Appendix B.6 The classification pipeline is protected by a series of privacy measures, detailed below, to ensure no leakage of sensitive information during the automated analysis. In a secure data clean room, we relate taxonomies of messages to aggregated employment and education categories. Table 1 shows the growth in total message volume for work and non-work usage. Both types of 1Reuters (2025), Roth (2025) 2Bick et al. (2024) report that 28% of US adults used ChatGPT in late 2024, higher than any other chatbot. 3We use the term LLM loosely here and give more details in the following section. 4Wiggers (2025) reports estimates that in April 2025 ChatGPT was receiving more than 10 times as many visitors as either Claude or Copilot. 5Our sample includes the three consumer plans (Free, Plus, or Pro). OpenAI also offers a variety of other ChatGPT plans (Business fka. Teams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day.', '<2-hop>\n\nOverall, our findings suggest that ChatGPT has a broad-based impact on the global economy.\nThe fact that non-work usage is increasing faster suggests that the welfare gains from generative AI\nusage could be substantial. Collis and Brynjolfsson (2025) estimate that US users would have to\nbe paid$98 to forgo using generative AI for a month, implying a surplus of at least$97 billion a\nyear. Within work usage, we find that users currently appear to derive value from using ChatGPT\nas an advisor or research assistant, not just a technology that performs job tasks directly. Still,\nChatGPT likely improves worker output by providingdecision support, which is especially important\nin knowledge-intensive jobs where productivity is increasing in the quality of decision-making.\n36\x0c T. Chan, Pat Pataranuta- porn, and Pattie Maes, “Investigating Affective Use and Emotional Well-being on ChatGPT,” 2025. Reuters, “OpenAI hits$12 billion in annualized revenue, The Information reports,”Reuters, July 30 2025.']","The estimated economic surplus generated by US users of ChatGPT is at least $97 billion a year, as Collis and Brynjolfsson (2025) suggest that users would need to be paid $98 to forgo using generative AI for a month. This economic impact is further highlighted by the increasing volume of non-work messages, which is growing faster than work-related messages, indicating substantial welfare gains from generative AI usage.",multi_hop_specific_query_synthesizer
"What demographic trends in ChatGPT usage are highlighted by Zao-Sanders, and how do they compare to the overall message classification in ChatGPT?","['<1-hop>\n\nTeams, Enterprise, Education), which we do not include in our sample. 6Our classifiers take into account not just the randomly-selected user message, but also a portion of the preceding messages in that conversation. 1 Month Non-Work (M)(%)Work (M)(%)Total Messages (M) Jun 2024 238 53% 213 47% 451 Jun 2025 1,911 73% 716 27% 2,627 Table 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related. Total daily counts are exact measurements of message volume from all consumer plans. Daily counts of work and non-work related messages are estimated by classifying a random sample of conversations from that day. Sampling is done to exclude users who opt-out of sharing their messages for model training, users who self- report their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated or banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation) ending on the 26th of June 2024 and 26th of June 2025. messages have grown continuously, but non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its impact on productivity in paid work, the impact on activity outside of work (home production) is on a similar scale and possibly larger. The decrease in the share of work-related messages is primarily due to changing usage within each cohort of users rather than a change in the composition of new ChatGPT users. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to uncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion in 2024 alone in the US. We next report on a classification of messages using a taxonomy developed at OpenAI for un- derstanding product usage (“conversation classifier”). Nearly 80% of all ChatGPT usage falls into three broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical Guidanceis the most common use case and includes activities like tutoring and teaching, how-to advice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for information about people, current events, products, and recipes, and appears to be a very close sub- stitute for web search.Writingincludes the automated production of emails, documents and other communications, but also editing, critiquing, summarizing, and translating text provided by the user. Writingis the most common use case at work, accounting for 40% of work-related messages on average in June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing, critiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages are requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT. Two of our findings stand in contrast to other work. First, we find the share of messages related to computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer programming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we find the share of messages related to companionship or social-emotional issues is fairly small: only 1.9% of ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related 7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the user and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be the same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying times by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their goals and current level of fitness (Practical Guidance). 8Handa et al. (2025) report that 37% of conversations are mapped to a “computer and mathematical” occupation category, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the discrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al. (2025) only includes queries that ”possibly involve an occupational task”. 2 toGames and Role Play. In contrast, Zao-Sanders (2025) estimates thatTherapy/Companionshipis the most prevalent use case for generative AI. 9', '<2-hop>\n\nWe also document several important facts about demographic variation in ChatGPT usage. First, we show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time, and may have closed completely. In the few months after ChatGPT was released about 80% of active users had typically masculine first names. 10 However, that number declined to 48% as of June 2025, with active users slightly more likely to have typically feminine first names. Second, we find that nearly half of all messages sent by adults were sent by users under the age of 26, although age gaps have narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively faster in low- and middle-income countries over the last year. Fourth, we find that educated users and users in highly-paid professional occupations are substantially more likely to use ChatGPT for work. We introduce a new taxonomy to classify messages according to the kind of output the user is seeking, using a simple rubric that we callAsking, Doing,orExpressing. 11 Askingis when the user is seeking information or clarification to inform a decision, corresponding to problem-solving models of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and Schneider (2025); Ide and Talamas (2025)).Doingis when the user wants to produce some output or perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al. (2003)).Expressingis when the user is expressing views or feelings but not seeking any information or action. We estimate that about 49% of messages areAsking, 40% areDoing, and 11% areExpressing. However, as of July 2025 about 56% of work-related messages are classified asDoing(e.g., performing job tasks), and nearly three-quarters of those areWritingtasks. The relative frequency of writing- related conversations is notable for two reasons. First, writing is a task that is common to nearly all white-collar jobs, and good written communication skills are among the top “soft” skills demanded by employers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of generative AI, relative to other information technologies, is its ability to produce long-form outputs such as writing and software code. We also map message content to work activities using the Occupational Information Network (O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that about 81% of work-related messages are associated with two broad work activities: 1) obtaining, documenting, and interpreting information; and 2) making decisions, giving advice, solving problems, and thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage are highly similar across very different kinds of occupations. For example, the work activitiesGetting InformationandMaking Decisions and Solving Problemsare in the top five of message frequency in nearly all occupations, ranging from management and business to STEM to administrative and sales occupations. Overall, we find that information-seeking and decision support are the most common ChatGPT use cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is eitherPractical GuidanceorSeeking Information. We also show thatAskingis growing faster than 9Zao-Sanders (2025) is based on a manual collection and labeling of online resources (Reddit, Quora, online articles), and so we believe it likely resulted in an unrepresentative distribution of use cases. 10Among those with names commonly associated with a particular gender. 11Appendix A gives the full prompt text and Appendix B gives detail about how the prompts were validated against public conversation data. 3 Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier that measures user satisfaction and from direct user feedback.']","Zao-Sanders (2025) highlights several demographic trends in ChatGPT usage, including a significant narrowing of the gender gap, with active users with typically masculine first names decreasing from 80% shortly after release to 48% by June 2025. Additionally, nearly half of all messages were sent by users under the age of 26, indicating a younger demographic engagement. In contrast, the overall message classification in ChatGPT reveals that about 49% of messages are categorized as Asking (seeking information), 40% as Doing (producing output), and 11% as Expressing (sharing views or feelings). This classification shows that information-seeking and decision support are the most common use cases across various demographics.",multi_hop_specific_query_synthesizer
Wht is the share of Practical Guidance in ChatGPT convrsations and how does it compare to other topics like Writing and Seeking Information?,"['<1-hop>\n\nWhat are the topics of ChatGPT conversations?\nWe modify a classifier used by internal research teams at OpenAI that identifies which capabilities\nthe user is requesting from ChatGPT. The classifier itself directly assigns the user’s query into one\nof 24 categories. We aggregate these 24 categories into seven topical groupings (the full conversation-\ncategorization prompt is given in Appendix A):\nTopic Conversation Category\nWriting Edit or Critique Provided Text\nPersonal Writing or Communication\nTranslation\nArgument or Summary Generation\nWrite Fiction\nPractical Guidance How-To Advice\nTutoring or Teaching\nCreative Ideation\nHealth, Fitness, Beauty, or Self-Care\nTechnical Help Mathematical Calculation\nData Analysis\n13\x0cTopic Conversation Category\nComputer Programming\nMultimedia Create an Image\nAnalyze an Image\nGenerate or Retrieve Other Media\nSeeking Information Specific Info\nPurchasable Products\nCooking and Recipes\nSelf-Expression Greetings and Chitchat\nRelationships and Personal Reflection\nGames and Role Play\nOther/Unknown Asking About the Model\nOther\nUnclear\nTable 3:Coarse Conversation Topics and Underlying Classifier Categories\nFigure 7 shows the composition of user messages over time. The three most common Conversation\nTopics arePractical Guidance,Seeking Information, andWriting, collectively accounting for about\n77% of all ChatGPT conversations.Practical Guidancehas remained constant at roughly 29% of\noverall usage.Writinghas declined from 36% of all usage in July 2024 to 24% a year later.Seeking\nInformationhas grown from 14% to 24% of all usage over the same period. The share ofTechnical\nHelpdeclined from 12% from all usage in July 2024 to around 5% a year later – this may be because\nthe use of LLMs for programming has grown very rapidly through the API (outside of ChatGPT),\nfor AI assistance in code editing and for autonomous programming agents (e.g. Codex).Multimedia\ngrew from 2% to just over 7%, with a large spike in April 2025 after ChatGPT released new image-\ngeneration capabilities: the spike attenuated but the elevated level has persisted.\nFigure 8 shows Conversation Topics, restricting the sample to only work-related messages. About\n40% of all work-related messages in July 2025 areWriting, by far the most common Conversation\nTopic.Practical Guidanceis the second most common use case at 24%.Technical Helphas declined\nfrom 18% of all work-related messages in July 2024 to just over 10% in July 2025.\nFigure 9 disaggregates four of the seven Conversation Topics into smaller groups and sums up\nmessages of each type over a one-year period. For example, the five sub-categories withinWriting\nare (in order of frequency)Editing or Critiquing Provided Text,Personal Writing or Communication,\nTranslation,Argument or Summary Generation, andWriting Fiction. Three of those five categories\n(Editing or Critiquing Provided Text,Translation, andArgument or Summary Generation) are re-\nquests to modify text that has been provided to ChatGPT by the user, whereas the other two are\nrequests to produce novel text. The former constitute two thirds of allWritingconversations, which\n14\x0cFigure 7:Share of consumer ChatGPT messages broken down by high level conversation topic, according\nto the mapping in Table 3. Values are averaged over a 28 day lagging window. ', '<2-hop>\n\nFigure 9 disaggregates four of the seven Conversation Topics into smaller groups and sums up\nmessages of each type over a one-year period. For example, the five sub-categories withinWriting\nare (in order of frequency)Editing or Critiquing Provided Text,Personal Writing or Communication,\nTranslation,Argument or Summary Generation, andWriting Fiction. Three of those five categories\n(Editing or Critiquing Provided Text,Translation, andArgument or Summary Generation) are re-\nquests to modify text that has been provided to ChatGPT by the user, whereas the other two are\nrequests to produce novel text. The former constitute two thirds of allWritingconversations, which\n14\x0cFigure 7:Share of consumer ChatGPT messages broken down by high level conversation topic, according\nto the mapping in Table 3. Values are averaged over a 28 day lagging window. Shares are calculated from\na sample of approximately 1.1 million sampled conversations from May 15, 2024 through June 26, 2025.\nObservations are reweighted to reflect total message volumes on a given day. Sampling details available in\nSection 3.\nFigure 8:Share ofwork relatedconsumer ChatGPT messages broken down by high level conversation\ntopic, according to the mapping in Table 3. Values are averaged over a 28 day lagging window. Shares are\ncalculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024 through June\n26, 2025. Observations are reweighted to reflect total message volumes on a given day. Sampling details\navailable in Section 3.\n15\x0csuggests that most userWritingconversations with ChatGPT are requests to modify user inputs\nrather than to create something new. Education is a major use case for ChatGPT. 10.2% of all user\nmessages and 36% ofPractical Guidancemessages are requests forTutoring or Teaching. Another\nlarge share - 8.5% in total and 30% ofPractical Guidance- is general how-to advice on a variety\nof topics.Technical HelpincludesComputer Programming(4.2% of messages),Mathematical Calcu-\nlations(3%), andData Analysis(0.4%). Looking at the topic ofSelf-Expression, only 2.4% of all\nChatGPT messages are aboutRelationships and Personal Reflection(1.9%) orGames and Role Play\n(0.4%).\nWhile users can seek information and advice from traditional web search engines as well as from\nChatGPT, the ability to produce writing, software code, spreadsheets, and other digital products\ndistinguishes generative AI from existing technologies. ChatGPT is also more flexible than web\nsearch even for traditional applications likeSeeking InformationandPractical Guidance, because\nusers receive customized responses (e.g., tailored workout plans, new product ideas, ideas for fantasy\nfootball team names) that represent newly generated content or novel modification of user-provided\ncontent and follow-up requests.\nFigure 9:Breakdown of granular conversation topic shares within the coarse mapping defined in Table 3. The\nunderlying classifier prompt is available in Appendix A. Each bin reports a percentage of the total population.\nShares are calculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024\nthrough June 26, 2025. Observations are reweighted to reflect total message volumes on a given day. Sampling\ndetails available in Section 3.\n5.3 ']","The share of Practical Guidance in ChatGPT conversations has remained constant at roughly 29% of overall usage. In comparison, Writing has declined from 36% of all usage in July 2024 to 24% a year later, while Seeking Information has grown from 14% to 24% of all usage over the same period. Together, Practical Guidance, Seeking Information, and Writing account for about 77% of all ChatGPT conversations.",multi_hop_specific_query_synthesizer
What are the differences in ChatGPT usage for work-related messages among users with varying education levels and occupations?,"['<1-hop>\n\n37% of messages are work-related\nfor users with less than a bachelor’s degree, compared to 46% for users with exactly a bachelor’s\ndegree and 48% for those with some graduate education. Those differences are cut roughly in half\nafter adjusting for other characteristics, but they are still statistically significant at the less than 1\npercent level. Educated users are more likely to send work-related messages.\nPanel B explores variation by education in user intent.Askingconstitutes about 49% of messages\nfor users with less than a bachelor’s degree, with little variation for more educated users. After\nregression adjustment, we find that users with a graduate degree are about two percentage points\nmore likely to use ChatGPT forAskingmessages, a difference that is statistically significant at the\n5% level. Prior to regression adjustment, the frequency ofDoingmessages is increasing in education.\nHowever, this pattern reverses after adjusting for other characteristics such as occupation. Users with\na graduate degree are about 1.6 percentage points less likely to sendDoingmessages than users with\nless than a bachelor’s degree, and the difference is statistically significant at the 10% level.\nPanel C studies variation by education in the frequency of four different conversation topics –\nPractical Guidance,Seeking Information,Technical Help, andWriting. We find only modest differ-\nences by education across most of these categories. The one exception is that the share of messages\nrelated toWritingis increasing in relation to education.\n28\x0cPanel A.Work Related\nPanel B1.Asking. Panel B2.Doing.\nPanel B3.Expressing.\nFigure 22:(continued on next page)\n29\x0cPanel C1.Writing. Panel C2.Technical Help.\nPanel C3.Seeking Information. Panel C4.Practical Guidance.\nFigure 22:Variation in ChatGPT usage by education. Each plot shows unadjusted vs. regression-adjusted\nestimates, with 95% confidence intervals. We regress each message share on education and occupation, control-\nling for the following covariates: age, whether the name was typically masculine or feminine, seniority within\nrole, company size, and industry. (To guarantee user privacy, we coarsen all covariates to broad categories and\nprogrammatically enforce that each group has at least 100 members prior to running the regression) We add\nthe coefficients on each education and occupation category to the unadjusted value for the reference category\nand compute 95% confidence intervals using the standard errors from the regression coefficients. The sample\nfor this regression is the approximately 40,000 users of the original 130,000 sample whose publicly available\noccupation was not blank or consisted of strictly special characters (as determined by a classification script).\nShares for each user are calculated by randomly sampling up to six conversations attributed to the user from\nMay 2024 through July 2025.\n30\x0c', '<2-hop>\n\n6.5 Variation by Occupation\nFigure 23 presents variation in ChatGPT usage by user occupation. Due to privacy-preserving aggre-\ngation limits, we report results for the following broad occupation categories – (1) all nonprofessional\noccupations, including administrative, clerical, service, and blue-collar occupations; (2) computer-\nrelated occupations; (3) engineering and science occupations; (4) management and business occupa-\ntions; and (5) all other professional occupations, including law, education, and health care. 26 As\nabove, the left-hand side of the figure shows unadjusted comparisons and the right-hand side presents\nthe coefficients on each occupation category from a regression of message shares on age, whether the\nname was typically masculine or feminine, education, occupation categories, job seniority, firm size,\nand industry.\nUsers in highly paid professional and technical occupations are more likely to use ChatGPT for\nwork.27 Panel A shows that the unadjusted work shares are 57% for computer-related occupations;\n50% for management and business; 48% for engineering and science; 44% for other professional oc-\ncupations; and only 40% for all non-professional occupations. Regression adjustment moves these\nfigures around slightly, but the gaps by occupation remain highly statistically significant. Users in\nhighly-paid professional occupations are more likely to send work-related messages.\nBecause work usage is so different by occupation, we restrict the sample only to work-related\nmessages in Panels B and C. Panel B presents the share of work-related messages that areAsking\nmessages, by occupation. We find that users in highly paid professional occupations are more likely\nto use ChatGPT forAskingrather thanDoing. 28 This is especially true in scientific and technical\noccupations. 47% of the work-related messages sent by users employed in computer-related occupa-\ntions areAskingmessages, compared to only 32% for non-professional occupations. These differences\nshrink somewhat with regression adjustment, but remain highly statistically significant.\nPanel C presents results by conversation topic.Writingis especially common for users employed\nin management and business occupations, accounting for 52% of all work-related messages. Writing\nis also relatively common in non-professional and other professional occupations like education and\nhealth care, accounting for 50% and 49% of work-related messages respectively.Technical Helpconsti-\ntutes 37% of all work-related messages for users employed in computer-related occupations, compared\nto 16% in engineering and science and only about 8% for all other categories. Regression adjustment\naffects gaps by occupation only modestly. Overall there are stark differences in the distribution of\nconversation topics by user occupation, with work-related messages clearly focused on the core tasks\nin each job (e.g.Writingfor management and business,Technical Helpfor technical occupations).\nWe also present data on the most common Generalized Work Activities (GWAs) associated with\neach broad occupation group, as measured by 2-digit Standard Occupation Classification (SOC) codes.\nTable 24 presents the frequency ranking of work-related messages in each SOC code of the seven most\ncommon GWAs.29\n26Management and business are SOC2 codes 11 and 13. Computer-related is SOC2 code 15. Engineering and Science\nare SOC2 codes 17 and 19. Other Professional are SOC2 codes 21 to 29. Nonprofessional occupations are SOC codes\n31 to 53.\n27As discussed in Section: Data and Privacy, our dataset only includes users on ChatGPT Consumer plans. Corporate\nusers may also use ChatGPT Business (formerly known as Teams) or ChatGPT Enterprise.\n28Very few work-related messages are classified asExpressing.\n29Appendix D contains a full report of GWA counts broken down by occupation, for both work-related ChatGPT\n31\x0cWe find remarkable similarity across occupations in how ChatGPT is used at work. For example,\nMaking Decisions and Solving Problemsis one of the two most common GWAs in every single oc-\ncupation group where at least two GWAs can be reported. 30 Similarly,Documenting and Recording\nInformationranks in the top four of all occupations.Thinking Creativelyis ranked as the third most\ncommon GWA in 10 of the 13 occupation groups where at least three GWAs can be reported. ']","Users with different education levels exhibit significant variations in ChatGPT usage for work-related messages. For instance, 37% of messages are work-related for users with less than a bachelor’s degree, compared to 46% for those with a bachelor’s degree and 48% for users with some graduate education. After adjusting for other characteristics, educated users are more likely to send work-related messages. Additionally, the usage of ChatGPT varies by occupation; for example, 57% of messages from users in computer-related occupations are work-related, while only 40% of messages from non-professional occupations are work-related. Users in highly paid professional occupations tend to use ChatGPT more for Asking messages rather than Doing messages, particularly in scientific and technical fields.",multi_hop_abstract_query_synthesizer
How do the conversation topics identified in user interactions with ChatGPT relate to user intent in terms of asking for information versus doing tasks?,"['<1-hop>\n\nFigure 9 disaggregates four of the seven Conversation Topics into smaller groups and sums up\nmessages of each type over a one-year period. For example, the five sub-categories withinWriting\nare (in order of frequency)Editing or Critiquing Provided Text,Personal Writing or Communication,\nTranslation,Argument or Summary Generation, andWriting Fiction. Three of those five categories\n(Editing or Critiquing Provided Text,Translation, andArgument or Summary Generation) are re-\nquests to modify text that has been provided to ChatGPT by the user, whereas the other two are\nrequests to produce novel text. The former constitute two thirds of allWritingconversations, which\n14\x0cFigure 7:Share of consumer ChatGPT messages broken down by high level conversation topic, according\nto the mapping in Table 3. Values are averaged over a 28 day lagging window. Shares are calculated from\na sample of approximately 1.1 million sampled conversations from May 15, 2024 through June 26, 2025.\nObservations are reweighted to reflect total message volumes on a given day. Sampling details available in\nSection 3.\nFigure 8:Share ofwork relatedconsumer ChatGPT messages broken down by high level conversation\ntopic, according to the mapping in Table 3. Values are averaged over a 28 day lagging window. Shares are\ncalculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024 through June\n26, 2025. Observations are reweighted to reflect total message volumes on a given day. Sampling details\navailable in Section 3.\n15\x0csuggests that most userWritingconversations with ChatGPT are requests to modify user inputs\nrather than to create something new. Education is a major use case for ChatGPT. 10.2% of all user\nmessages and 36% ofPractical Guidancemessages are requests forTutoring or Teaching. Another\nlarge share - 8.5% in total and 30% ofPractical Guidance- is general how-to advice on a variety\nof topics.Technical HelpincludesComputer Programming(4.2% of messages),Mathematical Calcu-\nlations(3%), andData Analysis(0.4%). Looking at the topic ofSelf-Expression, only 2.4% of all\nChatGPT messages are aboutRelationships and Personal Reflection(1.9%) orGames and Role Play\n(0.4%).\nWhile users can seek information and advice from traditional web search engines as well as from\nChatGPT, the ability to produce writing, software code, spreadsheets, and other digital products\ndistinguishes generative AI from existing technologies. ChatGPT is also more flexible than web\nsearch even for traditional applications likeSeeking InformationandPractical Guidance, because\nusers receive customized responses (e.g., tailored workout plans, new product ideas, ideas for fantasy\nfootball team names) that represent newly generated content or novel modification of user-provided\ncontent and follow-up requests.\nFigure 9:Breakdown of granular conversation topic shares within the coarse mapping defined in Table 3. The\nunderlying classifier prompt is available in Appendix A. Each bin reports a percentage of the total population.\nShares are calculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024\nthrough June 26, 2025. Observations are reweighted to reflect total message volumes on a given day. Sampling\ndetails available in Section 3.\n5.3 ', '<2-hop>\n\nUser Intent\nExisting studies of the economic impacts of generative AI focus almost exclusively on the potential\nfor AI to perform workplace tasks, either augmenting or automating human labor (e.g. Eloundou et\nal. (2025), Handa et al. (2025), Tomlinson et al. (2025)). However, generative AI is a highly flexible\n16\x0ctechnology that can be used in many different ways. In order to learn more about how people seek to\nuse generative AI at work and outside of work, we introduce a classifier that is designed to measure the\ntype of output the user hopes to receive. Specifically, we classify messages according to user intent,\ncoding up conversations according to a simple Asking,  Doing, or ', '<3-hop>\n\nBreakdown of Conversation Topics by Asking/Doing/Expressing category, with topic columns\nsorted by relative share of ”Doing” messages. Prompts for these automated classifiers are available in Appendix\nA. For a detailed breakdown of conversation topic contents, see Table 3. Each bin reports a percentage of\nthe total population. ']","The conversation topics identified in user interactions with ChatGPT show a significant focus on requests to modify user inputs, particularly within the Writing category, where two-thirds of conversations are about editing or critiquing provided text. This indicates that users often seek assistance in refining their existing content rather than generating new material. In terms of user intent, existing studies highlight that generative AI can be utilized for various purposes, including asking for information and performing tasks. The classifier introduced measures user intent by categorizing messages into Asking, Doing, or Expressing, which helps to understand how users engage with ChatGPT for different outcomes, such as seeking practical guidance or technical help.",multi_hop_abstract_query_synthesizer
"What percentage of work-related messages are sent by users in computer-related occupations compared to those in non-professional occupations, and how does this relate to ChatGPT usage by occupation?","['<1-hop>\n\n37% of messages are work-related\nfor users with less than a bachelor’s degree, compared to 46% for users with exactly a bachelor’s\ndegree and 48% for those with some graduate education. Those differences are cut roughly in half\nafter adjusting for other characteristics, but they are still statistically significant at the less than 1\npercent level. Educated users are more likely to send work-related messages.\nPanel B explores variation by education in user intent.Askingconstitutes about 49% of messages\nfor users with less than a bachelor’s degree, with little variation for more educated users. After\nregression adjustment, we find that users with a graduate degree are about two percentage points\nmore likely to use ChatGPT forAskingmessages, a difference that is statistically significant at the\n5% level. Prior to regression adjustment, the frequency ofDoingmessages is increasing in education.\nHowever, this pattern reverses after adjusting for other characteristics such as occupation. Users with\na graduate degree are about 1.6 percentage points less likely to sendDoingmessages than users with\nless than a bachelor’s degree, and the difference is statistically significant at the 10% level.\nPanel C studies variation by education in the frequency of four different conversation topics –\nPractical Guidance,Seeking Information,Technical Help, andWriting. We find only modest differ-\nences by education across most of these categories. The one exception is that the share of messages\nrelated toWritingis increasing in relation to education.\n28\x0cPanel A.Work Related\nPanel B1.Asking. Panel B2.Doing.\nPanel B3.Expressing.\nFigure 22:(continued on next page)\n29\x0cPanel C1.Writing. Panel C2.Technical Help.\nPanel C3.Seeking Information. Panel C4.Practical Guidance.\nFigure 22:Variation in ChatGPT usage by education. Each plot shows unadjusted vs. regression-adjusted\nestimates, with 95% confidence intervals. We regress each message share on education and occupation, control-\nling for the following covariates: age, whether the name was typically masculine or feminine, seniority within\nrole, company size, and industry. (To guarantee user privacy, we coarsen all covariates to broad categories and\nprogrammatically enforce that each group has at least 100 members prior to running the regression) We add\nthe coefficients on each education and occupation category to the unadjusted value for the reference category\nand compute 95% confidence intervals using the standard errors from the regression coefficients. The sample\nfor this regression is the approximately 40,000 users of the original 130,000 sample whose publicly available\noccupation was not blank or consisted of strictly special characters (as determined by a classification script).\nShares for each user are calculated by randomly sampling up to six conversations attributed to the user from\nMay 2024 through July 2025.\n30\x0c', '<2-hop>\n\n6.5 Variation by Occupation\nFigure 23 presents variation in ChatGPT usage by user occupation. Due to privacy-preserving aggre-\ngation limits, we report results for the following broad occupation categories – (1) all nonprofessional\noccupations, including administrative, clerical, service, and blue-collar occupations; (2) computer-\nrelated occupations; (3) engineering and science occupations; (4) management and business occupa-\ntions; and (5) all other professional occupations, including law, education, and health care. 26 As\nabove, the left-hand side of the figure shows unadjusted comparisons and the right-hand side presents\nthe coefficients on each occupation category from a regression of message shares on age, whether the\nname was typically masculine or feminine, education, occupation categories, job seniority, firm size,\nand industry.\nUsers in highly paid professional and technical occupations are more likely to use ChatGPT for\nwork.27 Panel A shows that the unadjusted work shares are 57% for computer-related occupations;\n50% for management and business; 48% for engineering and science; 44% for other professional oc-\ncupations; and only 40% for all non-professional occupations. Regression adjustment moves these\nfigures around slightly, but the gaps by occupation remain highly statistically significant. Users in\nhighly-paid professional occupations are more likely to send work-related messages.\nBecause work usage is so different by occupation, we restrict the sample only to work-related\nmessages in Panels B and C. Panel B presents the share of work-related messages that areAsking\nmessages, by occupation. We find that users in highly paid professional occupations are more likely\nto use ChatGPT forAskingrather thanDoing. 28 This is especially true in scientific and technical\noccupations. 47% of the work-related messages sent by users employed in computer-related occupa-\ntions areAskingmessages, compared to only 32% for non-professional occupations. These differences\nshrink somewhat with regression adjustment, but remain highly statistically significant.\nPanel C presents results by conversation topic.Writingis especially common for users employed\nin management and business occupations, accounting for 52% of all work-related messages. Writing\nis also relatively common in non-professional and other professional occupations like education and\nhealth care, accounting for 50% and 49% of work-related messages respectively.Technical Helpconsti-\ntutes 37% of all work-related messages for users employed in computer-related occupations, compared\nto 16% in engineering and science and only about 8% for all other categories. Regression adjustment\naffects gaps by occupation only modestly. Overall there are stark differences in the distribution of\nconversation topics by user occupation, with work-related messages clearly focused on the core tasks\nin each job (e.g.Writingfor management and business,Technical Helpfor technical occupations).\nWe also present data on the most common Generalized Work Activities (GWAs) associated with\neach broad occupation group, as measured by 2-digit Standard Occupation Classification (SOC) codes.\nTable 24 presents the frequency ranking of work-related messages in each SOC code of the seven most\ncommon GWAs.29\n26Management and business are SOC2 codes 11 and 13. Computer-related is SOC2 code 15. Engineering and Science\nare SOC2 codes 17 and 19. Other Professional are SOC2 codes 21 to 29. Nonprofessional occupations are SOC codes\n31 to 53.\n27As discussed in Section: Data and Privacy, our dataset only includes users on ChatGPT Consumer plans. Corporate\nusers may also use ChatGPT Business (formerly known as Teams) or ChatGPT Enterprise.\n28Very few work-related messages are classified asExpressing.\n29Appendix D contains a full report of GWA counts broken down by occupation, for both work-related ChatGPT\n31\x0cWe find remarkable similarity across occupations in how ChatGPT is used at work. For example,\nMaking Decisions and Solving Problemsis one of the two most common GWAs in every single oc-\ncupation group where at least two GWAs can be reported. 30 Similarly,Documenting and Recording\nInformationranks in the top four of all occupations.Thinking Creativelyis ranked as the third most\ncommon GWA in 10 of the 13 occupation groups where at least three GWAs can be reported. ']","Users in computer-related occupations send 57% of their messages as work-related, while only 40% of messages from users in non-professional occupations are work-related. This indicates that ChatGPT usage is significantly higher among users in highly paid professional occupations, particularly for work-related tasks.",multi_hop_abstract_query_synthesizer
"What are the main conversation topics in ChatGPT messages and how do they relate to user intent in terms of asking, doing, or expressing?","['<1-hop>\n\nFigure 9 disaggregates four of the seven Conversation Topics into smaller groups and sums up\nmessages of each type over a one-year period. For example, the five sub-categories withinWriting\nare (in order of frequency)Editing or Critiquing Provided Text,Personal Writing or Communication,\nTranslation,Argument or Summary Generation, andWriting Fiction. Three of those five categories\n(Editing or Critiquing Provided Text,Translation, andArgument or Summary Generation) are re-\nquests to modify text that has been provided to ChatGPT by the user, whereas the other two are\nrequests to produce novel text. The former constitute two thirds of allWritingconversations, which\n14\x0cFigure 7:Share of consumer ChatGPT messages broken down by high level conversation topic, according\nto the mapping in Table 3. Values are averaged over a 28 day lagging window. Shares are calculated from\na sample of approximately 1.1 million sampled conversations from May 15, 2024 through June 26, 2025.\nObservations are reweighted to reflect total message volumes on a given day. Sampling details available in\nSection 3.\nFigure 8:Share ofwork relatedconsumer ChatGPT messages broken down by high level conversation\ntopic, according to the mapping in Table 3. Values are averaged over a 28 day lagging window. Shares are\ncalculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024 through June\n26, 2025. Observations are reweighted to reflect total message volumes on a given day. Sampling details\navailable in Section 3.\n15\x0csuggests that most userWritingconversations with ChatGPT are requests to modify user inputs\nrather than to create something new. Education is a major use case for ChatGPT. 10.2% of all user\nmessages and 36% ofPractical Guidancemessages are requests forTutoring or Teaching. Another\nlarge share - 8.5% in total and 30% ofPractical Guidance- is general how-to advice on a variety\nof topics.Technical HelpincludesComputer Programming(4.2% of messages),Mathematical Calcu-\nlations(3%), andData Analysis(0.4%). Looking at the topic ofSelf-Expression, only 2.4% of all\nChatGPT messages are aboutRelationships and Personal Reflection(1.9%) orGames and Role Play\n(0.4%).\nWhile users can seek information and advice from traditional web search engines as well as from\nChatGPT, the ability to produce writing, software code, spreadsheets, and other digital products\ndistinguishes generative AI from existing technologies. ChatGPT is also more flexible than web\nsearch even for traditional applications likeSeeking InformationandPractical Guidance, because\nusers receive customized responses (e.g., tailored workout plans, new product ideas, ideas for fantasy\nfootball team names) that represent newly generated content or novel modification of user-provided\ncontent and follow-up requests.\nFigure 9:Breakdown of granular conversation topic shares within the coarse mapping defined in Table 3. The\nunderlying classifier prompt is available in Appendix A. Each bin reports a percentage of the total population.\nShares are calculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024\nthrough June 26, 2025. Observations are reweighted to reflect total message volumes on a given day. Sampling\ndetails available in Section 3.\n5.3 ', '<2-hop>\n\nUser Intent\nExisting studies of the economic impacts of generative AI focus almost exclusively on the potential\nfor AI to perform workplace tasks, either augmenting or automating human labor (e.g. Eloundou et\nal. (2025), Handa et al. (2025), Tomlinson et al. (2025)). However, generative AI is a highly flexible\n16\x0ctechnology that can be used in many different ways. In order to learn more about how people seek to\nuse generative AI at work and outside of work, we introduce a classifier that is designed to measure the\ntype of output the user hopes to receive. Specifically, we classify messages according to user intent,\ncoding up conversations according to a simple Asking,  Doing, or ', '<3-hop>\n\nBreakdown of Conversation Topics by Asking/Doing/Expressing category, with topic columns\nsorted by relative share of ”Doing” messages. Prompts for these automated classifiers are available in Appendix\nA. For a detailed breakdown of conversation topic contents, see Table 3. Each bin reports a percentage of\nthe total population. ', '<4-hop>\n\nWhat are the topics of ChatGPT conversations?\nWe modify a classifier used by internal research teams at OpenAI that identifies which capabilities\nthe user is requesting from ChatGPT. The classifier itself directly assigns the user’s query into one\nof 24 categories. We aggregate these 24 categories into seven topical groupings (the full conversation-\ncategorization prompt is given in Appendix A):\nTopic Conversation Category\nWriting Edit or Critique Provided Text\nPersonal Writing or Communication\nTranslation\nArgument or Summary Generation\nWrite Fiction\nPractical Guidance How-To Advice\nTutoring or Teaching\nCreative Ideation\nHealth, Fitness, Beauty, or Self-Care\nTechnical Help Mathematical Calculation\nData Analysis\n13\x0cTopic Conversation Category\nComputer Programming\nMultimedia Create an Image\nAnalyze an Image\nGenerate or Retrieve Other Media\nSeeking Information Specific Info\nPurchasable Products\nCooking and Recipes\nSelf-Expression Greetings and Chitchat\nRelationships and Personal Reflection\nGames and Role Play\nOther/Unknown Asking About the Model\nOther\nUnclear\nTable 3:Coarse Conversation Topics and Underlying Classifier Categories\nFigure 7 shows the composition of user messages over time. The three most common Conversation\nTopics arePractical Guidance,Seeking Information, andWriting, collectively accounting for about\n77% of all ChatGPT conversations.Practical Guidancehas remained constant at roughly 29% of\noverall usage.Writinghas declined from 36% of all usage in July 2024 to 24% a year later.Seeking\nInformationhas grown from 14% to 24% of all usage over the same period. The share ofTechnical\nHelpdeclined from 12% from all usage in July 2024 to around 5% a year later – this may be because\nthe use of LLMs for programming has grown very rapidly through the API (outside of ChatGPT),\nfor AI assistance in code editing and for autonomous programming agents (e.g. Codex).Multimedia\ngrew from 2% to just over 7%, with a large spike in April 2025 after ChatGPT released new image-\ngeneration capabilities: the spike attenuated but the elevated level has persisted.\nFigure 8 shows Conversation Topics, restricting the sample to only work-related messages. About\n40% of all work-related messages in July 2025 areWriting, by far the most common Conversation\nTopic.Practical Guidanceis the second most common use case at 24%.Technical Helphas declined\nfrom 18% of all work-related messages in July 2024 to just over 10% in July 2025.\nFigure 9 disaggregates four of the seven Conversation Topics into smaller groups and sums up\nmessages of each type over a one-year period. For example, the five sub-categories withinWriting\nare (in order of frequency)Editing or Critiquing Provided Text,Personal Writing or Communication,\nTranslation,Argument or Summary Generation, andWriting Fiction. Three of those five categories\n(Editing or Critiquing Provided Text,Translation, andArgument or Summary Generation) are re-\nquests to modify text that has been provided to ChatGPT by the user, whereas the other two are\nrequests to produce novel text. The former constitute two thirds of allWritingconversations, which\n14\x0cFigure 7:Share of consumer ChatGPT messages broken down by high level conversation topic, according\nto the mapping in Table 3. Values are averaged over a 28 day lagging window. ']","The main conversation topics in ChatGPT messages include Writing, Practical Guidance, and Seeking Information, which collectively account for about 77% of all conversations. Writing conversations are further disaggregated into sub-categories such as Editing or Critiquing Provided Text, Personal Writing or Communication, Translation, Argument or Summary Generation, and Writing Fiction. Most of these Writing conversations involve requests to modify user inputs rather than create new content. In terms of user intent, messages are classified into categories like Asking, Doing, or Expressing, which helps to understand how users seek to utilize generative AI for various tasks, whether for practical guidance, tutoring, or self-expression.",multi_hop_abstract_query_synthesizer
"What percentage of work-related messages are classified as Doing, and how does this relate to job classification according to O*NET?","['<1-hop>\n\nNearly 35% of all work-related queries areDoingmessages related toWriting.DoingandAsking\ncomprise equal shares ofTechnical Helpqueries.\n17\x0cFigure 10:Breakdown of Conversation Topics by Asking/Doing/Expressing category, with topic columns\nsorted by relative share of ”Doing” messages. Prompts for these automated classifiers are available in Appendix\nA. For a detailed breakdown of conversation topic contents, see Table 3. Each bin reports a percentage of\nthe total population. Shares are calculated from a sample of approximately 1.1 million sampled conversations\nfrom May 15, 2024 through June 26, 2025. Observations are reweighted to reflect total message volumes on a\ngiven day. Sampling details available in Section 3.\nFigure 11:Breakdown of Conversation Topics by Asking/Doing/Expressing category foronly work-related\nmessages, with topic columns sorted by relative share of ”Doing” messages. Prompts for these automated\nclassifiers are available in Appendix A. For a detailed breakdown of conversation topic contents, see Table 3.\nEach bin reports a percentage of the total population. Shares are calculated from a sample of approximately\n1.1 million sampled conversations from May 15, 2024 through June 26, 2025. Observations are reweighted to\nreflect total message volumes on a given day. Sampling details available in Section 3.\n18\x0cFigure 12 presents changes over time in the composition of messages by user intent. In July\n2024, usage was evenly split betweenAskingandDoing, with just under 8% of messages classified as\nExpressing.AskingandExpressinggrew much faster thanDoingover the next year, and by late June\n2025 the split was 51.6%Asking, 34.6%Doing, and 13.8%Expressing.\nFigure 12:Shares of messages classified as Asking, Doing, or Expressing by an automated ternary classifier.\nValues are averaged over a 28 day lagging window. Shares are calculated from a sample of approximately\n1.1 million sampled conversations from May 15, 2024 through June 26, 2025. Observations are reweighted to\nreflect total message volumes on a given day. Sampling details available in Section 3.\nFigure 13 presents the share of work-related messages by user intent.Doingmessages, which\naccount for approximately 40% of messages, have an even split of messages between work-related and\nnon-work related.\n', '<2-hop>\n\n5.4 O*NET Work Activities\nWe map message content to work activities using the Occupational Information Network (O*NET)\nDatabase Version 29.0, similar to Tomlinson et al (2025). O*NET was developed in partnership with\nthe U.S. Department of Labor and systematically classifies jobs according to the skills, tasks, and\nwork activities required to perform them. O*NET associates each occupation with a set of tasks that\nare performed at different levels of intensity. Each task is then aggregated up to three levels of detail\n- 2,087 detailed work activities (DWAs), 332 intermediate work activities (IWAs), and 41 generalized\nwork activities (GWAs).\nTo understand the work activities associated with ChatGPT usage, we mapped messages to one\nof the 332 O*NET Intermediate Work Activities (IWA), with an additional option ofAmbiguousto\naccount for situations where the user message lacked sufficient context. 22 We then used the official\n22We drew a sample of approximately 1.1 million conversations from May 2024 to June 2025, selected a random\nmessage within each, and classified it according to the prompt in A.\n19\x0cFigure 13:Shares of Asking, Doing, and Expressing messages split by work vs. non-work. See A to review\nthe prompts used by the automated classifiers. The annotations on the right show the shares of work and\nnon-work for the full sample. Each bin reports a percentage of the total population. Shares are calculated\nfrom a sample of approximately 1.1 million sampled conversations from May 15, 2024 through June 26, 2025.\nObservations are reweighted to reflect total message volumes on a given day. Sampling details available in\nSection 3.\nO*NET taxonomy to map these classified IWAs to one of the Generalized Work Activities (GWA). We\ndo not show the shares for the following GWAs as there were fewer than 100 users sending messages\nfor each category and group them intoSuppressed.\nFigure 14 presents the share of messages that belong to each GWA, in descending order. Nearly\nhalf of all messages (45.2%) fall under just three GWAs related to information use and manipula-\ntion:Getting Information(19.3%),Interpreting the Meaning of Information for Others(13.1%), and\nDocumenting/Recording Information(12.8%). The next most common work activities areProviding\nConsultation and Advice(9.2%),Thinking Creatively(9.1%),Making Decisions and Solving Problems\n(8.5%), andWorking with Computers(4.9%). These seven GWAs collectively account for 76.9% of\nall messages.\nFigure 15 presents the distribution of GWAs for the subsample of messages we classify as work-\nrelated. Among work-related messages, the most common GWAs areDocumenting/Recording In-\nformation(18.4%),Making Decisions and Solving Problems(14.9%),Thinking Creatively(13.0%),\nWorking with Computers(10.8%),Interpreting the Meaning of Information for Others(10.1%),Get-\nting Information(9.3%), andProviding Consultation and Advice to Others(4.4%). These seven GWAs\ncollectively account for nearly 81% of work-related messages. Overall, the majority of ChatGPT usage\nat work appears to be focused on two broad functions: 1) obtaining, documenting, and interpreting\ninformation; and 2) making decisions, giving advice, solving problems, and thinking creatively.\n20\x0cFigure 14:GWA Shares of 1.1M ChatGPT Messages. Messages are classified as pertaining to one of 332\nO*NET IWAs, orAmbiguoususing the prompt provided in the Appendix. IWAs were then aggregated to\nGWAs using the O*NET Work Activities taxonomy. Message sample from May 15, 2024 through June 26,\n2025. ', '<3-hop>\n\nExpressingrubric. The critical part\nof our classification prompt is as follows:\nIntent Prompt\nAskingAsking is seeking information or advice that will help the user be better\ninformed or make better decisions, either at work, at school, or in their\npersonal life. (e.g. “Who was president after Lincoln?”, “How do I create a\nbudget for this quarter?”, “What was the inflation rate last year?”,\n“What’s the difference between correlation and causation?”, “What should I\nlook for when choosing a health plan during open enrollment?”).\nDoingDoing messages request that ChatGPT perform tasks for the user. User is\ndrafting an email, writing code, etc. Classify messages as “doing” if they\ninclude requests for output that is created primarily by the model. (e.g.\n“Rewrite this email to make it more formal”, “Draft a report summarizing\nthe use cases of ChatGPT”, “Produce a project timeline with milestones\nand risks in a table”, “Extract companies, people, and dates from this text\ninto CSV.”, “Write a Dockerfile and a minimal docker-compose.yml for\nthis app.”)\nExpressingExpressing statements are neither asking for information, nor for the\nchatbot to perform a task.\nConceptually,Doingconversations are delivering output that can be plugged into a production\nprocess, whileAskingconversations support decision-making but do not produce output directly, and\nExpressingconversations have little or no economic content.\nFigure 10 shows the share of messages by each intent type in our sample. 49% of user messages\nareAsking, 40% areDoing, and 11% areExpressing. The figure also shows the relationship with\nour Topic classification: the two taxonomies are correlated but not redundant:Askingqueries are\nmore likely to bePractical GuidanceandSeeking Information.Doingqueries are disproportionately\nWritingandMultimedia.Expressingqueries are disproportionatelySelf-Expression. However, the\noverlap is imperfect. For example, within thePractical Guidancetopic, anAskingmessage might\nbe advice about how to recover from a sports injury given a user’s personal history, while aDoing\nmessage might request ChatGPT to produce a customized recovery and training plan that could be\nprinted or saved. WithinTechnical Help, anAskingmessage might request help understanding how\nto debug some code, while aDoingmessage might ask ChatGPT to write code for the user directly.\nFigure 11 presents shares ofAsking/Doing/Expressingjust for work-related messages.Doing\nconstitutes nearly 56% of work-related queries, compared to 35% forAskingand 9% forExpressing.\nNearly 35% of all work-related queries areDoingmessages related toWriting.DoingandAsking\ncomprise equal shares ofTechnical Helpqueries.\n17\x0cFigure 10:']","Nearly 56% of work-related queries are classified as Doing messages, while 35% are classified as Asking and 9% as Expressing. This classification is mapped to work activities using the O*NET Database, which systematically categorizes jobs based on the skills, tasks, and work activities required. The majority of ChatGPT usage at work focuses on obtaining, documenting, and interpreting information, as well as making decisions, giving advice, solving problems, and thinking creatively.",multi_hop_abstract_query_synthesizer
