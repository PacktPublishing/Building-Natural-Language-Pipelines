user_input,reference_contexts,reference,synthesizer_name
What role does Microsoft play in the development of AI technologies?,"['You may or may not be aware of how pervasive AI is in our everyday lives already. According to one survey of 6,000 consumers, while only 33% of people think that they use AI, over 77% use an AI-powered service or device. It’s not surprising that people are unaware of all the ways AI touches their lives. After all, the development of AI surged over recent years as researchers made strides they didn’t expect to make for another several decades.\nSo what are some common uses and applications of AI? You may be surprised to learn that it can be anything from advanced robotics to the voice search function on your smartphone. We’ll dive into more specific examples below.\nIn this article, we’ll cover:\n What is artificial intelligence?\nArtificial intelligence is a specific branch of computer science concerned with replicating the thought process and decision-making ability of humans through computer algorithms. There are many different branches of AI that can create and do different things. Some types complete simple tasks, while others are much more complex. Some AI programs adjust their own algorithms, and some specialized algorithms are so advanced they can beat human experts in their given fields.\n Examples and applications of AI\nSo what are some examples of AI? Well, it can be almost anything. Your smartphone uses AI, as do services like digital assistants, chatbots, social media websites, and much more. Many home electronics also use AI, such as robot vacuum cleaners or security systems. And, of course, there are classic examples of auto-navigation and robotics.\nBelow, we’ve outlined applications in greater detail so you can understand how AI impacts everyday life.\n Digital assistants\nPerhaps the application used by most people would be the digital assistants on our various pieces of technology. If you have a smartphone or laptop, you probably have and use digital assistant software to some degree.\nSome of the most popular digital assistants include:\n- Siri (Apple)\n- Alexa (Amazon)\n- Cortana (Microsoft)\n- Google Assistant (Google)\n- Bixby (Samsung)\n Search engines\nAnother common application of AI is search engines. Search engine algorithms utilize AI to refine and show better results without the intervention of programmers. You can see this in action on Google if you search a question. You’ll see a section called “People also ask” and if you open one of those questions, it will spawn two more related questions below.\nAn even simpler example is Google’s auto-complete answers when you type in the search bar. An AI algorithm gathers data on what people search most often and uses that to populate predictions you can use to navigate.\nPopular search engines include:\n- Yahoo\n- Bing\n- DuckDuckGo\n']","Microsoft is known for its digital assistant, Cortana, which is one of the popular applications of AI technology. Additionally, Microsoft contributes to the development of AI through its various services and products that utilize AI algorithms to enhance user experience.",single_hop_specific_query_synthesizer
How does Instagram utilize AI algorithms to enhance user engagement and advertising?,"['Social media\nSocial media platforms are another common way people interact with AI. All major social media platforms run off AI-powered algorithms which are designed to serve specific purposes. Most use algorithms to determine what their users like and serve more of that content, to keep the user engaged. Many also run AI algorithms to gather and store user data to use for advertising purposes.\nYou can train your social media algorithms to show the content you like by creating filters, or searching carefully for what you like, and purposefully interacting (liking, commenting, sharing, etc.) with things you enjoy.\nPopular social media platforms include:\n- Facebook (Meta)\n- Instagram (Meta)\n- YouTube\n- TikTok\nOnline shopping\nThis is probably one of the least obvious ways people interact with AI in their daily lives. Many online shopping and ecommerce platforms use AI to streamline their customer experience in a variety of ways.\nAs a customer, you may experience AI through:\n- Personalized product recommendations based on previous shopping activity or customer profile.\n- Pricing optimization based on supply, demand, or previous shopping activity.\n- Chatbots to provide instant responses to customer service or technical issues.\n- Shipping and delay estimates.\nAs a business owner, you may consider implementing AI in the following additional ways:\n- Sales and demand forecasting to help you manage your inventory in the face of increased or decreased demand.\n- Creating customer profiles and segmentation to boost sales.\n- Smart analytics to show in real-time how your business is performing.\nRobots\nThe word “robot” probably makes many people think of sci-fi movies like Star Wars or shows like Star Trek with their humanoid, intelligent robots. Though those may seem futuristic or even far-fetched, in reality, many robots already exist in our world. You may even own some, or something produced by one.\nRobots are used in a myriad of fields to streamline production or keep workers safe. They handle repetitive tasks or anything deemed too dangerous for a human worker. Some examples of industrial robots include:\n- Aerospace: You may be familiar with the Mars rovers NASA has landed over the years. These are programmed to explore, gather samples and send transmissions back to Earth to provide data from Mars that an astronaut would be unable to obtain. Most recently, NASA sent the rover Perseverance to Mars to gather samples and search for signs of ancient life.\n- Manufacturing: The use of robots in assembly lines dates back to 1961, when General Motors introduced a robot to assist with welding and transporting die casings (jobs deemed too dangerous for humans). It continues to this day, streamlining production and providing safer working conditions for humans.\n']","Instagram, like other major social media platforms, runs off AI-powered algorithms designed to serve specific purposes. These algorithms determine what users like and serve more of that content to keep them engaged. Additionally, Instagram gathers and stores user data to use for advertising purposes, enhancing the effectiveness of targeted ads.",single_hop_specific_query_synthesizer
How did General Motors contribute to the use of industrial robots in manufacturing?,"['Some examples of industrial robots include:\n- Aerospace: You may be familiar with the Mars rovers NASA has landed over the years. These are programmed to explore, gather samples and send transmissions back to Earth to provide data from Mars that an astronaut would be unable to obtain. Most recently, NASA sent the rover Perseverance to Mars to gather samples and search for signs of ancient life.\n- Manufacturing: The use of robots in assembly lines dates back to 1961, when General Motors introduced a robot to assist with welding and transporting die casings (jobs deemed too dangerous for humans). It continues to this day, streamlining production and providing safer working conditions for humans.\n- Hospitality: Particularly in recent years, the hospitality industry has adopted robots to help complete simple tasks and fill in for worker shortages. These can do things like check-in guests at hotels, mix drinks at cafes, deliver meals to tables in restaurants, and more.\n Transportation and Navigation\nYou’ve probably heard of self-driving cars, whether in a sci-fi show or in the news from recent attempts by various companies. But there are more ways that AI is utilized in transportation. Most major map software uses some kind of AI to interpret real-time traffic data and provide routes and ETAs. Additionally, many aircraft use an AI-powered autopilot that takes in weather conditions and flight data to set the course.\nIn fact, studies show that the application of AI in transportation has made it safer, more efficient, and more reliable.\nOther examples of AI in transportation and navigation include:\n- Traffic management systems take in real-time data about the road, weather, and traffic conditions to predict heavier traffic flows and congestion.\n- Direction apps such as Google Maps, Apple Maps, and Waze all use location data collected from users to determine traffic, ETAs, and more.\n- Rideshare apps, much like direction apps, use AI that takes in location and environmental data to give ETAs, predict road conditions, and set fare rates.\n Text editing and autocorrect\nAnother example of AI in the palm of your hand (if you have a smartphone, anyway) is autocorrect and other text editing software. This software takes input from generalized dictionaries and common use but also learns from your specific patterns to pick up the words you use most frequently and help you spell them.\nOther online text editors like Grammarly or Hemingway App take standards of style, length, and grammar, and compare them to your texts, generating reports on errors and readability stats. Some of them also analyze other online content in real-time to compare for originality.\n']","General Motors introduced a robot to assist with welding and transporting die casings in 1961, marking the beginning of robot use in assembly lines. This innovation was aimed at jobs deemed too dangerous for humans and continues to streamline production while providing safer working conditions for human workers.",single_hop_specific_query_synthesizer
What F.E.A.R do in gaming?,"['Fraud prevention\nIf you have an account with any major bank, chances are they use AI in their fraud detection and prevention systems. These work by analyzing thousands of transactions, and recognizing normal patterns so they can flag suspicious activity. These programs can auto-decline anything suspicious and flag an investigation, as well as notify the individual for verification.\n Predictions\nSince AI can process large amounts of data all at once, it’s useful in identifying patterns and using those to make predictions. Businesses can then use these predictions to make informed decisions or prevent possible future issues.\nCommon uses of predictive AI include:\n- Maintenance: Tracking previous repairs and general wear and tear on parts in equipment allows AI to predict when maintenance needs to happen, preventing inconvenient breakdowns or possible accidents.\n- Modeling: Predictive modeling uses data mining and probability forecasting to predict and estimate future outcomes.\nGaming\nPerhaps surprisingly, AI has been in the field of gaming for years. Over the years, many AI systems were designed to play various games as the developers worked on building software that would learn. AIs have beaten human champions in Chess, Go, StarCraft 2, and also on the game show Jeopardy.\nOf course, many games also utilize AI in their development to continually increase interest and incentives for users to keep playing. Some games that use AI include:\n- Minecraft: uses AI to generate unending virtual environments and adapt to the player’s style.\n- F.E.A.R: uses enemy AI to allow characters to learn and adapt to the player’s movements in game.\n- The Last of Us: has a dynamic AI for each non-player character allowing them to react differently to the player character depending on their specific choices.\n Healthcare\nFrom robotics in hospitals and clinics to predictive software used to diagnose rare diseases, AI has many uses in the field of healthcare. Doctors and medical staff work with AI-powered software to provide better care to patients of all types.\nSome uses of AI in healthcare:\n- Early diagnosis: AI can analyze patient and disease data to predict the likelihood of a patient developing a disease and either diagnose it early or help to prevent it entirely.\n- Disease tracking: Using predictive analytics, AI can model how a contagious disease could spread over the course of time or across a specific area.\n- Drug discovery: AI models can discover new applications or potentially harmful interactions between different drugs.\nAdvertising\nLike many of the above examples, AI has numerous applications in the field of advertising. From offering dynamic ads based on demographics or location to AI that can write the copy itself, AI drives the field of advertising and marketing forward.\nExamples of AI in advertising:\n- Ad creation: AI software can be trained to write copy or even make images based on interaction and purchase data.\n- Dynamic presentation: Many ad platforms allow you to create ads that present different images or text based on customer demographics or location, personalizing the ad experience.\n- Budget optimization: Some ad platforms use AI agents to help determine where an advertiser’s budget goes, focusing budget spending on the best-performing ad on the most cost-effective days and times it to the best-performing ad, day, and time.\nAnalytics\nFinally, another common use for AI is in the field of data science and analytics. One of the most common uses is in predictive analytics, but AI can also be useful in data analysis. Most crucially, using AI analytics helps companies to scale their analytics and allows them to have accurate data at a much quicker rate than before.\nSome common uses for AI in analytics are:\n- Forecasting: Taking in historical data and creating a reasonable forecast of what you can expect to see in the future.\n- Predictive analytics: Predicting trends and future results based on historical data.\n- Business monitoring: Real-time analytics on all key data points, from revenue to cost to customer experience.\nBusiness and AI\nWhile that list of examples may seem extensive, it’s certainly not all-encompassing. ']",F.E.A.R uses enemy AI to allow characters to learn and adapt to the player’s movements in game.,single_hop_specific_query_synthesizer
Who is David J. Deming?,"['NBER WORKING PAPER SERIES\nHOW PEOPLE USE CHATGPT\nAaron Chatterji\nThomas Cunningham\nDavid J. Deming\nZoe Hitzig\nChristopher Ong\nCarl Yan Shan\nKevin Wadman\nWorking Paper 34255\nhttp://www.nber.org/papers/w34255\nNATIONAL BUREAU OF ECONOMIC RESEARCH\n1050 Massachusetts Avenue\nCambridge, MA 02138\nSeptember 2025\nWe acknowledge help and comments from Joshua Achiam, Hemanth Asirvatham, Ryan Beiermeister, Rachel Brown, Cassandra Duchan Solis, Jason Kwon, Elliott Mokski, Kevin Rao, Harrison Satcher, Gawesha Weeratunga, Hannah Wong, and Analytics & Insights team. We especially thank Tyna Eloundou and Pamela Mishkin who in several ways laid the foundation for this work. This study was approved by Harvard IRB (IRB25-0983). A repository containing all code run to produce the analyses in this paper is available on request. The views expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.\nAt least one co-author has disclosed additional relationships of potential relevance for this research. Further information is available online at http://www.nber.org/papers/w34255\nNBER working papers are circulated for discussion and comment purposes. They have not been peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies official NBER publications.\n© 2025 by Aaron Chatterji, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl Yan Shan, and Kevin Wadman. All rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including © notice, is given to the source.\x0cHow People Use ChatGPT\nAaron Chatterji, Thomas Cunningham, David J. Deming, Zoe Hitzig, Christopher Ong, Carl\nYan Shan, and Kevin Wadman\nNBER Working Paper No. 34255\nSeptember 2025\nJEL No. J01, O3, O4\nABSTRACT\nDespite the rapid adoption of LLM chatbots, little is known about how they are used. We document the growth of ChatGPT’s consumer product from its launch in November 2022 through July 2025, when it had been adopted by around 10% of the world’s adult population. Early adopters were disproportionately male but the gender gap has narrowed dramatically, and we find higher growth rates in lower-income countries. Using a privacy-preserving automated pipeline, we classify usage patterns within a representative sample of ChatGPT conversations. We find steady growth in work-related messages bu t even faster growth in non-work-related messages, which have grown from 53% to more than 70% of all usage. Work usage is more common for educated users in highly-paid professional occupations. We classify messages by conversation top\nic and find that “Practical Guidance,” “Seeking Information,” and “Writing” are the three most common topics and collectively account for nearly 80% of all conversations. Writing dominates work-related tasks, highlighting chatbots’ unique ability to generate digital outputs compared to traditional sear ch engines. Computer programming and self-expression both represent relatively small shares of use. Overall, we find that ChatGPT provides economic value through decision support, which is especially important in knowledge-intensive jobs.\nAaron Chatterji\nDuke University\nFuqua School of Business and OpenAI\nronnie@duke.edu\nThomas Cunningham OpenAI\ntom.cunningham@gmail.com\nDavid J. Deming\nHarvard University\nHarvard Kennedy School and NBER\ndavid_deming@harvard.edu\nZoe Hitzig\nOpenAI\nand Harvard Society of Fellows\nzhitzig@g.harvard.edu\nChristopher Ong\nHarvard University\nand OpenAI\nchristopherong@hks.harvard.edu\nCarl Yan Shan\nOpenAI\ncshan@openai.com\nKevin Wadman\nOpenAI\nkevin.wadman@c-openai.com\x0c']",David J. Deming is one of the co-authors of the NBER Working Paper titled 'How People Use ChatGPT.' He is affiliated with Harvard University and the Harvard Kennedy School.,single_hop_specific_query_synthesizer
What role did Ouyang play in the development of ChatGPT and how does it relate to the training of language models?,"['<1-hop>\n\nOuyang, Long, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela\nMishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schul-\nman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter\nWelinder, Paul Christiano, Jan Leike, and Ryan Lowe, “Training Language Models to\nFollow Instructions with Human Feedback,” 2022.\nPew Research Center, “U.S. adults’ use of ChatGPT (June 2025 report),” 2025.\nPhang, Jason, Michael Lampe, Lama Ahmad, Sandhini Agarwal, Cathy Mengying Fang,\nAuren R. Liu, Valdemar Danry, Eunhae Lee, Samantha W. T. Chan, Pat Pataranuta-\nporn, and Pattie Maes, “Investigating Affective Use and Emotional Well-being on ChatGPT,”\n2025.\nReuters, “OpenAI hits$12 billion in annualized revenue, The Information reports,”Reuters, July\n30 2025. Accessed: 2025-09-11.\nRoth, Emma, “OpenAI says ChatGPT users send over 2.5 billion prompts every day,” July 21 2025.\nAccessed: 2025-09-11.\nTomlinson, Kiran, Sonia Jaffe, Will Wang, Scott Counts, and Siddharth Suri, “Working\nwith AI: Measuring the Occupational Implications of Generative AI,” 2025.\n39\x0cVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N.\nGomez, Lukasz Kaiser, and Illia Polosukhin, “Attention Is All You Need,” in I. Guyon,\nU. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, eds.,Ad-\nvances in Neural Information Processing Systems, Vol. 30 of31st Conference on Neural Information\nProcessing Systems (NIPS)Curran Associates, Inc. Long Beach, CA, USA 2017.\nWest, Jevin D., Jennifer Jacquet, Molly M. King, Shelley J. Correll, and Carl T.\nBergstrom, “The Role of Gender in Scholarly Authorship,”PLoS ONE, 2013,8(7), e66212.\nWiggers, Kyle, “ChatGPT Isn’t the Only Chatbot That’s Gaining Users,”TechCrunch, 2025. Ac-\ncessed: 2025-09-10.\nZao-Sanders, Marc, “How People Are Really Using Gen AI in 2025,” Harvard Business Review\nApril 2025. https://hbr.org/2025/04/how-people-are-really-using-gen-ai-in-2025.\nZhao, Wenting, Xiang Ren, Jack Hessel, Claire Cardie, Yejin Choi, and Yuntian Deng,\n“WildChat: 1M ChatGPT Interaction Logs in the Wild,” 2024.\n40\x0c', '<2-hop>\n\nWhat is ChatGPT?\nHere we give a simplified overview of LLMs and chatbots. For more precise details, refer to the papers\nand system cards that OpenAI has released with each model e.g., (OpenAI, 2023, 2024a, 2025b). A\nchatbot is a statistical model trained to generate a text response given some text input, so as to\nmaximize the “quality” of that response, where the quality is measured with a variety of metrics.\nIn a prototypical interaction, a user submits a plain-text message (“prompt”) and ChatGPT\nreturns the message (“response”) generated from an underlying LLM. A large set of additional features\nhave been added to ChatGPT—including the possibility for the LLM to search the web or external\ndatabases, and generate images based on text—but the exchange of text-based messages remains the\nmost typical interaction.\nSince its launch ChatGPT has used a variety of different underlying LLMs e.g., GPT-3.5, GPT-4,\nGPT-4o, o1, o3, and GPT-5. 12 In addition there are occasional updates to the model’s weights and\nto the model’s system prompt (text instructions sent to the model along with all the queries).\nAn LLM can be thought of as a function from a string of words to a probability distribution over\nthe set of all possible words (more precisely, “tokens,” which very roughly correspond to words13). The\nfunctions are implemented with deep neural nets, typically with a transformer architecture (Vaswani\net al., 2017), parameterized with billions of model “weights”. We will refer to all of ChatGPT’s models\nas language models, though most can additionally process tokens representing images, audio, or other\nmedia.\nThe weights in an LLM-based chatbot are often trained in two stages, commonly called “pre-\ntraining” and “post-training”. In the first stage (“pre-training”), the LLMs are trained to predict the\nnext word in a string, given the preceding words, over an enormous corpus of text. At that point the\nmodels are purely predictors of the likelihood of the next word given a prior context, and as such they\nhave a relatively narrow application. In the second stage (“post-training”), the models are trained to\nproduce words that comprise “good” responses to some prompt. This stage often consists of a variety\nof different strategies: fine-tuning on a dataset of queries and ideal responses, reinforcement learning\nagainst another model that is trained to grade the quality of a response (Ouyang et al., 2022), or\nreinforcement learning against a function that knows the true response to queries (OpenAI (2024b),\n12For a timeline of model launches, see Appendix C.\n13Tokenization is a way of cutting a string of text into discrete chunks, chosen to be statistically efficient. In many\ntokenization schemes, one token corresponds to roughly three-quarters of an English word.\n4\x0cLambert et al. (2024)). This second stage also typically includes a number of “safety” constraints to\navoid certain classes of response, especially those which are deemed harmful or dangerous (OpenAI,\n2025a).\nThis two-stage process has a common statistical interpretation: the first stage teaches the model a\nlatent representation of the world; the second stage fits a function using that representation (Bengio\net al., 2014). Pre-training the model to predict the next word effectively teaches the model a low-\ndimensional representation of text, representing only the key semantic features, and therefore rendering\nthe prompt-response problem tractable with a reasonable set of training examples.\nTwo common ways of evaluating chatbots are with benchmarks (batteries of questions with known\nanswers, e.g. Measuring Massive Multitask Language Understanding (Hendrycks et al., 2021)) and\ncomparisons of human preferences over two alternative responses to the same message (e.g. Chatbot\nArena (Chiang et al., 2024)).\n3 ']","Ouyang, along with other researchers, contributed to the paper titled 'Training Language Models to Follow Instructions with Human Feedback' in 2022, which discusses methods for improving language models like ChatGPT. This work is significant as it outlines the reinforcement learning techniques used in the post-training phase of language models, which are essential for generating high-quality responses to user prompts.",multi_hop_specific_query_synthesizer
Wht does Figure 5 show abt daily msgs sent per wkly active user by sign-up cohort?,"['<1-hop>\n\nThe yellow line represents the first cohort of ChatGPT users: their usage declined somewhat over\n2023, but started growing again in late 2024 and is now higher than it has ever been. The pink line\nrepresents messages from users who signed up in Q3 of 2023 or earlier, and so thedifferencebetween\n20Note that we expect our counts of distinct accounts to somewhat exceed distinct people when one person has two\naccounts (or, for logged-out users, one person using two devices). For logged-in users, the count is based on distinct\nlogin credentials (email addresses), and one person may have multiple accounts. For logged-out users, the count is based\non distinct browser cookies; this would double-count people if someone returns to ChatGPT after clearing their cookies,\nor if they access ChatGPT with two different devices in the same week.\n10\x0cFigure 4:Daily message volumes from ChatGPT consumer plans (Free, Plus, Pro), split by sign-up date of\nthe requesting user. Reported values are moving averages of the past 90 days. Y-axis is an index normalized\nto the reported value for ”All Cohorts” at the end of Q1 2024 (April 1, 2024).\nthe yellow and pink lines represents the messages sent by users who signed up in Q2 and Q3 of 2023.\nThere has been dramatic growth in message volume both by new cohorts of users, and from growth\nin existing cohorts.\nFigure 5 normalizes each cohort, plotting daily messages per weekly active user. Each line rep-\nresents an individual cohort (instead of a cumulative cohort, as in Figure 4). The figure shows that\nearlier sign-ups have consistently had higher usage, but that usage has also consistently grown within\nevery cohort, which we interpret as due to both (1) improvements in the capabilities of the models,\nand (2) users slowly discovering new uses for existing capabilities.\n5  How ChatGPT is Used\nWe next report on thecontentof ChatGPT conversations using a variety of different taxonomies. For\neach taxonomy we describe a “prompt” which defines a set of categories, and then apply an LLM\nto map each message to a category. Our categories often apply to the user’sintention, rather than\nthe text of the conversation, and as such we never directly observe the ground truth. Nevertheless\nthe classifier results can be interpreted as the best-guess inferences that a human would make: the\nguesses from the LLM correlate highly with human guesses from the same prompt, and we get similar\nqualitative results when the prompt includes a third category for “uncertain.”\n11\x0cFigure 5:Daily messages sent per weekly active user, split by sign-up cohort. Sample only considers users of\nChatGPT consumer plans (Free, Plus, Pro). Reported values are moving averages of the past 90 days and are\nreported starting 90 days after the cohort is fully formed. Y-axis is an index normalized to the first reported\nvalue for the Q1 2023 cohort.\n5.1 ']","Figure 5 shows the daily messages sent per weekly active user, split by sign-up cohort. It indicates that earlier sign-ups have consistently had higher usage, while usage has also grown within every cohort. This growth is interpreted as a result of improvements in the capabilities of the models and users discovering new uses for existing capabilities.",multi_hop_specific_query_synthesizer
"In what ways does the use of automated classifiers ensure privacy while analyzing message content, and what specific measures are taken to prevent accidental access to the underlying text?","['<1-hop>\n\nPrivacy via Automated Classifiers.No one looked at the content of messages while conducting\nanalysis for this paper. All analysis of message content was performed via automated LLM-based\nclassifiers run on de-identified and PII-scrubbed message data (see Figure 1). The messages are first\nscrubbed of PII using an internal LLM-based tool,17 and then classified according to classifiers defined\nover a controlled label space—the most precise classifier we use on the message-level data set is the\nO*NET Intermediate Work Activities taxonomy, which we augment to end up with 333 categories.\nWe introduce technical and procedural frictions that prevent accidental access to the underlying text\n(for example, interfaces that do not render message text to researchers).\nOur classifications aim to discern the intent of a given message, and thus we include the prior 10\nmessages in a conversation as context. 18 For an example, see Table 2.\nStand-Alone Message Message with Prior Context\n[user]: “10 more” [user]: “give me 3 cultural activities to do with teens”\n[assistant]: “1. Visit a museum . . . ” (truncated)\n[user]: “10 more”\nTable 2:Illustration of Context-Augmented Message Classifications (Synthetic Example). The left column\nshows a standalone message to be classified, and the right column shows the prior context included in the\nclassification of the message on the left.\nWe truncate each message to a maximum of 5,000 characters, because long context windows could\ninduce variability in the quality of the classification (Liu et al., 2023). We classify each message\nwith the “gpt-5-mini” model, with the exception ofInteraction Quality,which uses “gpt-5,” using the\nprompts listed in Appendix A.\n17Internal analyses show that the tool,Privacy Filter, has substantial alignment with human judgment.\n']","The use of automated classifiers ensures privacy during the analysis of message content by employing LLM-based classifiers on de-identified and PII-scrubbed message data. This process begins with scrubbing messages of personally identifiable information (PII) using an internal LLM-based tool. Additionally, technical and procedural frictions are introduced to prevent accidental access to the underlying text, such as interfaces that do not render message text to researchers. These measures are designed to maintain the confidentiality of the data while allowing for the classification of messages based on their intent, utilizing prior context from conversations to enhance accuracy.",multi_hop_specific_query_synthesizer
What role does Apple's Siri play in the context of AI applications mentioned in the article?,"['<1-hop>\n\nYou may or may not be aware of how pervasive AI is in our everyday lives already. According to one survey of 6,000 consumers, while only 33% of people think that they use AI, over 77% use an AI-powered service or device. It’s not surprising that people are unaware of all the ways AI touches their lives. After all, the development of AI surged over recent years as researchers made strides they didn’t expect to make for another several decades.\nSo what are some common uses and applications of AI? You may be surprised to learn that it can be anything from advanced robotics to the voice search function on your smartphone. We’ll dive into more specific examples below.\nIn this article, we’ll cover:\n What is artificial intelligence?\nArtificial intelligence is a specific branch of computer science concerned with replicating the thought process and decision-making ability of humans through computer algorithms. There are many different branches of AI that can create and do different things. Some types complete simple tasks, while others are much more complex. Some AI programs adjust their own algorithms, and some specialized algorithms are so advanced they can beat human experts in their given fields.\n Examples and applications of AI\nSo what are some examples of AI? Well, it can be almost anything. Your smartphone uses AI, as do services like digital assistants, chatbots, social media websites, and much more. Many home electronics also use AI, such as robot vacuum cleaners or security systems. And, of course, there are classic examples of auto-navigation and robotics.\nBelow, we’ve outlined applications in greater detail so you can understand how AI impacts everyday life.\n Digital assistants\nPerhaps the application used by most people would be the digital assistants on our various pieces of technology. If you have a smartphone or laptop, you probably have and use digital assistant software to some degree.\nSome of the most popular digital assistants include:\n- Siri (Apple)\n- Alexa (Amazon)\n- Cortana (Microsoft)\n- Google Assistant (Google)\n- Bixby (Samsung)\n Search engines\nAnother common application of AI is search engines. Search engine algorithms utilize AI to refine and show better results without the intervention of programmers. You can see this in action on Google if you search a question. You’ll see a section called “People also ask” and if you open one of those questions, it will spawn two more related questions below.\nAn even simpler example is Google’s auto-complete answers when you type in the search bar. An AI algorithm gathers data on what people search most often and uses that to populate predictions you can use to navigate.\nPopular search engines include:\n- Yahoo\n- Bing\n- DuckDuckGo\n']","Apple's Siri is highlighted as one of the most popular digital assistants that utilize AI technology. It exemplifies how AI is integrated into everyday life through smartphones and laptops, allowing users to interact with their devices using voice commands and enhancing the overall user experience.",multi_hop_specific_query_synthesizer
What are some common uses of AI in everyday life and how does it help in fraud prevention?,"['<1-hop>\n\nYou may or may not be aware of how pervasive AI is in our everyday lives already. According to one survey of 6,000 consumers, while only 33% of people think that they use AI, over 77% use an AI-powered service or device. It’s not surprising that people are unaware of all the ways AI touches their lives. After all, the development of AI surged over recent years as researchers made strides they didn’t expect to make for another several decades.\nSo what are some common uses and applications of AI? You may be surprised to learn that it can be anything from advanced robotics to the voice search function on your smartphone. We’ll dive into more specific examples below.\nIn this article, we’ll cover:\n What is artificial intelligence?\nArtificial intelligence is a specific branch of computer science concerned with replicating the thought process and decision-making ability of humans through computer algorithms. There are many different branches of AI that can create and do different things. Some types complete simple tasks, while others are much more complex. Some AI programs adjust their own algorithms, and some specialized algorithms are so advanced they can beat human experts in their given fields.\n Examples and applications of AI\nSo what are some examples of AI? Well, it can be almost anything. Your smartphone uses AI, as do services like digital assistants, chatbots, social media websites, and much more. Many home electronics also use AI, such as robot vacuum cleaners or security systems. And, of course, there are classic examples of auto-navigation and robotics.\nBelow, we’ve outlined applications in greater detail so you can understand how AI impacts everyday life.\n Digital assistants\nPerhaps the application used by most people would be the digital assistants on our various pieces of technology. If you have a smartphone or laptop, you probably have and use digital assistant software to some degree.\nSome of the most popular digital assistants include:\n- Siri (Apple)\n- Alexa (Amazon)\n- Cortana (Microsoft)\n- Google Assistant (Google)\n- Bixby (Samsung)\n Search engines\nAnother common application of AI is search engines. Search engine algorithms utilize AI to refine and show better results without the intervention of programmers. You can see this in action on Google if you search a question. You’ll see a section called “People also ask” and if you open one of those questions, it will spawn two more related questions below.\nAn even simpler example is Google’s auto-complete answers when you type in the search bar. An AI algorithm gathers data on what people search most often and uses that to populate predictions you can use to navigate.\nPopular search engines include:\n- Yahoo\n- Bing\n- DuckDuckGo\n', '<2-hop>\n\nFraud prevention\nIf you have an account with any major bank, chances are they use AI in their fraud detection and prevention systems. These work by analyzing thousands of transactions, and recognizing normal patterns so they can flag suspicious activity. These programs can auto-decline anything suspicious and flag an investigation, as well as notify the individual for verification.\n Predictions\nSince AI can process large amounts of data all at once, it’s useful in identifying patterns and using those to make predictions. Businesses can then use these predictions to make informed decisions or prevent possible future issues.\nCommon uses of predictive AI include:\n- Maintenance: Tracking previous repairs and general wear and tear on parts in equipment allows AI to predict when maintenance needs to happen, preventing inconvenient breakdowns or possible accidents.\n- Modeling: Predictive modeling uses data mining and probability forecasting to predict and estimate future outcomes.\nGaming\nPerhaps surprisingly, AI has been in the field of gaming for years. Over the years, many AI systems were designed to play various games as the developers worked on building software that would learn. AIs have beaten human champions in Chess, Go, StarCraft 2, and also on the game show Jeopardy.\nOf course, many games also utilize AI in their development to continually increase interest and incentives for users to keep playing. Some games that use AI include:\n- Minecraft: uses AI to generate unending virtual environments and adapt to the player’s style.\n- F.E.A.R: uses enemy AI to allow characters to learn and adapt to the player’s movements in game.\n- The Last of Us: has a dynamic AI for each non-player character allowing them to react differently to the player character depending on their specific choices.\n Healthcare\nFrom robotics in hospitals and clinics to predictive software used to diagnose rare diseases, AI has many uses in the field of healthcare. Doctors and medical staff work with AI-powered software to provide better care to patients of all types.\nSome uses of AI in healthcare:\n- Early diagnosis: AI can analyze patient and disease data to predict the likelihood of a patient developing a disease and either diagnose it early or help to prevent it entirely.\n- Disease tracking: Using predictive analytics, AI can model how a contagious disease could spread over the course of time or across a specific area.\n- Drug discovery: AI models can discover new applications or potentially harmful interactions between different drugs.\nAdvertising\nLike many of the above examples, AI has numerous applications in the field of advertising. From offering dynamic ads based on demographics or location to AI that can write the copy itself, AI drives the field of advertising and marketing forward.\nExamples of AI in advertising:\n- Ad creation: AI software can be trained to write copy or even make images based on interaction and purchase data.\n- Dynamic presentation: Many ad platforms allow you to create ads that present different images or text based on customer demographics or location, personalizing the ad experience.\n- Budget optimization: Some ad platforms use AI agents to help determine where an advertiser’s budget goes, focusing budget spending on the best-performing ad on the most cost-effective days and times it to the best-performing ad, day, and time.\nAnalytics\nFinally, another common use for AI is in the field of data science and analytics. One of the most common uses is in predictive analytics, but AI can also be useful in data analysis. Most crucially, using AI analytics helps companies to scale their analytics and allows them to have accurate data at a much quicker rate than before.\nSome common uses for AI in analytics are:\n- Forecasting: Taking in historical data and creating a reasonable forecast of what you can expect to see in the future.\n- Predictive analytics: Predicting trends and future results based on historical data.\n- Business monitoring: Real-time analytics on all key data points, from revenue to cost to customer experience.\nBusiness and AI\nWhile that list of examples may seem extensive, it’s certainly not all-encompassing. ']","Common uses of AI in everyday life include digital assistants like Siri and Alexa, search engines that refine results, and applications in home electronics such as robot vacuum cleaners. In terms of fraud prevention, major banks utilize AI in their fraud detection systems by analyzing thousands of transactions to recognize normal patterns and flag suspicious activity, which helps in auto-declining anything deemed suspicious and notifying individuals for verification.",multi_hop_specific_query_synthesizer
What is the IWA ID for creating a spreadsheet based on user messages that involve spreadsheet creation and data analysis?,"['<1-hop>\n\nTask details Your response should be an output with the following fields: iwa_id (str): The ID of the IWA. All of the following fields will be based on this IWA.,→ iwa_explanation (str): Explain in one English sentence why you decided these messages were *most appropriately* categorized for this IWA.,→ You *must* output one of the 332 IWAs and Descriptions. Do not make up new IWAs or descriptions. The only exception is if the messages are unclear or ambiguous, in which case you can output -1 for the IWA ID and ""Unclear"" for the description. ,→ ,→ ,→ Return exactly two lines and nothing else: iwa_id: <IWA ID> iwa_explanation: <one concise sentence> # Examples Below are a series of examples of user messages, and your intended output: Example 1: User Message: What\'s the difference between Python and Javascript? Which is a better language for a beginner?,→ Expected output: 49 iwa_id: 4.A.2.a.1.I07 iwa_explanation: The user is interested in about comparing the characteristics of different technologies (programming languages).,→ Example 2: User Message: hi. how\'s it going? what\'s the weather Expected output: iwa_id: -1 iwa_explanation: The user is not trying to accomplish any of the IWAs. Example 3: User Message: Fix this bug: Traceback (most recent call last): File """"/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py"""", line 1963, in _execute_context,→ self.dialect.do_execute(cursor, statement, parameters) psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint """"users_email_key"""",→ DETAIL: Key (email)=(foo@example.com) already exists. Expected output: iwa_id: 4.A.3.b.1.I01 iwa_explanation: The user is asking the chatbot to fix a bug in their code. Example 4: User Message: french revolution causes Expected output: iwa_id: 4.A.1.a.1.I18 iwa_explanation: The user appears to be asking for information on a historical political movement.,→ Example 5: User Message: do a discounted cash flow analysis on this company we\'re looking to acquire,→ Expected output: iwa_id: 4.A.1.b.3.I03 iwa_explanation: The user is looking for assistance in performing a discounted cash flow analysis for the purposes of a company acquisition.,→ 50 # Full list of all 332 IWA IDs and Descriptions: 4.A.1.a.1.I01 Study details of artistic productions. 4.A.1.a.1.I02 Read documents or materials to inform work processes. 4.A.1.a.1.I03 Investigate criminal or legal matters. ... 4.A.4.c.3.I05 Purchase goods or services. 4.A.4.c.3.I06 Prescribe medical treatments or devices. 4.A.4.c.3.I07 Monitor resources or inventories. # Hints - Provide your answers in **English** using the given structured output format. 51 B Appendix: Classifier Validation To assess the performance of our classifiers, we compare LLM-generated labels to human labels on a publicly available corpus of chatbot conversations (WildChat; Zhao et al., 2024). Annotations were carried out by several in-house annotators 31. Table 5 reports agreement rates both among humans and between the model and human annota- tions across all tasks. Task nlabels Fleiss’κ (human only) Fleiss’κ (with model) Cohen’sκ (human vs. human) Cohen’sκ (model vs. plurality) Work Related (binary) 149 0.66 [0.54, 0.76] 0.68 [0.59, 0.77] 0.66 0.83 [0.72, 0.92] Asking / Doing / Expressing (3-class) 149 0.60 [0.51, 0.68] 0.63 [0.56, 0.70] 0.60 0.74 [0.64, 0.83] Conversation Topic (coarse) 149 0.46 [0.38, 0.53] 0.48 [0.41, 0.54] 0.47 0.56 [0.46, 0.65] IWA Classification 100 0.34 [0.23, 0.45] 0.47 [0.40, 0.53] 0.37 — GWA Classification 100 0.33 [0.22, 0.44] 0.47 [0.40, 0.54] 0.36 — Interaction Quality (3-class incl. unknown) 149 0.13 [0.04, 0.22] 0.10 [0.04, 0.17] 0.20 0.14 [0.01, 0.27] Table 5:Validation topline results. ”—” indicates classifiers where only two human annotators participated and a plurality measure was not possible. For each task we report: (i) Fleiss’κacross human annotators; (ii) Fleiss’κwhen treating the model as an additional annotator;', '<2-hop>\n\n- ""Create a spreadsheet for mortgage payments.""- ""Find me a podcast about ancient history.""- ""Busca un video que explique la teor´ ıa de la relatividad.""** data_analysis**:\n- ""Heres a spreadsheet with my expenses; tell me how much I spent on which\ncategories."",→\n- ""Whats the mean, median, and mode of this dataset?""\n- ""Create a CSV with the top 10 most populated countries and their populations over\ntime. Give me the mean annual growth rate for each country."",→\n- ""Perform a regression analysis on this data.""- ""Analyse these survey results and summarize the key findings.""** unclear**:\n- ""[If there is no indication of what the user wants; usually this would be a very\nshort prompt.]"",→\n** other**:\n- ""[If there is a capability requested but none of the above apply; should be\npretty rare.]"",→\n-----\nOkay, now your turn, taking the user conversation at the top into account: What\ncapability are they seeking? (JUST SAY A SINGLE CATEGORY FROM THE LIST, NOTHING\nELSE).\n,→\n,→\nIf the conversation has multiple distinct capabilities, choose the one that is the\nmost relevant to the LAST message in the conversation.,→\n48\x0cA.4 O*NET IWA classification\nNote we only include a few of the full list of 332 IWA IDs for conciseness.\n#  Task overview\nYou will be given a series of messages sent by a user to a chatbot. There may be a\nsingle message, or multiple messages. It\'s also possible the message may be\ntruncated. Your goal is to classify the user\'s intent relative to a list of\nCandidate Intermediate Work Activity (IWA) statements from O*NET.\n,→\n,→\n,→\nYour primary task is to determine the most applicable IWA that corresponds to the\nuser messages, according to the meaning of the IWA in the context of O*NET\ntaxonomy. The conversation must provide direct evidence that the user is\nthemself trying to accomplish the IWA. It is possible that a user\'s messages\nmay be unrelated to any IWAs or contextually ambiguous. In those cases, you can\nreturn an unknown option which will be described later on.\n,→\n,→\n,→\n,→\n,→\n#  classes (IWA has 332 activities) as well as inherent ambiguity in the messages. For instance, if a user in the WildChat dataset was trying to generate a fictional short story, one human label might beDevelop news, entertainment, or artistic content, while another human label could beWrite material for artistic or commercial purposes. These two IWAs also belong to different GWAs despite being conceptually similar. B.1.5 Interaction Quality Classifier Human and model annotations of interaction quality are noisy. The classifier attains only slight agree- ment with the human plurality (Cohen’sκ= 0.14), below the likewise modest mean human–human agreement (κ= 0.20; Table 5). Figures 30 and 31 show weak concordance overall and a mild tendency for the model to assignBadless frequently than humans. This contrasts with our small development set, in which GPT-5 labeledBadmore often than humans. We retain this classifier because theseκ statistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text alone. While this latent “prior” is unobserved in our validation data, it is partially observable when users provide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned 56 Figure 30:Agreement Between Model and Plurality for Interaction Quality Figure 31:Bias Between Model and Plurality for Interaction Quality 57 with user experience, we link model predictions to voluntary feedback on assistant messages. We draw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i) the assistant message received explicit feedback and (ii) the user sent a subsequent message that our classifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not be fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy user satisfaction.']","The IWA ID for creating a spreadsheet based on user messages that involve spreadsheet creation and data analysis is 4.A.4.c.3.I07, which corresponds to monitoring resources or inventories.",multi_hop_abstract_query_synthesizer
How does the variation in ChatGPT usage by education level relate to the observed gender parity in user names by mid-2025?,"['<1-hop>\n\nHowever, in the first half of 2025, we see the share of active users with typically feminine and typically\nmasculine names reach near-parity. By June 2025 we observe active users are more likely to have\ntypically feminine names. This suggests that gender gaps in ChatGPT usage have closed substantially\nover time.\nWe also study differences in usage topics. Users with typically female first names are relatively more\nlikely to send messages related toWritingandPractical Guidance. By contrast, users with typically\nmale first names are more likely to use ChatGPT forTechnical Help,Seeking Out Information, and\nMultimedia(e.g., modifying or creating images).\n 6.2 Variation by Age\nA subset of users self-report their age when registering for OpenAI. Among those who self-report their\nage, around 46% of the messages in our dataset are accounted for by users 18-25.\nA higher share of messages are work-related for older users. Work-related messages comprised\napproximately 23% of messages for users under age 26, with this share increasing with age. The\none exception is users who self-attest to being 66 years-old or older, with only 16% of their classified\nmessages being work-related. The plot below shows trends in the share of work-related messages by\nage group. ChatGPT usage has become less work-related over time for users of all ages.\n25\x0cFigure 18:Breakdown of weekly active users by typically masculine and typically feminine first names. We\ndraw on a uniform sample of 1.1M ChatGPT accounts, subject to the same user exclusion principles as other\ndatasets we analyze. Note that this is a separate sample than those described in Section 3. First names\nare classified as typically masculine or typically feminine using public aggregated datasets of name-gender\nassociations.\nFigure 19:Difference in share of topic prevalence in messages by users with typically masculine/feminine\nfirst name. We draw on a uniform sample of 1.1M ChatGPT accounts, subject to the same user exclusion\nprinciples as other datasets we analyze. Note that this is a separate sample than those described in Section\n3. First names are classified as typically masculine or typically feminine using public aggregated datasets\nof name-gender associations. Topics are aggregated groupings from a classifier whose prompt we provide in\nAppendix A.\n26\x0cFigure 20:Likelihood that a message is work related, conditioned on self-reported user age. Messages are\nidentified as work related using an automated classifier. As with our other samples (see Section 3), users who\nself-report an age under 18 are excluded from analysis. Values are averaged over a 28 day lagging window.\nShares are calculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024\nthrough June 26, 2025. Observations are reweighted to reflect total message volumes on a given day.\n', '<2-hop>\n\n6.3 Variation by Country\nWe study global patterns of ChatGPT usage by measuring the proportion of weekly consumer Chat-\nGPT users among the internet enabled population of countries with populations larger than 1 million.\nWe also exclude countries in which ChatGPT is blocked. The figure below plots this proportion in\nMay 2024 and May 2025 by GDP-per-capita deciles: countries are ranked by GDP-per-capita and split\ninto ten deciles, and the x-axis shows each decile’s median GDP-per-capita (in thousands of U.S. dol-\nlars).24 The solid line shows the median share within each decile; the shaded band is the interquartile\nrange (25th–75th percentile) of country values within that decile. Comparing May 2024 to May 2025,\nwe see that the adoption of ChatGPT grew dramatically, but also that there was disproportionate\ngrowth in low to middle-income countries ($10,000–40,000 GDP-per-capita). Overall, we find that\nmany low-to-middle income countries have experienced high growth in ChatGPT adoption.\n 6.4 Variation by Education\nWe next analyze results from matching with publicly available datasets.\nFigure 22 presents variation in ChatGPT usage by user education. Panel A shows the share of\nmessages that are work-related, for users with less than a bachelor’s degree, exactly a bachelor’s\ndegree, and some graduate education respectively.25 The left-hand side of figure 22 shows unadjusted\ncomparisons, while the right-hand side presents the coefficient on education from a regression of\n24GDP and population data are from the World Bank 2023 estimates.\n25For non-US users, we consider tertiary education to be the equivalent of a bachelor’s degree.\n27\x0cFigure 21:ChatGPT Weekly Active Users as Share of Internet Population vs GDP decile, May 2024 vs May\n2025. Point estimates are medians within each decile. Internet Using Population uses 2023 estimates from the\nWorld Bank. Shaded regions indicate the interquartile range (25th–75th percentile) of country values within\neach GDP decile.\nmessage shares on age, whether the name was typically masculine or feminine, education, occupation\ncategories, job seniority, firm size, and industry. We also include 95% confidence intervals for the\nregression-adjusted results.\nEducated users are much more likely to use ChatGPT for work. 37% of messages are work-related\nfor users with less than a bachelor’s degree, compared to 46% for users with exactly a bachelor’s\ndegree and 48% for those with some graduate education. Those differences are cut roughly in half\nafter adjusting for other characteristics, but they are still statistically significant at the less than 1\npercent level. Educated users are more likely to send work-related messages.\nPanel B explores variation by education in user intent.Askingconstitutes about 49% of messages\nfor users with less than a bachelor’s degree, with little variation for more educated users. After\nregression adjustment, we find that users with a graduate degree are about two percentage points\nmore likely to use ChatGPT forAskingmessages, a difference that is statistically significant at the\n5% level. ']","By mid-2025, the share of active users with typically feminine and typically masculine names reached near-parity, indicating a significant closing of gender gaps in ChatGPT usage. In terms of education, users with less than a bachelor’s degree sent 37% of their messages as work-related, while those with exactly a bachelor’s degree and some graduate education sent 46% and 48% respectively. This suggests that as gender parity in user names improves, the educational background of users also influences their engagement with ChatGPT, with more educated users being more likely to send work-related messages.",multi_hop_abstract_query_synthesizer
What is the IWA ID for a user seeking assistance with data analysis based on their conversation about creating spreadsheets and analyzing datasets?,"['<1-hop>\n\nTask details Your response should be an output with the following fields: iwa_id (str): The ID of the IWA. All of the following fields will be based on this IWA.,→ iwa_explanation (str): Explain in one English sentence why you decided these messages were *most appropriately* categorized for this IWA.,→ You *must* output one of the 332 IWAs and Descriptions. Do not make up new IWAs or descriptions. The only exception is if the messages are unclear or ambiguous, in which case you can output -1 for the IWA ID and ""Unclear"" for the description. ,→ ,→ ,→ Return exactly two lines and nothing else: iwa_id: <IWA ID> iwa_explanation: <one concise sentence> # Examples Below are a series of examples of user messages, and your intended output: Example 1: User Message: What\'s the difference between Python and Javascript? Which is a better language for a beginner?,→ Expected output: 49 iwa_id: 4.A.2.a.1.I07 iwa_explanation: The user is interested in about comparing the characteristics of different technologies (programming languages).,→ Example 2: User Message: hi. how\'s it going? what\'s the weather Expected output: iwa_id: -1 iwa_explanation: The user is not trying to accomplish any of the IWAs. Example 3: User Message: Fix this bug: Traceback (most recent call last): File """"/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py"""", line 1963, in _execute_context,→ self.dialect.do_execute(cursor, statement, parameters) psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint """"users_email_key"""",→ DETAIL: Key (email)=(foo@example.com) already exists. Expected output: iwa_id: 4.A.3.b.1.I01 iwa_explanation: The user is asking the chatbot to fix a bug in their code. Example 4: User Message: french revolution causes Expected output: iwa_id: 4.A.1.a.1.I18 iwa_explanation: The user appears to be asking for information on a historical political movement.,→ Example 5: User Message: do a discounted cash flow analysis on this company we\'re looking to acquire,→ Expected output: iwa_id: 4.A.1.b.3.I03 iwa_explanation: The user is looking for assistance in performing a discounted cash flow analysis for the purposes of a company acquisition.,→ 50 # Full list of all 332 IWA IDs and Descriptions: 4.A.1.a.1.I01 Study details of artistic productions. 4.A.1.a.1.I02 Read documents or materials to inform work processes. 4.A.1.a.1.I03 Investigate criminal or legal matters. ... 4.A.4.c.3.I05 Purchase goods or services. 4.A.4.c.3.I06 Prescribe medical treatments or devices. 4.A.4.c.3.I07 Monitor resources or inventories. # Hints - Provide your answers in **English** using the given structured output format. 51 B Appendix: Classifier Validation To assess the performance of our classifiers, we compare LLM-generated labels to human labels on a publicly available corpus of chatbot conversations (WildChat; Zhao et al., 2024). Annotations were carried out by several in-house annotators 31. Table 5 reports agreement rates both among humans and between the model and human annota- tions across all tasks. Task nlabels Fleiss’κ (human only) Fleiss’κ (with model) Cohen’sκ (human vs. human) Cohen’sκ (model vs. plurality) Work Related (binary) 149 0.66 [0.54, 0.76] 0.68 [0.59, 0.77] 0.66 0.83 [0.72, 0.92] Asking / Doing / Expressing (3-class) 149 0.60 [0.51, 0.68] 0.63 [0.56, 0.70] 0.60 0.74 [0.64, 0.83] Conversation Topic (coarse) 149 0.46 [0.38, 0.53] 0.48 [0.41, 0.54] 0.47 0.56 [0.46, 0.65] IWA Classification 100 0.34 [0.23, 0.45] 0.47 [0.40, 0.53] 0.37 — GWA Classification 100 0.33 [0.22, 0.44] 0.47 [0.40, 0.54] 0.36 — Interaction Quality (3-class incl. unknown) 149 0.13 [0.04, 0.22] 0.10 [0.04, 0.17] 0.20 0.14 [0.01, 0.27] Table 5:Validation topline results. ”—” indicates classifiers where only two human annotators participated and a plurality measure was not possible. For each task we report: (i) Fleiss’κacross human annotators; (ii) Fleiss’κwhen treating the model as an additional annotator;', '<2-hop>\n\n- ""Create a spreadsheet for mortgage payments.""- ""Find me a podcast about ancient history.""- ""Busca un video que explique la teor´ ıa de la relatividad.""** data_analysis**:\n- ""Heres a spreadsheet with my expenses; tell me how much I spent on which\ncategories."",→\n- ""Whats the mean, median, and mode of this dataset?""\n- ""Create a CSV with the top 10 most populated countries and their populations over\ntime. Give me the mean annual growth rate for each country."",→\n- ""Perform a regression analysis on this data.""- ""Analyse these survey results and summarize the key findings.""** unclear**:\n- ""[If there is no indication of what the user wants; usually this would be a very\nshort prompt.]"",→\n** other**:\n- ""[If there is a capability requested but none of the above apply; should be\npretty rare.]"",→\n-----\nOkay, now your turn, taking the user conversation at the top into account: What\ncapability are they seeking? (JUST SAY A SINGLE CATEGORY FROM THE LIST, NOTHING\nELSE).\n,→\n,→\nIf the conversation has multiple distinct capabilities, choose the one that is the\nmost relevant to the LAST message in the conversation.,→\n48\x0cA.4 O*NET IWA classification\nNote we only include a few of the full list of 332 IWA IDs for conciseness.\n#  Task overview\nYou will be given a series of messages sent by a user to a chatbot. There may be a\nsingle message, or multiple messages. It\'s also possible the message may be\ntruncated. Your goal is to classify the user\'s intent relative to a list of\nCandidate Intermediate Work Activity (IWA) statements from O*NET.\n,→\n,→\n,→\nYour primary task is to determine the most applicable IWA that corresponds to the\nuser messages, according to the meaning of the IWA in the context of O*NET\ntaxonomy. The conversation must provide direct evidence that the user is\nthemself trying to accomplish the IWA. It is possible that a user\'s messages\nmay be unrelated to any IWAs or contextually ambiguous. In those cases, you can\nreturn an unknown option which will be described later on.\n,→\n,→\n,→\n,→\n,→\n#  classes (IWA has 332 activities) as well as inherent ambiguity in the messages. For instance, if a user in the WildChat dataset was trying to generate a fictional short story, one human label might beDevelop news, entertainment, or artistic content, while another human label could beWrite material for artistic or commercial purposes. These two IWAs also belong to different GWAs despite being conceptually similar. B.1.5 Interaction Quality Classifier Human and model annotations of interaction quality are noisy. The classifier attains only slight agree- ment with the human plurality (Cohen’sκ= 0.14), below the likewise modest mean human–human agreement (κ= 0.20; Table 5). Figures 30 and 31 show weak concordance overall and a mild tendency for the model to assignBadless frequently than humans. This contrasts with our small development set, in which GPT-5 labeledBadmore often than humans. We retain this classifier because theseκ statistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text alone. While this latent “prior” is unobserved in our validation data, it is partially observable when users provide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned 56 Figure 30:Agreement Between Model and Plurality for Interaction Quality Figure 31:Bias Between Model and Plurality for Interaction Quality 57 with user experience, we link model predictions to voluntary feedback on assistant messages. We draw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i) the assistant message received explicit feedback and (ii) the user sent a subsequent message that our classifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not be fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy user satisfaction.', '<3-hop>\n\nA.3 Conversation Topic ----- You are an internal tool that classifies a message from a user to an AI chatbot, based on the context of the previous messages before it.,→ Based on the last user message of this conversation transcript and taking into account the examples further below as guidance, please select the capability the user is clearly interested in, or `other` if it is clear but not in the list below, or `unclear` if it is hard to tell what the user even wants: ,→ ,→ ,→ - **edit_or_critique_provided_text**: Improving or modifying text provided by the user.,→ - **argument_or_summary_generation**: Creating arguments or summaries on topics not provided in detail by the user.,→ - **personal_writing_or_communication**: Assisting with personal messages, emails, or social media posts.,→ - **write_fiction**: Crafting poems, stories, or fictional content. - **how_to_advice**: Providing step-by-step instructions or guidance on how to perform tasks or learn new skills.,→ - **creative_ideation**: Generating ideas or suggestions for creative projects or activities.,→ - **tutoring_or_teaching**: Explaining concepts, teaching subjects, or helping the user understand educational material.,→ - **translation**: Translating text from one language to another. - **mathematical_calculation**: Solving math problems, performing calculations, or working with numerical data.,→ - **computer_programming**: Writing code, debugging, explaining programming concepts, or discussing programming languages and tools.,→ - **purchasable_products**: Inquiries about products or services available for purchase.,→ 42 - **cooking_and_recipes**: Seeking recipes, cooking instructions, or culinary advice.,→ - **health_fitness_beauty_or_self_care**: Seeking advice or information on physical health, fitness routines, beauty tips, or self-care practices.,→ - **specific_info**: Providing specific information typically found on websites, including information about well-known individuals, current events, historical events, and other facts and knowledge. ,→ ,→ - **greetings_and_chitchat**: Casual conversation, small talk, or friendly interactions without a specific informational goal.,→ - **relationships_and_personal_reflection**: Discussing personal reflections or seeking advice on relationships and feelings.,→ - **games_and_role_play**: Engaging in interactive games, simulations, or imaginative role-playing scenarios.,→ - **asking_about_the_model**: Questions about the AI models capabilities or characteristics.,→ - **create_an_image**: Requests to generate or draw new visual content based on the user’s description.,→ - **analyze_an_image**: Interpreting or describing visual content provided by the user, such as photos, charts, graphs, or illustrations.,→ - **generate_or_retrieve_other_media**: Creating or finding media other than text or images, such as audio, video, or multimedia files.,→ - **data_analysis**: Performing statistical analysis, interpreting datasets, or extracting insights from data.,→ - **unclear**: If the user’s intent is not clear from the conversation. - **other**: If the capability requested doesn’t fit any of the above categories. Only reply with one of the capabilities above, without quotes and as presented (all lower case with underscores and spaces as shown).,→ 43 If the conversation has multiple distinct capabilities, choose the one that is the most relevant to the **LAST message** in the conversation.,→ Examples: **edit_or_critique_provided_text**: - ""Help me improve my essay, including improving flow and correcting grammar errors."",→ - ""Please shorten this paragraph.""- ""Can you proofread my article for grammatical mistakes?"" - ""Here’s my draft speech; can you suggest enhancements?"" - ""Stp aide moi ` a corriger ma dissertation.""**argument_or_summary_generation**: - ""Make an argument for why the national debt is important.""- ""Write a three-paragraph essay about Abraham Lincoln.""- ""Summarize the Book of Matthew.""- ""Provide a summary of the theory of relativity.""- ""R´ ediger un essai sur la politique au Moyen-Orient.""**personal_writing_or_communication**: - ""Write a nice birthday card note for my girlfriend.""- ""What should my speech say to Karl at his retirement party?"" - ""Help me write a cover letter for a job application.""- ""Compose an apology email to my boss.""- ""Aide moi ` a ´ ecrire une lettre ` a mon p` ere.""**write_fiction**: - ""Write a poem about the sunset.""- ""Create a short story']","The IWA ID for a user seeking assistance with data analysis is 4.A.1.b.3.I03, as they are looking for help in performing statistical analysis and interpreting datasets.",multi_hop_abstract_query_synthesizer
"What trends can be observed regarding gender parity in user names and the variation in ChatGPT usage by education level, particularly in relation to work-related messages?","['<1-hop>\n\nHowever, in the first half of 2025, we see the share of active users with typically feminine and typically\nmasculine names reach near-parity. By June 2025 we observe active users are more likely to have\ntypically feminine names. This suggests that gender gaps in ChatGPT usage have closed substantially\nover time.\nWe also study differences in usage topics. Users with typically female first names are relatively more\nlikely to send messages related toWritingandPractical Guidance. By contrast, users with typically\nmale first names are more likely to use ChatGPT forTechnical Help,Seeking Out Information, and\nMultimedia(e.g., modifying or creating images).\n 6.2 Variation by Age\nA subset of users self-report their age when registering for OpenAI. Among those who self-report their\nage, around 46% of the messages in our dataset are accounted for by users 18-25.\nA higher share of messages are work-related for older users. Work-related messages comprised\napproximately 23% of messages for users under age 26, with this share increasing with age. The\none exception is users who self-attest to being 66 years-old or older, with only 16% of their classified\nmessages being work-related. The plot below shows trends in the share of work-related messages by\nage group. ChatGPT usage has become less work-related over time for users of all ages.\n25\x0cFigure 18:Breakdown of weekly active users by typically masculine and typically feminine first names. We\ndraw on a uniform sample of 1.1M ChatGPT accounts, subject to the same user exclusion principles as other\ndatasets we analyze. Note that this is a separate sample than those described in Section 3. First names\nare classified as typically masculine or typically feminine using public aggregated datasets of name-gender\nassociations.\nFigure 19:Difference in share of topic prevalence in messages by users with typically masculine/feminine\nfirst name. We draw on a uniform sample of 1.1M ChatGPT accounts, subject to the same user exclusion\nprinciples as other datasets we analyze. Note that this is a separate sample than those described in Section\n3. First names are classified as typically masculine or typically feminine using public aggregated datasets\nof name-gender associations. Topics are aggregated groupings from a classifier whose prompt we provide in\nAppendix A.\n26\x0cFigure 20:Likelihood that a message is work related, conditioned on self-reported user age. Messages are\nidentified as work related using an automated classifier. As with our other samples (see Section 3), users who\nself-report an age under 18 are excluded from analysis. Values are averaged over a 28 day lagging window.\nShares are calculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024\nthrough June 26, 2025. Observations are reweighted to reflect total message volumes on a given day.\n', '<2-hop>\n\n6.3 Variation by Country\nWe study global patterns of ChatGPT usage by measuring the proportion of weekly consumer Chat-\nGPT users among the internet enabled population of countries with populations larger than 1 million.\nWe also exclude countries in which ChatGPT is blocked. The figure below plots this proportion in\nMay 2024 and May 2025 by GDP-per-capita deciles: countries are ranked by GDP-per-capita and split\ninto ten deciles, and the x-axis shows each decile’s median GDP-per-capita (in thousands of U.S. dol-\nlars).24 The solid line shows the median share within each decile; the shaded band is the interquartile\nrange (25th–75th percentile) of country values within that decile. Comparing May 2024 to May 2025,\nwe see that the adoption of ChatGPT grew dramatically, but also that there was disproportionate\ngrowth in low to middle-income countries ($10,000–40,000 GDP-per-capita). Overall, we find that\nmany low-to-middle income countries have experienced high growth in ChatGPT adoption.\n 6.4 Variation by Education\nWe next analyze results from matching with publicly available datasets.\nFigure 22 presents variation in ChatGPT usage by user education. Panel A shows the share of\nmessages that are work-related, for users with less than a bachelor’s degree, exactly a bachelor’s\ndegree, and some graduate education respectively.25 The left-hand side of figure 22 shows unadjusted\ncomparisons, while the right-hand side presents the coefficient on education from a regression of\n24GDP and population data are from the World Bank 2023 estimates.\n25For non-US users, we consider tertiary education to be the equivalent of a bachelor’s degree.\n27\x0cFigure 21:ChatGPT Weekly Active Users as Share of Internet Population vs GDP decile, May 2024 vs May\n2025. Point estimates are medians within each decile. Internet Using Population uses 2023 estimates from the\nWorld Bank. Shaded regions indicate the interquartile range (25th–75th percentile) of country values within\neach GDP decile.\nmessage shares on age, whether the name was typically masculine or feminine, education, occupation\ncategories, job seniority, firm size, and industry. We also include 95% confidence intervals for the\nregression-adjusted results.\nEducated users are much more likely to use ChatGPT for work. 37% of messages are work-related\nfor users with less than a bachelor’s degree, compared to 46% for users with exactly a bachelor’s\ndegree and 48% for those with some graduate education. Those differences are cut roughly in half\nafter adjusting for other characteristics, but they are still statistically significant at the less than 1\npercent level. Educated users are more likely to send work-related messages.\nPanel B explores variation by education in user intent.Askingconstitutes about 49% of messages\nfor users with less than a bachelor’s degree, with little variation for more educated users. After\nregression adjustment, we find that users with a graduate degree are about two percentage points\nmore likely to use ChatGPT forAskingmessages, a difference that is statistically significant at the\n5% level. ']","In the first half of 2025, the share of active users with typically feminine and typically masculine names reached near-parity, with a notable increase in users with typically feminine names by June 2025. This indicates a significant closing of gender gaps in ChatGPT usage over time. Additionally, the analysis of ChatGPT usage by education reveals that educated users are more likely to engage in work-related messaging. Specifically, 37% of messages from users with less than a bachelor’s degree are work-related, compared to 46% for those with exactly a bachelor’s degree and 48% for users with some graduate education. This suggests that as gender parity in user names improves, there is also a corresponding increase in the likelihood of work-related engagement among more educated users.",multi_hop_abstract_query_synthesizer
How does the variation in ChatGPT usage by education levels relate to the gender parity in user names observed in 2025?,"['<1-hop>\n\nHowever, in the first half of 2025, we see the share of active users with typically feminine and typically\nmasculine names reach near-parity. By June 2025 we observe active users are more likely to have\ntypically feminine names. This suggests that gender gaps in ChatGPT usage have closed substantially\nover time.\nWe also study differences in usage topics. Users with typically female first names are relatively more\nlikely to send messages related toWritingandPractical Guidance. By contrast, users with typically\nmale first names are more likely to use ChatGPT forTechnical Help,Seeking Out Information, and\nMultimedia(e.g., modifying or creating images).\n 6.2 Variation by Age\nA subset of users self-report their age when registering for OpenAI. Among those who self-report their\nage, around 46% of the messages in our dataset are accounted for by users 18-25.\nA higher share of messages are work-related for older users. Work-related messages comprised\napproximately 23% of messages for users under age 26, with this share increasing with age. The\none exception is users who self-attest to being 66 years-old or older, with only 16% of their classified\nmessages being work-related. The plot below shows trends in the share of work-related messages by\nage group. ChatGPT usage has become less work-related over time for users of all ages.\n25\x0cFigure 18:Breakdown of weekly active users by typically masculine and typically feminine first names. We\ndraw on a uniform sample of 1.1M ChatGPT accounts, subject to the same user exclusion principles as other\ndatasets we analyze. Note that this is a separate sample than those described in Section 3. First names\nare classified as typically masculine or typically feminine using public aggregated datasets of name-gender\nassociations.\nFigure 19:Difference in share of topic prevalence in messages by users with typically masculine/feminine\nfirst name. We draw on a uniform sample of 1.1M ChatGPT accounts, subject to the same user exclusion\nprinciples as other datasets we analyze. Note that this is a separate sample than those described in Section\n3. First names are classified as typically masculine or typically feminine using public aggregated datasets\nof name-gender associations. Topics are aggregated groupings from a classifier whose prompt we provide in\nAppendix A.\n26\x0cFigure 20:Likelihood that a message is work related, conditioned on self-reported user age. Messages are\nidentified as work related using an automated classifier. As with our other samples (see Section 3), users who\nself-report an age under 18 are excluded from analysis. Values are averaged over a 28 day lagging window.\nShares are calculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024\nthrough June 26, 2025. Observations are reweighted to reflect total message volumes on a given day.\n', '<2-hop>\n\n6.3 Variation by Country\nWe study global patterns of ChatGPT usage by measuring the proportion of weekly consumer Chat-\nGPT users among the internet enabled population of countries with populations larger than 1 million.\nWe also exclude countries in which ChatGPT is blocked. The figure below plots this proportion in\nMay 2024 and May 2025 by GDP-per-capita deciles: countries are ranked by GDP-per-capita and split\ninto ten deciles, and the x-axis shows each decile’s median GDP-per-capita (in thousands of U.S. dol-\nlars).24 The solid line shows the median share within each decile; the shaded band is the interquartile\nrange (25th–75th percentile) of country values within that decile. Comparing May 2024 to May 2025,\nwe see that the adoption of ChatGPT grew dramatically, but also that there was disproportionate\ngrowth in low to middle-income countries ($10,000–40,000 GDP-per-capita). Overall, we find that\nmany low-to-middle income countries have experienced high growth in ChatGPT adoption.\n 6.4 Variation by Education\nWe next analyze results from matching with publicly available datasets.\nFigure 22 presents variation in ChatGPT usage by user education. Panel A shows the share of\nmessages that are work-related, for users with less than a bachelor’s degree, exactly a bachelor’s\ndegree, and some graduate education respectively.25 The left-hand side of figure 22 shows unadjusted\ncomparisons, while the right-hand side presents the coefficient on education from a regression of\n24GDP and population data are from the World Bank 2023 estimates.\n25For non-US users, we consider tertiary education to be the equivalent of a bachelor’s degree.\n27\x0cFigure 21:ChatGPT Weekly Active Users as Share of Internet Population vs GDP decile, May 2024 vs May\n2025. Point estimates are medians within each decile. Internet Using Population uses 2023 estimates from the\nWorld Bank. Shaded regions indicate the interquartile range (25th–75th percentile) of country values within\neach GDP decile.\nmessage shares on age, whether the name was typically masculine or feminine, education, occupation\ncategories, job seniority, firm size, and industry. We also include 95% confidence intervals for the\nregression-adjusted results.\nEducated users are much more likely to use ChatGPT for work. 37% of messages are work-related\nfor users with less than a bachelor’s degree, compared to 46% for users with exactly a bachelor’s\ndegree and 48% for those with some graduate education. Those differences are cut roughly in half\nafter adjusting for other characteristics, but they are still statistically significant at the less than 1\npercent level. Educated users are more likely to send work-related messages.\nPanel B explores variation by education in user intent.Askingconstitutes about 49% of messages\nfor users with less than a bachelor’s degree, with little variation for more educated users. After\nregression adjustment, we find that users with a graduate degree are about two percentage points\nmore likely to use ChatGPT forAskingmessages, a difference that is statistically significant at the\n5% level. ']","In 2025, the share of active users with typically feminine and typically masculine names reached near-parity, indicating that gender gaps in ChatGPT usage have closed significantly. Additionally, the analysis of ChatGPT usage by education shows that educated users are more likely to send work-related messages, with 48% of messages from users with some graduate education being work-related. This suggests that as gender parity improves, the educational background of users also influences how they utilize ChatGPT, with educated users engaging more in work-related topics regardless of gender.",multi_hop_abstract_query_synthesizer
What is the IWA ID for data analysis tasks like creating a spreadsheet for expenses or performing regression analysis?,"['<1-hop>\n\nTask details Your response should be an output with the following fields: iwa_id (str): The ID of the IWA. All of the following fields will be based on this IWA.,→ iwa_explanation (str): Explain in one English sentence why you decided these messages were *most appropriately* categorized for this IWA.,→ You *must* output one of the 332 IWAs and Descriptions. Do not make up new IWAs or descriptions. The only exception is if the messages are unclear or ambiguous, in which case you can output -1 for the IWA ID and ""Unclear"" for the description. ,→ ,→ ,→ Return exactly two lines and nothing else: iwa_id: <IWA ID> iwa_explanation: <one concise sentence> # Examples Below are a series of examples of user messages, and your intended output: Example 1: User Message: What\'s the difference between Python and Javascript? Which is a better language for a beginner?,→ Expected output: 49 iwa_id: 4.A.2.a.1.I07 iwa_explanation: The user is interested in about comparing the characteristics of different technologies (programming languages).,→ Example 2: User Message: hi. how\'s it going? what\'s the weather Expected output: iwa_id: -1 iwa_explanation: The user is not trying to accomplish any of the IWAs. Example 3: User Message: Fix this bug: Traceback (most recent call last): File """"/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py"""", line 1963, in _execute_context,→ self.dialect.do_execute(cursor, statement, parameters) psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint """"users_email_key"""",→ DETAIL: Key (email)=(foo@example.com) already exists. Expected output: iwa_id: 4.A.3.b.1.I01 iwa_explanation: The user is asking the chatbot to fix a bug in their code. Example 4: User Message: french revolution causes Expected output: iwa_id: 4.A.1.a.1.I18 iwa_explanation: The user appears to be asking for information on a historical political movement.,→ Example 5: User Message: do a discounted cash flow analysis on this company we\'re looking to acquire,→ Expected output: iwa_id: 4.A.1.b.3.I03 iwa_explanation: The user is looking for assistance in performing a discounted cash flow analysis for the purposes of a company acquisition.,→ 50 # Full list of all 332 IWA IDs and Descriptions: 4.A.1.a.1.I01 Study details of artistic productions. 4.A.1.a.1.I02 Read documents or materials to inform work processes. 4.A.1.a.1.I03 Investigate criminal or legal matters. ... 4.A.4.c.3.I05 Purchase goods or services. 4.A.4.c.3.I06 Prescribe medical treatments or devices. 4.A.4.c.3.I07 Monitor resources or inventories. # Hints - Provide your answers in **English** using the given structured output format. 51 B Appendix: Classifier Validation To assess the performance of our classifiers, we compare LLM-generated labels to human labels on a publicly available corpus of chatbot conversations (WildChat; Zhao et al., 2024). Annotations were carried out by several in-house annotators 31. Table 5 reports agreement rates both among humans and between the model and human annota- tions across all tasks. Task nlabels Fleiss’κ (human only) Fleiss’κ (with model) Cohen’sκ (human vs. human) Cohen’sκ (model vs. plurality) Work Related (binary) 149 0.66 [0.54, 0.76] 0.68 [0.59, 0.77] 0.66 0.83 [0.72, 0.92] Asking / Doing / Expressing (3-class) 149 0.60 [0.51, 0.68] 0.63 [0.56, 0.70] 0.60 0.74 [0.64, 0.83] Conversation Topic (coarse) 149 0.46 [0.38, 0.53] 0.48 [0.41, 0.54] 0.47 0.56 [0.46, 0.65] IWA Classification 100 0.34 [0.23, 0.45] 0.47 [0.40, 0.53] 0.37 — GWA Classification 100 0.33 [0.22, 0.44] 0.47 [0.40, 0.54] 0.36 — Interaction Quality (3-class incl. unknown) 149 0.13 [0.04, 0.22] 0.10 [0.04, 0.17] 0.20 0.14 [0.01, 0.27] Table 5:Validation topline results. ”—” indicates classifiers where only two human annotators participated and a plurality measure was not possible. For each task we report: (i) Fleiss’κacross human annotators; (ii) Fleiss’κwhen treating the model as an additional annotator;', '<2-hop>\n\n- ""Create a spreadsheet for mortgage payments.""- ""Find me a podcast about ancient history.""- ""Busca un video que explique la teor´ ıa de la relatividad.""** data_analysis**:\n- ""Heres a spreadsheet with my expenses; tell me how much I spent on which\ncategories."",→\n- ""Whats the mean, median, and mode of this dataset?""\n- ""Create a CSV with the top 10 most populated countries and their populations over\ntime. Give me the mean annual growth rate for each country."",→\n- ""Perform a regression analysis on this data.""- ""Analyse these survey results and summarize the key findings.""** unclear**:\n- ""[If there is no indication of what the user wants; usually this would be a very\nshort prompt.]"",→\n** other**:\n- ""[If there is a capability requested but none of the above apply; should be\npretty rare.]"",→\n-----\nOkay, now your turn, taking the user conversation at the top into account: What\ncapability are they seeking? (JUST SAY A SINGLE CATEGORY FROM THE LIST, NOTHING\nELSE).\n,→\n,→\nIf the conversation has multiple distinct capabilities, choose the one that is the\nmost relevant to the LAST message in the conversation.,→\n48\x0cA.4 O*NET IWA classification\nNote we only include a few of the full list of 332 IWA IDs for conciseness.\n#  Task overview\nYou will be given a series of messages sent by a user to a chatbot. There may be a\nsingle message, or multiple messages. It\'s also possible the message may be\ntruncated. Your goal is to classify the user\'s intent relative to a list of\nCandidate Intermediate Work Activity (IWA) statements from O*NET.\n,→\n,→\n,→\nYour primary task is to determine the most applicable IWA that corresponds to the\nuser messages, according to the meaning of the IWA in the context of O*NET\ntaxonomy. The conversation must provide direct evidence that the user is\nthemself trying to accomplish the IWA. It is possible that a user\'s messages\nmay be unrelated to any IWAs or contextually ambiguous. In those cases, you can\nreturn an unknown option which will be described later on.\n,→\n,→\n,→\n,→\n,→\n#  classes (IWA has 332 activities) as well as inherent ambiguity in the messages. For instance, if a user in the WildChat dataset was trying to generate a fictional short story, one human label might beDevelop news, entertainment, or artistic content, while another human label could beWrite material for artistic or commercial purposes. These two IWAs also belong to different GWAs despite being conceptually similar. B.1.5 Interaction Quality Classifier Human and model annotations of interaction quality are noisy. The classifier attains only slight agree- ment with the human plurality (Cohen’sκ= 0.14), below the likewise modest mean human–human agreement (κ= 0.20; Table 5). Figures 30 and 31 show weak concordance overall and a mild tendency for the model to assignBadless frequently than humans. This contrasts with our small development set, in which GPT-5 labeledBadmore often than humans. We retain this classifier because theseκ statistics primarily highlight the inherent difficulty of inferring the user’s latent satisfaction from text alone. While this latent “prior” is unobserved in our validation data, it is partially observable when users provide explicit thumbs-up/down feedback. To assess whether the classifier captures a signal aligned 56 Figure 30:Agreement Between Model and Plurality for Interaction Quality Figure 31:Bias Between Model and Plurality for Interaction Quality 57 with user experience, we link model predictions to voluntary feedback on assistant messages. We draw a 1-in-10,000 sample of conversations from June 2024 to June 2025 and retain cases where (i) the assistant message received explicit feedback and (ii) the user sent a subsequent message that our classifier can score, yielding roughly 60,000 eligible items. This is a restricted sample that may not be fully representative of all interactions, but it offers a unique lens on the classifier’s ability to proxy user satisfaction.']","The IWA ID for data analysis tasks such as creating a spreadsheet for expenses or performing regression analysis is 4.A.1.b.3.I03, as these tasks involve analyzing data to summarize key findings or perform calculations.",multi_hop_abstract_query_synthesizer
